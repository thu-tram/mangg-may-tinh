<!DOCTYPE HTML>
<html lang="vi" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Mạngg máy tính - Thư trạm</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Introduction</li><li class="chapter-item expanded "><a href="intro/intro.html"><strong aria-hidden="true">1.</strong> Giới thiệu về Internet</a></li><li class="chapter-item expanded "><a href="intro/layers.html"><strong aria-hidden="true">2.</strong> Các Layer của Internet</a></li><li class="chapter-item expanded "><a href="intro/headers.html"><strong aria-hidden="true">3.</strong> Headers</a></li><li class="chapter-item expanded "><a href="intro/architecture.html"><strong aria-hidden="true">4.</strong> Kiến trúc mạng</a></li><li class="chapter-item expanded "><a href="intro/sharing-resources.html"><strong aria-hidden="true">5.</strong> Designing Resource Sharing</a></li><li class="chapter-item expanded "><a href="intro/links.html"><strong aria-hidden="true">6.</strong> Links</a></li><li class="chapter-item expanded affix "><li class="part-title">Routing</li><li class="chapter-item expanded "><a href="routing/intro.html"><strong aria-hidden="true">7.</strong> Introduction to Routing</a></li><li class="chapter-item expanded "><a href="routing/model.html"><strong aria-hidden="true">8.</strong> Model for Intra-Domain Routing</a></li><li class="chapter-item expanded "><a href="routing/solutions.html"><strong aria-hidden="true">9.</strong> Routing States</a></li><li class="chapter-item expanded "><a href="routing/distance-vector.html"><strong aria-hidden="true">10.</strong> Distance-Vector Protocols</a></li><li class="chapter-item expanded "><a href="routing/link-state.html"><strong aria-hidden="true">11.</strong> Link-State Protocols</a></li><li class="chapter-item expanded "><a href="routing/addressing.html"><strong aria-hidden="true">12.</strong> Addressing</a></li><li class="chapter-item expanded "><a href="routing/router.html"><strong aria-hidden="true">13.</strong> Router Hardware</a></li><li class="chapter-item expanded "><a href="routing/autonomous-systems.html"><strong aria-hidden="true">14.</strong> Model for Inter-Domain Routing</a></li><li class="chapter-item expanded "><a href="routing/bgp.html"><strong aria-hidden="true">15.</strong> Border Gateway Protocol (BGP)</a></li><li class="chapter-item expanded "><a href="routing/bgp-implementation.html"><strong aria-hidden="true">16.</strong> BGP Implementation and Issues</a></li><li class="chapter-item expanded "><a href="routing/ip-header.html"><strong aria-hidden="true">17.</strong> IP Header</a></li><li class="chapter-item expanded affix "><li class="part-title">Transport</li><li class="chapter-item expanded "><a href="transport/reliability.html"><strong aria-hidden="true">18.</strong> Transport Layer Principles</a></li><li class="chapter-item expanded "><a href="transport/tcp-design.html"><strong aria-hidden="true">19.</strong> TCP Design</a></li><li class="chapter-item expanded "><a href="transport/tcp-implementation.html"><strong aria-hidden="true">20.</strong> TCP Implementation</a></li><li class="chapter-item expanded "><a href="transport/cc-principles.html"><strong aria-hidden="true">21.</strong> Congestion Control Principles</a></li><li class="chapter-item expanded "><a href="transport/cc-design.html"><strong aria-hidden="true">22.</strong> Congestion Control Design</a></li><li class="chapter-item expanded "><a href="transport/cc-implementation.html"><strong aria-hidden="true">23.</strong> Congestion Control Implementation</a></li><li class="chapter-item expanded "><a href="transport/throughput-model.html"><strong aria-hidden="true">24.</strong> TCP Throughput Model</a></li><li class="chapter-item expanded "><a href="transport/cc-issues.html"><strong aria-hidden="true">25.</strong> Congestion Control Issues</a></li><li class="chapter-item expanded "><a href="transport/router-based-cc.html"><strong aria-hidden="true">26.</strong> Router-Assisted Congestion Control</a></li><li class="chapter-item expanded affix "><li class="part-title">Applications</li><li class="chapter-item expanded "><a href="applications/dns.html"><strong aria-hidden="true">27.</strong> DNS</a></li><li class="chapter-item expanded "><a href="applications/http.html"><strong aria-hidden="true">28.</strong> HTTP</a></li><li class="chapter-item expanded affix "><li class="part-title">End-to-End</li><li class="chapter-item expanded "><a href="end-to-end/ethernet.html"><strong aria-hidden="true">29.</strong> Ethernet</a></li><li class="chapter-item expanded "><a href="end-to-end/l2-routing.html"><strong aria-hidden="true">30.</strong> Layer 2 Routing (STP)</a></li><li class="chapter-item expanded "><a href="end-to-end/arp.html"><strong aria-hidden="true">31.</strong> ARP: Connecting Layers 2 and 3</a></li><li class="chapter-item expanded "><a href="end-to-end/dhcp.html"><strong aria-hidden="true">32.</strong> DHCP: Joining Networks</a></li><li class="chapter-item expanded "><a href="end-to-end/nat.html"><strong aria-hidden="true">33.</strong> NAT: Network Address Translation</a></li><li class="chapter-item expanded "><a href="end-to-end/tls.html"><strong aria-hidden="true">34.</strong> TLS: Secure Bytestreams</a></li><li class="chapter-item expanded "><a href="end-to-end/end-to-end.html"><strong aria-hidden="true">35.</strong> End-to-End Connectivity</a></li><li class="chapter-item expanded affix "><li class="part-title">Datacenters</li><li class="chapter-item expanded "><a href="datacenter/topology.html"><strong aria-hidden="true">36.</strong> Topologies</a></li><li class="chapter-item expanded "><a href="datacenter/datacenter-cc.html"><strong aria-hidden="true">37.</strong> Congestion Control</a></li><li class="chapter-item expanded "><a href="datacenter/datacenter-routing.html"><strong aria-hidden="true">38.</strong> Routing</a></li><li class="chapter-item expanded "><a href="datacenter/datacenter-addressing.html"><strong aria-hidden="true">39.</strong> Addressing</a></li><li class="chapter-item expanded "><a href="datacenter/virtualization.html"><strong aria-hidden="true">40.</strong> Virtualization</a></li><li class="chapter-item expanded "><a href="datacenter/sdn.html"><strong aria-hidden="true">41.</strong> Software-Defined Networking</a></li><li class="chapter-item expanded "><a href="datacenter/host-networking.html"><strong aria-hidden="true">42.</strong> Host Networking</a></li><li class="chapter-item expanded affix "><li class="part-title">Beyond Client-Server</li><li class="chapter-item expanded "><a href="beyond-client-server/intro.html"><strong aria-hidden="true">43.</strong> Multicast</a></li><li class="chapter-item expanded "><a href="beyond-client-server/ip-multicast-service-model.html"><strong aria-hidden="true">44.</strong> IP Multicast</a></li><li class="chapter-item expanded "><a href="beyond-client-server/dvmrp.html"><strong aria-hidden="true">45.</strong> DVMRP</a></li><li class="chapter-item expanded "><a href="beyond-client-server/cbt.html"><strong aria-hidden="true">46.</strong> Core-Based Trees</a></li><li class="chapter-item expanded "><a href="beyond-client-server/ip-multicast-challenges.html"><strong aria-hidden="true">47.</strong> IP Multicast Challenges</a></li><li class="chapter-item expanded "><a href="beyond-client-server/overlay-multicast.html"><strong aria-hidden="true">48.</strong> Overlay Multicast</a></li><li class="chapter-item expanded "><a href="beyond-client-server/collective-operations.html"><strong aria-hidden="true">49.</strong> Collective Operations</a></li><li class="chapter-item expanded "><a href="beyond-client-server/collective-implementations.html"><strong aria-hidden="true">50.</strong> Collective Implementations</a></li><li class="chapter-item expanded affix "><li class="part-title">Wireless</li><li class="chapter-item expanded "><a href="wireless/wireless-links.html"><strong aria-hidden="true">51.</strong> Wireless Links</a></li><li class="chapter-item expanded "><a href="wireless/cellular.html"><strong aria-hidden="true">52.</strong> Cellular</a></li><li class="chapter-item expanded affix "><li class="part-title">Glossary</li><li class="chapter-item expanded "><a href="glossary.html"><strong aria-hidden="true">53.</strong> Glossary</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Mạngg máy tính - Thư trạm</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/thu-tram/mangg-may-tinh/" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="giới-thiệu-về-internet-introduction-to-the-internet"><a class="header" href="#giới-thiệu-về-internet-introduction-to-the-internet"><strong>Giới thiệu về Internet</strong> (Introduction to the Internet)</a></h1>
<h2 id="internet-là-gì-what-is-the-internet"><a class="header" href="#internet-là-gì-what-is-the-internet"><strong>Internet là gì?</strong> (What is the Internet?)</a></h2>
<p>Internet hiện diện ở khắp nơi như một công cụ để truyền dữ liệu giữa các thiết bị trên toàn thế giới. Trong khóa học này, chúng ta sẽ tập trung vào <strong>hạ tầng</strong> (bao gồm cả phần cứng và phần mềm) hỗ trợ cho hoạt động này.</p>
<p>Internet và <strong>World Wide Web</strong> không phải là cùng một thứ. Bạn có thể hình dung <strong>web</strong> là các ứng dụng được xây dựng trên nền tảng Internet (ví dụ: Facebook, Twitter) mà bạn có thể truy cập thông qua <strong>web browser</strong> (trình duyệt web) như Firefox, Chrome. Ngoài web, nhiều ứng dụng khác cũng sử dụng hạ tầng Internet. Ví dụ: các ứng dụng không thuộc web như Zoom, trò chơi trực tuyến, hoặc thậm chí các thiết bị <strong>Internet of Things (IoT)</strong> như cảm biến trong tủ lạnh hoặc ô tô của bạn.</p>
<h2 id="tại-sao-internet-thú-vị-why-is-the-internet-interesting"><a class="header" href="#tại-sao-internet-thú-vị-why-is-the-internet-interesting"><strong>Tại sao Internet thú vị?</strong> (Why is the Internet Interesting?)</a></h2>
<p>Internet không phải là một loại công nghệ mạng mới (ví dụ: dây điện đã tồn tại từ trước), mà là giải pháp cho một vấn đề hoàn toàn mới: <strong>kết nối các mạng khác nhau đã tồn tại</strong>. Giải quyết vấn đề này đòi hỏi một <strong>mô hình thiết kế</strong> mới, có ảnh hưởng đến nhiều lĩnh vực khác của khoa học máy tính.</p>
<p><strong>Networking</strong> (mạng máy tính) là một lĩnh vực tương đối mới trong khoa học máy tính. Internet đã đưa ra nhiều thách thức mới, khác biệt so với các lĩnh vực truyền thống. Ví dụ: khác với các lĩnh vực lý thuyết, chúng ta không có mô hình hình thức cho Internet; khác với các lĩnh vực phần cứng, chúng ta không có thước đo hiệu năng cố định.</p>
<p>Khác với các môn học trước đây bạn từng học, giờ đây chỉ viết mã chạy được là chưa đủ. Mã bạn viết phải <strong>scale</strong> (mở rộng) tới hàng tỷ người dùng. Mã bạn viết cũng phải phù hợp với các mối quan hệ kinh doanh giữa các nhà vận hành (nếu không, họ có thể không đồng ý chạy mã của bạn).</p>
<p>Mã chạy tốt cho một ứng dụng nhẹ (ví dụ: máy tính cá nhân) có thể không hoạt động trên một <strong>server</strong> (máy chủ) chịu tải nặng. Mã chạy tốt hôm nay có thể không chạy được ngày mai, khi các máy tính khác tham gia hoặc rời khỏi mạng.</p>
<p>Thiết kế của Internet đã ảnh hưởng đến cách chúng ta kiến trúc các hệ thống hiện đại (ví dụ: cân nhắc mục tiêu, ràng buộc và đánh đổi trong thiết kế). <strong>Network architecture</strong> (kiến trúc mạng) thiên về tư duy thiết kế hơn là chứng minh định lý hoặc viết mã. Nó thiên về cân nhắc đánh đổi hơn là đạt các chỉ số cụ thể. Nó thiên về thiết kế hệ thống thực tiễn hơn là tìm kiếm thiết kế tối ưu. Internet không phải là tối ưu, nhưng đã cân bằng thành công nhiều mục tiêu khác nhau.</p>
<h2 id="internet-là-hệ-thống-liên-kết-liên-bang-the-internet-is-federated"><a class="header" href="#internet-là-hệ-thống-liên-kết-liên-bang-the-internet-is-federated"><strong>Internet là hệ thống liên kết liên bang</strong> (The Internet is Federated)</a></h2>
<p>Internet là một hệ thống <strong>federated</strong> (liên kết liên bang) và yêu cầu khả năng <strong>interoperability</strong> (tương tác) giữa các nhà vận hành. Nói cách khác, mỗi nhà vận hành (<strong>ISP</strong>) hoạt động độc lập, nhưng tất cả phải hợp tác để kết nối toàn thế giới. Tất cả các ISP trên thế giới cần thống nhất về một số <strong>protocol</strong> (giao thức) chung để đạt được khả năng kết nối toàn cầu.</p>
<p>Mô hình liên kết liên bang mang đến nhiều thách thức. Các thực thể cạnh tranh (ví dụ: các công ty đối thủ) buộc phải hợp tác, dù họ có thể không muốn chia sẻ thông tin mật. Khi thiết kế giao thức, chúng ta phải cân nhắc cả yếu tố kinh doanh thực tế bên cạnh yếu tố kỹ thuật.</p>
<p>Liên kết liên bang cũng làm phức tạp hóa đổi mới. Trong các lĩnh vực khác, công ty có thể đổi mới bằng cách phát triển tính năng mà không ai có. Nhưng trên Internet, nếu bạn có tính năng mà không ai khác có, bạn sẽ không thể sử dụng nó. Mọi người phải nói cùng một “ngôn ngữ” (protocol), vì vậy mọi nâng cấp Internet phải được thực hiện với khả năng tương tác trong tâm trí.</p>
<h2 id="internet-có-khả-năng-mở-rộng-the-internet-is-scalable"><a class="header" href="#internet-có-khả-năng-mở-rộng-the-internet-is-scalable"><strong>Internet có khả năng mở rộng</strong> (The Internet is Scalable)</a></h2>
<p>Liên kết liên bang cho phép Internet đạt quy mô khổng lồ. Thay vì một nhà vận hành duy nhất quản lý hàng tỷ người dùng và hàng nghìn tỷ dịch vụ, chúng ta chỉ cần tập trung vào việc kết nối các nhà vận hành khác nhau. Liên kết liên bang cũng cho phép xây dựng Internet từ nhiều công nghệ đa dạng (ví dụ: <strong>wireless</strong>, <strong>optical</strong>) với nhiều mức năng lực khác nhau (ví dụ: đường truyền gia đình dung lượng nhỏ, hoặc cáp quang biển dung lượng cực lớn). Các công nghệ này liên tục phát triển, nghĩa là chúng ta không thể đặt ra một mục tiêu cố định (ví dụ: dung lượng và nhu cầu liên tục tăng theo cấp số nhân).</p>
<p>Quy mô khổng lồ của Internet cũng đồng nghĩa với việc bất kỳ hệ thống nào chúng ta thiết kế phải hỗ trợ phạm vi rộng lớn người dùng và ứng dụng (ví dụ: một số cần nhiều băng thông hơn, một số có thể có hành vi độc hại).</p>
<p>Quy mô toàn cầu của Internet yêu cầu hệ thống và giao thức hoạt động <strong>asynchronously</strong> (bất đồng bộ). Dữ liệu không thể di chuyển nhanh hơn tốc độ ánh sáng (và thường chậm hơn nhiều). Giả sử bạn gửi một thông điệp tới một server ở phía bên kia thế giới. Khi thông điệp đến nơi, CPU của bạn có thể đã thực hiện hàng triệu lệnh khác, và thông điệp bạn gửi có thể đã lỗi thời.</p>
<p>Quy mô Internet cũng có nghĩa là ngay cả việc gửi một thông điệp đơn lẻ cũng có thể cần tương tác với nhiều thành phần (ví dụ: phần mềm, switch, liên kết). Bất kỳ thành phần nào cũng có thể hỏng, và chúng ta có thể không biết. Nếu có sự cố, có thể mất nhiều thời gian để nhận thông tin xấu. Internet là hệ thống đầu tiên được thiết kế để chịu lỗi ở quy mô lớn. Nhiều ý tưởng này sau đó đã được áp dụng trong các lĩnh vực khác.</p>
<h2 id="giao-thức-protocols"><a class="header" href="#giao-thức-protocols"><strong>Giao thức</strong> (Protocols)</a></h2>
<p>Trong khóa học này, chúng ta sẽ tập trung nhiều vào <strong>protocol</strong> – các quy tắc xác định cách các thực thể trao đổi thông tin. Giao thức quy định <strong>định dạng</strong> của thông điệp và <strong>cách phản hồi</strong> với các thông điệp đó.</p>
<p>Ví dụ: bạn viết một ứng dụng cần gửi và nhận dữ liệu qua Internet. Mã ở máy gửi và mã ở máy nhận phải thống nhất về cách định dạng dữ liệu và cách xử lý các thông điệp khác nhau.</p>
<p>Ví dụ về một giao thức: Alice và Bob cùng chào nhau, sau đó Alice yêu cầu một tệp, và Bob gửi lại tệp. Để định nghĩa giao thức này, chúng ta cần xác định <strong>syntax</strong> (cú pháp – ví dụ: cách viết “hãy gửi tôi tệp này” bằng bit 0 và 1) và <strong>semantics</strong> (ngữ nghĩa – ví dụ: Alice phải nhận lời chào từ Bob trước khi yêu cầu tệp).</p>
<p>Các giao thức khác nhau được thiết kế cho các nhu cầu khác nhau. Ví dụ: nếu Alice cần nhận tệp càng nhanh càng tốt, ta có thể thiết kế giao thức bỏ qua bước chào ban đầu. Thiết kế một giao thức tốt có thể khó hơn tưởng tượng! Chúng ta cũng cần tính đến các trường hợp ngoại lệ, lỗi và hành vi độc hại. Ví dụ: nếu Alice yêu cầu tệp, nhưng Bob lại trả lời bằng lời chào, Alice nên phản ứng thế nào?</p>
<p>Trong khóa học này, chúng ta sẽ thấy nhiều giao thức đã được <strong>standardize</strong> (tiêu chuẩn hóa) trên toàn Internet. Bạn sẽ đôi khi thấy từ viết tắt <strong>RFC</strong> (Request For Comments) khi nhắc đến một giao thức. Nhiều tiêu chuẩn được công bố dưới dạng tài liệu RFC và sau đó được chấp nhận rộng rãi, mặc dù không phải tất cả RFC đều được áp dụng. Các tài liệu RFC được đánh số, và đôi khi giao thức được gọi theo số RFC. Ví dụ: “RFC 1918 addresses” đề cập đến các địa chỉ được định nghĩa trong tài liệu đó.</p>
<p>Có nhiều tổ chức tiêu chuẩn khác nhau chịu trách nhiệm tiêu chuẩn hóa giao thức. <strong>IEEE</strong> tập trung vào các tầng thấp hơn liên quan đến kỹ thuật điện tử. <strong>IETF</strong> tập trung vào Internet và chịu trách nhiệm về các RFC.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="layers-of-the-internet"><a class="header" href="#layers-of-the-internet">Layers of the Internet</a></h1>
<h2 id="layer-1-physical-layer-tầng-vật-lý"><a class="header" href="#layer-1-physical-layer-tầng-vật-lý"><strong>Layer 1: Physical Layer</strong> (Tầng vật lý)</a></h2>
<p>Trong phần này, chúng ta sẽ xây dựng Internet theo hướng <strong>bottom-up</strong> (từ dưới lên), bắt đầu với các khối cơ bản và kết hợp chúng để hình thành hạ tầng Internet. Chúng ta sẽ sử dụng hệ thống bưu điện như một phép so sánh xuyên suốt, vì nó có nhiều lựa chọn thiết kế tương đồng với Internet.</p>
<p>Trước tiên, chúng ta cần một cách để gửi tín hiệu qua không gian. Trong hệ thống bưu điện, điều này có thể là một người đưa thư, dịch vụ Pony Express, xe tải, chim bồ câu đưa thư, v.v.</p>
<p>Trong Internet, chúng ta tìm cách truyền <strong>bit</strong> (1 và 0) qua không gian. Công nghệ có thể là điện áp trên dây dẫn điện, sóng vô tuyến không dây, xung ánh sáng qua cáp quang, v.v. Có cả một lĩnh vực <strong>electrical engineering</strong> (kỹ thuật điện) chuyên nghiên cứu việc truyền tín hiệu qua không gian, nhưng chúng ta sẽ không đi sâu vào chi tiết trong khóa học này.</p>
<h2 id="layer-2-link-layer-tầng-liên-kết"><a class="header" href="#layer-2-link-layer-tầng-liên-kết"><strong>Layer 2: Link Layer</strong> (Tầng liên kết)</a></h2>
<p>Trong phép so sánh, khi đã có cách gửi dữ liệu qua không gian, chúng ta có thể dùng khối cơ bản này để kết nối hai ngôi nhà. Thậm chí, chúng ta có thể kết nối tất cả các ngôi nhà trong một thị trấn.</p>
<p>Trong Internet, một <strong>link</strong> (liên kết) kết nối hai máy. Liên kết này có thể sử dụng bất kỳ loại công nghệ nào (có dây, không dây, cáp quang, v.v.). Nếu chúng ta dùng các liên kết để kết nối nhiều máy tính gần nhau (ví dụ: tất cả máy tính trong UC Berkeley), chúng ta sẽ có một <strong>Local Area Network (LAN)</strong> (mạng cục bộ).</p>
<img width="175px" src="intro/../assets/intro/1-01-lan.png">
<p>Ở Layer 2, chúng ta cũng có thể nhóm các bit thành các đơn vị dữ liệu gọi là <strong>packet</strong> (gói tin – đôi khi ở tầng này gọi là <strong>frame</strong>), và xác định điểm bắt đầu và kết thúc của một gói tin trong tín hiệu vật lý. Chúng ta cũng có thể xử lý các vấn đề như nhiều người cùng lúc sử dụng chung một dây để gửi dữ liệu.</p>
<h2 id="layer-3-internet-layer-tầng-internet"><a class="header" href="#layer-3-internet-layer-tầng-internet"><strong>Layer 3: Internet Layer</strong> (Tầng Internet)</a></h2>
<p>Giờ đây, chúng ta đã có cách kết nối mọi người trong một khu vực cục bộ, nhưng nếu hai người ở hai khu vực khác nhau muốn giao tiếp thì sao? Một cách tiếp cận là thêm nhiều liên kết giữa các mạng cục bộ khác nhau, nhưng điều này không hiệu quả (đặc biệt nếu hai mạng ở hai châu lục khác nhau).</p>
<img width="400px" src="intro/../assets/intro/1-02-mesh.png">
<p>Thay vào đó, một cách thông minh hơn là đặt một bưu điện trong mỗi mạng, và chỉ cần kết nối hai bưu điện này. Khi ai đó trong mạng A muốn liên lạc với ai đó trong mạng B, họ gửi thư tới bưu điện của mạng A. Bưu điện này sẽ chuyển thư tới bưu điện của mạng B, và bưu điện B sẽ giao thư tới đích.</p>
<img width="400px" src="intro/../assets/intro/1-03-router.png">
<p>Trong Internet, bưu điện nhận và chuyển tiếp thư được gọi là <strong>switch</strong> hoặc <strong>router</strong>.</p>
<p>Nếu chúng ta xây thêm các liên kết giữa các switch, chúng ta có thể kết nối các mạng cục bộ. Với đủ liên kết và mạng cục bộ, chúng ta có thể kết nối mọi người trên toàn thế giới, tạo thành Internet.</p>
<img width="700px" src="intro/../assets/intro/1-04-network-of-networks.png">
<p>Một câu hỏi cần trả lời là: Làm thế nào để tìm đường đi qua mạng? Khi một switch nhận gói tin, làm sao nó biết phải chuyển tiếp gói tin đi đâu để đến gần đích hơn? Đây sẽ là trọng tâm của phần <strong>routing</strong> (định tuyến).</p>
<p>Chúng ta cũng cần đảm bảo rằng các liên kết này có đủ <strong>capacity</strong> (dung lượng) để truyền dữ liệu. Đây sẽ là trọng tâm của phần <strong>congestion control</strong> (kiểm soát tắc nghẽn).</p>
<p>Bức tranh này cho thấy hạ tầng Internet, nhưng trong khóa học này, chúng ta cũng sẽ nghiên cứu các <strong>operator</strong> (nhà vận hành) quản lý hạ tầng. Trong phép so sánh, đây là những người xây dựng và quản lý bưu điện. Trên Internet, các operator là <strong>Internet Service Provider (ISP)</strong> như AT&amp;T, Amazon Web Services, hoặc UC Berkeley, những đơn vị sở hữu và vận hành hạ tầng Internet. Ngoài hạ tầng phần cứng và phần mềm, chúng ta cần xem xét các tổ chức này như những doanh nghiệp và tổ chức thực tế, cân nhắc động cơ kinh tế và chính trị của họ. Ví dụ: nếu AT&amp;T xây dựng một tuyến cáp quang biển, họ có thể thu phí các ISP khác khi gửi dữ liệu qua tuyến cáp này.</p>
<h2 id="network-of-networks-mạng-của-các-mạng"><a class="header" href="#network-of-networks-mạng-của-các-mạng"><strong>Network of Networks</strong> (Mạng của các mạng)</a></h2>
<p>Internet thường được mô tả là một <strong>network of networks</strong>. Có rất nhiều mạng cục bộ nhỏ, và những gì diễn ra bên trong mạng cục bộ có thể được quản lý nội bộ (ví dụ: bởi UC Berkeley). Sau đó, tất cả các mạng cục bộ kết nối với nhau để tạo thành Internet.</p>
<p>Trong mạng, các liên kết khác nhau có thể sử dụng công nghệ Layer 2 khác nhau. Một số liên kết có thể dùng <strong>Ethernet</strong> có dây, số khác dùng cáp quang hoặc công nghệ di động không dây. Ở Layer 2, chúng ta tìm cách gửi một gói tin trong mạng cục bộ, qua các liên kết trong mạng đó, sử dụng công nghệ cụ thể của mạng. Sau đó, ở Layer 3, chúng ta dùng khả năng gửi gói tin qua các liên kết như một khối xây dựng để gửi gói tin đi bất cứ đâu trên Internet. Khi gói tin nhảy qua nhiều mạng khác nhau, nó có thể được truyền qua nhiều loại liên kết khác nhau.</p>
<img width="700px" src="intro/../assets/intro/1-05-different-links.png">
<p>Trong phép so sánh, chúng ta thấy sự khác biệt giữa <strong>home</strong> (nhà) và <strong>post office</strong> (bưu điện). Các ngôi nhà gửi và nhận thư cho nhau. Các bưu điện không gửi hoặc nhận thư của riêng mình, mà giúp kết nối các ngôi nhà khác.</p>
<p>Trên Internet, <strong>end host</strong> là các máy (ví dụ: server, laptop, điện thoại) giao tiếp qua Internet. Ngược lại, <strong>switch</strong> (còn gọi là <strong>router</strong>) là máy không gửi hoặc nhận dữ liệu của riêng mình, mà tồn tại để giúp các end host giao tiếp với nhau. Ví dụ về switch là router trong nhà bạn, hoặc các router lớn hơn do ISP triển khai (ví dụ: AT&amp;T).</p>
<p>Trong các ghi chú này, chúng ta thường vẽ end host dưới dạng hình tròn, và router dưới dạng hình vuông.</p>
<h2 id="layers-of-abstraction-các-tầng-trừu-tượng"><a class="header" href="#layers-of-abstraction-các-tầng-trừu-tượng"><strong>Layers of Abstraction</strong> (Các tầng trừu tượng)</a></h2>
<p>Khi xây dựng Internet, bạn có thể nhận thấy rằng chúng ta đã chia nhỏ vấn đề thành các nhiệm vụ và <strong>abstraction</strong> (trừu tượng) nhỏ hơn.</p>
<blockquote>
<p>“Modularity based on abstraction is the way things are done.” – Barbara Liskov, Turing Lecture.</p>
</blockquote>
<p>Đây là cách chúng ta xây dựng và duy trì các hệ thống máy tính lớn. <strong>Modularity</strong> (tính mô-đun) đặc biệt quan trọng với Internet vì Internet bao gồm nhiều thiết bị (host, router) và nhiều thực thể trong thế giới thực (người dùng, công ty công nghệ, ISP), và việc mọi người đồng ý về cách phân chia nhiệm vụ là yếu tố giúp Internet hoạt động ở quy mô lớn.</p>
<p>Một lợi thế lớn của cách tiếp cận phân tầng và network-of-networks là mỗi mạng có thể tự quyết định cách di chuyển dữ liệu. Ví dụ: khi gói tin của bạn di chuyển qua các <strong>hop</strong> trên Internet, một số liên kết có thể dùng công nghệ không dây, số khác dùng công nghệ có dây. Các giao thức tầng thấp hơn có thể thay đổi qua các hop khác nhau, nhưng giao thức Layer 3 vẫn hoạt động.</p>
<p>Phân tầng cũng cho phép đổi mới diễn ra song song. Các cộng đồng khác nhau (ví dụ: nhà thiết kế chip phần cứng, lập trình viên phần mềm) có thể đổi mới ở các tầng khác nhau.</p>
<h2 id="layer-3-best-effort-service-model-mô-hình-dịch-vụ-nỗ-lực-tối-đa"><a class="header" href="#layer-3-best-effort-service-model-mô-hình-dịch-vụ-nỗ-lực-tối-đa"><strong>Layer 3: Best-Effort Service Model</strong> (Mô hình dịch vụ nỗ lực tối đa)</a></h2>
<p>Có vẻ như chúng ta đã xây dựng được một hệ thống có thể gửi dữ liệu đi bất cứ đâu trên thế giới, vậy tại sao không dừng lại ở đây? Vẫn còn hai vấn đề ở <strong>Layer 3</strong> mà chúng ta cần giải quyết.</p>
<p>Vấn đề đầu tiên liên quan đến <strong>service model</strong> (mô hình dịch vụ) của Layer 3. Nếu bạn sử dụng hạ tầng Layer 3 để gửi thông điệp qua Internet, mô hình dịch vụ mà mạng cung cấp cho bạn – với tư cách là người dùng – là gì? Bạn có thể coi mô hình dịch vụ như một hợp đồng giữa mạng và người dùng, mô tả những gì mạng hỗ trợ và không hỗ trợ.</p>
<p>Ví dụ về các mô hình dịch vụ thực tế có thể bao gồm:</p>
<ul>
<li>Mạng đảm bảo dữ liệu sẽ được giao.</li>
<li>Mạng đảm bảo dữ liệu sẽ được giao trong một khoảng thời gian nhất định.</li>
<li>Mạng không đảm bảo giao dữ liệu, nhưng cam kết báo lỗi nếu thất bại.</li>
</ul>
<p>Các nhà thiết kế Internet đã không hỗ trợ bất kỳ mô hình nào trong số đó. Thay vào đó, Internet chỉ hỗ trợ <strong>best-effort</strong> (nỗ lực tối đa) trong việc truyền dữ liệu. Nếu bạn gửi dữ liệu qua Layer 3, Internet sẽ cố gắng hết sức để giao nó, nhưng không có gì đảm bảo dữ liệu sẽ được giao. Internet cũng sẽ không cho bạn biết liệu việc giao có thành công hay không.</p>
<p>Tại sao các nhà thiết kế lại chọn một mô hình dịch vụ “yếu” như vậy? Một lý do chính là việc xây dựng mạng đáp ứng các yêu cầu yếu hơn này dễ dàng hơn rất nhiều.</p>
<h2 id="layer-3-packets-abstraction-khái-niệm-trừu-tượng-gói-tin"><a class="header" href="#layer-3-packets-abstraction-khái-niệm-trừu-tượng-gói-tin"><strong>Layer 3: Packets Abstraction</strong> (Khái niệm trừu tượng gói tin)</a></h2>
<p>Cho đến nay, ở Layer 3, chúng ta vẫn đang nghĩ về việc gửi từng thông điệp qua Internet một cách độc lập. Nói một cách chính xác hơn, <strong>đơn vị dữ liệu cơ bản</strong> được truyền ở Layer 3 là <strong>packet</strong> (gói tin) – một khối byte nhỏ di chuyển qua Internet, bật qua các <strong>router</strong> (bộ định tuyến) như một đơn vị duy nhất.</p>
<p>Vấn đề thứ hai ở Layer 3 là: <strong>Packet</strong> bị giới hạn về kích thước. Nếu ứng dụng có một lượng dữ liệu lớn cần gửi (ví dụ: một video), chúng ta cần chia nhỏ dữ liệu đó thành nhiều packet và gửi từng packet qua mạng một cách độc lập.</p>
<p>Với khái niệm trừu tượng packet này, chúng ta có thể xem xét “hành trình” của một packet khi nó di chuyển qua mạng:</p>
<ul>
<li><strong>Sender</strong> (máy gửi) chia dữ liệu thành các packet riêng lẻ.</li>
<li>Packet di chuyển qua một <strong>link</strong> (liên kết) và đến một <strong>switch</strong> (bộ chuyển mạch).</li>
<li>Switch chuyển tiếp packet tới đích hoặc tới một switch khác gần đích hơn.</li>
<li>Packet nhảy qua một hoặc nhiều switch, mỗi switch chuyển tiếp nó gần hơn tới đích, cho đến khi nó đến nơi.</li>
</ul>
<p>Lưu ý rằng, do mô hình <strong>best-effort</strong>, bất kỳ switch nào cũng có thể <strong>drop</strong> (loại bỏ) packet, và không có gì đảm bảo packet thực sự đến được đích.</p>
<img width="700px" src="intro/../assets/intro/1-06-path-through-network.png">
<h2 id="layer-4-transport-tầng-vận-chuyển"><a class="header" href="#layer-4-transport-tầng-vận-chuyển"><strong>Layer 4: Transport</strong> (Tầng vận chuyển)</a></h2>
<p>Chúng ta đã xác định hai vấn đề ở <strong>Layer 3</strong>:</p>
<ul>
<li>Dữ liệu lớn phải được chia nhỏ thành các <strong>packet</strong> (gói tin).</li>
<li><strong>IP</strong> chỉ cung cấp dịch vụ <strong>best-effort</strong> (nỗ lực tối đa, không đảm bảo).</li>
</ul>
<p>Để giải quyết cả hai vấn đề này, chúng ta sẽ giới thiệu một tầng mới – <strong>transport layer</strong> (tầng vận chuyển). Tầng này sử dụng Layer 3 như một khối xây dựng và triển khai một <strong>protocol</strong> (giao thức) bổ sung để:</p>
<ul>
<li>Gửi lại các gói tin bị mất.</li>
<li>Chia dữ liệu thành các packet.</li>
<li>Sắp xếp lại các packet đến sai thứ tự.</li>
<li>(Cùng nhiều tính năng khác.)</li>
</ul>
<p>Giao thức tầng vận chuyển cho phép chúng ta ngừng suy nghĩ ở mức packet riêng lẻ và bắt đầu suy nghĩ ở mức <strong>flow</strong> (luồng) – tức là các chuỗi packet được trao đổi giữa hai <strong>endpoint</strong> (điểm cuối).</p>
<h2 id="layer-7-application-tầng-ứng-dụng"><a class="header" href="#layer-7-application-tầng-ứng-dụng"><strong>Layer 7: Application</strong> (Tầng ứng dụng)</a></h2>
<p>Việc xây dựng <strong>application layer</strong> (tầng ứng dụng) trên nền Internet là một lựa chọn thiết kế mạnh mẽ. Nếu ở các tầng thấp hơn, chúng ta xây dựng hạ tầng chỉ để truyền video giữa các end host, thì các <strong>email client</strong> (ứng dụng email) sẽ phải tự xây dựng hạ tầng riêng để truyền email. Thiết kế của Internet cho phép nó trở thành một mạng truyền thông đa dụng cho mọi loại dữ liệu ứng dụng.</p>
<p>Trong khóa học này, chúng ta sẽ tập trung nhiều hơn vào <strong>hạ tầng hỗ trợ tầng ứng dụng</strong> (ví dụ: người đưa thư, bưu điện) và ít hơn vào chính các ứng dụng (ví dụ: nội dung của thư). Tuy nhiên, chúng ta sẽ tìm hiểu một số <strong>application protocol</strong> (giao thức ứng dụng) phổ biến ở cuối khóa học.</p>
<p>Bây giờ, khi đã xem tất cả các tầng, hãy chú ý rằng mỗi tầng dựa vào dịch vụ của tầng ngay bên dưới và cung cấp dịch vụ cho tầng ngay bên trên. Ví dụ: một người viết <strong>Layer 7 protocol</strong> có thể giả định rằng họ có dịch vụ truyền dữ liệu tin cậy từ Layer 4. Họ không cần lo lắng về việc mất packet riêng lẻ, vì Layer 4 đã xử lý vấn đề này.</p>
<img width="700px" src="intro/../assets/intro/1-07-layers.png">
<p>Hai tầng tương tác trực tiếp thông qua <strong>interface</strong> (giao diện) giữa chúng. Không có cách thực tiễn nào để bỏ qua tầng và xây dựng Layer 7 trực tiếp trên Layer 3, chẳng hạn.</p>
<p><strong>Lưu ý:</strong> Bạn có thể nhận thấy chúng ta đã bỏ qua <strong>Layer 5</strong> và <strong>Layer 6</strong>. Vào những năm 1970, khi mô hình phân tầng được tiêu chuẩn hóa, các nhà thiết kế nghĩ rằng hai tầng này là cần thiết, nhưng trong Internet hiện đại, chúng đã trở nên lỗi thời.</p>
<ul>
<li><strong>Session layer (Layer 5)</strong>: dự kiến dùng để tập hợp các flow khác nhau thành một <strong>session</strong> (phiên), ví dụ: tải nhiều hình ảnh và advertise để tạo thành một trang web.</li>
<li><strong>Presentation layer (Layer 6)</strong>: dự kiến giúp người dùng <strong>visualize</strong> (trực quan hóa) dữ liệu.</li>
</ul>
<p>Ngày nay, hầu hết chức năng của hai tầng này được triển khai trong Layer 7.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="headers-tiêu-đề-gói-tin"><a class="header" href="#headers-tiêu-đề-gói-tin"><strong>Headers</strong> (Tiêu đề gói tin)</a></h1>
<h2 id="tại-sao-chúng-ta-cần-headers-why-do-we-need-headers"><a class="header" href="#tại-sao-chúng-ta-cần-headers-why-do-we-need-headers"><strong>Tại sao chúng ta cần Headers?</strong> (Why Do We Need Headers?)</a></h2>
<p>Trong phần trước, chúng ta đã thấy rằng ở <strong>Layer 3</strong>, dữ liệu di chuyển qua Internet dưới dạng <strong>packet</strong> (gói tin). Giả sử một ứng dụng muốn gửi một tệp qua Internet. Chúng ta có thể lấy một số bit của hình ảnh, đặt chúng vào một packet và gửi qua Internet. Khi một <strong>switch</strong> nhận được chuỗi các bit 1 và 0 này, nó hoàn toàn không biết phải làm gì với chúng.</p>
<img width="700px" src="intro/../assets/intro/1-08-no-headers.png">
<p>Trong phép so sánh, nếu tôi viết một bức thư cho bạn mình và đưa nó cho bưu điện, bưu điện sẽ không biết phải làm gì với nó. Thay vào đó, chúng ta nên đặt bức thư vào một phong bì và ghi một số thông tin lên phong bì (ví dụ: địa chỉ của bạn tôi) để cho bưu điện biết phải làm gì với bức thư.</p>
<p>Tương tự như phong bì, khi chúng ta gửi một packet, chúng ta cần gắn thêm <strong>metadata</strong> (siêu dữ liệu) để cho hạ tầng mạng biết phải xử lý packet đó như thế nào. Phần siêu dữ liệu bổ sung này được gọi là <strong>header</strong> (tiêu đề). Phần còn lại của các bit (ví dụ: tệp đang được gửi, bức thư bên trong phong bì) được gọi là <strong>payload</strong> (tải dữ liệu).</p>
<img width="700px" src="intro/../assets/intro/1-09-header.png">
<p>Trong phép so sánh, bưu điện không nên đọc nội dung bên trong bức thư, mà chỉ đọc những gì ghi trên phong bì để quyết định cách gửi. Tương tự, hạ tầng mạng chỉ nên đọc header để quyết định cách chuyển dữ liệu.</p>
<p>Người nhận quan tâm đến nội dung bên trong bức thư, không phải phong bì. Tương tự, ứng dụng ở <strong>end host</strong> (máy đầu cuối) quan tâm đến payload, không phải header. Tuy nhiên, end host vẫn cần biết về header để có thể thêm header vào packet trước khi gửi.</p>
<h2 id="headers-được-tiêu-chuẩn-hóa-headers-are-standardized"><a class="header" href="#headers-được-tiêu-chuẩn-hóa-headers-are-standardized"><strong>Headers được tiêu chuẩn hóa</strong> (Headers are Standardized)</a></h2>
<p>Bạn cũng có thể coi header như <strong>API</strong> giữa end host gửi/nhận dữ liệu và hạ tầng mạng vận chuyển dữ liệu. Khi viết phần mềm, chúng ta cần xác định <strong>interface</strong> (giao diện) mà người dùng sẽ sử dụng để tương tác với mã của chúng ta (ví dụ: các hàm có thể gọi, tham số truyền vào). Tương tự, thông tin trong header là cách người dùng truy cập các chức năng và truyền tham số cho mạng.</p>
<p>Tất cả mọi người trên Internet (mọi end host, mọi switch) cần thống nhất về định dạng của header. Nếu <strong>Microsoft Windows</strong> thay đổi mã trong hệ điều hành để gửi packet với cấu trúc header khác, sẽ không ai khác hiểu được các packet đó.</p>
<p>Điều này cũng có nghĩa là chúng ta cần cẩn thận khi thiết kế header. Một khi đã thiết kế và triển khai header trên Internet, việc thay đổi nó là rất khó (chúng ta sẽ phải thuyết phục tất cả mọi người đồng ý thay đổi). Đây là lý do tại sao các tổ chức tiêu chuẩn có thể mất nhiều năm để thiết kế và tiêu chuẩn hóa header.</p>
<h2 id="header-nên-chứa-những-gì-what-should-a-header-contain"><a class="header" href="#header-nên-chứa-những-gì-what-should-a-header-contain"><strong>Header nên chứa những gì?</strong> (What Should a Header Contain?)</a></h2>
<p>Thông tin nào nên được đưa vào header?</p>
<ul>
<li><strong>Địa chỉ đích</strong>: chắc chắn phải có, để cho biết nơi cần gửi packet.</li>
<li><strong>Địa chỉ nguồn</strong>: về mặt kỹ thuật không bắt buộc để chuyển packet, nhưng trên thực tế, chúng ta gần như luôn đưa vào để người nhận có thể gửi phản hồi lại cho người gửi.</li>
<li><strong>Checksum</strong>: để đảm bảo packet không bị lỗi trong quá trình truyền.</li>
<li><strong>Độ dài packet</strong>: vì packet có thể có kích thước khác nhau (ví dụ: người dùng chỉ cần gửi vài byte).</li>
</ul>
<h2 id="nhiều-header-multiple-headers"><a class="header" href="#nhiều-header-multiple-headers"><strong>Nhiều header</strong> (Multiple Headers)</a></h2>
<p>Quay lại phép so sánh bưu điện. Giả sử giám đốc Công ty A muốn viết thư cho giám đốc Công ty B. Thông điệp sẽ được gửi như thế nào?</p>
<img width="700px" src="intro/../assets/intro/1-10-multiheader1.png">
<p>Giám đốc Công ty A gấp thư và đưa cho thư ký. Thư ký đặt thư vào phong bì có ghi đầy đủ tên giám đốc Công ty B.</p>
<img width="700px" src="intro/../assets/intro/1-11-multiheader2.png">
<p>Thư ký chuyển thư này cho phòng thư. Nhân viên bưu điện đặt thư vào một hộp có ghi địa chỉ đường phố của Công ty B và đưa gói hàng lên xe tải giao hàng.</p>
<img width="700px" src="intro/../assets/intro/1-12-multiheader3.png">
<p>Lúc này, bức thư đã được bọc trong nhiều lớp thông tin nhận dạng (phong bì, hộp). Công ty vận chuyển gửi thư tới Công ty B (có thể qua nhiều xe tải, máy bay, nhân viên bưu điện, v.v.).</p>
<img width="700px" src="intro/../assets/intro/1-13-multiheader4.png">
<p>Khi thư đến Công ty B, phòng thư gỡ bỏ hộp và chuyển phong bì cho thư ký.</p>
<img width="700px" src="intro/../assets/intro/1-14-multiheader5.png">
<p>Sau đó, thư ký nhìn thấy tên giám đốc trên phong bì, mở phong bì và chuyển thư cho giám đốc Công ty B.</p>
<img width="700px" src="intro/../assets/intro/1-15-multiheader6.png">
<p>Hãy chú ý rằng khi đi xuống các tầng trừu tượng thấp hơn, chúng ta bọc thêm nhiều header quanh dữ liệu. Khi đi lên các tầng trừu tượng cao hơn, chúng ta gỡ bỏ các lớp header này.</p>
<img width="900px" src="intro/../assets/intro/1-16-wrapping-unwrapping.png">
<p>Mỗi tầng chỉ cần hiểu header của riêng mình và “giao tiếp” (theo một nghĩa nào đó) với các <strong>peer</strong> (thực thể ngang hàng) ở cùng tầng. Khi Thư ký A ghi tên lên phong bì, điều đó là để Thư ký B đọc (không phải nhân viên bưu điện hay giám đốc).</p>
<p>Một cách chính xác hơn, trên Internet, các peer ở cùng tầng giao tiếp bằng cách thiết lập một <strong>protocol</strong> tại tầng đó. Giao thức này chỉ có ý nghĩa đối với các thực thể ở tầng cụ thể đó.</p>
<img width="900px" src="intro/../assets/intro/1-17-layer-peers.png">
<p>Lưu ý rằng một số tầng cung cấp nhiều lựa chọn giao thức (ví dụ: giao thức không dây hoặc có dây ở Layer 2). Trong các trường hợp này, hai bên giao tiếp cần sử dụng cùng một lựa chọn giao thức. Một bên gửi có dây không thể giao tiếp với một bên nhận không dây.</p>
<h2 id="addressing-and-naming-Địa-chỉ-hóa-và-Định-danh"><a class="header" href="#addressing-and-naming-Địa-chỉ-hóa-và-Định-danh"><strong>Addressing and Naming</strong> (Địa chỉ hóa và Định danh)</a></h2>
<p>Trước đó, chúng ta đã nói rằng <strong>header</strong> (tiêu đề gói tin) cần chứa địa chỉ của người nhận. Vậy chính xác thì địa chỉ đó là gì? Về mặt hình thức, <strong>network address</strong> (địa chỉ mạng) là một giá trị cho biết vị trí của một <strong>host</strong> (máy chủ/máy trạm) trong mạng.</p>
<p>Khi xem xét chi tiết các tầng khác nhau, chúng ta sẽ thấy mỗi tầng có một <strong>addressing scheme</strong> (cơ chế địa chỉ hóa) riêng. Nếu bạn muốn gửi thư trong tòa nhà Soda Hall, bạn có thể ghi địa chỉ đích là “413 Soda Hall”, và những người trong tòa nhà sẽ biết cách chuyển thư. Ngược lại, nếu muốn gửi thư tới New York, bạn phải ghi đầy đủ địa chỉ đường phố, ví dụ: “123 Main Street, New York, NY”.</p>
<p>Tương tự, các tầng khác nhau trong Internet có các cơ chế địa chỉ hóa phù hợp nhất cho tầng đó. Ví dụ: đôi khi một host được gọi bằng <strong>tên dễ đọc với con người</strong> (human-readable name), như <em>www.google.com</em>. Lúc khác, cùng host đó được gọi bằng <strong>địa chỉ IP</strong> (ví dụ: <em>74.124.56.2</em>), là dạng máy có thể đọc được, trong đó con số này mã hóa thông tin về vị trí của server (và có thể thay đổi nếu server di chuyển). Lại có lúc, cùng host đó được gọi bằng <strong>địa chỉ MAC</strong> phần cứng, vốn không bao giờ thay đổi.</p>
<img width="700px" src="intro/../assets/intro/1-18-naming.png">
<h2 id="layers-at-hosts-and-routers-các-tầng-tại-host-và-router"><a class="header" href="#layers-at-hosts-and-routers-các-tầng-tại-host-và-router"><strong>Layers at Hosts and Routers</strong> (Các tầng tại Host và Router)</a></h2>
<p>Internet không chỉ đơn giản là một bên gửi và một bên nhận. Ngoài hai <strong>end host</strong> (máy đầu cuối), còn có các <strong>router</strong> (bộ định tuyến) chuyển tiếp packet qua nhiều <strong>hop</strong> (bước nhảy) để đến đích. Vậy ý tưởng về phân tầng và header hoạt động thế nào trên tất cả các thiết bị này?</p>
<p><strong>End host</strong> cần triển khai tất cả các tầng. Máy tính của bạn cần biết về <strong>Layer 7</strong> để chạy trình duyệt web. Máy tính của bạn cũng cần biết về <strong>Layer 1</strong> để gửi các bit ra dây. Bạn cũng cần tất cả các tầng ở giữa để dữ liệu ở mức ứng dụng (bức thư của giám đốc) được truyền xuống tới tầng vật lý.</p>
<p>Còn <strong>router</strong> thì sao? Router cần <strong>Layer 1</strong> để nhận bit qua dây, <strong>Layer 2</strong> để gửi packet qua dây, và <strong>Layer 3</strong> để chuyển tiếp packet trong mạng toàn cầu. Tuy nhiên, router không cần quan tâm đến <strong>Layer 4</strong> và <strong>Layer 7</strong>. Router không chạy trình duyệt web để hiển thị trang, và cũng không cần xử lý tính tin cậy (nhớ lại mô hình <strong>best-effort service</strong>).</p>
<img width="900px" src="intro/../assets/intro/1-19-layers-host-routers.png">
<p><strong>Tóm lại:</strong> Ba tầng thấp nhất được triển khai ở mọi nơi, nhưng hai tầng cao nhất chỉ được triển khai tại end host.</p>
<h2 id="multiple-headers-at-hosts-and-routers-analogy-nhiều-header-tại-host-và-router-phép-so-sánh"><a class="header" href="#multiple-headers-at-hosts-and-routers-analogy-nhiều-header-tại-host-và-router-phép-so-sánh"><strong>Multiple Headers at Hosts and Routers: Analogy</strong> (Nhiều header tại Host và Router: Phép so sánh)</a></h2>
<p>Hãy quay lại ví dụ gửi thư. Công ty A bọc bức thư trong phong bì, rồi đặt phong bì vào hộp. Chiếc hộp này không tự di chuyển đến Công ty B, mà có thể đi qua nhiều bưu điện.</p>
<img width="900px" src="intro/../assets/intro/1-20-layer2-forwarding1.png">
<p>Tại mỗi bưu điện, nhân viên mở hộp và phân loại thư. Họ nhìn vào phong bì (header tiếp theo được lộ ra sau khi mở hộp) và thấy rằng phong bì này gửi cho Công ty B.</p>
<img width="900px" src="intro/../assets/intro/1-21-layer2-forwarding2.png">
<p>Nhân viên bưu điện đặt phong bì vào một chiếc hộp khác (có thể khác loại), để bức thư có thể đến bưu điện tiếp theo trên đường tới Công ty B.</p>
<img width="900px" src="intro/../assets/intro/1-22-layer2-forwarding3.png">
<p>Quy trình này lặp lại ở mỗi bưu điện: hộp được mở, lộ ra phong bì bên trong; sau đó phong bì được đặt vào hộp mới, gửi tới bưu điện kế tiếp. Lưu ý rằng không bưu điện nào mở phong bì để đọc thư bên trong, vì họ không cần đọc nội dung đó.</p>
<img width="900px" src="intro/../assets/intro/1-23-layer2-forwarding4.png">
<p>Cuối cùng, bức thư đến Công ty B trong một chiếc hộp, và lần này Công ty B mở hộp, rồi mở phong bì, để lấy thư bên trong.</p>
<h2 id="multiple-headers-at-hosts-and-routers-nhiều-header-tại-host-và-router"><a class="header" href="#multiple-headers-at-hosts-and-routers-nhiều-header-tại-host-và-router"><strong>Multiple Headers at Hosts and Routers</strong> (Nhiều header tại Host và Router)</a></h2>
<p>Bây giờ khi đã có bức tranh đầy đủ về host và router, hãy xem lại quá trình <strong>bọc và gỡ header</strong> khi packet đi qua nhiều hop trong mạng.</p>
<p>Đầu tiên, <strong>Host A</strong> lấy thông điệp và đi xuống <strong>protocol stack</strong> (ngăn xếp giao thức), thêm header cho <strong>Layer 7</strong>, <strong>Layer 4</strong>, <strong>Layer 3</strong>, <strong>Layer 2</strong> và <strong>Layer 1</strong>. Giờ chúng ta có một packet được bọc header ở mọi tầng.</p>
<p><strong>Layer 1 protocol</strong> gửi các bit của packet này qua dây tới router đầu tiên trên đường đến đích.</p>
<img width="900px" src="intro/../assets/intro/1-24-multiheader1.png">
<p>Router này phải chuyển tiếp packet tới hop tiếp theo để packet đến được <strong>Host B</strong>. Chúng ta biết rằng việc chuyển tiếp packet trong mạng toàn cầu là nhiệm vụ của <strong>Layer 3</strong>. Do đó, router phải phân tích packet đến <strong>Layer 3</strong>.</p>
<p>Router đọc và gỡ bỏ header của <strong>Layer 1</strong> và <strong>Layer 2</strong>, để lộ ra header của <strong>Layer 3</strong> bên dưới. Router đọc header này để quyết định nơi chuyển tiếp packet tiếp theo.</p>
<img width="900px" src="intro/../assets/intro/1-25-multiheader2.png">
<p>Bây giờ, để gửi packet tới hop tiếp theo, router phải đi xuống stack một lần nữa, bọc header mới cho <strong>Layer 2</strong> và <strong>Layer 1</strong>, rồi gửi các bit qua dây tới hop tiếp theo.</p>
<img width="900px" src="intro/../assets/intro/1-26-multiheader3.png">
<p>Mẫu này lặp lại ở mỗi router: <strong>Layer 1</strong> và <strong>Layer 2</strong> được gỡ bỏ để lộ header <strong>Layer 3</strong>, sau đó header mới của Layer 2 và Layer 1 được bọc lại trước khi gửi packet đi. Lưu ý rằng không router nào đọc sâu hơn <strong>Layer 3 protocol</strong>, vì các tầng trên chỉ được phân tích bởi end host.</p>
<img width="900px" src="intro/../assets/intro/1-27-multiheader4.png">
<p>Cuối cùng, packet đến <strong>Host B</strong>, nơi nó được gỡ từng tầng một: Layer 1, 2, 3, 4, 7. Host B đã nhận thành công thông điệp!</p>
<img width="900px" src="intro/../assets/intro/1-28-multiheader5.png">
<p>Một hệ quả của mô hình phân tầng này là mỗi hop có thể sử dụng các giao thức khác nhau ở Layer 2 và Layer 1. Ví dụ: hop đầu tiên có thể truyền qua dây, và header Layer 2 và Layer 1 ban đầu do Host A và router đầu tiên sử dụng sẽ là giao thức có dây. Ngược lại, một hop sau đó có thể truyền qua liên kết không dây, và header Layer 2 và Layer 1 do các router ở hai đầu hop đó sử dụng sẽ là giao thức không dây.</p>
<img width="900px" src="intro/../assets/intro/1-29-layer2-peers.png">
<p>Nói chung, chúng ta đã nói rằng mỗi tầng chỉ cần giao tiếp với <strong>peer</strong> (thực thể ngang hàng) ở cùng tầng. Giờ đây, chúng ta có thể thấy điều này diễn ra ở tất cả các tầng:</p>
<ul>
<li>Ở <strong>Layer 4</strong> và <strong>Layer 7</strong>, hai host phải dùng cùng giao thức để gửi và nhận packet. Peer của host là host còn lại.</li>
<li>Ở <strong>Layer 1</strong> và <strong>Layer 2</strong>, router phải dùng cùng giao thức với router ở hop trước và hop sau, để nhận packet từ hop trước và gửi packet tới hop sau. Peer của router là các router lân cận trên đường đi.</li>
</ul>
<img width="900px" src="intro/../assets/intro/1-19-layers-host-routers.png">
<p><strong>Tóm lại:</strong> Mỗi router phân tích từ Layer 1 đến Layer 3, trong khi end host phân tích từ Layer 1 đến Layer 7.</p>
<img width="900px" src="intro/../assets/intro/1-30-packet-path.png">
<div style="break-before: page; page-break-before: always;"></div><h1 id="kiến-trúc-mạng-network-architecture"><a class="header" href="#kiến-trúc-mạng-network-architecture"><strong>Kiến trúc mạng</strong> (Network Architecture)</a></h1>
<h2 id="các-mô-hình-thiết-kế-design-paradigms"><a class="header" href="#các-mô-hình-thiết-kế-design-paradigms"><strong>Các mô hình thiết kế</strong> (Design Paradigms)</a></h2>
<p>Cho đến nay, chúng ta đã xem Internet từ góc nhìn <strong>bottom-up</strong> (từ dưới lên), bắt đầu từ các thành phần cơ bản để xây dựng bức tranh tổng thể. Trong phần này, chúng ta sẽ nhìn Internet từ góc nhìn <strong>top-down</strong> (từ trên xuống) và phân tích các lựa chọn kiến trúc tổng thể trong thiết kế.</p>
<p>Các <strong>Internet design paradigms</strong> (mô hình thiết kế Internet) này ảnh hưởng đến lý do tại sao Internet hoạt động như hiện nay, và cũng ảnh hưởng đến các ứng dụng mà chúng ta xây dựng trên nền tảng Internet. Những mô hình này là một sự thay đổi lớn so với cách các hệ thống từng được xây dựng trong lịch sử.</p>
<p>Những thiết kế này chỉ là một trong nhiều khả năng, và nhiều quyết định thiết kế đã được đưa ra từ nhiều năm trước, khi Internet chưa phát triển đến quy mô hiện tại. Các thiết kế khác vẫn tồn tại, và các cuộc tranh luận về thiết kế tối ưu vẫn tiếp diễn.</p>
<p>Ví dụ: Internet được xây dựng theo mô hình <strong>federated</strong> (liên kết liên bang – các nhà vận hành độc lập hợp tác với nhau), nhưng trong những năm gần đây, <strong>Software-Defined Networking (SDN)</strong> xuất hiện như một cách tiếp cận tập trung hơn để quản lý mạng.</p>
<p>Trong Internet ban đầu, các <strong>switch</strong> được thiết kế cố ý để “ngu” – chỉ chuyển tiếp dữ liệu mà không phân tích nội dung. Tuy nhiên, trong Internet hiện đại, kẻ tấn công có thể cố gắng làm quá tải switch bằng cách <strong>flood</strong> (phát tràn) dữ liệu vô nghĩa, và switch có thể cần cơ chế phát hiện điều này. Các nhà thiết kế Internet thời kỳ đầu, khi đưa ra mô hình hạ tầng “ngu”, đã không tính đến hệ quả bảo mật này.</p>
<h2 id="narrow-waist-eo-hẹp"><a class="header" href="#narrow-waist-eo-hẹp"><strong>Narrow Waist</strong> (Eo hẹp)</a></h2>
<p>Có thể tồn tại nhiều giao thức ở cùng một tầng. Ví dụ: ở <strong>Layer 7</strong>, chúng ta có thể dùng <strong>HTTP</strong> để phục vụ website, hoặc <strong>NTP</strong> để đồng bộ đồng hồ hệ thống, cả hai đều chạy trên cùng hạ tầng Internet. Hoặc ở <strong>Layer 2</strong>, chúng ta có thể dùng <strong>Ethernet</strong> cho mạng có dây, hoặc <strong>Wi-Fi</strong> cho mạng không dây.</p>
<p>Lưu ý rằng mặc dù có nhiều giao thức ở một tầng, bạn có thể chọn một <strong>stack</strong> (ngăn xếp) giao thức cụ thể cho ứng dụng của mình. Ví dụ: bạn có thể chọn <strong>HTTP over TCP over IP</strong>, và không cần dùng các giao thức Layer 7 hoặc Layer 4 khác. Khi đó, tất cả người dùng ứng dụng của bạn sẽ dùng cùng một stack.</p>
<img width="900px" src="intro/../assets/intro/1-31-multi-protocols.png">
<p>Nếu nhìn vào sơ đồ này, bạn sẽ thấy chỉ có <strong>một giao thức ở Layer 3</strong>. Đây chính là “<strong>narrow waist</strong>” (eo hẹp) cho phép kết nối Internet. Cuối cùng, mọi người trên Internet phải đồng ý sử dụng <strong>IP</strong> để các gói tin có thể được gửi đi khắp Internet.</p>
<h2 id="demultiplexing-phân-kênh"><a class="header" href="#demultiplexing-phân-kênh"><strong>Demultiplexing</strong> (Phân kênh)</a></h2>
<p><em>(Phần này trong bản gốc chưa được viết đầy đủ – TODO)</em></p>
<img width="900px" src="intro/../assets/intro/1-32-demultiplex.png">
<img width="500px" src="intro/../assets/intro/1-33-layer3-demultiplex.png">
<img width="700px" src="intro/../assets/intro/1-34-layer4-demultiplex.png">
<img width="700px" src="intro/../assets/intro/1-35-demultiplex-headers.png">
<img width="900px" src="intro/../assets/intro/1-36-ports.png">
<p>Cần cẩn thận với thuật ngữ. Trong mạng máy tính, <strong>port</strong> có thể chỉ hai khái niệm khác nhau:</p>
<ul>
<li><strong>Physical port</strong> (cổng vật lý): vị trí thực tế để cắm dây mạng vào switch.</li>
<li><strong>Logical port</strong> (cổng logic): một số trong <strong>Layer 4 header</strong> để phân biệt gói tin thuộc về ứng dụng nào.</li>
</ul>
<img width="700px" src="intro/../assets/intro/1-37-logical-physical-port.png">
<p><strong>Lưu ý:</strong> Thuật ngữ <strong>socket</strong> chỉ cơ chế của hệ điều hành (OS) để kết nối một ứng dụng với <strong>networking stack</strong> (ngăn xếp mạng) trong OS. Khi một ứng dụng mở một socket, socket đó được gán với một số cổng logic. Khi OS nhận một gói tin, nó dùng số cổng để chuyển gói tin tới socket tương ứng.</p>
<img width="900px" src="intro/../assets/intro/1-38-layers-in-os1.png">
<img width="900px" src="intro/../assets/intro/1-39-layers-in-os2.png">
<img width="900px" src="intro/../assets/intro/1-40-layers-in-os3.png">
<h2 id="nguyên-tắc-end-to-end-end-to-end-principle"><a class="header" href="#nguyên-tắc-end-to-end-end-to-end-principle"><strong>Nguyên tắc End-to-End</strong> (End-to-End Principle)</a></h2>
<p>Tại sao chúng ta thiết kế Internet với cấu trúc phân tầng như hiện nay? Tại sao chỉ các <strong>host</strong> hiểu <strong>Layer 4</strong> và <strong>Layer 7</strong>, còn các <strong>router</strong> thì không?</p>
<p><strong>End-to-end principle</strong> (nguyên tắc đầu-cuối) đưa ra định hướng và triết lý cho việc thiết kế Internet. <strong>David D. Clark</strong>, nhà khoa học tại MIT và thành viên <strong>Internet Architecture Board</strong>, là người đóng góp lớn cho nguyên tắc này. Hai bài báo của ông, <em>&quot;End-to-End Arguments in System Design&quot;</em> (1981) và <em>&quot;The Design Philosophy of the DARPA Internet Protocols&quot;</em> (1988), có ảnh hưởng sâu rộng đến triết lý thiết kế Internet.</p>
<p>Nguyên tắc end-to-end định hướng tranh luận về việc chức năng nào nên và không nên được triển khai trong mạng. Nguyên tắc này khá rộng và có nhiều ứng dụng, nhưng ở đây chúng ta tập trung vào câu hỏi: <strong>Có nên triển khai tính tin cậy (Layer 4) trong mạng, hay chỉ ở các end host?</strong></p>
<p>Giả sử một giao thức đơn giản để đảm bảo tin cậy: Host A muốn gửi 10 gói tin tới Host B, đánh số từ 1 đến 10. Mục tiêu là B nhận đủ tất cả gói, hoặc phát hiện thiếu gói và báo lỗi (bỏ qua việc khôi phục lỗi).</p>
<p><strong>Nếu triển khai tính tin cậy trong mạng:</strong> Mỗi router phải hiểu Layer 4 ngoài Layer 1–3. Router trung gian phải đảm bảo gửi tin cậy tới <strong>next hop</strong> (bước nhảy tiếp theo), và nếu mất gói, router phải gửi lại. Host không kiểm tra, mà tin tưởng mạng đảm bảo tất cả gói được nhận.</p>
<img width="900px" src="intro/../assets/intro/1-41-reliability-in-network.png">
<p>Nhược điểm: Host phải <strong>trust</strong> (tin tưởng) mạng. Nếu một router bị lỗi và làm mất gói, host không thể làm gì.</p>
<img width="900px" src="intro/../assets/intro/1-42-buggy-reliability-in-network.png">
<p><strong>Nếu triển khai tính tin cậy ở end host (end-to-end approach):</strong> Mạng có thể làm mất gói, và host sẽ tự kiểm tra, xác nhận và xử lý.</p>
<img width="900px" src="intro/../assets/intro/1-43-reliability-in-endhost.png">
<p>Ưu điểm: Quyền kiểm soát nằm ở host. Nếu host bị lỗi, họ có thể tự sửa. Nói chung, khi lập trình, tốt hơn là bạn tự kiểm soát tính đúng đắn thay vì phụ thuộc vào người khác (và không thể sửa lỗi của họ).</p>
<p>So sánh hai cách: Nếu dựa vào mạng, ta không thể đảm bảo tin cậy tuyệt đối nếu mạng bị lỗi. Cuối cùng, host vẫn phải làm kiểm tra end-to-end.</p>
<p>Trong Internet cũ, mỗi liên kết đều triển khai tính tin cậy. Nhưng Internet hiện đại chỉ cung cấp <strong>best-effort</strong> (nỗ lực tối đa, không đảm bảo), và buộc end host triển khai tính tin cậy – phù hợp với nguyên tắc end-to-end.</p>
<p><strong>Tóm lại:</strong> Một số yêu cầu ứng dụng phải được triển khai end-to-end để đảm bảo tính đúng đắn. Việc triển khai end-to-end là đủ, không cần hỗ trợ thêm từ mạng. Thêm chức năng vào mạng sẽ làm tăng độ phức tạp và chi phí mà không cải thiện kết quả.</p>
<p>Lưu ý rằng <strong>end-to-end principle</strong> (nguyên tắc đầu-cuối) không phải là một định lý hay một chứng minh luôn đúng. Đây là một nguyên tắc định hướng và một lập luận mang tính triết lý, và các nhà thiết kế khác nhau có thể đưa ra những lập luận ủng hộ hoặc phản đối nguyên tắc này.</p>
<p>Dưới đây là một ví dụ cho thấy nguyên tắc end-to-end không phải là một quy tắc tuyệt đối. Mặc dù nguyên tắc này nói rằng chỉ nên triển khai <strong>reliability</strong> (tính tin cậy) ở <strong>end host</strong> (máy đầu cuối), chúng ta vẫn có thể bổ sung thêm một chút tính tin cậy trong mạng, bên cạnh việc kiểm tra end-to-end. Điều này có thể hữu ích nếu chúng ta có các liên kết kém ổn định. Giả sử có 10 liên kết giữa A và B, và mỗi liên kết có xác suất lỗi 10%. Khi đó, mỗi lần gửi gói tin, xác suất bị mất gói là 65%. Tuy nhiên, nếu mỗi <strong>router</strong> được chỉnh sửa để gửi hai bản sao của gói tin nhằm tăng độ tin cậy, thì mỗi liên kết chỉ còn xác suất lỗi 0,1%, và gói tin chỉ còn 1% khả năng bị mất. Các liên kết <strong>wireless</strong> (không dây) đôi khi cũng triển khai cơ chế tin cậy để giảm tỷ lệ lỗi và cải thiện hiệu năng cho end host.</p>
<p>Nguyên tắc end-to-end cũng mở rộng sang các lĩnh vực khác. Ví dụ, trong bảo mật, nguyên tắc này có thể nói rằng hai end host khi giao tiếp nên <strong>encrypt</strong> (mã hóa) thông điệp của mình ngay tại end host, thay vì tại các điểm trung gian trong mạng.</p>
<p>Lập luận end-to-end theo lời của Clark:</p>
<blockquote>
<p>“Chức năng đang được xét chỉ có thể được triển khai đầy đủ và chính xác với sự hiểu biết và hỗ trợ của ứng dụng tại các điểm cuối. Do đó, việc cung cấp chức năng đó như một tính năng của chính hệ thống truyền thông là không khả thi. Đôi khi, một phiên bản chưa hoàn chỉnh của chức năng được cung cấp bởi hệ thống truyền thông có thể hữu ích như một cách cải thiện hiệu năng.”</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="thiết-kế-chia-sẻ-tài-nguyên-designing-resource-sharing"><a class="header" href="#thiết-kế-chia-sẻ-tài-nguyên-designing-resource-sharing"><strong>Thiết kế chia sẻ tài nguyên</strong> (Designing Resource Sharing)</a></h1>
<h2 id="chia-sẻ-tài-nguyên-statistical-multiplexing-ghép-kênh-thống-kê"><a class="header" href="#chia-sẻ-tài-nguyên-statistical-multiplexing-ghép-kênh-thống-kê"><strong>Chia sẻ tài nguyên: Statistical Multiplexing</strong> (Ghép kênh thống kê)</a></h2>
<p>Các <strong>link</strong> (liên kết) và <strong>switch</strong> (bộ chuyển mạch) trên Internet đều có <strong>finite capacity</strong> (dung lượng hữu hạn). Một vấn đề thiết kế quan trọng cần giải quyết là: <strong>Làm thế nào để chia sẻ các tài nguyên này giữa những người dùng Internet khác nhau?</strong></p>
<p>Hãy mô hình hóa vấn đề rõ hơn. Nhớ rằng một <strong>flow</strong> (luồng) là một chuỗi <strong>packet</strong> (gói tin) được trao đổi giữa hai <strong>end host</strong> (máy đầu cuối), ví dụ: một cuộc gọi video giữa bạn và bạn bè. Internet cần hỗ trợ nhiều flow đồng thời, mặc dù dung lượng có hạn.</p>
<img width="600px" src="intro/../assets/intro/1-44-multiple-flows.png">
<p>Chúng ta thường nói rằng tài nguyên mạng được <strong>statistically multiplexed</strong> (ghép kênh thống kê), nghĩa là chúng ta sẽ phân bổ tài nguyên cho người dùng một cách <strong>dynamic</strong> (động) dựa trên nhu cầu của họ, thay vì chia cố định một phần tài nguyên cho mỗi người dùng.</p>
<img width="900px" src="intro/../assets/intro/1-45-statistical-multiplex.png">
<p>Ví dụ tương tự: máy tính cá nhân của bạn không chia sẵn một nửa CPU cho Firefox và một nửa cho Zoom, rồi chỉ cho mỗi ứng dụng dùng phần của mình. Thay vào đó, máy tính phân bổ tài nguyên động cho các ứng dụng tùy theo nhu cầu.</p>
<p>Ghép kênh thống kê hiện diện ở khắp nơi trong khoa học máy tính. Ví dụ: trong <strong>cloud computing</strong> (điện toán đám mây), các công ty khác nhau có thể chia sẻ tài nguyên trong một <strong>datacenter</strong> (trung tâm dữ liệu) một cách động.</p>
<p>Ghép kênh thống kê là một cách hiệu quả để chia sẻ tài nguyên mạng, vì nhu cầu của người dùng thay đổi theo thời gian. Bạn có thể không dùng liên tục 10 Mbps băng thông mỗi giây, 24 giờ/ngày. Bạn có thể dùng nhiều hơn khi thức và ít hơn khi ngủ.</p>
<p>Tiền đề giúp ghép kênh thống kê hoạt động là: <strong>Trên thực tế, đỉnh của tổng nhu cầu nhỏ hơn nhiều so với tổng của các đỉnh nhu cầu riêng lẻ.</strong></p>
<p>Giả sử có hai người dùng A và B. Chúng ta vẽ đồ thị nhu cầu của từng người theo thời gian.</p>
<img width="700px" src="intro/../assets/intro/1-46-demand-over-time.png">
<p><strong>Chiến lược kém hiệu quả</strong> (không ghép kênh thống kê) là cộng đỉnh nhu cầu của từng người. Ta lấy đỉnh nhu cầu của A và B, rồi cộng lại.</p>
<img width="900px" src="intro/../assets/intro/1-47-sum-of-peak1.png">
<p>Nếu phân bổ dung lượng bằng tổng này, chắc chắn đáp ứng được nhu cầu. Ví dụ: đỉnh nhu cầu của A là X, ta cấp X cho A; đỉnh của B là Y, ta cấp Y cho B. Nhưng cách này lãng phí, vì đỉnh của A và B không xảy ra cùng lúc.</p>
<img width="400px" src="intro/../assets/intro/1-48-sum-of-peak2.png">
<p><strong>Chiến lược tốt hơn</strong> (ghép kênh thống kê) là tính <strong>aggregate demand</strong> (tổng nhu cầu) bằng cách cộng nhu cầu của A và B tại từng thời điểm. Ví dụ: nhu cầu lúc 10h sáng = nhu cầu của A lúc 10h + nhu cầu của B lúc 10h. Sau đó, ta tìm đỉnh của tổng nhu cầu này.</p>
<img width="900px" src="intro/../assets/intro/1-49-peak-of-sum1.png">
<p>Nếu phân bổ dung lượng bằng đỉnh của tổng nhu cầu, ta không thể chia cố định cho từng người. Nhưng bằng cách thay đổi động lượng cấp cho mỗi người theo thời gian, ta vẫn đáp ứng được nhu cầu, dù tổng dung lượng ít hơn.</p>
<img width="400px" src="intro/../assets/intro/1-50-peak-of-sum2.png">
<p>Cách tiếp cận này cho phép hỗ trợ cùng số người dùng với dung lượng ít hơn (tiết kiệm chi phí, sử dụng tài nguyên hiệu quả hơn). Với nhiều phân phối, đỉnh của tổng nhu cầu gần bằng tổng nhu cầu trung bình, nhỏ hơn nhiều so với tổng các đỉnh riêng lẻ.</p>
<p>Trong thực tế, mạng không được thiết kế để đáp ứng <strong>worst case</strong> (trường hợp xấu nhất) khi tất cả cùng đạt đỉnh. Thay vào đó, ta chia sẻ tài nguyên động và hy vọng các đỉnh không trùng nhau. Nếu đỉnh trùng nhau, packet có thể bị trễ hoặc bị drop (rớt) — nhớ lại hàng đợi ở liên kết. Dù vậy, chúng ta chọn ghép kênh thống kê để dùng tài nguyên hiệu quả hơn, chấp nhận hệ quả là đôi khi có đỉnh trùng.</p>
<p>Cuối cùng, ghép kênh thống kê là một lựa chọn thiết kế có <strong>trade-off</strong> (đánh đổi), và người dùng khác nhau có thể chọn khác nhau. Ví dụ: các sàn giao dịch tài chính đôi khi xây mạng riêng để đáp ứng nhu cầu đỉnh, vì họ ưu tiên đảm bảo kết nối trong giờ cao điểm và có thể chi trả chi phí.</p>
<h2 id="chia-sẻ-tài-nguyên-circuit-switching-vs-packet-switching"><a class="header" href="#chia-sẻ-tài-nguyên-circuit-switching-vs-packet-switching"><strong>Chia sẻ tài nguyên: Circuit Switching vs. Packet Switching</strong></a></h2>
<p>Chúng ta đã biết có thể dùng ghép kênh thống kê để quyết định dung lượng cần xây dựng. Câu hỏi tiếp theo: <strong>Làm thế nào để phân bổ tài nguyên động giữa người dùng?</strong></p>
<p>Ví dụ tương tự: một nhà hàng đông khách và số bàn có hạn. Có hai cách phân bổ bàn: đặt chỗ trước hoặc phục vụ theo thứ tự đến trước.</p>
<p>Hai cách chia sẻ tài nguyên mạng cũng tương tự:</p>
<ul>
<li><strong>Best-effort</strong>: Mọi người gửi dữ liệu vào mạng mà không đặt chỗ, và hy vọng mọi thứ ổn. Không có gì đảm bảo băng thông đủ cho nhu cầu.</li>
<li>Thiết kế chuẩn cho best-effort là <strong>packet switching</strong> (chuyển mạch gói). Switch xử lý từng packet độc lập và chuyển nó gần hơn tới đích. Các switch không quan tâm đến flow hay đặt chỗ.</li>
</ul>
<p>Ngoài việc packet độc lập với nhau, các switch cũng độc lập với nhau. Khi packet đi qua nhiều switch, mỗi switch xử lý nó riêng, không phối hợp.</p>
<img width="700px" src="intro/../assets/intro/1-51-best-effort.png">
<ul>
<li><strong>Reservations</strong> (đặt chỗ): Khi bắt đầu một flow, người dùng yêu cầu và đặt trước băng thông cần thiết. Sau khi gửi xong dữ liệu, tài nguyên được giải phóng cho người khác.</li>
</ul>
<p>Thiết kế chuẩn cho reservations, được nghiên cứu và áp dụng trong công nghiệp, là <strong>circuit switching</strong> (chuyển mạch kênh).</p>
<p>Khi bắt đầu một flow, end host xác định một đường đi (chuỗi switch và link) qua mạng, dùng một <strong>routing algorithm</strong> (thuật toán định tuyến). (Chúng ta sẽ học định tuyến sau, tạm coi là “ma thuật” ở đây.)</p>
<p>Sau đó, nguồn gửi một <strong>reservation request message</strong> (thông điệp yêu cầu đặt chỗ) tới đích. Trên đường đi, mỗi switch nhận yêu cầu này. Nếu tất cả switch chấp nhận, đặt chỗ được thiết lập, và một <strong>circuit</strong> (kênh) giữa nguồn và đích được hình thành.</p>
<img width="700px" src="intro/../assets/intro/1-52-reservations.png">
<p>Khi tất cả switch xác nhận, dữ liệu có thể được gửi. Khi flow kết thúc, nguồn gửi một <strong>teardown message</strong> (thông điệp hủy kênh) tới đích. Trên đường đi, mỗi switch nhận thông điệp và giải phóng dung lượng.</p>
<img width="700px" src="intro/../assets/intro/1-53-reservation-teardown.png">
<p><strong>Lưu ý:</strong> Từ “circuit” xuất phát từ mạng điện thoại, nơi hai người gọi cho nhau bằng cách thiết lập một kênh như vậy.</p>
<p>Nhớ rằng, cả circuit switching và packet switching đều áp dụng ghép kênh thống kê. Khác biệt chính là <strong>granularity</strong> (độ chi tiết) khi phân bổ tài nguyên:</p>
<ul>
<li>Circuit switching: theo flow, có đặt chỗ.</li>
<li>Packet switching: theo packet, best-effort.</li>
</ul>
<p>Ngay cả trong circuit switching, chúng ta vẫn phân bổ tài nguyên động dựa trên đặt chỗ, chứ không đặt trước cho mọi flow có thể xảy ra.</p>
<img width="600px" src="intro/../assets/intro/1-54-circuit-packet-multiplexing.png">
<h2 id="circuit-switching-vs-packet-switching-các-yếu-tố-đánh-đổi-trade-offs"><a class="header" href="#circuit-switching-vs-packet-switching-các-yếu-tố-đánh-đổi-trade-offs"><strong>Circuit Switching vs. Packet Switching: Các yếu tố đánh đổi</strong> (Trade-offs)</a></h2>
<p>Chúng ta hiện có hai cách tiếp cận để chia sẻ tài nguyên trên Internet. Cách nào tốt hơn? Điều đó phụ thuộc vào tiêu chí mà chúng ta dùng để đánh giá.</p>
<p>Có bốn khía cạnh chính để so sánh hai cách tiếp cận này:</p>
<p><strong>1. Đây có phải là một abstraction (hoặc API) tốt để mạng cung cấp cho lập trình viên ứng dụng không?</strong></p>
<p><strong>Circuit switching</strong> cung cấp một abstraction hữu ích hơn cho lập trình viên, vì nó đảm bảo <strong>reserved bandwidth</strong> (băng thông được đặt trước). Điều này giúp lập trình viên dự đoán và hiểu rõ hành vi của hệ thống hơn (giả sử mọi thứ diễn ra suôn sẻ). Ví dụ tương tự: đặt trước một máy chủ trên <strong>cloud</strong> để chạy tác vụ. Lập trình viên dễ dàng ước lượng hiệu năng hơn nếu biết cấu hình máy mình nhận được. Nếu không biết, tác vụ vẫn có thể chạy, nhưng hiệu năng sẽ khó dự đoán.</p>
<p>Circuit switching cũng hữu ích nếu bạn là <strong>network operator</strong> (nhà vận hành mạng) cần phân bổ tài nguyên cho người dùng. Bạn biết chính xác mỗi người dùng yêu cầu bao nhiêu băng thông và có thể tính phí phù hợp. Nếu không có đảm bảo, việc xây dựng mô hình kinh doanh trực quan sẽ khó hơn.</p>
<p><strong>2. Cách tiếp cận này có hiệu quả ở quy mô lớn không? Có tận dụng hết băng thông khả dụng hay lãng phí?</strong></p>
<p><strong>Packet switching</strong> thường hiệu quả hơn. Mức độ hơn bao nhiêu phụ thuộc vào <strong>burstiness</strong> (mức độ bùng nổ) của nguồn lưu lượng.</p>
<ul>
<li>Nếu mỗi bên gửi dữ liệu với tốc độ <strong>constant rate</strong> (ổn định) theo thời gian, cả circuit switching và packet switching đều tận dụng hết dung lượng.</li>
</ul>
<img width="900px" src="intro/../assets/intro/1-55-smooth.png">
<ul>
<li>Ngược lại, nếu tốc độ gửi thay đổi theo thời gian, packet switching tận dụng băng thông tốt hơn.</li>
</ul>
<img width="900px" src="intro/../assets/intro/1-56-bursty.png">
<p>Ví dụ: với <strong>reservations</strong> (đặt chỗ), ba flow phải đặt lần lượt 12, 11 và 13 Mbps. Một yêu cầu sẽ bị từ chối vì tổng chỉ có 30 Mbps. Cách này lãng phí băng thông ở hai điểm:</p>
<ol>
<li>Flow đặt 12 Mbps không dùng hết phần lớn thời gian.</li>
<li>Nếu flow 12 Mbps và 11 Mbps được chấp nhận, còn dư 7 Mbps không ai dùng.</li>
</ol>
<p>Ngược lại, với packet switching (gửi packet khi đến), tổng băng thông dùng tại mọi thời điểm không vượt quá 30 Mbps, và ta có thể hỗ trợ tất cả flow.</p>
<p><strong>Burstiness</strong> được định nghĩa là tỉ lệ giữa <strong>peak rate</strong> (tốc độ đỉnh) và <strong>average rate</strong> (tốc độ trung bình). Không có ngưỡng rõ ràng để phân loại smooth hay bursty — đây là các thuật ngữ mô tả.</p>
<ul>
<li><strong>Voice call</strong>: thường có tỉ lệ mượt hơn, khoảng 3:1 → phù hợp với circuit switching (điện thoại cố định).</li>
<li><strong>Web browsing</strong>: thường bursty hơn, khoảng 100:1.</li>
</ul>
<p>Một lý do khác packet switching hiệu quả hơn: circuit switching tốn thời gian <strong>setup</strong> và <strong>teardown</strong> kênh, đặc biệt lãng phí với flow rất ngắn (ví dụ: tải một file nhỏ).</p>
<p><strong>3. Khả năng xử lý sự cố ở quy mô lớn</strong></p>
<p><strong>Packet switching</strong> xử lý sự cố tốt hơn. Nếu một <strong>router</strong> hỏng, ta chỉ cần gửi packet theo đường khác (routing algorithm sẽ xử lý). <strong>End host</strong> không cần thay đổi gì.</p>
<p>Ngược lại, với circuit switching, nếu router trên đường đi hỏng, mạng vẫn phải tìm đường mới, nhưng end host phải làm nhiều việc hơn: phát hiện sự cố, gửi lại yêu cầu đặt chỗ, giải phóng kênh cũ. Nếu yêu cầu mới bị từ chối thì sao?</p>
<p>Cách này <strong>scale</strong> kém: nếu một router hỏng và hàng triệu flow đi qua nó, hàng triệu yêu cầu đặt chỗ phải được thiết lập lại cùng lúc.</p>
<p><strong>4. Độ phức tạp khi triển khai ở quy mô lớn</strong></p>
<p>Thiết kế circuit switching kéo theo nhiều câu hỏi phức tạp:</p>
<ul>
<li>Làm sao router biết đặt chỗ thành công? Khi router 2 đồng ý, làm sao biết router 3 và 4 cũng đồng ý? (Giải pháp: gửi <strong>confirmation</strong> ngược lại để xác nhận.)</li>
<li>Nếu <strong>reservation request</strong> bị mất giữa đường? (Giải pháp: đặt <strong>timer</strong>, nếu không xác nhận kịp thì xóa đặt chỗ, end host thử lại.)</li>
<li>Nếu yêu cầu được chấp nhận nhưng <strong>confirmation</strong> bị mất trên đường về?</li>
<li>Nếu bị từ chối, end host nên thử lại với băng thông nhỏ hơn, hay chờ rồi thử lại? Router có nên gợi ý mức băng thông khả dụng?</li>
</ul>
<p>Vấn đề cốt lõi khiến circuit switching phức tạp là <strong>state consensus</strong> (đồng thuận trạng thái). Tất cả router phải lưu trạng thái bổ sung và đồng ý về trạng thái đó.</p>
<p>Bạn có thể đã nghe về <strong>Paxos protocol</strong> — thuật toán đồng thuận phức tạp, thường chỉ chạy trên 4–5 server. Circuit switching yêu cầu chạy điều này ở quy mô Internet, với hàng triệu router và flow.</p>
<p><strong>Tóm lại:</strong></p>
<ul>
<li><strong>Circuit switching</strong>: hiệu năng tốt hơn cho ứng dụng nhờ băng thông đặt trước, hành vi dễ dự đoán.</li>
<li><strong>Packet switching</strong>: chia sẻ băng thông hiệu quả hơn, không tốn thời gian khởi tạo, phục hồi sự cố dễ hơn, triển khai đơn giản hơn.</li>
</ul>
<h2 id="circuit-switching-vs-packet-switching-trong-thực-tế"><a class="header" href="#circuit-switching-vs-packet-switching-trong-thực-tế"><strong>Circuit Switching vs. Packet Switching trong thực tế</strong></a></h2>
<p>Trên Internet hiện đại, <strong>packet switching</strong> là mặc định.</p>
<p><strong>Circuit switching</strong> chỉ dùng trong một số trường hợp hạn chế:</p>
<ul>
<li><strong>RSVP (Resource Reservation Protocol)</strong> trong mạng cục bộ nhỏ, cho phép router (không phải end host) đặt băng thông giữa nhau.</li>
<li><strong>Dedicated circuits</strong> (ví dụ: MPLS circuits, leased lines): doanh nghiệp mua băng thông Internet (có thể kèm hạ tầng vật lý) dành riêng cho mình. Chi phí cao hơn nhiều so với kết nối Internet tiêu chuẩn.</li>
</ul>
<p>Các dedicated circuits này triển khai ở quy mô nhỏ hơn nhiều so với ý tưởng circuit switching toàn Internet. Thường được thiết lập thủ công, tồn tại lâu dài (nhiều năm), và ở cấp độ công ty, không phải từng flow.</p>
<p><strong>Lịch sử ngắn gọn:</strong></p>
<ul>
<li>1970–1980: Internet được thiết kế dưới dạng packet switching, phục vụ nghiên cứu do chính phủ tài trợ.</li>
<li>1990: Khi Internet thương mại hóa, nhiều người nghĩ cần chuyển sang circuit switching, dự đoán ứng dụng chính sẽ là thoại và truyền hình trực tiếp (nhu cầu băng thông mượt, phù hợp circuit switching). ISP cũng nghĩ circuit switching dễ xây dựng mô hình kinh doanh hơn.</li>
</ul>
<p>Nhiều nghiên cứu và tiêu chuẩn đã được đề xuất, nhưng thất bại vì các lý do đã nêu. Thêm vào đó, ứng dụng thúc đẩy Internet lại là email và web, không phải thoại và TV.</p>
<p><strong>Hệ quả thú vị:</strong> Người dùng và lập trình viên đã thích nghi với packet switching. Ví dụ: khi xem video mà kết nối kém, ứng dụng sẽ tự giảm chất lượng video — điều mà truyền hình quảng bá không làm. Đây là minh chứng cho việc công nghệ có thể thay đổi hành vi người dùng.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="links"><a class="header" href="#links"><strong>Links</strong></a></h1>
<h2 id="properties-of-links-các-đặc-tính-của-links"><a class="header" href="#properties-of-links-các-đặc-tính-của-links"><strong>Properties of Links</strong> (Các đặc tính của links)</a></h2>
<p>Bây giờ khi chúng ta đã có bức tranh tổng thể về cách các tầng của Internet được xây dựng, hãy tập trung vào cách một <strong>packet</strong> (gói tin) được gửi qua một <strong>link</strong>.</p>
<p>Có ba đặc tính mà chúng ta có thể dùng để đo hiệu năng của một liên kết:</p>
<ul>
<li>
<p><strong>Bandwidth</strong> (băng thông) của một liên kết cho biết số bit có thể gửi qua liên kết trong một đơn vị thời gian. Hiểu một cách trực quan, đây là “tốc độ” của liên kết. Nếu coi liên kết như một ống dẫn nước, băng thông chính là độ rộng của ống. Ống càng rộng thì mỗi giây càng có thể dẫn nhiều nước hơn. Băng thông thường được đo bằng <strong>bit per second</strong> (bit mỗi giây), ví dụ: 5 Gbps = 5 tỷ bit mỗi giây.</p>
</li>
<li>
<p><strong>Propagation delay</strong> (độ trễ lan truyền) của một liên kết cho biết thời gian để một bit di chuyển hết chiều dài liên kết. Trong phép so sánh ống nước, đây là chiều dài của ống. Ống càng ngắn thì nước càng mất ít thời gian để đến đầu bên kia. Độ trễ lan truyền được đo bằng đơn vị thời gian (ví dụ: nanosecond, millisecond).</p>
</li>
<li>
<p>Nếu nhân băng thông với độ trễ lan truyền, ta được <strong>Bandwidth-Delay Product (BDP)</strong>. Hiểu đơn giản, đây là <strong>capacity</strong> (dung lượng) của liên kết, tức là số bit tồn tại trên liên kết tại một thời điểm. Trong phép so sánh ống nước, nếu ta làm đầy ống và “đóng băng” thời gian, dung lượng của ống chính là lượng nước có trong ống tại thời điểm đó.</p>
</li>
</ul>
<img width="600px" src="intro/../assets/intro/1-57-link-properties.png">
<p><strong>Lưu ý:</strong> Đôi khi bạn sẽ thấy thuật ngữ <strong>latency</strong> (độ trễ). Trong ngữ cảnh của một liên kết, latency chính là propagation delay, mặc dù từ này cũng được dùng trong các ngữ cảnh khác (ví dụ: độ trễ từ end host đến end host qua nhiều liên kết). Latency không có định nghĩa chính thức duy nhất và phụ thuộc vào ngữ cảnh.</p>
<h2 id="timing-diagram-biểu-đồ-thời-gian"><a class="header" href="#timing-diagram-biểu-đồ-thời-gian"><strong>Timing Diagram</strong> (Biểu đồ thời gian)</a></h2>
<p>Giả sử chúng ta có một liên kết với băng thông 1 Mbps = 1 triệu bit mỗi giây, và độ trễ lan truyền 1 ms = 0,001 giây.</p>
<p>Chúng ta muốn gửi một packet 100 byte = 800 bit qua liên kết này. Mất bao lâu để gửi xong packet, tính từ lúc bit đầu tiên được gửi đến lúc bit cuối cùng được nhận?</p>
<p>Để trả lời, ta có thể vẽ một <strong>timing diagram</strong>. Cột bên trái là <strong>sender</strong> (bên gửi), cột bên phải là <strong>recipient</strong> (bên nhận). Thời gian bắt đầu từ 0 và tăng dần khi ta di chuyển xuống biểu đồ.</p>
<img width="300px" src="intro/../assets/intro/1-58-timing1.png">
<p>Xét bit đầu tiên: Với băng thông 1.000.000 bit/giây, mất 1/1.000.000 = 0,000001 giây để đặt một bit lên liên kết. Tại thời điểm 0,000001 giây, liên kết có một bit ở đầu bên gửi.</p>
<p>Bit này mất 0,001 giây để di chuyển hết liên kết (propagation delay), nên tại thời điểm 0,000001 + 0,001 giây, bit đầu tiên đến được bên nhận.</p>
<img width="900px" src="intro/../assets/intro/1-59-timing2.png">
<p>Xét bit cuối cùng: Như trên, mất 0,000001 giây để đặt một bit lên liên kết. Có 800 bit cần gửi, nên bit cuối cùng được đặt lên liên kết tại thời điểm:</p>
<p>$$800 \cdot 0,000001 = 0,0008 \ \text{giây}$$</p>
<p>Bit này cũng mất 0,001 giây để truyền, nên tại thời điểm 0,0008 + 0,001 giây, bit cuối cùng đến bên nhận. Đây là lúc ta nói packet đã đến nơi.</p>
<img width="900px" src="intro/../assets/intro/1-60-timing3.png">
<h2 id="packet-delay-Độ-trễ-gói-tin"><a class="header" href="#packet-delay-Độ-trễ-gói-tin"><strong>Packet Delay</strong> (Độ trễ gói tin)</a></h2>
<p>Tổng quát hơn, <strong>packet delay</strong> là thời gian để gửi toàn bộ một packet, tính từ lúc bit đầu tiên được đặt lên dây đến lúc bit cuối cùng được nhận ở đầu bên kia. Độ trễ này bằng tổng của <strong>transmission delay</strong> (độ trễ truyền) và <strong>propagation delay</strong>.</p>
<ul>
<li><strong>Transmission delay</strong>: thời gian để đặt tất cả bit của packet lên dây. Trong ví dụ, giá trị này là:</li>
</ul>
<p>$$800 \cdot \frac{1}{1{,}000{,}000}$$</p>
<p>Nói chung, transmission delay = kích thước packet / băng thông liên kết.</p>
<p>Vì transmission delay phụ thuộc vào băng thông, ta có thể tính packet delay dựa trên hai đặc tính của liên kết: bandwidth và propagation delay.</p>
<h2 id="bandwidth-và-propagation-delay-sự-đánh-đổi-trade-offs"><a class="header" href="#bandwidth-và-propagation-delay-sự-đánh-đổi-trade-offs"><strong>Bandwidth và Propagation Delay: Sự đánh đổi</strong> (Trade-offs)</a></h2>
<p>Xét hai liên kết:</p>
<ul>
<li><strong>Link 1</strong>: bandwidth 10 Mbps, propagation delay 10 ms.</li>
<li><strong>Link 2</strong>: bandwidth 1 Mbps, propagation delay 1 ms.</li>
</ul>
<p>Liên kết nào tốt hơn? Câu trả lời phụ thuộc vào packet bạn gửi.</p>
<ul>
<li>Nếu gửi một packet 10 byte: thời gian đặt packet lên dây là không đáng kể, propagation delay là yếu tố chính. Link 2 có propagation delay ngắn hơn, nên tốt hơn.</li>
<li>Nếu gửi một packet 10.000 byte: transmission delay là yếu tố chính, và ta chọn Link 1 vì băng thông cao hơn. Tính toán cho thấy: Link 1 mất khoảng 18 ms, Link 2 mất khoảng 81 ms.</li>
</ul>
<p>Ví dụ thực tế:</p>
<ul>
<li>Nếu chất lượng video call kém → có thể do bandwidth không đủ (giảm propagation delay không giúp).</li>
<li>Nếu có độ trễ giữa lúc bạn nói và lúc người kia trả lời → có thể do propagation delay quá dài (tăng bandwidth không giúp).</li>
</ul>
<h2 id="pipe-diagram-biểu-đồ-ống"><a class="header" href="#pipe-diagram-biểu-đồ-ống"><strong>Pipe Diagram</strong> (Biểu đồ ống)</a></h2>
<p>Trước giờ, chúng ta vẽ timing diagram để biểu diễn thời điểm các sự kiện mạng xảy ra (ví dụ: khi bên nhận nhận được packet).</p>
<p>Một cách khác để hình dung packet được gửi qua mạng là vẽ các bit trên liên kết tại một thời điểm “đóng băng”. Cả hai cách đều truyền tải cùng thông tin, nhưng tùy ngữ cảnh, một cách có thể hữu ích hơn.</p>
<p>Để vẽ liên kết, ta tưởng tượng liên kết là một ống (giống phép so sánh nước) và vẽ ống dưới dạng hình chữ nhật:</p>
<ul>
<li><strong>Chiều rộng</strong> = propagation delay.</li>
<li><strong>Chiều cao</strong> = bandwidth.</li>
<li><strong>Diện tích</strong> = capacity của liên kết.</li>
</ul>
<img width="600px" src="intro/../assets/intro/1-61-pipe1.png">
<p>Giả sử ta muốn gửi một packet 50 byte qua liên kết. Trong biểu đồ ống, ta có thể minh họa một thời điểm đóng băng khi packet đang được gửi.</p>
<p>Packet được biểu diễn dưới dạng hình chữ nhật, trong đó chiều cao cho biết số byte được đặt lên dây trong một đơn vị thời gian. Mỗi bước thời gian, packet trượt sang phải trong ống. Cuối cùng, packet bắt đầu thoát ra khỏi ống, và ở mỗi bước thời gian, một cột của hình chữ nhật rời khỏi ống.</p>
<img width="900px" src="intro/../assets/intro/1-62-pipe2.png">
<img width="900px" src="intro/../assets/intro/1-63-pipe3.png">
<img width="900px" src="intro/../assets/intro/1-64-pipe4.png">
<p>Một sự thật không hiển nhiên: <strong>Packet transmission delay</strong> (độ trễ truyền gói tin) trong <strong>timing diagram</strong> (biểu đồ thời gian) tương ứng với <strong>chiều rộng</strong> của hình chữ nhật.</p>
<p>Để thấy tại sao, giả sử chúng ta có một <strong>link</strong> (liên kết) có thể gửi 5 bit mỗi giây, và chúng ta có một packet 20 bit. Trong timing diagram, có 11 giây giữa thời điểm bit đầu tiên và bit cuối cùng được gửi.</p>
<img width="900px" src="intro/../assets/intro/1-65-packet-delay-1.png">
<p>Trong <strong>pipe diagram</strong> (biểu đồ ống), mỗi giây, một cột gồm 5 bit “bước” vào ống. Chúng ta cần 4 cột để đưa toàn bộ packet vào ống, mất 4 giây. Điều này có nghĩa là chiều rộng của packet trong ống là 4 cột = 4 giây.</p>
<img width="900px" src="intro/../assets/intro/1-66-packet-delay-2.png">
<p>Pipe diagram cho phép chúng ta quan sát <strong>thời gian truyền packet</strong> trên cùng một trục với <strong>propagation delay</strong> (độ trễ lan truyền) và so sánh hai giá trị này.</p>
<p>Pipe diagram cũng hữu ích khi so sánh các liên kết khác nhau. Hãy xem cùng một packet di chuyển qua ba liên kết khác nhau.</p>
<img width="700px" src="intro/../assets/intro/1-67-different-pipes.png">
<p>Nếu chúng ta rút ngắn propagation delay, <strong>chiều rộng</strong> của ống ngắn lại. <strong>Chiều cao</strong> của ống giữ nguyên, và hình dạng của mỗi packet hình chữ nhật cũng giữ nguyên. (Hãy nhớ: chiều cao của packet = số bit được đưa vào ống mỗi đơn vị thời gian; chiều rộng của packet = thời gian để đưa toàn bộ bit vào ống.)</p>
<p>Quan sát khác: Chiều rộng packet giữ nguyên nghĩa là <strong>transmission delay</strong> (độ trễ truyền) không thay đổi. Ngoài ra, diện tích của liên kết giảm, cho thấy <strong>capacity</strong> (dung lượng) của liên kết giảm.</p>
<p>Khi tăng <strong>bandwidth</strong> (băng thông), chiều cao của ống tăng, cho thấy chúng ta có thể đưa nhiều bit vào ống hơn mỗi đơn vị thời gian.</p>
<p>Lúc này, hình dạng packet cũng thay đổi: packet cao hơn vì mỗi đơn vị thời gian có thể đưa nhiều bit hơn vào ống. Kết quả là chúng ta hoàn tất việc đưa packet vào ống nhanh hơn, nên <strong>chiều rộng</strong> của packet (transmission delay) giảm.</p>
<h2 id="overloaded-links-liên-kết-quá-tải"><a class="header" href="#overloaded-links-liên-kết-quá-tải"><strong>Overloaded Links</strong> (Liên kết quá tải)</a></h2>
<img width="700px" src="intro/../assets/intro/1-68-link1.png">
<p>Xem hình minh họa packet đến một <strong>switch</strong> (bộ chuyển mạch). Switch cần chuyển tiếp tất cả packet qua <strong>outgoing link</strong> (liên kết đầu ra). Trong trường hợp này, không có vấn đề gì vì switch có đủ khả năng xử lý mọi packet khi chúng đến.</p>
<img width="700px" src="intro/../assets/intro/1-69-link2.png">
<p>Còn trong hình này thì sao?</p>
<img width="700px" src="intro/../assets/intro/1-70-transient1.png">
<p>Về lâu dài, chúng ta có đủ khả năng để gửi tất cả packet ra ngoài, nhưng tại một thời điểm cụ thể, có hai packet đến cùng lúc, và chúng ta chỉ có thể gửi một. Đây được gọi là <strong>transient overload</strong> (quá tải tạm thời), và nó cực kỳ phổ biến ở các switch trên Internet.</p>
<p>Để xử lý quá tải tạm thời, switch duy trì một <strong>queue</strong> (hàng đợi) packet. Nếu hai packet đến cùng lúc, switch sẽ đưa một packet vào hàng đợi và gửi packet còn lại.</p>
<img width="700px" src="intro/../assets/intro/1-71-transient2.png">
<p>Tại bất kỳ thời điểm nào, switch có thể chọn gửi một packet từ một trong các <strong>incoming link</strong> (liên kết đầu vào), hoặc gửi một packet từ hàng đợi. Lựa chọn này được xác định bởi một <strong>packet scheduling algorithm</strong> (thuật toán lập lịch gói tin), và có rất nhiều thiết kế khác nhau mà chúng ta sẽ tìm hiểu.</p>
<img width="900px" src="intro/../assets/intro/1-72-transient3.png">
<p>Khi không có packet đến, switch có thể <strong>drain</strong> (xả) hàng đợi và gửi các packet đang chờ.</p>
<img width="900px" src="intro/../assets/intro/1-73-transient4.png">
<p>Điều này cho phép hàng đợi giúp hấp thụ các đợt bùng nổ tạm thời.</p>
<img width="700px" src="intro/../assets/intro/1-74-transient5.png">
<p>Nhưng nếu các liên kết đầu vào trông như thế này thì sao?</p>
<img width="700px" src="intro/../assets/intro/1-75-persistent.png">
<p>Lúc này, chúng ta có <strong>persistent overload</strong> (quá tải kéo dài). Đơn giản là không đủ dung lượng trên liên kết đầu ra để đáp ứng mức lưu lượng đầu vào.</p>
<p>Chúng ta có thể làm đầy hàng đợi, nhưng điều đó vẫn không đủ để xử lý tải đầu vào. Dù thế nào, switch cũng sẽ phải <strong>drop</strong> (loại bỏ) packet.</p>
<p>Làm thế nào để xử lý quá tải kéo dài? <strong>Operator</strong> (nhà vận hành) cần cấu hình hợp lý các liên kết và switch. Nếu họ nhận thấy một switch thường xuyên quá tải, họ có thể quyết định nâng cấp liên kết (có thể cần thao tác thủ công).</p>
<p>Một giải pháp khả thi là để <strong>router</strong> thông báo cho bên gửi giảm tốc độ gửi (chúng ta sẽ học khi tìm hiểu <strong>congestion control</strong> – kiểm soát tắc nghẽn). Tuy nhiên, nhìn chung, không có nhiều cách để giải quyết hoàn toàn quá tải, và đó là lý do Internet được thiết kế chỉ cung cấp dịch vụ <strong>best-effort</strong>.</p>
<p>Bây giờ khi đã có khái niệm về <strong>queuing</strong> (xếp hàng), chúng ta cần cập nhật công thức tính <strong>packet delay</strong>:<br />
<strong>Packet delay</strong> = Transmission delay + Propagation delay + Queuing delay.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="giới-thiệu-về-Định-tuyến-routing"><a class="header" href="#giới-thiệu-về-Định-tuyến-routing">Giới thiệu về Định tuyến (Routing)</a></h1>
<h2 id="Định-tuyến-routing-là-gì"><a class="header" href="#Định-tuyến-routing-là-gì">Định tuyến (Routing) là gì?</a></h2>
<p>Giả sử máy A và máy B đều được kết nối với Internet. Máy A muốn gửi một thông điệp đến máy B, nhưng hai máy này không được kết nối trực tiếp với nhau. Vậy làm thế nào để máy A biết phải gửi thông điệp đến đâu để thông điệp đó cuối cùng sẽ đến được máy B? Thông điệp sẽ đi theo con đường nào trong mạng để đến được đích là máy B? Trong chương này, chúng ta sẽ nghiên cứu về <strong>routing</strong> (<em>định tuyến</em>) để trả lời những câu hỏi này.</p>
<img width="600px" src="routing/../assets/routing/2-001-intro-pic.png">
<p>Trước tiên, chúng ta sẽ xây dựng một mô hình của Internet để có thể đặt bài toán định tuyến một cách rõ ràng. Chúng ta cũng sẽ xem xét các câu trả lời cho bài toán định tuyến trông như thế nào, và điều gì khiến một câu trả lời trở nên hợp lệ và tốt.</p>
<p>Tiếp theo, chúng ta sẽ tìm hiểu một số loại giao thức định tuyến khác nhau có thể được triển khai để tạo ra lời giải cho bài toán định tuyến. Chúng ta cũng sẽ xem cách các giao thức định địa chỉ có thể được sử dụng để giúp giao thức định tuyến mở rộng quy mô ra toàn bộ Internet.</p>
<p>Cuối cùng, chúng ta sẽ điểm qua một số phần cứng thực tế được sử dụng để triển khai các giao thức định tuyến này.</p>
<h2 id="Định-tuyến-liên-miền-và-nội-miền"><a class="header" href="#Định-tuyến-liên-miền-và-nội-miền">Định tuyến Liên miền và Nội miền</a></h2>
<p>Một chiến lược khả thi cho việc định tuyến là xây dựng một mô hình Internet bao gồm mọi máy tính trên thế giới, và thiết kế một giao thức định tuyến khổng lồ duy nhất cho phép chúng ta gửi các gói tin (<em>packet</em>) đến bất kỳ đâu trên thế giới. Tuy nhiên, điều này không khả thi trong thực tế do quy mô quá lớn của Internet.</p>
<p>Thay vào đó, chúng ta sẽ tận dụng thực tế rằng Internet là một mạng của các mạng (<em>network of networks</em>). Nói cách khác, Internet bao gồm nhiều mạng cục bộ. Mỗi mạng cục bộ triển khai giao thức định tuyến riêng của mình, quy định cách gửi các gói tin trong phạm vi mạng cục bộ đó. Sau đó, chúng ta có thể kết nối tất cả các mạng cục bộ này lại với nhau và triển khai một giao thức định tuyến trên toàn bộ các mạng cục bộ, quy định cách gửi các gói tin giữa các mạng cục bộ khác nhau.</p>
<img width="900px" src="routing/../assets/routing/2-002-network-of-networks.png">
<p>Các mạng cục bộ không giống nhau. Ví dụ, chúng có thể khác nhau về kích thước: Một số mạng có thể có nhiều máy hơn các mạng khác. Hoặc, các máy có thể được phân bố trên một khu vực địa lý rộng hơn (ví dụ: toàn bộ khuôn viên Đại học UC Berkeley), hoặc một khu vực nhỏ hơn (ví dụ: nhà bạn). Các mạng cũng có thể khác nhau về băng thông (<em>bandwidth</em>) cần hỗ trợ, tỷ lệ lỗi cho phép, số lượng nhân viên kỹ thuật hỗ trợ, độ tuổi của hạ tầng, ngân sách xây dựng và vận hành, v.v.</p>
<p>Vì mỗi mạng có cấu trúc và yêu cầu riêng, các mạng cục bộ khác nhau có thể lựa chọn sử dụng các giao thức định tuyến khác nhau. Một chiến lược định tuyến có thể hiệu quả trên một mạng, nhưng không hiệu quả trên mạng khác.</p>
<p>Với mô hình mạng của các mạng, chúng ta có thể để từng mạng cục bộ lựa chọn chiến lược định tuyến phù hợp cho các gói tin trong mạng của họ. Mỗi nhà vận hành có thể chọn giao thức phù hợp nhất với họ. Các giao thức định tuyến gói tin trong một mạng cục bộ được gọi là <strong>intra-domain</strong> routing protocols (<em>giao thức định tuyến nội miền</em>), hay <strong>interior gateway protocols (IGPs)</strong> (<em>giao thức cổng nội bộ</em>). Các ví dụ thực tế bao gồm OSPF (<em>Open Shortest Path First – Tìm đường ngắn nhất mở</em>) và IS-IS (<em>Intermediate System to Intermediate System – Hệ thống trung gian đến hệ thống trung gian</em>).</p>
<img width="900px" src="routing/../assets/routing/2-003-intradomain.png">
<p>Ngược lại, các giao thức định tuyến gói tin giữa các mạng khác nhau được gọi là <strong>inter-domain</strong> routing protocols (<em>giao thức định tuyến liên miền</em>), hay <strong>exterior gateway protocols (EGPs)</strong> (<em>giao thức cổng bên ngoài</em>). Để hỗ trợ việc gửi gói tin giữa các mạng cục bộ khác nhau, mọi mạng cần đồng thuận sử dụng cùng một giao thức để định tuyến gói tin giữa nhau. Nếu các mạng khác nhau sử dụng các giao thức liên miền khác nhau, thì không có gì đảm bảo rằng toàn bộ Internet có thể được kết nối một cách nhất quán. Giả sử một nhà vận hành chỉ triển khai giao thức X, còn nhà vận hành khác chỉ triển khai giao thức Y? Không rõ hai mạng cục bộ này sẽ trao đổi thông điệp như thế nào.</p>
<p>Vì mọi mạng phải đồng thuận sử dụng cùng một giao thức liên miền, nên chỉ có một giao thức được triển khai ở quy mô toàn Internet, đó là BGP (<em>Border Gateway Protocol – Giao thức cổng biên</em>).</p>
<img width="900px" src="routing/../assets/routing/2-004-interdomain.png">
<p>Mô hình phân chia giữa giao thức cổng nội bộ và cổng bên ngoài này rất thuận tiện để hình dung, nhưng trong thực tế, không phải lúc nào cũng có sự phân biệt rõ ràng giữa chúng. Ví dụ, BGP đôi khi cũng được sử dụng bên trong một mạng cục bộ, ngoài việc sử dụng giữa các mạng khác nhau.</p>
<p>Bất kể giao thức được triển khai nội bộ trong một mạng hay bên ngoài giữa các mạng, chúng ta cũng có thể phân loại giao thức định tuyến bằng cách xem xét thuật toán cơ bản mà nó sử dụng. Cụ thể, chúng ta sẽ nghiên cứu các giao thức kiểu vector khoảng cách (<em>distance-vector</em>), trạng thái liên kết (<em>link-state</em>), và vector đường đi (<em>path-vector</em>) (sẽ tìm hiểu chi tiết từng loại sau).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mô-hình-Định-tuyến-nội-miền-intra-domain-routing"><a class="header" href="#mô-hình-Định-tuyến-nội-miền-intra-domain-routing">Mô hình Định tuyến Nội miền (Intra-Domain Routing)</a></h1>
<h2 id="mô-hình-hóa-mạng-dưới-dạng-Đồ-thị"><a class="header" href="#mô-hình-hóa-mạng-dưới-dạng-Đồ-thị">Mô hình hóa Mạng dưới dạng Đồ thị</a></h2>
<p>Hãy cùng xây dựng một mô hình đơn giản hóa của Internet để giúp chúng ta định nghĩa bài toán định tuyến một cách chính xác.</p>
<p>Nhớ lại từ chương trước rằng chúng ta có thể hình dung Internet như một tập hợp các máy tính, được kết nối với nhau thông qua một tập hợp các liên kết (<em>link</em>), trong đó mỗi liên kết kết nối hai máy tính trong mạng.</p>
<img width="900px" src="routing/../assets/routing/2-002-network-of-networks.png">
<p>Chúng ta có thể biểu diễn cấu trúc mạng dưới dạng một đồ thị, trong đó mỗi nút (<em>node</em>) đại diện cho một máy tính, và mỗi cạnh (<em>edge</em>) giữa hai nút đại diện cho một liên kết giữa hai máy tính.</p>
<p>Trong lịch sử, đôi khi các liên kết có thể kết nối nhiều hơn hai máy tính, nhưng trong các mạng hiện đại, liên kết gần như luôn kết nối chính xác hai máy tính.</p>
<h2 id="cấu-trúc-mạng-full-mesh"><a class="header" href="#cấu-trúc-mạng-full-mesh">Cấu trúc Mạng Full Mesh</a></h2>
<p>Giả sử chúng ta có hai máy tính, A và B. Nếu hai máy này muốn trao đổi thông điệp, chúng ta có thể thêm một liên kết giữa chúng.</p>
<p>Nhưng nếu chúng ta có năm máy tính thay vì hai thì sao? Một cách tiếp cận khả thi là tạo liên kết giữa mọi cặp máy tính, sao cho mỗi máy được kết nối với tất cả các máy còn lại. Cấu trúc này đôi khi được gọi là <strong>full mesh topology</strong> (<em>cấu trúc mạng lưới đầy đủ</em>).</p>
<img width="300px" src="routing/../assets/routing/2-005-mesh.png">
<p>Vậy những hạn chế của cách tiếp cận này là gì?</p>
<p>Cách tiếp cận này không mở rộng tốt. Nếu chúng ta cố gắng mở rộng nó ra quy mô của Internet hiện đại, chúng ta sẽ cần một dây kết nối giữa mọi cặp máy tính trên thế giới. Khi một máy tính mới tham gia mạng, chúng ta sẽ phải tạo các liên kết mới giữa máy đó và mọi máy tính khác trên thế giới.</p>
<p>Mặc dù không thể mở rộng ra toàn bộ Internet, nhưng cấu trúc full mesh vẫn có một số lợi ích trong các môi trường nhỏ hơn. Cụ thể, việc có liên kết giữa mọi cặp máy tính mang lại rất nhiều <strong>bandwidth</strong> (<em>băng thông</em>) cho mạng. Mỗi máy có một liên kết riêng đến tất cả các máy khác, và mỗi cặp máy có thể sử dụng toàn bộ băng thông trên liên kết riêng của họ.</p>
<p>Nói chung, không có gì đảm bảo rằng mỗi máy có liên kết trực tiếp đến tất cả các máy khác. Nói cách khác, không có gì đảm bảo rằng đồ thị cơ bản là đồ thị liên thông hoàn toàn.</p>
<h2 id="cấu-trúc-mạng-một-liên-kết"><a class="header" href="#cấu-trúc-mạng-một-liên-kết">Cấu trúc Mạng Một Liên kết</a></h2>
<p>Ngoài cấu trúc full mesh, còn có những cách khác để triển khai liên kết nhằm kết nối nhiều máy tính. Ví dụ, chúng ta có thể sử dụng một liên kết duy nhất để kết nối cả năm máy tính:</p>
<img width="300px" src="routing/../assets/routing/2-006-single-link.png">
<p>(Tại đây, chúng ta tạm thời phá vỡ giả định rằng một liên kết chỉ kết nối hai máy tính, bằng cách xem xét một liên kết kết nối nhiều hơn hai máy.)</p>
<p>Cách tiếp cận này mở rộng tốt hơn so với cấu trúc full mesh. Ví dụ, nếu một máy tính mới tham gia mạng, thay vì tạo năm liên kết mới giữa máy tính mới và năm máy tính hiện có, chúng ta chỉ cần mở rộng dây hiện có đến máy tính mới.</p>
<p>Tuy nhiên, cách tiếp cận này bị giới hạn hơn về lượng băng thông có sẵn cho các máy. Cụ thể, chỉ có một liên kết duy nhất, và cả năm máy phải chia sẻ băng thông trên liên kết này.</p>
<p>Để tạo ra các cấu trúc mạng phức tạp hơn, chúng ta cần giới thiệu khái niệm <strong>router</strong> (<em>bộ định tuyến</em>).</p>
<h2 id="router-và-host"><a class="header" href="#router-và-host">Router và Host</a></h2>
<p>Trong mô hình đơn giản hóa của chúng ta, mỗi máy tính sẽ được phân loại thành một trong hai loại.</p>
<p><strong>End hosts</strong> (<em>máy chủ đầu cuối</em>) là các máy tính kết nối với Internet để gửi và nhận dữ liệu. Ví dụ về end host bao gồm các ứng dụng trên máy tính cá nhân của bạn, như trình duyệt web. Các máy chủ web, chẳng hạn như máy chủ của Google nhận truy vấn tìm kiếm và gửi lại kết quả, cũng là end host. Những máy này gửi các gói tin (<em>packet</em>) ra ngoài đến các đích khác, và có thể là đích cuối cùng của các gói tin đến. Tuy nhiên, chúng thường không nhận và chuyển tiếp các gói tin trung gian (tức là các gói tin có đích cuối khác).</p>
<p><strong>Router</strong>, ngược lại, là các máy tính kết nối với Internet có nhiệm vụ nhận và chuyển tiếp các gói tin trung gian đến gần hơn với đích cuối của chúng. Ví dụ, hãy xem xét router được lắp đặt trong mạng gia đình của bạn, hoặc các router trong một trung tâm dữ liệu nào đó. Những máy này thường không tự tạo và gửi các gói tin mới, và thường không phải là đích cuối của các gói tin. Ví dụ, trong quá trình sử dụng Internet hàng ngày, bạn có thể muốn gửi gói tin đến máy chủ web của Google để thực hiện tìm kiếm, nhưng bạn có lẽ không cần gửi thông điệp trực tiếp đến router gia đình hoặc router trong trung tâm dữ liệu. Những router đó sẽ giúp bạn chuyển tiếp gói tin đến Google, nhưng không phải là đích cuối của gói tin.</p>
<img width="900px" src="routing/../assets/routing/2-007-host-router.png">
<p>Tùy thuộc vào thiết kế mạng, router có thể là đích hợp lệ, nhưng trong chương này, chúng ta sẽ bỏ qua việc coi router là đích. Tuy nhiên, cần lưu ý rằng router vẫn có thể là nguồn và gửi các gói tin mới của riêng mình.</p>
<p>Router đôi khi cũng được gọi là <strong>switch</strong> (<em>bộ chuyển mạch</em>). Có sự khác biệt lịch sử giữa router và switch, nhưng ngày nay, hai thuật ngữ này thường được sử dụng thay thế cho nhau. Trong tài liệu này, chúng ta sẽ sử dụng &quot;router&quot; khi có thể.</p>
<p>Trong mô hình đồ thị của Internet, router xuất hiện như các nút trung gian thường được kết nối với nhiều nút lân cận. End host xuất hiện như các nút thường được kết nối với một hoặc nhiều router. Trong thực tế, các giả định này không phải lúc nào cũng đúng.</p>
<p>Trong tài liệu này, khi có thể, chúng ta sẽ luôn vẽ router dưới dạng hình vuông và end host dưới dạng hình tròn. Trong thực tế, đôi khi router được biểu diễn bằng các biểu tượng khác. Ví dụ, đây là một biểu tượng router phổ biến được sử dụng trong sơ đồ mạng:</p>
<img width="100px" src="routing/../assets/routing/2-008-router-icon.png">
<h2 id="cấu-trúc-mạng-với-router"><a class="header" href="#cấu-trúc-mạng-với-router">Cấu trúc Mạng với Router</a></h2>
<p>Giờ đây, khi chúng ta có thêm router bên cạnh các end host, chúng ta có thể tạo ra các cấu trúc mạng phức tạp hơn như sau:</p>
<img width="400px" src="routing/../assets/routing/2-009-router-topology.png">
<p>Cấu trúc này cho phép chúng ta kết hợp các lợi ích của cấu trúc full mesh và cấu trúc một liên kết. Cụ thể, cấu trúc này sử dụng ít liên kết hơn so với cấu trúc full mesh trước đó. Đồng thời, nó có nhiều băng thông hơn so với cấu trúc một liên kết.</p>
<p>Cấu trúc này cũng có khả năng chống lỗi tốt hơn. Nếu một liên kết bị hỏng, gói tin có thể đi theo một đường khác trong mạng và vẫn đến được đích.</p>
<img width="900px" src="routing/../assets/routing/2-010-different-path.png">
<h2 id="end-host-trong-Định-tuyến"><a class="header" href="#end-host-trong-Định-tuyến">End Host trong Định tuyến</a></h2>
<p>Lưu ý rằng end host thường không tham gia vào các giao thức định tuyến, vì chúng không chuyển tiếp các gói tin trung gian. Thay vào đó, end host thường được kết nối với một router duy nhất thông qua một liên kết duy nhất. Theo mặc định, end host sẽ gửi tất cả thông điệp ra ngoài đến router, và router sẽ xác định cách gửi gói tin đến đích cuối. Chiến lược gửi mọi thứ đến router này đôi khi được gọi là <strong>default route</strong> (<em>định tuyến mặc định</em>) của end host.</p>
<p>Khi thiết kế các giao thức định tuyến, chúng ta thường bỏ qua end host, ngoại trừ khi chúng là đích đến (vì router cần biết cách đến các đích khác nhau).</p>
<h2 id="gói-tin-packet"><a class="header" href="#gói-tin-packet">Gói tin (Packet)</a></h2>
<p>Nhớ lại từ chương trước rằng khi một ứng dụng muốn gửi dữ liệu qua Internet, ứng dụng sẽ tạo ra một <strong>packet</strong> (<em>gói tin</em>) chứa dữ liệu. Khi gói tin được chuyển xuống các giao thức tầng thấp hơn, các phần tiêu đề (<em>header</em>) bổ sung sẽ được bọc quanh gói tin để cung cấp thông tin metadata giúp gói tin đến được đích.</p>
<p>Trong chương định tuyến này, chúng ta sẽ xem xét một mô hình đơn giản hóa, trong đó mỗi gói tin có một phần tiêu đề chứa metadata, và một phần payload chứa dữ liệu ở tầng ứng dụng. Chúng ta sẽ bỏ qua các tiêu đề lồng nhau và nhiều tầng trong thời điểm này.</p>
<p>Các giao thức định tuyến không quan tâm đến dữ liệu ở tầng ứng dụng. Không quan trọng người dùng đang cố gắng gửi một hình ảnh, một trang HTML, hay một tệp âm thanh; từ góc nhìn của <strong>routing</strong> (<em>định tuyến</em>), chúng ta chỉ có một chuỗi các số 1 và 0, và cần một giao thức để gửi những bit đó đến đúng đích.</p>
<p>Trong phần tiêu đề (<em>header</em>) của gói tin, trường metadata chính mà chúng ta quan tâm là <strong>địa chỉ đích</strong> (<em>destination address</em>). Trường này cho biết đích cuối cùng của gói tin. Khi một <strong>router</strong> (<em>bộ định tuyến</em>) nhận được gói tin, nó sẽ đọc trường metadata trong tiêu đề để xác định cách gửi gói tin đến gần hơn với đích cuối. Bài toán xác định nơi cần gửi gói tin chính là vấn đề cốt lõi mà chúng ta cần giải quyết trong định tuyến.</p>
<img width="200px" src="routing/../assets/routing/2-011-header.png">
<h2 id="Định-địa-chỉ-addressing"><a class="header" href="#Định-địa-chỉ-addressing">Định địa chỉ (Addressing)</a></h2>
<p>Làm thế nào để chúng ta ghi lại địa chỉ đích của gói tin trong phần tiêu đề? Chúng ta cần một cách để định địa chỉ cho từng máy trong mạng. Nói cách khác, chúng ta cần một giao thức để gán địa chỉ cho mỗi máy trong mạng.</p>
<p>Ở phần sau của chương này, chúng ta sẽ thảo luận về các cách tiếp cận có khả năng mở rộng để định địa chỉ. Còn hiện tại, hãy gán cho mỗi máy một nhãn duy nhất (ví dụ: chúng ta có thể gán nhãn cho ba router là X, Y và Z), và coi các nhãn đó là địa chỉ của từng router. Cách làm này cho phép chúng ta tách biệt bài toán định tuyến và bài toán định địa chỉ.</p>
<p>Tại thời điểm này, chúng ta có thể định nghĩa bài toán định tuyến: Khi một router nhận được một gói tin, làm thế nào để router biết phải chuyển tiếp gói tin đến đâu để nó cuối cùng đến được đích cuối?</p>
<h2 id="cấu-trúc-mạng-thay-đổi"><a class="header" href="#cấu-trúc-mạng-thay-đổi">Cấu trúc Mạng Thay đổi</a></h2>
<p>Tại thời điểm này, chúng ta đã định nghĩa được bài toán định tuyến, nhưng vẫn còn một số yếu tố thực tế khiến bài toán này trở nên phức tạp.</p>
<p>Nếu Internet có thể được vẽ dưới dạng một đồ thị cố định, không thay đổi, thì có lẽ chúng ta có thể giải bài toán định tuyến bằng cách đơn giản là nhìn vào đồ thị và tính toán các đường đi trong đó.</p>
<p>Tuy nhiên, cấu trúc mạng liên tục thay đổi. Ví dụ, các liên kết có thể bị hỏng vào những thời điểm không thể dự đoán. Khi đó, gói tin phải được gửi theo một tuyến đường khác để đến được đích.</p>
<p>Các liên kết mới cũng có thể được thêm vào, tạo ra các đường đi bổ sung có thể được xem xét trong quá trình định tuyến.</p>
<p>Do đó, các giao thức định tuyến mà chúng ta thiết kế cần phải có khả năng chống chịu với sự thay đổi của cấu trúc mạng.</p>
<h2 id="giao-thức-Định-tuyến-là-giao-thức-phân-tán"><a class="header" href="#giao-thức-Định-tuyến-là-giao-thức-phân-tán">Giao thức Định tuyến là Giao thức Phân tán</a></h2>
<p>Nếu mạng thay đổi, có lẽ chúng ta có thể giải bài toán định tuyến bằng cách cập nhật đồ thị và tính toán lại các đường đi trong đồ thị mới.</p>
<p>Một vấn đề khác khiến định tuyến trở nên khó khăn là các router không có cái nhìn toàn cục về toàn bộ mạng. Ví dụ, nếu một liên kết ở đâu đó trong mạng bị hỏng, không có cách nào để tất cả các router tự động biết được điều đó. Chúng ta sẽ phải truyền thông tin về cấu trúc mạng mới đến các router như một phần của giao thức định tuyến.</p>
<img width="900px" src="routing/../assets/routing/2-012-non-global.png">
<p>Điều này dẫn đến việc các giao thức định tuyến thường là <strong>distributed protocols</strong> (<em>giao thức phân tán</em>). Thay vì có một trung tâm tính toán duy nhất đưa ra tất cả các câu trả lời, mỗi router phải tự tính toán phần của mình (có thể là không có đầy đủ thông tin về toàn bộ mạng). Tập hợp các câu trả lời được tính toán bởi từng router phải tạo thành một lời giải toàn cục cho bài toán định tuyến, cho phép các gói tin đến được đích cuối của chúng.</p>
<p>Tính chất phân tán của các giao thức định tuyến cũng có nghĩa là chúng ta phải tính đến khả năng từng router bị lỗi. Nếu có một máy tính duy nhất giải bài toán, và máy đó bị lỗi và quên mất lời giải, chúng ta có thể đơn giản yêu cầu máy tính đó tính toán lại toàn bộ lời giải từ đầu. Tuy nhiên, trong một giao thức phân tán, nếu một router bị lỗi và quên mất phần lời giải của nó, giao thức của chúng ta cần có cách giúp router đó phục hồi sau lỗi và học lại phần lời giải của mình.</p>
<h2 id="liên-kết-là-nỗ-lực-tốt-nhất-best-effort"><a class="header" href="#liên-kết-là-nỗ-lực-tốt-nhất-best-effort">Liên kết là Nỗ lực Tốt nhất (Best-Effort)</a></h2>
<p>Nhớ lại từ chương trước rằng các giao thức ở tầng 3 trở xuống là <strong>best-effort</strong> (<em>nỗ lực tốt nhất</em>). Nói cách khác, khi một gói tin được gửi qua một liên kết, không có gì đảm bảo rằng gói tin sẽ đến được đích. Liên kết có thể làm rơi gói tin.</p>
<p>Khi thiết kế các giao thức định tuyến, chúng ta cũng cần tính đến vấn đề này.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="trạng-thái-Định-tuyến-routing-states"><a class="header" href="#trạng-thái-Định-tuyến-routing-states">Trạng thái Định tuyến (Routing States)</a></h1>
<h2 id="các-chiến-lược-Định-tuyến-tồi-bad-routing-strategies"><a class="header" href="#các-chiến-lược-Định-tuyến-tồi-bad-routing-strategies">Các chiến lược Định tuyến Tồi (Bad Routing Strategies)</a></h2>
<p>Cho đến nay, chúng ta đã định nghĩa bài toán định tuyến như sau: Khi một router nhận được một gói tin, làm thế nào để router biết được nơi để chuyển tiếp gói tin đó sao cho nó cuối cùng sẽ đến được đích cuối cùng?</p>
<img width="600px" src="routing/../assets/routing/2-013-forwarding.png">
<p>Một khi chúng ta tìm thấy một thuật toán (một routing protocol (giao thức định tuyến)) để giải quyết vấn đề này, chúng ta có thể áp dụng thuật toán đó để tạo ra một câu trả lời, mà chúng ta sẽ gọi là <strong>routing state</strong> (trạng thái định tuyến). Bạn có thể nghĩ về một routing state như một tập hợp các quy tắc mà mỗi router sử dụng để chuyển tiếp các gói tin mà nó nhận được. Một routing state trông như thế nào, và làm thế nào chúng ta có thể kiểm tra xem một routing state cho trước có hợp lệ hay tốt không?</p>
<p>Để bắt đầu, chúng ta có thể xem xét một số chiến lược tồi để tạo ra các routing state. Một chiến lược định tuyến khả thi là: Router chuyển tiếp gói tin đến một láng giềng được chọn ngẫu nhiên. Về mặt trực quan, chúng ta đã có thể thấy rằng các routing state được tạo ra theo cách này có lẽ sẽ không hợp lệ. Nếu chúng ta sử dụng chiến lược này, chúng ta không thể chắc chắn rằng các gói tin sẽ đến được đích cuối cùng của chúng.</p>
<p>Một chiến lược tồi khả thi khác là: Router chuyển tiếp một bản sao của gói tin đến tất cả các láng giềng của nó. Về mặt trực quan, điều này có thể hợp lệ, theo nghĩa là các bản sao của gói tin cuối cùng sẽ lan truyền khắp toàn bộ mạng và có thể đến được đích. Tuy nhiên, chiến lược này không hiệu quả, vì nó lãng phí rất nhiều bandwidth (băng thông) để chuyển tiếp gói tin đến các router không cần thiết để gửi gói tin đến đích cuối cùng của nó.</p>
<p>Chúng ta có thể thấy một cách trực quan rằng hai chiến lược này là tồi, nhưng để phân tích các routing protocol thông minh hơn, chúng ta sẽ cần phải định nghĩa một cách chính thức một routing state trông như thế nào. Sau đó, chúng ta sẽ cần phải chính thức hóa điều gì làm cho một routing state hợp lệ, và điều gì làm cho một routing state tốt.</p>
<h2 id="bảng-chuyển-tiếp-forwarding-tables"><a class="header" href="#bảng-chuyển-tiếp-forwarding-tables">Bảng Chuyển tiếp (Forwarding Tables)</a></h2>
<p>Trong mô hình mạng của chúng ta, mỗi router có một số liên kết đi ra kết nối nó với các router và máy chủ liền kề. Nói cách khác, trong đồ thị cơ bản, mỗi nút router có một số láng giềng, được kết nối với router bằng một cạnh.</p>
<p>Khi router nhận được một gói tin, với đích cuối cùng của nó trong siêu dữ liệu, router cần quyết định gói tin nên được chuyển tiếp đến router hoặc máy chủ liền kề nào. Router trung gian tiếp theo mà gói tin sẽ được chuyển tiếp đến được gọi là <strong>next hop</strong> (chặng kế tiếp).</p>
<img width="700px" src="routing/../assets/routing/2-014-nexthop.png">
<p>Ví dụ, hãy xem xét mạng này. Nếu R2 nhận được một gói tin có đích cuối cùng là B, next hop tự nhiên tương ứng sẽ là R3. Các lựa chọn next hop có thể là R1, R3 và R4 (ba router liền kề với R2), và R3 là next hop gửi gói tin đến gần B hơn.</p>
<p>Nếu R2 thay vào đó nhận được một gói tin có đích cuối cùng là A, thì next hop tự nhiên tương ứng sẽ là R1.</p>
<p>Đối với mỗi đích cuối cùng có thể, chúng ta có thể viết ra next hop tương ứng để chuyển tiếp gói tin đến gần đích đó hơn. Kết quả được gọi là <strong>forwarding table</strong> (bảng chuyển tiếp).</p>
<img width="850px" src="routing/../assets/routing/2-015-forwarding-table.png">
<p>Lưu ý rằng trong việc ánh xạ từ đích đến next hop, một next hop có thể được sử dụng nhiều lần. Ví dụ, trong forwarding table của R2, các gói tin đến B và các gói tin đến C đều sẽ được chuyển tiếp đến R3.</p>
<p>Bằng cách viết ra forwarding table cho mỗi router trung gian, chúng ta hiện có một routing state đầy đủ cho mạng. Nói cách khác, với một gói tin có một đích cuối cùng nào đó, chúng ta biết chính xác cách mỗi router sẽ chuyển tiếp gói tin đó.</p>
<p>Trong thế giới thực, thay vì ánh xạ các đích đến các next hop, các router thường sẽ ánh xạ các đích đến các <strong>physical ports</strong> (cổng vật lý), trong đó mỗi cổng vật lý tương ứng với một liên kết. Trong mô hình đồ thị, bây giờ chúng ta sẽ ánh xạ mỗi đích đến một cạnh, thay vì ánh xạ mỗi đích đến một nút láng giềng. Trong thế giới thực, bạn có thể nghĩ về điều này như một router có nhiều dây đi ra, trong đó mỗi dây được kết nối với một router khác. Thay vì viết ra các router láng giềng trong forwarding table, router thay vào đó viết ra dây nào mà một gói tin nên được gửi đi.</p>
<img width="550px" src="routing/../assets/routing/2-016-ports.png">
<p>Đây là một sự khác biệt tinh tế, và nó phản ánh thực tế rằng router không thực sự quan tâm đến danh tính của router láng giềng. Quyết định duy nhất mà router cần đưa ra là gửi gói tin đi theo một trong các dây, bất kể dây đó được kết nối với ai. Trong các ghi chú này, chúng ta sẽ vẽ các forwarding table dưới dạng ánh xạ các đích đến các next hop (thay vì các cổng vật lý), để đơn giản.</p>
<h2 id="chuyển-tiếp-dựa-trên-Đích-đến-destination-based-forwarding"><a class="header" href="#chuyển-tiếp-dựa-trên-Đích-đến-destination-based-forwarding">Chuyển tiếp Dựa trên Đích đến (Destination-Based Forwarding)</a></h2>
<p>Một hệ quả của việc sử dụng forwarding table là với một gói tin cho trước, quyết định về nơi chuyển tiếp gói tin chỉ phụ thuộc vào trường đích của gói tin. Nói cách khác, nếu một router nhận được nhiều gói tin khác nhau, tất cả đều có cùng một đích, chúng sẽ đều được định tuyến đến cùng một next hop (giả sử forwarding table không thay đổi). Vì mỗi đích chỉ được ánh xạ đến một next hop duy nhất, không có cách nào để hai gói tin có cùng một đích được chuyển tiếp đến các router khác nhau. Cách tiếp cận này được gọi là <strong>destination-based forwarding</strong> (chuyển tiếp dựa trên đích đến) hoặc <strong>destination-based routing</strong> (định tuyến dựa trên đích đến).</p>
<p>Destination-based routing là cách tiếp cận phổ biến nhất để định tuyến, và đó là những gì được sử dụng trong Internet hiện đại. Về lý thuyết, các cách tiếp cận khác có thể tồn tại, nơi siêu dữ liệu bổ sung được sử dụng để đưa ra quyết định chuyển tiếp, nhưng chúng thường chỉ được sử dụng trong các ứng dụng hạn chế (ví dụ: bên trong một mạng cục bộ cụ thể).</p>
<p>Trong các đơn vị sau, khi chúng ta xem xét các cấu trúc liên kết trung tâm dữ liệu, chúng ta có thể xem xét các phương pháp destination-based forwarding nơi có thể có nhiều hơn một next hop cho một đích cụ thể. Trong đơn vị này, chúng ta sẽ giả định rằng mỗi đích chỉ được ánh xạ đến một next hop duy nhất.</p>
<h2 id="Định-tuyến-và-chuyển-tiếp-routing-vs-forwarding"><a class="header" href="#Định-tuyến-và-chuyển-tiếp-routing-vs-forwarding">Định tuyến và Chuyển tiếp (Routing vs. Forwarding)</a></h2>
<p>Bây giờ chúng ta đã giới thiệu ý tưởng về forwarding table, chúng ta cần phân biệt giữa quá trình tạo ra forwarding table và quá trình sử dụng forwarding table.</p>
<p><strong>Routing</strong> (Định tuyến) là quá trình các router giao tiếp với nhau để xác định cách điền vào forwarding table của chúng.</p>
<p><strong>Forwarding</strong> (Chuyển tiếp) là quá trình nhận một gói tin, tra cứu next hop thích hợp của nó trong bảng, và gửi gói tin đến láng giềng thích hợp.</p>
<p>Forwarding không giống như Routing. Khi Forwarding các gói tin, các router sử dụng forwarding table hiện có, mà không cần biết bảng đó được tạo ra như thế nào.</p>
<p>Forwarding là một quy trình cục bộ. Khi một router đang Forwarding các gói tin, router không cần biết toàn bộ cấu trúc liên kết mạng. Router cũng không quan tâm đến việc gói tin đi đâu sau khi nó đã được chuyển tiếp đến next hop. Router chỉ cần biết về gói tin đến và forwarding table của chính nó.</p>
<p>Ngược lại, Routing là một quy trình toàn cục. Để điền vào các forwarding table, chúng ta sẽ cần tìm hiểu một cái gì đó về cấu trúc liên kết toàn cục của mạng.</p>
<img width="950px" src="routing/../assets/routing/2-017-forwarding-routing.png">
<p>Ví dụ, khi điền vào forwarding table của R2, chúng ta đã phải bằng cách nào đó biết được rằng đích B được liên kết với R3, mặc dù máy chủ B không được kết nối trực tiếp với R2. Trong quá trình Routing, mỗi router cũng sẽ cần biết về các đích không thuộc cục bộ.</p>
<h2 id="tính-hợp-lệ-của-trạng-thái-Định-tuyến-là-toàn-cục-routing-state-validity-is-global"><a class="header" href="#tính-hợp-lệ-của-trạng-thái-Định-tuyến-là-toàn-cục-routing-state-validity-is-global">Tính hợp lệ của Trạng thái Định tuyến là Toàn cục (Routing State Validity is Global)</a></h2>
<p>Hãy nhớ lại rằng một routing state bao gồm một forwarding table cho mỗi router, chúng cùng nhau cho chúng ta biết cách các gói tin sẽ di chuyển qua mạng. Với một routing state cho trước, làm thế nào chúng ta có thể biết được routing state đó là đúng hay sai?</p>
<p>Đầu tiên, chúng ta cần định nghĩa chính thức <strong>routing state validity</strong> (tính hợp lệ của trạng thái định tuyến) để xác định xem một routing state có hợp lệ hay không (mặc dù thuật ngữ này có thể không được sử dụng rộng rãi ngoài khóa học CS 168 tại UC Berkeley). Yêu cầu chính đối với tính hợp lệ là: routing state cần tạo ra các quyết định chuyển tiếp đảm bảo rằng các gói tin thực sự đến được đích của chúng.</p>
<p>Lưu ý rằng tính hợp lệ phải được đánh giá trong bối cảnh toàn cục, không phải bối cảnh cục bộ. Việc xem xét routing state cục bộ, chẳng hạn như forwarding table của một router duy nhất, không thể cho chúng ta biết liệu một routing state có hợp lệ hay không. Ví dụ, trong forwarding table cục bộ của router R2, chúng ta có thể thấy rằng next hop cho đích A là router R3, nhưng chúng ta không có cách nào để quyết định xem điều này có hợp lệ hay không. Liệu việc chuyển tiếp các gói tin đến R3 có giúp các gói tin đến được đích A không? Không có cách nào để biết chỉ từ forwarding table.</p>
<img width="800px" src="routing/../assets/routing/2-018-validity-local.png">
<p>Thay vào đó, chúng ta cần xem xét routing state toàn cục, bao gồm tập hợp tất cả các forwarding table trong tất cả các router.</p>
<img width="950px" src="routing/../assets/routing/2-019-validity-global.png">
<h2 id="Định-nghĩa-tính-hợp-lệ-của-trạng-thái-Định-tuyến-routing-state-validity-definition"><a class="header" href="#Định-nghĩa-tính-hợp-lệ-của-trạng-thái-Định-tuyến-routing-state-validity-definition">Định nghĩa Tính hợp lệ của Trạng thái Định tuyến (Routing State Validity Definition)</a></h2>
<p>Bây giờ, chúng ta có thể định nghĩa một điều kiện chính thức mà chúng ta có thể sử dụng để kiểm tra xem các gói tin có đến được đích của chúng hay không đối với một routing state cho trước.</p>
<p>Một routing state toàn cục là hợp lệ khi và chỉ khi, đối với bất kỳ đích nào, các gói tin không bị kẹt trong các ngõ cụt hoặc vòng lặp.</p>
<p>Một <strong>dead end</strong> (ngõ cụt) xảy ra nếu một gói tin đến một router, nhưng router không biết cách chuyển tiếp gói tin đến đích của nó, vì vậy gói tin không được chuyển tiếp. Điều này có thể xảy ra nếu forwarding table của router không chứa một mục cho đích của gói tin.</p>
<p>Lưu ý rằng điều kiện dead end chỉ áp dụng cho các router trung gian, chứ không phải các máy chủ cuối. Khi một gói tin đến máy chủ cuối đích, không cần thiết máy chủ cuối phải chuyển tiếp gói tin đi xa hơn, vì vậy chúng ta sẽ không xem xét các máy chủ cuối trong điều kiện dead end.</p>
<img width="950px" src="routing/../assets/routing/2-020-dead-end.png">
<p>Một <strong>loop</strong> (vòng lặp) xảy ra nếu một gói tin được gửi theo một chu kỳ xung quanh cùng một nhóm các nút. Lưu ý rằng vì chúng ta đang sử dụng destination-based forwarding, nơi next hop chỉ phụ thuộc vào đích, một khi một gói tin đi vào một loop, nó sẽ bị kẹt trong loop đó mãi mãi. Khi gói tin đến router lần đầu tiên, hoặc lần thứ 10, hoặc lần thứ 500, nó sẽ được chuyển tiếp theo cùng một cách chính xác (vì đích cuối cùng là như nhau). Vì điều này áp dụng cho mọi router trên loop, gói tin sẽ bị kẹt trong loop mãi mãi.</p>
<img width="850px" src="routing/../assets/routing/2-021-loop.png">
<p>Điều kiện này (không có dead ends, không có loops) là cần và đủ để một tuyến đường là hợp lệ. Hãy kiểm tra cả hai chiều của mệnh đề logic này.</p>
<p>Không có dead ends và không có loops là một điều kiện cần cho tính hợp lệ. Nói cách khác, một trạng thái là hợp lệ chỉ khi không có dead ends và không có loops.</p>
<p>Chứng minh: Nếu có một dead end, gói tin sẽ không đến được đích. Gói tin sẽ đến dead end và không được chuyển tiếp.</p>
<p>Nếu có loops, gói tin sẽ không đến được đích. Gói tin sẽ bị kẹt trong loop mãi mãi (vì destination-based forwarding, được mô tả trước đó). Ngoài ra, lưu ý rằng đích cuối cùng không thể là một phần của loop, vì đích sẽ không chuyển tiếp gói tin. Do đó, một gói tin bị kẹt trong loop sẽ không đến được đích.</p>
<p>Bây giờ, hãy kiểm tra chiều ngược lại. Nếu không có loops và không có dead ends, thì trạng thái đó là hợp lệ.</p>
<p>Chứng minh: Giả sử rằng routing state không có loops hoặc dead ends. Một gói tin sẽ không đến cùng một nút hai lần (vì không có loops). Ngoài ra, gói tin sẽ không dừng lại trước khi đến đích (vì không có dead ends). Do đó, gói tin phải tiếp tục đi qua mạng, đến các nút khác nhau. Chỉ có một số lượng hữu hạn các nút duy nhất để ghé thăm, vì vậy gói tin cuối cùng phải đến được đích. Do đó, routing state phải hợp lệ.</p>
<h2 id="cây-phân-phối-có-hướng-directed-delivery-trees"><a class="header" href="#cây-phân-phối-có-hướng-directed-delivery-trees">Cây Phân phối Có hướng (Directed Delivery Trees)</a></h2>
<p>Bây giờ chúng ta đã có một định nghĩa chính thức cho routing state validity, chúng ta có thể hỏi: với một routing state toàn cục cho trước, làm thế nào chúng ta có thể kiểm tra xem nó có hợp lệ không?</p>
<p>Để đơn giản hóa vấn đề, hãy bắt đầu bằng cách chỉ xem xét một máy chủ cuối đích duy nhất, bỏ qua tất cả các máy chủ cuối khác. Trong mỗi router, chúng ta có thể tra cứu đích này để lấy next hop tương ứng, điều này cho chúng ta biết cách mỗi router sẽ chuyển tiếp các gói tin dành cho đích này.</p>
<p>Chúng ta có thể biểu diễn next hop tại mỗi router (cho đích duy nhất này) dưới dạng một mũi tên, cho chúng ta thấy tất cả các đường đi có thể mà gói tin này có thể đi để đến đích duy nhất.</p>
<img width="800px" src="routing/../assets/routing/2-022-delivery-tree.png">
<p>Trong đồ thị kết quả, mỗi nút sẽ chỉ có một mũi tên đi ra. Điều này phản ánh giả định của chúng ta rằng trong forwarding table của mỗi router, chỉ có một next hop tương ứng với một đích.</p>
<p>Lưu ý rằng trong đồ thị kết quả, một khi hai đường đi gặp nhau, chúng không bao giờ tách ra. Nói cách khác, ngay cả khi có nhiều mũi tên (đường đi) đến một nút, vì chỉ có một mũi tên đi ra, các đường đi đó bây giờ sẽ hội tụ thành một đường đi duy nhất. Điều này phản ánh phương pháp destination-based forwarding của chúng ta, bởi vì mỗi router chỉ sử dụng đích cuối cùng để quyết định cách chuyển tiếp một gói tin. Router không quan tâm gói tin đã đến router bằng cách nào ngay từ đầu.</p>
<img width="900px" src="routing/../assets/routing/2-023-no-diverging.png">
<p>Các mũi tên mà chúng ta đã vẽ tạo thành một tập hợp các đường đi mà một gói tin có thể đi để đến đích duy nhất. Tập hợp các đường đi này được gọi là <strong>directed delivery tree</strong> (cây phân phối có hướng).</p>
<p>Về mặt thuật ngữ đồ thị, các mũi tên trong một directed delivery tree hợp lệ phải tạo thành một <strong>oriented spanning tree</strong> (cây khung có hướng), có gốc tại đích. Hãy nhớ lại rằng một cây khung là một tập hợp các cạnh trong đồ thị chạm vào mọi nút và tạo thành một cây. Chúng ta muốn directed delivery tree là một cây, vì không nên có chu trình (các gói tin không thể đi theo vòng lặp). Chúng ta muốn directed delivery tree là cây khung (chạm vào mọi nút), bởi vì chúng ta muốn có thể đến đích từ mọi nơi. Directed delivery tree có hướng vì các cạnh có mũi tên, cho chúng ta biết hướng để chuyển tiếp gói tin.</p>
<p>Tất cả các cạnh trong một directed delivery tree hợp lệ phải hướng về phía đích. Nói cách khác, bắt đầu từ bất kỳ nút nào, đi theo các mũi tên phải luôn luôn dẫn đến việc đến được đích.</p>
<h2 id="xác-minh-tính-hợp-lệ-của-trạng-thái-Định-tuyến-verifying-routing-state-validity"><a class="header" href="#xác-minh-tính-hợp-lệ-của-trạng-thái-Định-tuyến-verifying-routing-state-validity">Xác minh Tính hợp lệ của Trạng thái Định tuyến (Verifying Routing State Validity)</a></h2>
<p>Như trước đây, hãy chỉ xem xét một máy chủ cuối đích duy nhất, bỏ qua tất cả các máy chủ cuối khác.</p>
<p>Ví dụ: Mặc dù có nhiều máy chủ cuối ở đây, hãy chỉ xem xét máy chủ cuối A.</p>
<img width="800px" src="routing/../assets/routing/2-024-validity1.png">
<p>Sử dụng các forwarding table tại mỗi router, chúng ta sẽ vẽ các mũi tên vào mạng để tạo thành directed delivery tree cho đích duy nhất này. Về mặt chính thức, đối với mỗi router (nút trong đồ thị), chúng ta sẽ vẽ một mũi tên đi ra duy nhất từ nút đó.</p>
<p>Ví dụ: Sử dụng các forwarding table (không hiển thị), chúng ta có thể vẽ một mũi tên đi ra cho mỗi router.</p>
<img width="800px" src="routing/../assets/routing/2-025-validity2.png">
<p>Để đơn giản, tại thời điểm này, chúng ta có thể xóa tất cả các liên kết không có mũi tên trên chúng. Các liên kết không có mũi tên này sẽ không bao giờ được sử dụng để gửi gói tin đến đích duy nhất, vì chúng không nằm trên directed delivery tree.</p>
<p>Ví dụ: Chúng ta có thể xóa tất cả các liên kết không có mũi tên.</p>
<img width="800px" src="routing/../assets/routing/2-026-validity3.png">
<p>Nếu đồ thị còn lại là một directed delivery tree hợp lệ (cây khung, tất cả các mũi tên đều hướng về đích), thì chúng ta có thể nói rằng routing state là hợp lệ cho đích duy nhất này.</p>
<p>Trong ví dụ trên, đồ thị còn lại thực sự là một cây khung hợp lệ hội tụ tại A, vì vậy chúng ta có thể nói routing state này là hợp lệ cho A.</p>
<p>Dưới đây là một số ví dụ về các routing state không hợp lệ:</p>
<img width="800px" src="routing/../assets/routing/2-027-dead-end.png">
<p>Trạng thái này không hợp lệ. Về mặt trực quan, có một router dead end. Một gói tin hướng đến A có thể được gửi đến router này, và router này sẽ loại bỏ gói tin mà không chuyển tiếp nó. Về mặt chính thức, đồ thị còn lại không phải là một cây khung, bởi vì các cạnh không được kết nối với nhau (có hai thành phần không liên thông, điều này không được phép trong một cây).</p>
<img width="800px" src="routing/../assets/routing/2-028-loop.png">
<p>Trạng thái này cũng không hợp lệ. Về mặt trực quan, có một loop mà gói tin có thể bị kẹt trong đó. Về mặt chính thức, đồ thị còn lại không phải là một cây khung, bởi vì các cạnh không liên thông, và có một chu trình.</p>
<p>Chúng ta có thể lặp lại quá trình này, một lần cho mỗi máy chủ cuối khác nhau (cô lập một máy chủ cuối khác nhau mỗi lần). Nếu routing state là hợp lệ cho tất cả các đích, thì chúng ta có thể nói rằng routing state là hợp lệ, và sẽ luôn chuyển giao các gói tin đến đúng đích của chúng.</p>
<h2 id="Định-tuyến-chi-phí-thấp-nhất-least-cost-routing"><a class="header" href="#Định-tuyến-chi-phí-thấp-nhất-least-cost-routing">Định tuyến Chi phí Thấp nhất (Least-Cost Routing)</a></h2>
<p>Bây giờ chúng ta đã có một định nghĩa về điều gì làm cho một routing state hợp lệ (các tuyến đường không có loops và dead ends), chúng ta có thể định nghĩa thêm điều gì làm cho một routing state tốt. Có thể một mạng có nhiều routing state hợp lệ, và chúng ta muốn có một số liệu có thể giúp chúng ta xác định xem một tuyến đường có tốt hơn tuyến đường khác hay không.</p>
<p><strong>Least-cost routing</strong> (định tuyến chi phí thấp nhất) là một cách tiếp cận phổ biến để đo lường xem một tuyến đường có tốt hay không. Trong least-cost routing, chúng ta gán một chi phí bằng số cho mọi liên kết, và tìm kiếm các tuyến đường giảm thiểu chi phí. Nói cách khác, chúng ta muốn các tuyến đường dẫn đến việc các gói tin di chuyển dọc theo các đường đi có chi phí thấp nhất đến đích của chúng.</p>
<img width="600px" src="routing/../assets/routing/2-029-costs.png">
<p>Có nhiều chi phí khác nhau mà chúng ta có thể xem xét gán cho các liên kết. Chi phí có thể phụ thuộc vào giá xây dựng liên kết, độ trễ lan truyền, khoảng cách vật lý của liên kết, độ không tin cậy, bandwidth, cùng nhiều yếu tố khác. Ví dụ, chúng ta có thể gán chi phí dựa trên chất lượng của liên kết (bandwidth và độ trễ lan truyền), sao cho đường đi chi phí thấp nhất ưu tiên các liên kết chất lượng cao hơn.</p>
<p>Bằng cách cho phép các nhà khai thác đặt chi phí liên kết một cách tùy ý, chúng ta trao cho nhà khai thác khả năng tối ưu hóa mạng cho các nhu cầu cụ thể của họ. Chi phí chúng ta gán phụ thuộc vào mục tiêu của nhà khai thác đối với mạng. Nếu chúng ta có một liên kết 400 Gbps với độ trễ lan truyền 20 ms, và một liên kết 10 Gbps với độ trễ lan truyền 5 ms, cái nào có chi phí thấp hơn? Điều đó phụ thuộc vào việc chúng ta đang tối ưu hóa cho bandwidth, độ trễ lan truyền, một sự kết hợp nào đó, hay một thứ gì đó hoàn toàn khác.</p>
<p>Nếu chúng ta gán chi phí là 1 cho mọi liên kết, thì đường đi chi phí thấp nhất là đường đi di chuyển qua ít liên kết nhất. Đôi khi chúng ta gọi đây là việc giảm thiểu <strong>hop count</strong> (số bước nhảy). Trong các ghi chú này, nếu các cạnh của một đồ thị không được dán nhãn với một chi phí, bạn có thể giả định tất cả các cạnh có chi phí là 1.</p>
<p>Nhà khai thác của một mạng có thể quyết định cách gán chi phí cho mỗi liên kết. Nhà khai thác có thể gán chi phí thủ công. Hoặc, nhà khai thác có thể để mạng tự động cấu hình chi phí, mặc dù điều này có thể không hoạt động với một số số liệu không thể đo lường tự động (ví dụ: mạng không biết gì về chi phí tài chính để xây dựng liên kết).</p>
<p>Khi thiết kế một routing protocol, chúng ta có thể trừu tượng hóa cách các chi phí được gán. Từ quan điểm của routing protocol, một ai đó khác (ví dụ: nhà khai thác mạng) đã gán các chi phí, dựa trên một cái gì đó mà họ cho là quan trọng. Thuật toán nhận các chi phí làm đầu vào, và tính toán các đường đi chi phí thấp nhất, bất kể các chi phí thực sự đại diện cho điều gì.</p>
<img width="950px" src="routing/../assets/routing/2-030-least-cost.png">
<p>Lưu ý rằng chi phí là cục bộ đối với mỗi router. Một router biết về chi phí của các liên kết đi ra của chính nó, nhưng không có cách nào để router tự động biết chi phí của tất cả các liên kết. Điều này phù hợp với ràng buộc mà chúng ta đã đề cập trước đó, nơi các router không có cái nhìn toàn cục về toàn bộ cấu trúc liên kết của mạng.</p>
<p>Để đơn giản, các routing protocol đưa ra một số giả định về cách các chi phí được định nghĩa.</p>
<p>Chúng ta sẽ giả định rằng chi phí luôn là số nguyên dương. Điều này phù hợp với nhiều số liệu phổ biến trong đời thực, chẳng hạn như chiều dài của một liên kết hoặc chi phí tiền tệ của một liên kết. Nếu chúng ta đang cố gắng giảm thiểu tổng khoảng cách vật lý mà một gói tin di chuyển, một chi phí liên kết âm không có ý nghĩa. Bạn không thể di chuyển dọc theo một liên kết và giảm tổng khoảng cách đã đi. Giả định này sẽ giúp đơn giản hóa các giao thức của chúng ta sau này, vì chúng ta sẽ không phải lo lắng về các trường hợp biên như các vòng lặp có trọng số âm (nơi giải pháp chi phí thấp nhất sẽ là đi vòng quanh vòng lặp mãi mãi).</p>
<p>Chúng ta sẽ giả định rằng chi phí là đối xứng. Chi phí từ A đến B giống như chi phí từ B đến A. Điều này phản ánh các sơ đồ chúng ta sẽ vẽ, trong đó một cạnh được dán nhãn với một chi phí đối xứng duy nhất. Về lý thuyết, có thể có chi phí liên kết bất đối xứng, nhưng điều này không được thực hiện trong thực tế, và sẽ dẫn đến các routing protocol phức tạp hơn.</p>
<p>Với những giả định này, định nghĩa của chúng ta về các tuyến đường tốt (chi phí thấp nhất) phù hợp với định nghĩa của chúng ta về các tuyến đường hợp lệ. Cụ thể, một tuyến đường chi phí thấp nhất sẽ không có bất kỳ loops nào, bởi vì chi phí là dương (việc đi qua loop sẽ chỉ làm tăng chi phí).</p>
<h2 id="Định-tuyến-tĩnh-static-routing"><a class="header" href="#Định-tuyến-tĩnh-static-routing">Định tuyến Tĩnh (Static Routing)</a></h2>
<p>Một cách khả thi để tạo ra các tuyến đường là để nhà khai thác mạng điền vào forwarding table một cách thủ công. Điều này được gọi là <strong>static routing</strong> (định tuyến tĩnh).</p>
<p>Bản thân static routing không thực tế (ví dụ: không thể mở rộng, dễ bị lỗi do con người), nhưng ngay cả khi đã triển khai một routing protocol, một số tuyến đường vẫn cần được các nhà khai thác tạo ra thủ công. Bạn có thể nghĩ về những tuyến đường thủ công này như những tuyến đường &quot;tầm thường&quot; hoặc &quot;trường hợp cơ sở&quot;, từ đó routing protocol tạo ra các tuyến đường phức tạp hơn.</p>
<p>Nếu chúng ta được kết nối trực tiếp với một máy khác mà chúng ta muốn định tuyến các gói tin đến, chúng ta có thể cấu hình thủ công một tuyến đường để chuyển tiếp các gói tin đến máy đó. Những tuyến đường này được gọi là <strong>direct routes</strong> (tuyến đường trực tiếp) hoặc <strong>connected routes</strong> (tuyến đường kết nối). Ví dụ, router nhà bạn được kết nối với máy tính cá nhân của bạn bằng một liên kết, vì vậy router nhà bạn có thể thêm một mục trong forwarding table tương ứng với máy tính của bạn. Mục này được thêm vào bằng cách thông báo cho router về kết nối, và không được thêm vào từ việc chạy bất kỳ routing protocol nào.</p>
<img width="800px" src="routing/../assets/routing/2-031-static.png">
<p>Cũng có thể sử dụng static routing để mã hóa cứng các mục cho các đích trong forwarding table, ngay cả khi chúng ta không được kết nối trực tiếp với đích đó. Điều này có thể hữu ích nếu có một tuyến đường không bao giờ thay đổi, và chúng ta muốn tuyến đường đó luôn ở trong forwarding table của mình, bất kể routing protocol đang làm gì.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="các-giao-thức-distance-vector"><a class="header" href="#các-giao-thức-distance-vector">Các Giao thức Distance-Vector</a></h1>
<h2 id="phác-thảo-thuật-toán"><a class="header" href="#phác-thảo-thuật-toán">Phác thảo Thuật toán</a></h2>
<p>Trong phần này, chúng ta sẽ thiết kế một <em><strong>distance-vector protocol</strong></em>, là một trong ba loại thuật toán định tuyến (cùng với <em>link-state (trạng thái liên kết)</em> và <em>path-vector (vector đường đi)</em>).</p>
<p>Các giao thức <em>distance-vector</em> có một lịch sử lâu đời trên Internet và ARPANET (tiền thân của Internet). Giao thức <em>distance-vector</em> tiêu biểu là <em><strong>Routing Information Protocol (RIP) (Giao thức Thông tin Định tuyến)</strong></em>, và giao thức D-V mà chúng ta sẽ thiết kế có nhiều điểm tương đồng với <em>RIP</em>.</p>
<p>Để có được một số trực giác về giao thức định tuyến mà chúng ta sẽ nghiên cứu trong phần này, hãy xem xét mạng sau đây.</p>
<img width="800px" src="routing/../assets/routing/2-032-sketch1.png">
<p>Để bắt đầu, <em>forwarding table</em> của mọi <em>router</em> đều trống. Mục tiêu của chúng ta là điền vào các <em>forwarding table</em> của mọi <em>router</em>, sao cho các <em>packet</em> có thể được định tuyến từ bất kỳ đâu đến đích là A.</p>
<p>Để bắt đầu, A có thể nói với R1: &quot;Tôi là A.&quot; Bây giờ, R1 biết cách <em>forwarding</em> các <em>packet</em> đến A.</p>
<p>Bây giờ R1 đã có một đường đi đến A, nó có thể nói với các neighbour của mình, R2 và R3: &quot;Tôi là R1, và tôi có thể đến được A.&quot;</p>
<img width="800px" src="routing/../assets/routing/2-033-sketch2.png">
<p>Bây giờ, R2 và R3 biết rằng chúng có thể đến được A bằng cách <em>forwarding</em> các <em>packet</em> đến R1.</p>
<p>R2 bây giờ có thể nói với các neighbour của mình, R4 và R5: &quot;Tôi là R2, và tôi có thể đến được A.&quot; Tương tự, R3 có thể nói với các neighbour của mình, R6 và R7: &quot;Tôi là R3, và tôi có thể đến được A.&quot;</p>
<img width="800px" src="routing/../assets/routing/2-034-sketch3.png">
<p>Bây giờ, R4 và R5 biết rằng các <em>packet</em> cho A có thể được chuyển tiếp đến R2, và R6 và R7 biết rằng các <em>packet</em> cho A có thể được chuyển tiếp đến R3.</p>
<p>Quá trình tiếp tục: R4, R5, R6, và R7 mỗi người nói với neighbour của mình họ là ai, và rằng họ có thể đến được A. Đến cuối cùng, <em>forwarding table</em> của mọi người đều được điền đầy, và chúng ta có thể định tuyến các <em>packet</em> từ bất kỳ đâu trong mạng hướng về A.</p>
<img width="800px" src="routing/../assets/routing/2-035-sketch4.png">
<p>Tóm lại: Khi bạn nhận được một thông báo từ ai đó nói rằng họ có thể đến được A, bạn nên ghi lại người đã gửi thông báo đó. Bây giờ, bạn có thể gửi các tin nhắn dành cho A thông qua người đó.</p>
<p>Ngoài ra, bây giờ bạn đã có cách để gửi tin nhắn đến A, bạn nên tạo một thông báo cho tất cả các neighbour của mình, để họ có thể gửi các tin nhắn dành cho A thông qua bạn.</p>
<p>Nếu có nhiều đích đến thì sao? Chúng ta có thể chạy cùng một thuật toán này lặp đi lặp lại, một lần cho mỗi đích. <em>Forwarding table</em> sau đó sẽ chứa nhiều mục, một mục cho mỗi đích.</p>
<p>Trong các ghi chú này, chúng ta sẽ tập trung vào một phần duy nhất cho đơn giản, nhưng giao thức chúng ta sẽ thiết kế có thể mở rộng cho nhiều đích.</p>
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe về một đường đi đến đích đó, hãy cập nhật bảng.</li>
<li>Sau đó, hãy nói cho tất cả các neighbour của bạn.</li>
</ul>
</blockquote>
<h2 id="hướng-của-thông-báo-và-tin-nhắn"><a class="header" href="#hướng-của-thông-báo-và-tin-nhắn">Hướng của Thông báo và Tin nhắn</a></h2>
<p>Trong giao thức này, rất dễ nhầm lẫn giữa hướng mà các thông báo và tin nhắn được gửi.</p>
<p>Các thông báo về cách đến A bắt đầu tại A, và lan truyền ra ngoài. Ví dụ, B đã gửi một thông báo đến D, nói rằng &quot;Tôi là B, và các tin nhắn cho A có thể được gửi qua tôi.&quot;</p>
<p>Ngược lại, các tin nhắn thực tế được gửi đến A lại được gửi vào trong, hướng về A. Ví dụ, một tin nhắn có thể bắt đầu tại D và được gửi đến B trên đường đến A.</p>
<img width="800px" src="routing/../assets/routing/2-036-directions.png">
<p>Hướng của các thông báo hoàn toàn ngược lại với hướng của chính các tin nhắn! Hãy cẩn thận đừng nhầm lẫn giữa các thông báo và các tin nhắn thực tế!</p>
<h2 id="quy-tắc-1-cập-nhật-bellman-ford"><a class="header" href="#quy-tắc-1-cập-nhật-bellman-ford">Quy tắc 1: Cập nhật Bellman-Ford</a></h2>
<p>Nếu có nhiều đường đi để đến A thì sao?</p>
<img width="500px" src="routing/../assets/routing/2-037-multipath1.png">
<p>Trong kịch bản này, cả R3 và R4 sẽ thông báo rằng chúng có thể đến được A. R5 nên chọn <em>forwarding</em> các <em>packet</em> đến R3 hay R4?</p>
<p>Hãy nhớ lại rằng mục tiêu của chúng ta là tìm các tuyến đường có chi phí thấp nhất qua mạng. Để cho phép các <em>router</em> chọn đường đi có chi phí thấp nhất trong số nhiều đường đang được advertise, chúng ta cũng cần bao gồm chi phí trong các thông báo.</p>
<p>Thông báo của R3 bây giờ nói: &quot;Tôi là R3, và tôi có thể đến A với chi phí 3.&quot;</p>
<p>Thông báo của R4 bây giờ nói: &quot;Tôi là R4, và tôi có thể đến A với chi phí 2.&quot;</p>
<p>Bây giờ, R5 nhận thấy rằng R4 đang cung cấp đường đi ngắn hơn, và quyết định <em>forwarding</em> các <em>packet</em> qua R4.</p>
<img width="700px" src="routing/../assets/routing/2-038-multipath2.png">
<p>Chúng ta sẽ sử dụng <em>forwarding table</em> để ghi nhớ chi phí tốt nhất đã biết đến đích (và chặng tiếp theo tương ứng). Mỗi mục của <em>forwarding table</em> bây giờ cho chúng ta biết: đích, chặng tiếp theo cho đích đó, và chi phí để đến đích qua chặng tiếp theo đó.</p>
<p>Lưu ý: Về mặt hình thức, <em>forwarding table</em> lưu trữ các cặp khóa-giá trị, ánh xạ mỗi đích đến một bộ 2-tuple chứa chặng tiếp theo và khoảng cách. Chúng ta sẽ vẽ các bảng với 3 cột cho đơn giản.</p>
<p>R5 có thể không nghe về cả hai đường đi đồng thời, vì vậy chúng ta cần phải chính xác hơn về những gì xảy ra khi chúng ta nghe về một đường đi mới. Có ba khả năng khi chúng ta nghe về một đường đi:</p>
<ol>
<li>
<p>Nếu bảng không có đường đi đến đích, hãy chấp nhận đường đi đó. Nếu tôi không có cách nào để đến A, tôi nên chấp nhận bất kỳ đường đi nào được cung cấp.</p>
<img width="900px" src="routing/../assets/routing/2-039-multipath3.png">
</li>
<li>
<p>Nếu đường đi mới (mà chúng ta nghe về) tốt hơn đường đi tốt nhất đã biết (từ <em>forwarding table</em>), chúng ta nên chấp nhận đường đi mới, và thay thế đường đi cũ khỏi bảng.</p>
<img width="900px" src="routing/../assets/routing/2-040-multipath4.png">
</li>
<li>
<p>Nếu đường đi mới (mà chúng ta nghe về) tệ hơn đường đi tốt nhất đã biết (từ <em>forwarding table</em>), chúng ta nên bỏ qua đường đi mới, và tiếp tục sử dụng đường đi trong bảng.</p>
</li>
</ol>
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe về một đường đi đến đích đó, hãy cập nhật bảng nếu:
<ul>
<li><strong>Đích không có trong bảng.</strong></li>
<li><strong>Chi phí được advertise tốt hơn chi phí tốt nhất đã biết.</strong></li>
</ul>
</li>
<li>Sau đó, hãy nói cho tất cả các neighbour của bạn.</li>
</ul>
</blockquote>
<p>Làm thế nào để chúng ta biết một đường đi mới là tốt hơn hay tệ hơn? Chúng ta phải cẩn thận, bởi vì không phải tất cả các chi phí liên kết đều giống nhau. Khi ai đó advertise một đường đi, chi phí qua đường đi đó thực sự là tổng của hai con số: Chi phí liên kết từ bạn đến neighbour, cộng với chi phí từ neighbour đến đích (như được advertise bởi neighbour).</p>
<p>Như một ví dụ cụ thể, giả sử chúng ta nghe: &quot;Tôi là R1, và A cách tôi 5.&quot; Chi phí của đường đi mới này thực sự là 1 (chi phí liên kết từ chúng ta đến R1), cộng với 5 (chi phí từ R1 đến A, từ advertise), là 6.</p>
<img width="600px" src="routing/../assets/routing/2-041-costs1.png">
<p>Sau đó, chúng ta có thể nghe: &quot;Tôi là R2, và A cách tôi 3.&quot; Sẽ là không chính xác nếu chỉ nhìn vào chi phí trong advertise. Trong trường hợp này, chi phí của đường đi mới thực sự là 10 (chi phí liên kết từ chúng ta đến R2), cộng với 3 (chi phí từ R2 đến A, từ advertise), là 13. Chi phí này không tốt hơn chi phí tốt nhất đã biết của chúng ta là 6, vì vậy chúng ta không cập nhật bảng. Các <em>packet</em> vẫn được chuyển tiếp đến R1.</p>
<img width="600px" src="routing/../assets/routing/2-042-costs2.png">
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe về một đường đi đến đích đó, hãy cập nhật bảng nếu:
<ul>
<li>Đích không có trong bảng.</li>
<li>Chi phí được advertise, <strong>cộng với chi phí liên kết đến neighbour</strong>, tốt hơn chi phí tốt nhất đã biết.</li>
</ul>
</li>
<li>Sau đó, hãy nói cho tất cả các neighbour của bạn.</li>
</ul>
</blockquote>
<p>Đối với mỗi thông báo chúng ta nghe được, chúng ta phải so sánh hai con số. Một con số là chi phí tốt nhất đã biết trong bảng. Con số kia là tổng của chi phí liên kết đến neighbour, cộng với chi phí được advertise từ neighbour đến đích. Nếu con số sau thấp hơn, chúng ta sử dụng đường đi mới và từ bỏ đường đi cũ.</p>
<h2 id="quy-tắc-1-thuật-toán-bellman-ford-phân-tán"><a class="header" href="#quy-tắc-1-thuật-toán-bellman-ford-phân-tán">Quy tắc 1: Thuật toán Bellman-Ford Phân tán</a></h2>
<p>Phép toán này có quen thuộc không? Hóa ra, đây chính là phép toán nới lỏng từ <em>Dijkstra's shortest paths algorithm (thuật toán tìm đường đi ngắn nhất của Dijkstra)</em>!</p>
<p><em><strong>Bellman-Ford (Thuật toán Bellman-Ford)</strong></em> là một thuật toán tìm đường đi ngắn nhất khác dựa trên phép nới lỏng làm hoạt động chính. <em>Bellman-Ford</em> thậm chí còn đơn giản hơn Dijkstra: Lặp đi lặp lại qua tất cả các cạnh, nới lỏng mọi cạnh, cho đến khi chúng ta có được tất cả các đường đi ngắn nhất.</p>
<p>Bạn có thể đã triển khai Dijkstra hoặc <em>Bellman-Ford</em> trước đây trong một lớp cấu trúc dữ liệu, như CS 61B tại UC Berkeley. Thật không may, đoạn mã bạn đã viết sẽ không hữu ích lắm cho giao thức định tuyến của chúng ta. Hãy nhớ rằng, giao thức định tuyến phải được phân tán, vì các <em>router</em> không có cái nhìn toàn cục về mạng (không có một bộ não trung tâm). Ngoài ra, các <em>router</em> đang hoạt động không đồng bộ. Không có ai thực thi thứ tự mà các <em>router</em> thực hiện các phép toán nới lỏng, hoặc thứ tự mà các <em>router</em> gửi đi các thông báo.</p>
<p>Thay vào đó, giao thức định tuyến mà chúng ta đã thiết kế là một phiên bản phân tán, không đồng bộ của thuật toán <em>Bellman-Ford</em>. Giao thức là phân tán, bởi vì chúng ta không yêu cầu một máy tính duy nhất chạy toàn bộ thuật toán. Thay vào đó, mỗi <em>router</em> đang tính toán phần câu trả lời của riêng mình (điền vào <em>forwarding table</em> của riêng mình) mà không thấy toàn bộ đồ thị. Giao thức là không đồng bộ, bởi vì các <em>router</em> đều có thể chạy thuật toán cùng một lúc, mà không cần phải kiểm soát thứ tự của các hoạt động.</p>
<img width="900px" src="routing/../assets/routing/2-043-bellman-ford.png">
<p>Lưu ý: Mặc dù chúng ta đang hiển thị một đích duy nhất cho đơn giản, đừng quên rằng giao thức định tuyến của chúng ta sẽ có thể tìm thấy các đường đi ngắn nhất đến tất cả các đích, giống như các thuật toán Dijkstra hoặc <em>Bellman-Ford</em> tập trung (một máy tính).</p>
<h2 id="demo-bellman-ford"><a class="header" href="#demo-bellman-ford">Demo Bellman-Ford</a></h2>
<p>Lưu ý về thuật ngữ: Khi chúng ta gửi một tin nhắn như &quot;Tôi là R1, và tôi có thể đến A với chi phí 5,&quot; đến các neighbour của chúng ta, điều này thường được gọi là <em><strong>announcing (thông báo)</strong></em> hoặc <em><strong>advertising (quảng bá)</strong></em> một tuyến đường. Lưu ý rằng advertise chứa ba giá trị: đích, danh tính của bạn (để neighbour của bạn có thể chuyển tiếp đến bạn), và tổng chi phí từ bạn đến đích.</p>
<p>Để trình bày lại thuật toán cho đến nay một lần nữa:</p>
<p>Khi bạn nhận được một thông báo từ một <em>router</em> khác, bạn cộng chi phí từ đích đến <em>router</em> đó (chi phí này có trong thông báo), cộng với chi phí của liên kết từ <em>router</em> đó đến bạn. Nếu tổng này nhỏ hơn khoảng cách tốt nhất đã biết đến đích trong bảng của bạn, bạn thay thế mục <em>forwarding table</em> của mình cho đích này bằng chặng tiếp theo mới (danh tính của <em>router</em> khác từ thông báo) và khoảng cách mới (tổng bạn vừa tính).</p>
<p>Nếu bạn nhận được một thông báo từ một <em>router</em> khác, và đích không có trong <em>forwarding table</em> của bạn thì sao? Bạn không có khoảng cách tốt nhất đã biết đến đích này, bởi vì bạn chưa biết cách đến đích này. Trong trường hợp này, bạn có thể thêm một mục mới vào <em>forwarding table</em> của mình với đích mới, và chặng tiếp theo và chi phí từ thông báo.</p>
<p>Khi bạn thay đổi <em>forwarding table</em> của mình, điều đó có nghĩa là bạn đã khám phá ra một đường đi mới đến đích. Để lan truyền đường đi mới này đến phần còn lại của mạng, bạn sẽ cần thông báo đường đi mới này (đích, danh tính của bạn, và chi phí qua bạn) cho các <em>router</em> liền kề của bạn.</p>
<p>Với thuật toán này trong tâm trí, hãy chạy qua một ví dụ. Trong mạng này, chúng ta sẽ giả sử tất cả các cạnh có chi phí 1 vì các cạnh không được gán nhãn. Chúng ta muốn điền vào các <em>forwarding table</em> với các tuyến đường đến A, đích duy nhất.</p>
<img width="900px" src="routing/../assets/routing/2-044-demo1.png">
<p>Đầu tiên, sử dụng <em>static routing (định tuyến tĩnh)</em>, chúng ta mã hóa cứng một mục trong <em>forwarding table</em> của R1. Để đến đích A, chặng tiếp theo là chính A, và chi phí của đường đi này là 1.</p>
<img width="900px" src="routing/../assets/routing/2-045-demo2.png">
<p><em>Forwarding table</em> của R1 đã thay đổi, vì vậy R1 sẽ tạo một thông báo mới với 3 giá trị: đích (A), danh tính của <em>router</em> (R1), và chi phí đến đích qua <em>router</em> này (1). Thông báo này được gửi đến tất cả các <em>router</em> liền kề của R1, cụ thể là chỉ R2.</p>
<img width="900px" src="routing/../assets/routing/2-046-demo3.png">
<p>R2 nhận được thông báo này và tìm trong <em>forwarding table</em> của nó một mục tương ứng với đích A. <em>Forwarding table</em> trống, vì vậy không có mục nào như vậy tồn tại. Do đó, R2 sẽ thêm một mục mới với 3 giá trị: đích (A), chặng tiếp theo (R1, từ thông báo), và chi phí đến đích qua R1 (2, tổng hợp chi phí trong thông báo và chi phí của liên kết đến R1).</p>
<p><em>Forwarding table</em> của R2 đã thay đổi, vì vậy R2 sẽ tạo một thông báo với 3 giá trị: đích (A), danh tính của <em>router</em> (R2), và chi phí đến đích qua <em>router</em> này (2). Thông báo này được gửi đến tất cả các <em>router</em> liền kề của R2, cụ thể là R3 và R1.</p>
<img width="900px" src="routing/../assets/routing/2-047-demo4.png">
<p>Lưu ý rằng trong giao thức của chúng ta cho đến nay, các <em>router</em> gửi thông báo đến tất cả các neighbour của chúng. Điều này có nghĩa là thông báo của R2 cũng được gửi đến R1. Nếu điều này làm bạn bận tâm, hãy chờ xem, chúng ta sẽ xem lại nó sau.</p>
<p>R1 nhận được thông báo này. Theo <em>forwarding table</em> của R1, cách tốt nhất đã biết để đến A có chi phí 1. Đường đi qua R2 sẽ có chi phí 2 (từ thông báo của R2), cộng 1 (liên kết đến R2), tổng cộng là 3. Đây là một cách tệ hơn để đến A, vì vậy R1 sẽ bỏ qua thông báo này và để <em>forwarding table</em> của nó không thay đổi.</p>
<img width="900px" src="routing/../assets/routing/2-048-demo5.png">
<p>R3 cũng nhận được cùng một thông báo. <em>Forwarding table</em> của R3 trống, vì vậy R3 sẽ cài đặt một mục mới với 3 giá trị: đích (A), chặng tiếp theo (R2, từ thông báo), và chi phí đến đích qua R2 (3, tổng hợp chi phí từ thông báo, và chi phí của liên kết R3-R2).</p>
<img width="900px" src="routing/../assets/routing/2-049-demo6.png">
<p>Theo các quy tắc của chúng ta cho đến nay, nếu bạn cập nhật <em>forwarding table</em> của mình, bạn cần gửi một thông báo đến tất cả các neighbour của bạn. Mặc dù chúng ta có thể thấy rằng thông báo tiếp theo này sẽ không thay đổi bất cứ điều gì, R3 không có cái nhìn toàn cục về mạng như chúng ta, vì vậy R3 sẽ gửi một thông báo đến tất cả các neighbour của nó, cụ thể là R2. Thông báo chứa: đích (A), chặng tiếp theo (R3), và chi phí qua chặng tiếp theo này (3).</p>
<img width="900px" src="routing/../assets/routing/2-050-demo7.png">
<p>R2 nhận được thông báo này. R2 biết một cách để đến A với chi phí 2, từ <em>forwarding table</em>. Thông báo cung cấp một đường đi với chi phí 3 (từ thông báo), cộng 1 (chi phí của liên kết R2-R3), cho tổng chi phí là 4. Điều này tệ hơn chi phí trong <em>forwarding table</em>, vì vậy R2 bỏ qua thông báo.</p>
<p>R2 không cập nhật <em>forwarding table</em> của nó, vì vậy nó không tạo thông báo. Tại thời điểm này, không có thông báo nào được tạo thêm, và chúng ta có thể thấy rằng mọi <em>router</em> đã điền vào <em>forwarding table</em> của nó với thông tin về cách đến A. Chúng ta cũng có thể thấy rằng các <em>forwarding table</em> cùng nhau tạo thành một cây phân phối hợp lệ, có chi phí thấp nhất với các tuyến đường ngắn nhất để đến A.</p>
<img width="900px" src="routing/../assets/routing/2-051-demo8.png">
<h2 id="quy-tắc-2-cập-nhật-từ-chặng-tiếp-theo"><a class="header" href="#quy-tắc-2-cập-nhật-từ-chặng-tiếp-theo">Quy tắc 2: Cập nhật từ Chặng tiếp theo</a></h2>
<p>Hãy nhớ lại một trong những thách thức định tuyến của chúng ta từ phần trước: <em>Topology</em> mạng có thể thay đổi.</p>
<p>Giả sử chúng ta nghe một advertise từ R2, nói rằng A cách R2 là 3. Nếu không có gì trong bảng của chúng ta, chúng ta sẽ chấp nhận advertise này và ghi lại chi phí là 1+3=4.</p>
<img width="900px" src="routing/../assets/routing/2-052-change1.png">
<p>Sau đó, chúng ta có thể nghe một advertise khác từ R2, nói rằng A cách R2 là 8. Từ quy tắc trước, chúng ta sẽ từ chối điều này, bởi vì chi phí được advertise (1+8=9) tệ hơn chi phí hiện tại của chúng ta (4).</p>
<img width="900px" src="routing/../assets/routing/2-053-change2.png">
<p>Tuy nhiên, chúng ta phải cẩn thận khi từ chối advertise này. <em>Router</em> tạo ra thông báo (R2), cũng chính là <em>router</em> chặng tiếp theo mà chúng ta đang sử dụng. R2 đang cố nói: &quot;Nếu bạn đang sử dụng tôi làm chặng tiếp theo, khoảng cách của tôi đến A không còn là 3 nữa, mà là 8.&quot; Nhưng chúng ta đã bỏ qua tin nhắn này vì chúng ta không nghĩ đến khả năng các đường đi có thể thay đổi.</p>
<p>Để khắc phục điều này, chúng ta phải sửa đổi quy tắc cập nhật của mình. Nếu chúng ta nghe một thông báo từ <em>router</em> chặng tiếp theo (router có đường đi tốt nhất đã biết mà chúng ta đang chuyển tiếp <em>packet</em> đến), chúng ta nên coi thông báo đó là một bản cập nhật, và chỉnh sửa <em>forwarding table</em> của mình. Chúng ta nên làm điều này ngay cả khi thông báo tạo ra một đường đi tệ hơn, bởi vì chặng tiếp theo có thể đang nói với chúng ta rằng chi phí đường đi đã thay đổi và trở nên tệ hơn.</p>
<img width="900px" src="routing/../assets/routing/2-054-change3.png">
<p>Lưu ý rằng khi quy tắc mới này được áp dụng, chúng ta không cập nhật đích hoặc chặng tiếp theo trong <em>forwarding table</em>, chỉ có khoảng cách. Trong ví dụ, các <em>packet</em> tại R3 dành cho A vẫn được chuyển tiếp đến R2 (cùng đích, cùng chặng tiếp theo), nhưng chi phí qua R2 đã thay đổi.</p>
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe một advertise cho đích đó, hãy cập nhật bảng nếu:
<ul>
<li>Đích không có trong bảng.</li>
<li>Chi phí được advertise, cộng với chi phí liên kết đến neighbour, tốt hơn chi phí tốt nhất đã biết.</li>
<li><strong>Quảng cáo đến từ chặng tiếp theo hiện tại.</strong></li>
</ul>
</li>
<li>Sau đó, hãy nói cho tất cả các neighbour của bạn.</li>
</ul>
</blockquote>
<p>Để hỗ trợ các <em>topology</em> thay đổi, các <em>router</em> sẽ chạy giao thức định tuyến vô thời hạn.</p>
<p>Giả sử chúng ta chạy giao thức vô thời hạn, không có thay đổi <em>topology</em>. Ban đầu, một số phép nới lỏng sẽ thành công và các <em>forwarding table</em> sẽ thay đổi. Cuối cùng, thuật toán sẽ <em><strong>converge (hội tụ)</strong></em> khi chúng ta đã tìm thấy tất cả các tuyến đường có chi phí thấp nhất qua mạng. Tại thời điểm này, nếu chúng ta tiếp tục nới lỏng các cạnh, các <em>forwarding table</em> sẽ không thay đổi. Mọi phép nới lỏng sẽ bị từ chối, bởi vì các đường đi tốt nhất đã biết đến mục tiêu đều là các đường đi ngắn nhất, và chúng ta sẽ không bao giờ tìm thấy một đường đi tốt hơn để thay thế các đường đi ngắn nhất hiện tại. Trạng thái của mạng khi hội tụ được gọi là <em><strong>steady state (trạng thái ổn định)</strong></em>.</p>
<p>Sau đó, giả sử chúng ta thay đổi <em>topology</em> (ví dụ: có thể một <em>router</em> bị lỗi). Khi chúng ta tiếp tục chạy giao thức, một số phép nới lỏng có thể thành công trở lại, vì chúng ta đã thay đổi đồ thị cơ bản. Sau một thời gian, cây phân phối sẽ hội tụ trở lại trên các tuyến đường có chi phí thấp nhất mới và ngừng thay đổi cho đến lần tiếp theo <em>topology</em> thay đổi.</p>
<p>Để tương tự, hãy xem xét một hồ nước. Ở <em>steady state</em>, không có sự xáo trộn, mặt nước hoàn toàn tĩnh lặng. Nếu bạn ném một viên đá xuống nước, sẽ có một số gợn sóng khi môi trường điều chỉnh theo sự thay đổi bạn vừa thực hiện, nhưng sau một thời gian, mặt nước sẽ trở lại hoàn toàn tĩnh lặng.</p>
<h2 id="quy-tắc-3-gửi-lại"><a class="header" href="#quy-tắc-3-gửi-lại">Quy tắc 3: Gửi lại</a></h2>
<p>Hãy nhớ lại một thách thức định tuyến khác của chúng ta từ phần trước: Các <em>packet</em> có thể bị mất.</p>
<p>Ví dụ, hãy quay lại từ đầu ví dụ trước đó. <em>Forwarding table</em> của R2 và R3 trống, và R1 được cập nhật với tuyến đường được mã hóa cứng đến A. Nếu R1 đưa ra một thông báo, nhưng <em>packet</em> bị mất thì sao? R2 không bao giờ nghe thấy thông báo, và giao thức thất bại.</p>
<img width="900px" src="routing/../assets/routing/2-055-dropped.png">
<p>Bạn có thể thử thiết kế một lược đồ phức tạp hơn để đảm bảo độ tin cậy (ví dụ: buộc người nhận gửi xác nhận), nhưng hãy sử dụng một cái gì đó đơn giản: Nếu bạn có một thông báo cần thực hiện, hãy gửi lại thông báo đó sau mỗi vài giây. Hóa ra cách tiếp cận đơn giản này hoạt động tốt với một số lựa chọn thiết kế sau này của chúng ta, và không cần gì phức tạp hơn.</p>
<p>Về mặt hình thức, giao thức sẽ định nghĩa một <em><strong>advertisement interval (khoảng thời gian quảng bá)</strong></em>. 30 giây là một khoảng thời gian phổ biến được sử dụng trong thực tế. Nếu khoảng thời gian là X giây, thì mọi advertise phải được gửi lại sau mỗi X giây.</p>
<p>Miễn là chúng ta đợi đủ lâu và gửi lại <em>packet</em> đủ nhiều lần, liên kết cuối cùng sẽ gửi thành công advertise, miễn là liên kết hoạt động một phần thời gian. Nếu liên kết làm mất mọi <em>packet</em>, thì không có cách nào để advertise được gửi đi (và có lẽ một liên kết với tỷ lệ thành công 0% không nên có trong đồ thị). Cuối cùng, với đủ lần gửi lại, giao thức này vẫn sẽ hội tụ.</p>
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe một advertise cho đích đó, hãy cập nhật bảng nếu:
<ul>
<li>Đích không có trong bảng.</li>
<li>Chi phí được advertise, cộng với chi phí liên kết đến neighbour, tốt hơn chi phí tốt nhất đã biết.</li>
<li><strong>Quảng cáo đến từ chặng tiếp theo hiện tại.</strong></li>
</ul>
</li>
<li>Quảng bá cho tất cả các neighbour của bạn <strong>khi bảng cập nhật, và định kỳ (advertisement interval)</strong>.</li>
</ul>
</blockquote>
<p>Lưu ý rằng việc gửi lại theo chu kỳ có thể hoạt động kết hợp với quy tắc của chúng ta từ trước đó, nơi chúng ta gửi một thông báo bất cứ khi nào <em>forwarding table</em> thay đổi. Các thông báo được gửi ngay sau khi có thay đổi được gọi là <em><strong>triggered updates (cập nhật kích hoạt)</strong></em>.</p>
<p>Giao thức vẫn sẽ hội tụ nếu chúng ta chỉ gửi thông báo theo chu kỳ. Bảng thay đổi, chúng ta đợi cho đến khi hết khoảng thời gian, và gửi đi thông báo. Tuy nhiên, việc thêm <em>triggered updates</em> ngoài các cập nhật theo chu kỳ là một tối ưu hóa có thể giúp giao thức hội tụ nhanh hơn. Ngay khi chúng ta biết về bản cập nhật, chúng ta cũng có thể thông báo nó ngay, mà không cần đợi hết khoảng thời gian.</p>
<p>Với quy tắc mới này, một khi mạng hội tụ, mọi <em>router</em> sẽ tiếp tục gửi lại các thông báo định kỳ, nhưng không có thông báo nào sẽ được chấp nhận, bởi vì chúng ta đang ở <em>steady state</em> và mọi người đã có các tuyến đường có chi phí ngắn nhất.</p>
<p>Trong ví dụ trước đó, sau khi mạng hội tụ, R3 có thể quyết định gửi lại thông báo của mình, với đích A, chặng tiếp theo R3, và chi phí qua R3 là 3. Nhưng R2 sẽ bỏ qua thông báo này vì <em>forwarding table</em> của nó đã có một tuyến đường rẻ hơn với chi phí 2 (đường đi trong thông báo có chi phí 3 + 1 = 4).</p>
<h2 id="quy-tắc-4-hết-hạn"><a class="header" href="#quy-tắc-4-hết-hạn">Quy tắc 4: Hết hạn</a></h2>
<p>Hãy nhớ lại thách thức định tuyến của chúng ta từ trước đó: <em>Topology</em> mạng có thể thay đổi. Cụ thể, các liên kết và <em>router</em> có thể bị lỗi. Nếu một <em>router</em> bị lỗi trong mạng, tuyến đường của chúng ta có thể trở nên không hợp lệ. <em>Router</em> bị lỗi sẽ không cho chúng ta biết về vấn đề (vì nó đã bị lỗi), vì vậy chúng ta bị mắc kẹt với tuyến đường không hợp lệ này.</p>
<p>Để giải quyết vấn đề này, chúng ta sẽ cho mỗi tuyến đường (tức là mỗi mục trong bảng) một <em><strong>time to live (TTL)</strong></em> hữu hạn. Đây là một bộ đếm thời gian ngược, cho chúng ta biết chúng ta có thể giữ mục chuyển tiếp này trong bao lâu nữa.</p>
<p>Các cập nhật định kỳ giúp chúng ta xác nhận rằng một tuyến đường vẫn còn tồn tại. Nếu chúng ta nhận được một advertise từ chặng tiếp theo, chúng ta có thể đặt lại (&quot;nạp lại&quot;) <em>TTL</em> về giá trị ban đầu của nó.</p>
<p>Nếu có điều gì đó trong mạng bị lỗi, chúng ta sẽ ngừng nhận các cập nhật định kỳ. Cuối cùng, <em>TTL</em> sẽ hết hạn. Nếu <em>TTL</em> hết hạn, chúng ta sẽ xóa mục đó khỏi bảng. Về mặt trực giác: Chúng ta không còn nhận được cập nhật nữa, vì vậy tuyến đường này có lẽ không còn hợp lệ.</p>
<p>Đây là một ví dụ về <em>TTL</em> đang hoạt động. Trong ví dụ này, chúng ta là R3. Tại thời điểm t=0, chúng ta nghe một thông báo: &quot;Tôi là R2, và A cách tôi 5.&quot; Bảng của chúng ta không có mục nào cho A, vì vậy chúng ta sẽ chấp nhận đường đi này, và đặt <em>TTL</em> của nó là 11. Lưu ý rằng <em>TTL</em> này được liên kết với mục bảng cụ thể. Nếu chúng ta có nhiều mục trong bảng, mỗi mục sẽ có <em>TTL</em> riêng.</p>
<img width="900px" src="routing/../assets/routing/2-056-ttl1.png">
<p><em>TTL</em> là 11 cho chúng ta biết rằng R2 phải gửi cho chúng ta một xác nhận khác về tuyến đường này trong 11 giây tới. Nếu không, mục bảng này sẽ bị xóa. (Lưu ý: <em>TTL</em> ban đầu là 11 được chọn một cách tùy ý. Trong thực tế, con số này sẽ được đặt bởi giao thức hoặc người vận hành <em>router</em>.)</p>
<p>Thời gian trôi qua. Tại t=1, <em>TTL</em> bây giờ là 10. Tại t=2, <em>TTL</em> là 9. Tại t=3, <em>TTL</em> là 8. Tại t=4, <em>TTL</em> là 7.</p>
<img width="900px" src="routing/../assets/routing/2-057-ttl2.png">
<p>Tại t=5, R2 thực hiện việc gửi lại thông báo định kỳ của mình: &quot;Tôi là R2, và A cách tôi 5.&quot; Chúng ta nhìn vào bảng của mình và nhận ra rằng R2 là chặng tiếp theo hiện tại đến A, vì vậy chúng ta nên chấp nhận advertise này (theo Quy tắc 2) và cập nhật bảng.</p>
<p>Bởi vì chúng ta đã nhận được một xác nhận rằng tuyến đường này vẫn còn tồn tại, <em>TTL</em> có thể được đặt lại về giá trị ban đầu là 11. Chúng ta cần nhận được một xác nhận khác về tuyến đường này từ R2 trong 11 giây tới.</p>
<img width="900px" src="routing/../assets/routing/2-058-ttl3.png">
<p>Giả sử rằng một liên kết bị hỏng tại t=6, và A bây giờ không thể đến được. R2 loại bỏ tuyến đường tĩnh của nó đến A, và không còn gửi bất kỳ cập nhật định kỳ nào nữa.</p>
<p>Tại t=16 (11 giây sau lần cập nhật cuối cùng tại t=5), <em>TTL</em> trong mục bảng của chúng ta đã giảm xuống 0, vì vậy chúng ta sẽ xóa mục đó khỏi bảng của mình.</p>
<img width="900px" src="routing/../assets/routing/2-059-ttl4.png">
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe một advertise cho đích đó, hãy cập nhật bảng <strong>và đặt lại TTL</strong> nếu:
<ul>
<li>Đích không có trong bảng.</li>
<li>Chi phí được advertise, cộng với chi phí liên kết đến neighbour, tốt hơn chi phí tốt nhất đã biết.</li>
<li>Quảng cáo đến từ chặng tiếp theo hiện tại.</li>
</ul>
</li>
<li>Quảng bá cho tất cả các neighbour của bạn khi bảng cập nhật, và định kỳ (advertisement interval).</li>
<li><strong>Nếu một mục trong bảng hết hạn, hãy xóa nó.</strong></li>
</ul>
</blockquote>
<p>Hãy cẩn thận đừng nhầm lẫn các bộ đếm thời gian khác nhau mà <em>router</em> phải duy trì.</p>
<p><em>Advertisement interval</em> cho <em>router</em> biết khi nào cần quảng bá các tuyến đường cho các neighbour. Đây thường là một bộ đếm thời gian duy nhất cho toàn bộ bảng, vì vậy <em>router</em> quảng bá tất cả các tuyến đường trong bảng bất cứ khi nào bộ đếm thời gian <em>advertisement interval</em> hết hạn. Trong ví dụ trên, bộ đếm thời gian <em>advertisement interval</em> là 5 giây, vì R2 đã gửi advertise tại t=0 và t=5.</p>
<p>Ngược lại, <em>TTL</em> cho <em>router</em> biết khi nào cần xóa một mục trong bảng. Mỗi mục trong bảng có <em>TTL</em> độc lập riêng, đếm ngược cho mục cụ thể đó. Trong ví dụ trên, <em>TTL</em> ban đầu là 11 giây (đặt lại thành 11 khi chúng ta chấp nhận một advertise), và đếm ngược cho mỗi mục trong bảng.</p>
<p>Tại thời điểm này, chúng ta có một giao thức định tuyến gần như hoạt động đầy đủ! Hãy thêm một số tối ưu hóa để hội tụ nhanh hơn.</p>
<h2 id="quy-tắc-5-poisoning-các-tuyến-đường-hết-hạn"><a class="header" href="#quy-tắc-5-poisoning-các-tuyến-đường-hết-hạn">Quy tắc 5: Poisoning các Tuyến đường Hết hạn</a></h2>
<p>Chờ đợi các tuyến đường hết hạn là chậm. Để thấy tại sao, hãy xem lại bản demo từ trước đó.</p>
<p>Trong ví dụ này, chúng ta là R3. Giả sử rằng đến t=5, chúng ta đã học được một tuyến đường đến A, qua R2, và tuyến đường này còn lại 11 giây <em>TTL</em>.</p>
<img width="900px" src="routing/../assets/routing/2-060-poison1.png">
<p>Tại t=6, liên kết A-đến-R2 bị hỏng! Mục trong bảng bây giờ đã hỏng, bởi vì nếu chúng ta chuyển tiếp các <em>packet</em> đến R2, chúng sẽ không thực sự đến được A. Tuy nhiên, chúng ta chưa biết rằng mục này đã hỏng. Chúng ta phải đợi thêm 10 giây nữa để tuyến đường này hết hạn.</p>
<p>Cũng tại t=6, chúng ta nhận được một thông báo mới: &quot;Tôi là R1, và A cách tôi 1.&quot; Chúng ta nhìn vào bảng của mình, và chúng ta đã có một cách để đến A, vì vậy chúng ta từ chối thông báo này. (Lưu ý: Điều này không quan trọng cho bản demo này, nhưng chúng ta đang giả định rằng chúng ta không chấp nhận các đường đi có chi phí bằng nhau ở đây.)</p>
<p>Giá như chúng ta biết rằng tuyến đường hiện tại của mình đã hỏng, chúng ta có thể chấp nhận advertise mới này ngay bây giờ. Nhưng thay vào đó, chúng ta phải chờ đợi thêm 10 giây nữa để sử dụng con đường hỏng này.</p>
<img width="900px" src="routing/../assets/routing/2-061-poison2.png">
<p>Thời gian trôi qua. Đến t=11 (năm giây sau), tuyến đường hỏng vẫn còn lại 5 giây <em>TTL</em>.</p>
<p>Tại t=11, chúng ta nhận được một thông báo khác: &quot;Tôi là R1, và A cách tôi 1.&quot; R1 đang gửi lại thông báo của mình từ trước đó. Một lần nữa, chúng ta nhìn vào bảng của mình, và chúng ta vẫn có một mục cho A, vì vậy chúng ta lại từ chối thông báo này.</p>
<p>Một lần nữa, giá như chúng ta có cách nào đó để biết rằng tuyến đường hiện tại của mình đã hỏng... thì chúng ta có thể chấp nhận advertise mới này. Tuy nhiên, với cách tiếp cận hiện tại của chúng ta, chúng ta phải tiếp tục sử dụng con đường hỏng trong 5 giây còn lại.</p>
<img width="900px" src="routing/../assets/routing/2-062-poison3.png">
<p>Thời gian trôi qua. Đến t=16 (năm giây sau), <em>TTL</em> của tuyến đường hỏng cuối cùng cũng về 0, và chúng ta có thể xóa mục này khỏi bảng.</p>
<p>Cũng tại t=16, R1 lại gửi lại thông báo của mình: &quot;Tôi là R1, và A cách tôi 1.&quot; Cuối cùng, bảng của chúng ta không có tuyến đường đến A (tuyến đường hỏng vừa bị xóa), vì vậy chúng ta có thể chấp nhận thông báo này.</p>
<img width="900px" src="routing/../assets/routing/2-063-poison4.png">
<p>Chuyện gì vừa xảy ra vậy? Tại t=6, sự cố xảy ra, và mục trong bảng của chúng ta trở nên hỏng. Tuy nhiên, vì còn lại 10 giây <em>TTL</em> trên tuyến đường hỏng, chúng ta phải tiếp tục sử dụng tuyến đường hỏng trong 10 giây nữa. Trong thời gian này, bất kỳ <em>packet</em> nào đến A sẽ bị mất, bởi vì chúng ta sẽ chuyển tiếp <em>packet</em> dọc theo một con đường hỏng. Ngoài ra, chúng ta có thể quảng bá tuyến đường hỏng này cho người khác, khiến họ cũng bị mất <em>packet</em>. Cuối cùng, như chúng ta đã thấy, chúng ta có thể từ chối các đường đi mới, nghĩ rằng con đường hỏng vẫn còn hợp lệ.</p>
<p>Vấn đề chính ở đây là: Khi có sự cố xảy ra, nó không được báo cáo, vì vậy chúng ta buộc phải dựa vào thời gian chờ để xóa các con đường hỏng. Điều này chậm. Có cách nào để chúng ta phát hiện sự cố sớm hơn không?</p>
<p>Giải pháp là <em><strong>poison (đánh dấu độc)</strong></em>: Khi có sự cố xảy ra, nếu có thể, hãy advertise một cách rõ ràng rằng một con đường đã hỏng.</p>
<p>Nói một cách thông thường, thông báo <em>poison</em> mới mà R2 gửi sẽ nói: &quot;Tôi là R2, và tôi không còn cách nào để đến A.&quot; Trong giao thức, chúng ta mã hóa thông điệp này bằng cách advertise một con đường với chi phí vô cực: &quot;Tôi là R2, và A cách tôi vô cực.&quot; Con đường chi phí vô cực này đại diện cho một con đường hỏng.</p>
<p>Các con đường bị <em>poison</em> lan truyền giống như bất kỳ con đường nào khác. Nếu chúng ta đang chuyển tiếp các <em>packet</em> đến R2, và chúng ta nhận được một thông điệp <em>poison</em> từ R2, chúng ta cập nhật <em>forwarding table</em> của mình và thay thế chi phí bằng vô cực (theo Quy tắc 2). Chúng ta cũng có thể quảng bá <em>poison</em> chi phí vô cực này cho các neighbour của mình, để họ cũng được cảnh báo về con đường hỏng. Điều này cho phép một con đường không hợp lệ lan truyền qua mạng, điều này có thể nhanh hơn nhiều so với việc chờ đợi con đường hết thời gian.</p>
<p>Hãy xem lại bản demo từ trước đó, nhưng với việc <em>poisoning</em> khi tuyến đường hết hạn. Như trước đây, giả sử rằng đến t=5, chúng ta đã học được một tuyến đường đến A, qua R2, và tuyến đường này còn lại 11 giây <em>TTL</em>.</p>
<img width="900px" src="routing/../assets/routing/2-060-poison1.png">
<p>Tại t=6, liên kết A-đến-R2 bị hỏng! Mục trong bảng bây giờ đã hỏng. Tuy nhiên, chúng ta chưa biết rằng mục này đã hỏng.</p>
<p>Với sửa đổi của chúng ta, thay vì không nói gì, R2 gửi cho chúng ta một thông báo <em>poison</em>: &quot;Tôi là R2, và A cách tôi vô cực.&quot; Theo Quy tắc 2 (chấp nhận từ chặng tiếp theo), chúng ta nhận thấy rằng R2 là chặng tiếp theo của chúng ta, vì vậy chúng ta chấp nhận thông báo này và cập nhật bảng của mình.</p>
<img width="900px" src="routing/../assets/routing/2-064-poison5.png">
<p>Mục trong bảng của chúng ta bây giờ mã hóa thực tế rằng A thực sự không thể đến được qua R2. Mục này có <em>TTL</em>, giống như bất kỳ mục nào khác trong bảng. Ngoài ra, chúng ta có thể quảng bá con đường chi phí vô cực này cho các neighbour của mình, giống như bất kỳ mục nào khác. Điều này cho các neighbour của chúng ta biết rằng chúng ta cũng không còn có thể đến A.</p>
<p>Cũng tại t=6, sau khi cập nhật bảng, chúng ta nhận được một thông báo mới: &quot;Tôi là R1, và A cách tôi 1.&quot; Sử dụng tuyến đường này có khoảng cách là 2 (1 từ liên kết, 1 từ advertise), tốt hơn vô cực (từ bảng). Chúng ta chấp nhận advertise này và cập nhật bảng. Bây giờ, các <em>packet</em> cho A được định tuyến qua R1 thay vì R2.</p>
<img width="900px" src="routing/../assets/routing/2-065-poison6.png">
<p>Trong bản demo trước của chúng ta, tại t=6, chúng ta buộc phải đợi 10 giây để tuyến đường hỏng hết hạn. Nhờ có thông báo <em>poison</em>, chúng ta đã có thể vô hiệu hóa ngay lập tức tuyến đường hỏng đó tại t=6, và chấp nhận con đường mới.</p>
<p>Với <em>poison</em>, chúng ta đã có thể hội tụ trên một con đường hợp lệ sớm hơn. Giữa t=6 và t=16, các <em>packet</em> bây giờ sẽ đến A một cách chính xác (trong khi trong cách tiếp cận không có <em>poison</em>, các <em>packet</em> trong khoảng thời gian này sẽ bị mất). Ngoài ra, nhờ có <em>poison</em>, chúng ta đã tránh được việc lan truyền một tuyến đường hỏng cho người khác trong khoảng thời gian đó. Thậm chí tốt hơn, chúng ta có thể lan truyền <em>poison</em> cho người khác và cho họ biết rằng con đường đến A qua chúng ta (và R2) đã hỏng.</p>
<p>Hãy hình thức hóa các quy tắc của <em>poison</em>. <em>Poison</em> bắt nguồn từ một trong hai nguồn: một trong các tuyến đường của bạn hết thời gian, hoặc bạn nhận thấy một sự cố cục bộ (ví dụ: một trong các liên kết của bạn bị hỏng). Khi một trong những điều này xảy ra, bạn có thể cập nhật mục bảng thích hợp với chi phí vô cực, đặt lại <em>TTL</em>, và quảng bá <em>poison</em> này cho các neighbour của bạn.</p>
<p><em>Poison</em> lan truyền như thế nào? Khi bạn nhận được một advertise <em>poison</em> từ chặng tiếp theo hiện tại của mình, hãy chấp nhận nó. Chặng tiếp theo của bạn đang nói với bạn rằng tuyến đường không còn tồn tại (tương tự như advertise các con đường tệ hơn trong Quy tắc 2), vì vậy bạn cần cập nhật bảng của mình. Khi bạn cập nhật bảng, bạn đặt lại <em>TTL</em>, giống như bất kỳ cập nhật bảng nào khác. Bạn cũng quảng bá <em>poison</em> cho các neighbour của mình, giống như bất kỳ cập nhật bảng nào khác, để các neighbour của bạn cũng biết về tuyến đường hỏng.</p>
<p>Một sửa đổi cuối cùng: Bây giờ bảng của chúng ta chứa <em>poison</em>, chúng ta phải cẩn thận không chuyển tiếp các <em>packet</em> dọc theo một tuyến đường bị <em>poison</em>. Nếu một mục trong bảng nói rằng A có thể đến được qua R1 với chi phí vô cực, điều này thực sự có nghĩa là A không thể đến được qua R1. Nếu chúng ta nhận được một <em>packet</em> dành cho A, chúng ta không thể chuyển tiếp nó đến R1.</p>
<img width="500px" src="routing/../assets/routing/2-066-poison-route.png">
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe một advertise cho đích đó, hãy cập nhật bảng <strong>và đặt lại TTL</strong> nếu:
<ul>
<li>Đích không có trong bảng.</li>
<li>Chi phí được advertise, cộng với chi phí liên kết đến neighbour, tốt hơn chi phí tốt nhất đã biết.</li>
<li>Quảng cáo đến từ chặng tiếp theo hiện tại. <strong>Bao gồm cả các advertise poison.</strong></li>
</ul>
</li>
<li>Quảng bá cho tất cả các neighbour của bạn khi bảng cập nhật, và định kỳ (advertisement interval).</li>
<li>Nếu một mục trong bảng hết hạn, <strong>hãy biến mục đó thành poison và quảng bá nó</strong>.</li>
</ul>
</blockquote>
<h2 id="quy-tắc-6a-split-horizon"><a class="header" href="#quy-tắc-6a-split-horizon">Quy tắc 6A: Split Horizon</a></h2>
<p>Hãy quay lại ví dụ yêu thích của chúng ta một lần nữa để minh họa một vấn đề khác. Giả sử chúng ta đang ở <em>steady state</em>, và các <em>forwarding table</em> có các tuyến đường ngắn nhất chính xác đến A. Các thông báo đang được gửi lại định kỳ, nhưng tất cả các thông báo đều bị từ chối vì chúng ta đang ở <em>steady state</em>.</p>
<img width="900px" src="routing/../assets/routing/2-067-splithorizon1.png">
<p>Liên kết R1-R2 bị hỏng, và mục của R2 hết hạn, bởi vì R1 đã ngừng gửi các thông báo định kỳ. R2 bây giờ có một <em>forwarding table</em> trống. Chuyện gì xảy ra tiếp theo?</p>
<img width="900px" src="routing/../assets/routing/2-068-splithorizon2.png">
<p>Cuối cùng, R3 gửi lại thông báo của mình đến R2, với đích (A), chặng tiếp theo (R3), và chi phí qua chặng tiếp theo (3).</p>
<p>Bảng của R2 trống, vì vậy nó chấp nhận thông báo này và thêm đích (A), chặng tiếp theo (R3), và chi phí qua chặng tiếp theo (3 + 1 = 4).</p>
<img width="900px" src="routing/../assets/routing/2-069-splithorizon3.png">
<p>Chúng ta đã tạo ra một vòng lặp định tuyến! R2 sẽ chuyển tiếp các <em>packet</em> đến R3, và R3 sẽ chuyển tiếp các <em>packet</em> đến R2.</p>
<img width="900px" src="routing/../assets/routing/2-070-splithorizon4.png">
<p>Vấn đề này có thể khó nhận ra lúc đầu, vì vậy hãy diễn đạt lại nó một cách trực quan. Giả sử tôi đã chấp nhận một tuyến đường từ Alice, điều đó có nghĩa là tôi sẽ chuyển tiếp các <em>packet</em> đến Alice. Điều gì xảy ra nếu sau đó tôi cung cấp lại tuyến đường này cho Alice? Nếu cô ấy chấp nhận tuyến đường, cô ấy sẽ chuyển tiếp các <em>packet</em> đến tôi, và tôi sẽ chuyển tiếp <em>packet</em> trở lại cho cô ấy.</p>
<p>Nếu <em>topology</em> mạng không bao giờ thay đổi, advertise này là vô hại. Con đường tôi đang cung cấp cho Alice đi từ Alice, đến tôi, trở lại Alice. Con đường mới này chắc chắn đắt hơn vì nó thêm một vòng lặp không cần thiết, vì vậy Alice sẽ luôn từ chối advertise này.</p>
<p>Tuy nhiên, advertise này nguy hiểm nếu Alice mất tuyến đường của mình. Bây giờ, advertise của tôi đang lừa Alice nghĩ rằng cô ấy có thể gửi <em>packet</em> cho tôi. Nhưng, con đường của tôi lại dựa vào chính Alice, vì vậy nếu cô ấy chấp nhận con đường này, chúng ta sẽ tạo ra một vòng lặp nơi cô ấy gửi <em>packet</em> cho tôi, chỉ để tôi gửi <em>packet</em> ngay trở lại cho cô ấy. Vấn đề chính ở đây là: Alice nghĩ rằng con đường tôi đang quảng bá là độc lập và không bao giờ đi qua Alice. Nhưng thực tế, con đường của tôi có đi qua Alice, vì vậy nếu cô ấy chấp nhận con đường của tôi, cô ấy sẽ chuyển tiếp các <em>packet</em> trở lại chính mình.</p>
<p>Để giải quyết vấn đề này, chúng ta cần tránh cung cấp cho Alice một tuyến đường đã liên quan đến chính cô ấy. Chúng ta không bao giờ muốn Alice chấp nhận một tuyến đường gửi các <em>packet</em> trở lại chính mình.</p>
<p>Điều này dẫn chúng ta đến một giải pháp được gọi là <em><strong>split horizon (chân trời phân tách)</strong></em>, nơi chúng ta không bao giờ quảng bá một tuyến đường trở lại cho người đã cung cấp tuyến đường đó cho chúng ta.</p>
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe một advertise cho đích đó, hãy cập nhật bảng <strong>và đặt lại TTL</strong> nếu:
<ul>
<li>Đích không có trong bảng.</li>
<li>Chi phí được advertise, cộng với chi phí liên kết đến neighbour, tốt hơn chi phí tốt nhất đã biết.</li>
<li>Quảng cáo đến từ chặng tiếp theo hiện tại. Bao gồm cả các advertise poison.</li>
</ul>
</li>
<li>Quảng bá cho tất cả các neighbour của bạn khi bảng cập nhật, và định kỳ (advertisement interval).
<ul>
<li><strong>Nhưng không quảng bá trở lại cho chặng tiếp theo.</strong></li>
</ul>
</li>
<li>Nếu một mục trong bảng hết hạn, hãy biến mục đó thành poison và quảng bá nó.</li>
</ul>
</blockquote>
<h2 id="quy-tắc-6b-poison-reverse"><a class="header" href="#quy-tắc-6b-poison-reverse">Quy tắc 6B: Poison Reverse</a></h2>
<p><em><strong>Poison reverse (đánh dấu độc ngược)</strong></em> là một cách thay thế để tránh các vòng lặp định tuyến. Chúng ta có thể sử dụng <em>split horizon</em> hoặc <em>poison reverse</em> để giải quyết vấn đề từ trước đó (nhưng không phải cả hai).</p>
<p>Trong <em>split horizon</em>, nếu ai đó cho tôi một tuyến đường, tôi không quảng bá tuyến đường đó trở lại cho họ.</p>
<p>Ngược lại, trong <em>poison reverse</em>, nếu ai đó cho tôi một tuyến đường, tôi quảng bá <em>poison</em> một cách rõ ràng trở lại cho họ. Nói cách khác, tôi nói rõ với họ, &quot;Đừng chuyển tiếp <em>packet</em> theo đường của tôi&quot; (bởi vì tôi sẽ chỉ chuyển tiếp chúng trở lại cho bạn).</p>
<img width="900px" src="routing/../assets/routing/2-071-poisonreverse1.png">
<p>Hãy xem lại bản demo, nhưng lần này sử dụng <em>poison reverse</em> thay vì <em>split horizon</em>. Như trước đây, chúng ta đạt <em>steady state</em>, sau đó R1-R2 bị hỏng, và R2 mất mục trong bảng của nó.</p>
<img width="900px" src="routing/../assets/routing/2-072-poisonreverse2.png">
<p>Nếu chúng ta không triển khai sửa lỗi nào, đây là lúc R3 sẽ quảng bá tuyến đường của mình cho R2, và R2 sẽ chấp nhận một tuyến đường đi qua chính nó.</p>
<p>Nếu chúng ta triển khai <em>split horizon</em>, R3 sẽ không quảng bá tuyến đường của mình trở lại cho R2 tại thời điểm này.</p>
<p>Trong cách tiếp cận <em>poison reverse</em>, R3 gửi một advertise một cách rõ ràng trở lại cho R2: &quot;Tôi là R3, và A cách tôi vô cực.&quot;</p>
<img width="900px" src="routing/../assets/routing/2-073-poisonreverse3.png">
<p>R2 không có mục nào cho A (mục cũ của nó đã hết hạn), vì vậy nó chấp nhận tuyến đường bị <em>poison</em> mới này. Bây giờ, bảng của R2 nói rõ rằng nó không thể đến A qua R3. Chúng ta đã tránh được vòng lặp định tuyến với sự trợ giúp của <em>poison reverse</em>!</p>
<p>Trong mô hình mạng của chúng ta, cả <em>split horizon</em> và <em>poison reverse</em> đều sẽ giúp tránh các vòng lặp định tuyến. Nói chung, <em>poison reverse</em> có thể giúp loại bỏ các vòng lặp định tuyến sớm hơn nếu chúng từng phát sinh.</p>
<p>Ví dụ, giả sử chúng ta kết thúc với một vòng lặp định tuyến bằng cách nào đó, nơi R2 và R3 đang chuyển tiếp các <em>packet</em> cho nhau.</p>
<p>Trong cách tiếp cận <em>split horizon</em>, không có <em>poison</em> nào được gửi. R2 nhận được tuyến đường của mình từ R3, vì vậy nó sẽ không gửi bất cứ điều gì cho R3. Tương tự, R3 nhận được tuyến đường của mình từ R2, vì vậy nó sẽ không gửi bất cứ điều gì cho R2. Vòng lặp tồn tại cho đến khi các mục trong bảng hết hạn. Cho đến lúc đó, các <em>packet</em> có thể bị mất trong vòng lặp.</p>
<img width="900px" src="routing/../assets/routing/2-074-split-and-poison1.png">
<p>Ngược lại, nếu chúng ta sử dụng cách tiếp cận <em>poison reverse</em>, R3 gửi <em>poison</em> một cách rõ ràng trở lại cho R2: &quot;Tôi là R3, và A cách tôi vô cực.&quot; R2 chấp nhận advertise này (Quy tắc 2, tuyến đường từ chặng tiếp theo của nó), và cập nhật bảng của mình để vô hiệu hóa đường đi qua R3. Quảng cáo <em>poison reverse</em> ngay lập tức loại bỏ vòng lặp định tuyến.</p>
<img width="900px" src="routing/../assets/routing/2-075-split-and-poison2.png">
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe một advertise cho đích đó, hãy cập nhật bảng <strong>và đặt lại TTL</strong> nếu:
<ul>
<li>Đích không có trong bảng.</li>
<li>Chi phí được advertise, cộng với chi phí liên kết đến neighbour, tốt hơn chi phí tốt nhất đã biết.</li>
<li>Quảng cáo đến từ chặng tiếp theo hiện tại. Bao gồm cả các advertise poison.</li>
</ul>
</li>
<li>Quảng bá cho tất cả các neighbour của bạn khi bảng cập nhật, và định kỳ (advertisement interval).
<ul>
<li>Nhưng không quảng bá trở lại cho chặng tiếp theo.</li>
<li><strong>...Hoặc, quảng bá poison trở lại cho chặng tiếp theo.</strong></li>
</ul>
</li>
<li>Nếu một mục trong bảng hết hạn, hãy biến mục đó thành poison và quảng bá nó.</li>
</ul>
</blockquote>
<p>Lưu ý rằng <em>split horizon</em> và <em>poison reverse</em> là hai lựa chọn, và bạn có thể chọn chính xác một để sử dụng (không phải cả hai). Hoặc bạn không nói gì trở lại cho chặng tiếp theo, hoặc bạn quảng bá <em>poison</em> một cách rõ ràng trở lại cho chặng tiếp theo.</p>
<h2 id="quy-tắc-7-Đếm-đến-vô-cực"><a class="header" href="#quy-tắc-7-Đếm-đến-vô-cực">Quy tắc 7: Đếm đến Vô cực</a></h2>
<p><em>Split horizon</em> hoặc <em>poison reverse</em> đã giúp chúng ta tránh các vòng lặp có độ dài 2, nơi R1 chuyển tiếp đến R2, và R2 chuyển tiếp đến R1. Nhưng chúng ta vẫn có thể gặp phải các vòng lặp định tuyến liên quan đến 3 hoặc nhiều <em>router</em> hơn.</p>
<img width="900px" src="routing/../assets/routing/2-076-infinity1.png">
<p>Để thấy tại sao, hãy xem xét mạng này. Giả sử các bảng đạt <em>steady-state</em>. Cả R1 và R2 đều chuyển tiếp đến R3, R3 chuyển tiếp đến A.</p>
<p>Liên kết A-R3 bị hỏng! A bây giờ không thể đến được. Theo Quy tắc 5, R3 cập nhật bảng của mình để hiển thị chi phí vô cực đến A, và gửi <em>poison</em> này đến cả R2 và R1.</p>
<img width="900px" src="routing/../assets/routing/2-077-infinity2.png">
<p>R2 nhận được advertise <em>poison</em> và cập nhật bảng của mình (Quy tắc 2, chấp nhận từ chặng tiếp theo). Bây giờ, cả R2 và R3 đều biết rằng A không thể đến được.</p>
<p>Quảng cáo <em>poison</em> đến R1 bị mất! R1 không thấy <em>poison</em>, vì vậy nó vẫn nghĩ rằng nó có thể đến A qua R3. (<em>Poison</em> có thể được gửi lại sau, nhưng trong bản demo này, tất cả những điều tồi tệ sắp xảy ra sẽ xảy ra trước khi <em>poison</em> có cơ hội được gửi lại.)</p>
<p>Tại thời điểm này, R2 và R3 không thể đến A, nhưng R1 nghĩ rằng nó vẫn có thể đến A.</p>
<img width="900px" src="routing/../assets/routing/2-078-infinity3.png">
<p>Cuối cùng, R1 gửi đi một advertise. Con đường của R1 đến A là qua R3, vì vậy theo <em>split horizon</em>, nó sẽ không quảng bá cho R3. Tuy nhiên, R1 vẫn sẽ quảng bá cho R2: &quot;Tôi là R1, và A cách tôi 2.&quot;</p>
<img width="900px" src="routing/../assets/routing/2-079-infinity4.png">
<p>R2 không có cách nào để đến A, vì vậy nó chấp nhận tuyến đường này. Bây giờ, R2 bị lừa nghĩ rằng nó có thể đến A với chi phí 3.</p>
<p>R2 gửi đi một advertise về tuyến đường mới của mình. <em>Split horizon</em> quy định rằng R2 sẽ không quảng bá trở lại cho R1, nhưng nó vẫn sẽ quảng bá cho R3: &quot;Tôi là R2, và A cách tôi 3.&quot;</p>
<img width="900px" src="routing/../assets/routing/2-080-infinity5.png">
<p>R3 không có cách nào để đến A, vì vậy nó chấp nhận tuyến đường này. Bây giờ, R3 bị lừa nghĩ rằng nó có thể đến A với chi phí 4.</p>
<p>Tiếp theo, R3 gửi đi một advertise cho R1 (không phải R2, theo <em>split horizon</em>): &quot;Tôi là R3, và A cách tôi 4.&quot;</p>
<img width="900px" src="routing/../assets/routing/2-081-infinity6.png">
<p>R1 sẽ chấp nhận advertise này (Quy tắc 2, advertise từ chặng tiếp theo) và cập nhật bảng của mình. Bây giờ, R1 nghĩ chi phí của nó đến A là 5.</p>
<p>Có lẽ bạn đang thấy điều này sẽ đi đến đâu. R1 quảng bá cho R2 (không phải R3, theo <em>split horizon</em>): &quot;Tôi là R1, và A cách tôi 5.&quot;</p>
<img width="900px" src="routing/../assets/routing/2-082-infinity7.png">
<p>R2 chấp nhận advertise này (Quy tắc 2), và nghĩ rằng nó có thể đến A với chi phí 6.</p>
<img width="900px" src="routing/../assets/routing/2-083-infinity8.png">
<p>R2 quảng bá một chi phí là 6 cho R3, người bây giờ nghĩ rằng nó có thể đến A với chi phí 7.</p>
<img width="900px" src="routing/../assets/routing/2-084-infinity9.png">
<p>R3 quảng bá một chi phí là 7 cho R1, người bây giờ nghĩ rằng nó có thể đến A với chi phí 8.</p>
<img width="900px" src="routing/../assets/routing/2-085-infinity10.png">
<p>R1, R2, và R3 sẽ tiếp tục gửi các advertise cho nhau theo một chu kỳ, với chi phí ngày càng cao (tất cả đều sẽ được chấp nhận bởi Quy tắc 2). Ngoài ra, các <em>packet</em> cho A sẽ bị kẹt trong một vòng lặp chuyển tiếp giữa các <em>router</em> này.</p>
<p>Hãy trình bày lại vấn đề một lần nữa. <em>Poison</em> đã không lan truyền chính xác đến tất cả các <em>host</em>, vì vậy một trong các <em>router</em> vẫn còn một con đường hỏng trong bảng của nó. Sau đó, con đường hỏng đó được quảng bá trong một vòng lặp, và Quy tắc 2 đã khiến chi phí tiếp tục tăng, không có hồi kết.</p>
<p>Tại sao <em>split horizon</em> không cứu chúng ta? Hãy nhớ rằng, <em>split horizon</em> chỉ ngăn một <em>router</em> quảng bá trở lại cho chặng tiếp theo của nó. Nhưng trong trường hợp này, vòng lặp có độ dài 3, và chúng ta chưa bao giờ quảng bá trở lại cho chặng tiếp theo.</p>
<p>(Lưu ý: <em>Poison reverse</em> cũng không cứu chúng ta. Nếu R3 quảng bá <em>poison</em> trở lại cho R2, thì R2 sẽ bỏ qua <em>poison</em> đó, bởi vì chặng tiếp theo của R2 là R1, không phải R3.)</p>
<p>Đây được gọi là vấn đề <em><strong>count-to-infinity (đếm đến vô cực)</strong></em>, và không có sửa lỗi nào của chúng ta cho đến nay (<em>poison</em> các tuyến đường hết hạn, <em>split horizon</em>, <em>poison reverse</em>) có thể giải quyết được nó.</p>
<p>Để giải quyết vấn đề này, chúng ta sẽ thực thi một chi phí tối đa. Trong <em>RIP</em>, giá trị này là 15. Tất cả các chi phí lớn hơn mức tối đa này (tức là 16 trở lên) được coi là vô cực.</p>
<p>Với sửa lỗi này, vòng lặp vẫn sẽ tồn tại trong một thời gian, nhưng cuối cùng, tất cả các chi phí sẽ đạt đến 16 (vô cực). Hãy xem điều này hoạt động.</p>
<p>Các chi phí đang tăng lên với mỗi advertise. Cuối cùng, R1 quảng bá cho R2: &quot;Tôi là R1, và A cách tôi 14.&quot; R2 chấp nhận (theo Quy tắc 2) và cập nhật chi phí của mình lên 15.</p>
<img width="900px" src="routing/../assets/routing/2-086-infinity11.png">
<p>R2 quảng bá cho R3: &quot;Tôi là R2, và A cách tôi 15.&quot; R3 chấp nhận (theo Quy tắc 2), nhưng thay vì cập nhật chi phí của mình lên 16, chi phí được cập nhật thành vô cực.</p>
<img width="900px" src="routing/../assets/routing/2-087-infinity12.png">
<p>Tiếp theo, R3 quảng bá cho R1: &quot;Tôi là R3, và A cách tôi vô cực.&quot; R1 chấp nhận (theo Quy tắc 2), và bây giờ R1 cũng có chi phí vô cực. (Lưu ý: Quảng cáo này trông giống như <em>poison</em>, mặc dù vô cực bắt nguồn từ việc đếm đến vô cực thay vì phát hiện một sự cố.)</p>
<img width="900px" src="routing/../assets/routing/2-088-infinity13.png">
<p>Cuối cùng, R1 quảng bá cho R2: &quot;Tôi là R1, và A cách tôi vô cực.&quot; R2 chấp nhận (theo Quy dashboards 2), và bây giờ tất cả các <em>router</em> đều có chi phí vô cực.</p>
<img width="900px" src="routing/../assets/routing/2-089-infinity14.png">
<p>Chúng ta đã đạt đến <em>steady-state</em> một lần nữa! Bất kỳ advertise nào trong tương lai đều sẽ quảng bá chi phí vô cực, và chúng sẽ không thay đổi các bảng. Cuối cùng, các mục chi phí vô cực đều sẽ hết hạn. Hoặc, nếu một tuyến đường khác đến A xuất hiện, nó sẽ thay thế mục chi phí vô cực.</p>
<p>{: .blue}</p>
<blockquote>
<p>Hãy xem lại giao thức của chúng ta cho đến nay.</p>
<p>Đối với mỗi đích:</p>
<ul>
<li>Nếu bạn nghe một advertise cho đích đó, hãy cập nhật bảng <strong>và đặt lại TTL</strong> nếu:
<ul>
<li>Đích không có trong bảng.</li>
<li>Chi phí được advertise, cộng với chi phí liên kết đến neighbour, tốt hơn chi phí tốt nhất đã biết.</li>
<li>Quảng cáo đến từ chặng tiếp theo hiện tại. Bao gồm cả các advertise poison.</li>
</ul>
</li>
<li>Quảng bá cho tất cả các neighbour của bạn khi bảng cập nhật, và định kỳ (advertisement interval).
<ul>
<li>Nhưng không quảng bá trở lại cho chặng tiếp theo.</li>
<li>...Hoặc, quảng bá poison trở lại cho chặng tiếp theo.</li>
<li><strong>Bất kỳ chi phí nào lớn hơn hoặc bằng 16 đều được quảng bá là vô cực.</strong></li>
</ul>
</li>
<li>Nếu một mục trong bảng hết hạn, hãy biến mục đó thành poison và quảng bá nó.</li>
</ul>
</blockquote>
<h2 id="cập-nhật-theo-sự-kiện"><a class="header" href="#cập-nhật-theo-sự-kiện">Cập nhật theo Sự kiện</a></h2>
<p>Có ba trường hợp mà một <em>router</em> có thể muốn gửi advertise:</p>
<ol>
<li>
<p>Gửi advertise khi bảng thay đổi. Đây được gọi là <em><strong>triggered updates</strong></em>. Bảng có thể thay đổi khi chúng ta chấp nhận một advertise mới, hoặc khi một liên kết mới được thêm vào (ví dụ: tuyến đường tĩnh mới), hoặc khi một liên kết bị hỏng (ví dụ: tuyến đường bị <em>poison</em>).</p>
</li>
<li>
<p>Gửi advertise định kỳ, một lần mỗi <em>advertisement interval</em>.</p>
</li>
<li>
<p>Gửi advertise khi một mục trong bảng hết hạn (và được thay thế bằng <em>poison</em>).</p>
</li>
</ol>
<p>Lưu ý rằng <em>triggered updates</em> là một tối ưu hóa. Thay vì advertise mỗi khi bảng thay đổi, chúng ta có thể chỉ cần đợi đến <em>advertisement interval</em> tiếp theo để quảng bá các thay đổi. Giao thức này vẫn sẽ đúng. Tuy nhiên, <em>triggered updates</em>, ngoài các cập nhật định kỳ, giúp giao thức của chúng ta hội tụ trên các tuyến đường chính xác nhanh hơn, bởi vì chúng ta lan truyền thông tin mới ngay khi chúng ta biết về nó.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="giao-thức-trạng-thái-liên-kết-link-state-protocols"><a class="header" href="#giao-thức-trạng-thái-liên-kết-link-state-protocols">Giao thức Trạng thái Liên kết (Link-State Protocols)</a></h1>
<h2 id="giới-thiệu-về-giao-thức-link-state"><a class="header" href="#giới-thiệu-về-giao-thức-link-state">Giới thiệu về Giao thức Link-State</a></h2>
<p>Hãy nhớ lại rằng có nhiều lớp <em>routing protocol</em> khác nhau, tùy thuộc vào thuật toán cơ bản của chúng. Trong phần trước, chúng ta đã tìm hiểu về lớp giao thức <em>distance-vector</em>. Trong phần này, chúng ta sẽ thảo luận về <em><strong>link-state</strong></em> (trạng thái liên kết), một lớp giao thức chính khác.</p>
<p>Cũng hãy nhớ lại rằng các giao thức cũng có thể được phân loại thành <em>exterior gateway protocols</em> (giao thức cổng ngoại vi) (hoạt động giữa các mạng) và <em>interior gateway protocols</em> (giao thức cổng nội vi) (hoạt động bên trong các mạng). Giống như <em>distance-vector</em>, các giao thức <em>link-state</em> thường là <em>interior gateway protocols</em>.</p>
<p><em>IS-IS</em> (Intermediate System to Intermediate System - Hệ thống trung gian đến Hệ thống trung gian) và <em>OSPF</em> (Open Shortest Path First - Ưu tiên đường đi ngắn nhất) là hai ví dụ chính về các giao thức <em>link-state</em>. Cả hai đều được triển khai rộng rãi ngày nay.</p>
<h2 id="tổng-quan-về-link-state"><a class="header" href="#tổng-quan-về-link-state">Tổng quan về Link-State</a></h2>
<p><em>Distance-vector</em> thực hiện một phép tính phân tán, hợp tác. Mỗi nút tự tính toán phần giải pháp của riêng mình, dựa trên kết quả được tính toán bởi các láng giềng của nó. Phép tính trên tất cả các nút cùng nhau tạo thành giải pháp đầy đủ. Mỗi nút chỉ cần thông tin cục bộ từ các láng giềng của nó trong phép tính (các nút không biết toàn bộ <em>network graph</em> (đồ thị mạng)).</p>
<p>Ngược lại, các giao thức <em>link-state</em> thực hiện một phép tính cục bộ. Mỗi nút tự tính toán giải pháp đầy đủ một cách độc lập và từ đầu, mà không sử dụng bất kỳ kết quả tính toán nào từ các láng giềng. Tuy nhiên, để làm được điều này, mỗi nút cần thông tin toàn cục từ tất cả các phần của mạng.</p>
<p>Giao thức <em>link-state</em> trong một câu: Mọi <em>router</em> tìm hiểu toàn bộ <em>network graph</em>, và sau đó chạy thuật toán tìm <em>shortest-paths</em> (đường đi ngắn nhất) trên đồ thị để điền vào <em>forwarding table</em>.</p>
<p>Có hai bước chính mà chúng ta phải thực hiện. Đầu tiên, <em>router</em> cần bằng cách nào đó tìm hiểu toàn bộ <em>network graph</em>, bao gồm trạng thái của mọi liên kết (hoạt động hay không), chi phí của mọi liên kết, và vị trí của mọi đích đến.</p>
<p>Sau đó, <em>router</em> cần chạy một thuật toán nào đó trên đồ thị đó để tìm hiểu cách <em>forwarding</em> các gói tin đến mọi đích đến.</p>
<p>Chúng ta sẽ suy nghĩ về bước thứ hai trước (<em>shortest-paths</em>), sau đó suy nghĩ về bước thứ nhất (tìm hiểu đồ thị).</p>
<h2 id="tính-toán-Đường-đi-computing-paths"><a class="header" href="#tính-toán-Đường-đi-computing-paths">Tính toán Đường đi (Computing Paths)</a></h2>
<p>Một khi <em>router</em> có cái nhìn toàn cục về mạng, nó có thể dễ dàng tính toán các đường đi qua mạng bằng một số <em>shortest-path algorithm</em> (thuật toán tìm đường đi ngắn nhất).</p>
<p>Cụ thể, <em>router</em> nên tính toán đường đi ngắn nhất đến mọi đích. Sau đó, đối với mỗi đích, <em>router</em> ghi lại <em>next hop</em> dọc theo đường đi ngắn nhất, giống như trong các giao thức <em>distance-vector</em>. Phần còn lại của đường đi không cần thiết trong quá trình <em>forwarding</em>.</p>
<p>Nhiều <em>shortest-path algorithm</em> từ một nguồn duy nhất có thể được sử dụng trong bước này. Ví dụ, <em>Bellman-Ford algorithm</em> (thuật toán Bellman-Ford) (phiên bản tuần tự, không có các thay đổi của <em>distance-vector</em>) và <em>Dijkstra's algorithm</em> (thuật toán Dijkstra) đều tính toán hiệu quả đường đi ngắn nhất từ một nguồn duy nhất đến tất cả các đích. Chúng ta cũng có thể xem xét các giải pháp thay thế như <em>breadth-first search</em> (tìm kiếm theo chiều rộng), hoặc các thuật toán có thể chạy song song.</p>
<p>Một điều chúng ta phải cẩn thận là sự không nhất quán giữa các <em>router</em>.</p>
<img width="900px" src="routing/../assets/routing/2-090-link-state-loop.png">
<p>Hãy nhớ rằng, mọi <em>router</em> đều tính toán các đường đi ngắn nhất một cách độc lập, và quyết định một <em>next hop</em> tương ứng. Mỗi <em>router</em> chỉ kiểm soát <em>next hop</em> của chính nó, và không thể ảnh hưởng đến những gì <em>next hop</em> sẽ làm.</p>
<p>Ví dụ, giả sử R3 tính toán đường đi ngắn nhất này đến A, và quyết định <em>forwarding</em> các gói tin đến R2. Sau đó, R2 tính toán đường đi ngắn nhất này đến A, và quyết định <em>forwarding</em> các gói tin đến R3. Cả hai <em>router</em> đều tính toán các đường đi ngắn nhất hợp lệ, nhưng quyết định của chúng đã dẫn đến một <em>routing loop</em> (vòng lặp định tuyến).</p>
<p>Để tránh vấn đề này, chúng ta phải đảm bảo rằng tất cả các <em>router</em> đang đưa ra các quyết định <em>forwarding</em> tương thích với nhau. Các yêu cầu để tất cả các <em>router</em> đưa ra các quyết định tương thích là gì?</p>
<ol>
<li>
<p>Tất cả các <em>router</em> phải đồng ý về <em>network topology</em> (cấu trúc liên kết mạng). Giả sử một liên kết bị lỗi, nhưng chỉ có một <em>router</em> biết về nó. Khi đó, các <em>router</em> khác nhau đang tính toán các đường đi trên các đồ thị hoàn toàn khác nhau, và có thể tạo ra các kết quả không nhất quán.</p>
</li>
<li>
<p>Tất cả các <em>router</em> đang tìm các đường đi chi phí thấp nhất qua đường đi. Nếu một <em>router</em> ưu tiên các đường đi đắt hơn vì một lý do nào đó, chúng ta sẽ nhận được kết quả không nhất quán.</p>
</li>
<li>
<p>Tất cả các chi phí đều là số dương. Chi phí âm có thể tạo ra các chu trình có trọng số âm.</p>
</li>
<li>
<p>Tất cả các <em>router</em> sử dụng cùng một quy tắc phá vỡ thế hòa (tiebreaking rules). Nếu chúng ta giả định rằng các đường đi ngắn nhất là duy nhất, thì hai điều kiện trước đó là đủ để đảm bảo mọi người đều chọn cùng một đường đi. Điều kiện này còn đảm bảo thêm rằng nếu có nhiều đường đi có cùng chi phí ngắn nhất, mọi người đều chọn cùng một đường.</p>
</li>
</ol>
<p>Với bốn điều kiện này, các <em>router</em> có thể sử dụng các <em>shortest-path algorithm</em> khác nhau, và chúng vẫn sẽ cùng tính toán ra các đường đi giống nhau và đưa ra các quyết định tương thích. Tuy nhiên, trên thực tế, các <em>router</em> thường sử dụng cùng một thuật toán để đơn giản.</p>
<h2 id="tìm-hiểu-về-cấu-trúc-liên-kết-Đồ-thị-learning-about-graph-topology"><a class="header" href="#tìm-hiểu-về-cấu-trúc-liên-kết-Đồ-thị-learning-about-graph-topology">Tìm hiểu về Cấu trúc Liên kết Đồ thị (Learning About Graph Topology)</a></h2>
<p>Làm thế nào các <em>router</em> tìm hiểu về toàn bộ <em>network graph</em>? Đầu tiên, chúng ta cần tìm hiểu ai là láng giềng của mình (cả <em>router</em> và đích đến). Sau đó, chúng ta cần phân phối thông tin đó ra toàn bộ mạng. Chúng ta cũng cần các <em>router</em> ghép nối tất cả thông tin mà nó nhận được thành một <em>network topology</em>.</p>
<p>Để khám phá các láng giềng, mọi <em>router</em> gửi một <em>hello message</em> (tin nhắn hello) đến tất cả các láng giềng của nó.</p>
<img width="600px" src="routing/../assets/routing/2-091-hellos.png">
<p>Ví dụ, trong mạng này, R2 gửi đến cả hai láng giềng của nó: &quot;Xin chào, tôi là R2.&quot; Bây giờ, R1 biết rằng nó được kết nối với R2, và R3 cũng biết rằng nó được kết nối với R2. Tương tự, R1 gửi lời chào đến R2, vì vậy bây giờ R2 biết về R1. Tương tự, R3 gửi lời chào đến R2, vì vậy R2 cũng biết về R3.</p>
<p>Kết quả là, mọi người bây giờ đều biết ai là láng giềng ngay cạnh mình. Lưu ý rằng R1 không biết về R3, vì R1 và R3 không phải là láng giềng.</p>
<img width="900px" src="routing/../assets/routing/2-092-after-hellos.png">
<p>Chúng ta cũng muốn biết nếu các liên kết bị hỏng. Để hỗ trợ điều này, chúng ta sẽ định kỳ gửi lại <em>hello message</em>. Nếu một láng giềng ngừng gửi lời chào (ví dụ: bỏ lỡ một số lần gửi hello), chúng ta giả định rằng họ đã biến mất.</p>
<p>Bây giờ chúng ta đã biết về các láng giềng của mình, chúng ta nên thông báo sự thật đó cho mọi người. Để đưa ra một thông báo toàn cục, chúng ta gửi thông báo đến tất cả các láng giềng của mình. Ngoài ra, nếu chúng ta nhận được một thông báo, chúng ta cũng nên gửi nó đến tất cả các láng giềng của mình. Điều này đảm bảo rằng mọi tin nhắn được lan truyền khắp mạng. Điều này được gọi là <em><strong>flooding</strong></em> (quảng bá) thông tin trên toàn mạng. Nếu có bất kỳ thông tin nào thay đổi (ví dụ: một láng giềng biến mất), chúng ta cũng nên <em>flooding</em> thông tin đó.</p>
<img width="800px" src="routing/../assets/routing/2-093-flooding.png">
<p>Chúng ta cũng cần đảm bảo rằng các tin nhắn không bị mất. Nếu không, các <em>router</em> khác có thể bỏ lỡ một bản cập nhật và tính toán các đường đi trên đồ thị sai. Để khắc phục vấn đề này, chúng ta sử dụng cùng một thủ thuật mà chúng ta đã sử dụng trong <em>distance-vector</em>, và định kỳ gửi lại tin nhắn. Miễn là liên kết hoạt động, tin nhắn của chúng ta sẽ được gửi đi sau đủ số lần thử.</p>
<h2 id="tránh-quảng-bá-vô-hạn-avoiding-infinite-flooding"><a class="header" href="#tránh-quảng-bá-vô-hạn-avoiding-infinite-flooding">Tránh Quảng bá Vô hạn (Avoiding Infinite Flooding)</a></h2>
<p>Chúng ta phải cẩn thận về cách chúng ta <em>flooding</em> các thông báo qua mạng.</p>
<img width="400px" src="routing/../assets/routing/2-094-flood-problem1.png">
<p>R2 biết được một số thông tin và thông báo cho láng giềng R3 của nó. Khi R3 nhận được thông tin này, nó lại thông báo cho láng giềng R2 của mình. Khi R2 nhận được thông tin này, nó lại thông báo cho láng giềng R3 của mình. Hai <em>router</em> này bị kẹt trong việc thông báo cho nhau, lãng phí <em>bandwidth</em>, mặc dù không có thông tin mới nào.</p>
<p>Lưu ý rằng điều này không giống như việc gửi lại tin nhắn định kỳ để đảm bảo độ tin cậy. Để đảm bảo độ tin cậy, chúng ta có thể gửi lại một tin nhắn 5 giây một lần. Trong vòng lặp vô hạn này, các <em>router</em> đang nhận và gửi lại các thông báo trùng lặp với tốc độ tối đa (ví dụ: hàng triệu lần mỗi giây).</p>
<p>Vấn đề còn tồi tệ hơn nếu mạng của chúng ta chứa một <em>loop</em>:</p>
<img width="300px" src="routing/../assets/routing/2-095-flood-problem2.png">
<p>Bước thời gian 1: R1 quảng bá đến R2 và R3.</p>
<p>Bước thời gian 2: R2 quảng bá đến R1 và R3. R3 quảng bá đến R1 và R2.</p>
<p>Bước thời gian 3: R1, R1, R2, và R3 tất cả đều thực hiện quảng bá đến (R2, R3), (R2, R3), (R1, R3), và (R1, R2) tương ứng. Lưu ý rằng R1 đã nhận được hai tin nhắn ở bước thời gian 2, vì vậy nó thực hiện hai lần quảng bá.</p>
<p>Bước thời gian 4: R1, R1, R2, R2, R2, R3, R3, R3 tất cả đều thực hiện quảng bá đến (R2, R3), (R2, R3), (R1, R3), (R1, R3), (R1, R3), (R1, R2), (R1, R2), (R1, R2), tương ứng.</p>
<p>Bước thời gian 5: R1 thực hiện 6 lần quảng bá, R2 thực hiện 5 lần quảng bá, R3 thực hiện 5 lần quảng bá.</p>
<img width="900px" src="routing/../assets/routing/2-096-flood-problem3.png">
<p>Tất cả thông tin mới đã được biết đến ở bước thời gian 1. Nhưng, mọi người vẫn tiếp tục gửi lại cùng một thông tin, và các thông báo trùng lặp nhân lên theo cấp số nhân và cuối cùng làm quá tải mạng.</p>
<p>Để khắc phục vấn đề này, chúng ta cần đảm bảo rằng các <em>router</em> không gửi cùng một thông tin hai lần.</p>
<p>Khi chúng ta thấy một tin nhắn lần đầu tiên, hãy gửi tin nhắn đó đến tất cả các láng giềng, và ghi lại rằng chúng ta đã thấy tin nhắn đó. (Dù sao chúng ta cũng phải ghi lại tin nhắn này, vì chúng ta đang cố gắng sử dụng thông tin này để xây dựng <em>network graph</em>.) Sau đó, nếu chúng ta thấy lại cùng một tin nhắn đó, đừng gửi nó lần thứ hai.</p>
<p>Để xác định duy nhất một tin nhắn, chúng ta có thể giới thiệu một <em>timestamp</em> (dấu thời gian) (hoặc một bộ đếm nào đó khác là duy nhất cho mỗi tin nhắn).</p>
<p>Bây giờ, nếu chúng ta quay lại ví dụ từ trước:</p>
<img width="500px" src="routing/../assets/routing/2-097-flood-solution.png">
<p>Bước thời gian 1: R1 quảng bá đến R2 và R3.</p>
<p>Bước thời gian 2: R2 quảng bá đến R1 và R3. R3 quảng bá đến R1 và R2.</p>
<p>Bước thời gian 3: Tại thời điểm này, R1, R2, và R3 đều đã thấy tin nhắn này trước đó, vì vậy chúng không gửi lại nó. Không có thêm tin nhắn trùng lặp nào được gửi đi.</p>
<p>Lưu ý rằng các tin nhắn trùng lặp đôi khi vẫn được gửi với sự sửa đổi này, nhưng chúng ta đã tránh được việc các tin nhắn trùng lặp được gửi đi vô hạn.</p>
<h2 id="sự-hội-tụ-convergence"><a class="header" href="#sự-hội-tụ-convergence">Sự hội tụ (Convergence)</a></h2>
<p><em>Link-state</em> <em>converges</em> (hội tụ) về một <em>routing state</em> <em>least-cost</em> hợp lệ sau khi mọi <em>router</em> tìm hiểu toàn bộ <em>network topology</em> và tính toán <em>forwarding table</em> của nó tương ứng. <em>Convergence</em> dựa trên việc mọi nút sử dụng cùng một đồ thị. Sau khi <em>convergence</em>, <em>routing state</em> vẫn hợp lệ miễn là <em>network topology</em> không thay đổi.</p>
<p>Ngay khi <em>network topology</em> thay đổi, có thể mất một khoảng thời gian để mạng <em>converge</em> trở lại. Chúng ta phải đợi cho sự thay đổi được phát hiện (ví dụ: một liên kết bị lỗi). Sau đó, chúng ta phải đợi thông tin mới được lan truyền qua mạng, và để các <em>router</em> tính toán lại các mục trong <em>forwarding table</em>. Trong khi mạng đang <em>converging</em>, chúng ta có thể ở trong một <em>routing state</em> không hợp lệ, bởi vì một số <em>router</em> đang sử dụng đồ thị cũ, trong khi những <em>router</em> khác đang sử dụng đồ thị đã được cập nhật. <em>Routing state</em> có thể có các <em>dead-ends</em>, <em>loops</em>, hoặc các đường đi không phải là <em>least-cost</em>.</p>
<img width="800px" src="routing/../assets/routing/2-098-link-state-converge.png">
<p>Ví dụ, giả sử liên kết R3-A đã bị lỗi. R3 biết về điều này, nhưng các <em>router</em> khác thì không. R3 sẽ <em>forwarding</em> các gói tin đến R1. Tuy nhiên, R1 vẫn sẽ <em>forwarding</em> các gói tin đến R3.</p>
<p>Phần lớn sự phức tạp trong các giao thức <em>link-state</em> nằm ở những chi tiết nhỏ. Để đảm bảo <em>convergence</em> nhanh hơn và tránh <em>routing</em> không hợp lệ càng nhiều càng tốt, chúng ta có thể thực hiện các tối ưu hóa và điều chỉnh nhỏ trong giao thức.</p>
<h2 id="link-state-so-với-distance-vector"><a class="header" href="#link-state-so-với-distance-vector">Link-State so với Distance-Vector</a></h2>
<p>Một số ưu và nhược điểm của các giao thức <em>link-state</em> so với các giao thức <em>distance-vector</em> là gì?</p>
<p>Trong <em>distance-vector</em>, khi chúng ta nhận được một thông báo, chúng ta không nhất thiết biết tất cả các chi tiết về đường đi mà chúng ta đang chấp nhận. Chúng ta phải tin vào bất cứ điều gì mà láng giềng của chúng ta tuyên bố trong thông báo. Ngược lại, trong <em>link-state</em>, chúng ta biết toàn bộ <em>topology</em> của đồ thị, vì vậy chúng ta biết nhiều hơn về các đường đi mà các gói tin đang đi.</p>
<p>Tùy thuộc vào việc triển khai, <em>distance-vector</em> có thể chậm hơn để <em>converge</em>. Nếu mạng thay đổi, chúng ta phải đợi láng giềng của mình tính toán lại và advertise lại một đường đi, trước khi chúng ta có thể cập nhật <em>forwarding table</em> của mình. Sau đó, tất cả các láng giềng của chúng ta phải đợi chúng ta, và cứ thế tiếp tục. Ngược lại, trong <em>link-state</em>, mọi người có thể nhanh chóng <em>flooding</em> thông tin mới và tính toán lại cùng một lúc.</p>
<p>Các giao thức <em>link-state</em> tốt cho các mạng cục bộ nhỏ, nhưng không mở rộng tốt cho Internet toàn cầu. Cụ thể, <em>link-state</em> yêu cầu mọi <em>router</em> phải biết về toàn bộ mạng. Trên Internet toàn cầu, các nhà khai thác có thể không muốn tiết lộ <em>network topology</em> của họ (ví dụ: vị trí của các <em>router</em> của họ, <em>bandwidth</em> của các liên kết của họ) cho các đối thủ cạnh tranh.</p>
<p>Trên thực tế, hầu hết các mạng đều triển khai một sự kết hợp của các giao thức <em>distance-vector</em> và <em>link-state</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Định-địa-chỉ-addressing-1"><a class="header" href="#Định-địa-chỉ-addressing-1">Định địa chỉ (Addressing)</a></h1>
<h2 id="mở-rộng-quy-mô-Định-tuyến-scaling-routing"><a class="header" href="#mở-rộng-quy-mô-Định-tuyến-scaling-routing">Mở rộng quy mô Định tuyến (Scaling Routing)</a></h2>
<p>Cho đến nay, <em>forwarding table</em> (bảng chuyển tiếp) của chúng ta có một mục cho mỗi đích đến. Điều này sẽ không thể mở rộng cho toàn bộ Internet.</p>
<p>Nếu chúng ta chạy giao thức <em>distance-vector</em> (vector khoảng cách) trên toàn bộ Internet, chúng ta sẽ phải gửi một thông báo cho mỗi máy chủ trên Internet. Nếu chúng ta chạy giao thức <em>link-state</em> (trạng thái liên kết) trên toàn bộ Internet, mỗi <em>router</em> (bộ định tuyến) sẽ phải biết toàn bộ đồ thị mạng Internet. Trong cả hai trường hợp, nếu bất kỳ máy chủ nào tham gia hoặc rời khỏi Internet, chúng ta sẽ phải thực hiện lại các phép tính để hội tụ về một trạng thái định tuyến mới.</p>
<p>Bí quyết để mở rộng quy mô định tuyến nằm ở cách chúng ta định địa chỉ cho các máy chủ. Cho đến nay, chúng ta đã gọi mỗi máy chủ và <em>router</em> bằng một cái tên nào đó (ví dụ: R1, R2, A, B), nhưng trên thực tế, chúng ta sẽ sử dụng một lược đồ định địa chỉ thông minh hơn.</p>
<img width="750px" src="routing/../assets/routing/2-099-scaling-routing.png">
<h2 id="Định-địa-chỉ-ip-ip-addressing"><a class="header" href="#Định-địa-chỉ-ip-ip-addressing">Định địa chỉ IP (IP Addressing)</a></h2>
<p>Hãy nhớ lại trong phép ví von về dịch vụ bưu chính, chúng ta đã có các lược đồ định địa chỉ khác nhau cho các bối cảnh khác nhau. Người đưa thư sử dụng địa chỉ đường phố như 2551 Hearst Ave. Người thư ký bên trong tòa nhà sử dụng số phòng như 413 Soda Hall. Địa chỉ được gán theo một cách có cấu trúc nào đó. Ví dụ, tất cả các số phòng ở tầng ba bắt đầu bằng chữ số 3, và tất cả các phòng ở tầng bốn bắt đầu bằng chữ số 4.</p>
<p>Cũng giống như hệ thống bưu chính, Internet sử dụng các lược đồ định địa chỉ khác nhau ở mỗi lớp. Trong phần này, chúng ta sẽ tập trung vào <em>IP address</em> (địa chỉ IP), có thể được sử dụng để định tuyến ở Lớp 3.</p>
<p>Mỗi máy chủ trên mạng (ví dụ: máy tính của bạn, máy chủ của Google) được gán một <em>IP address</em>. Trong phần này, bạn có thể giả định rằng mỗi máy chủ có một <em>IP address</em> duy nhất.</p>
<p>Một <em><strong>IP address</strong></em> là một con số định danh duy nhất cho một máy chủ. Giống như hệ thống bưu chính, con số này được chọn để chứa một số thông tin về nơi máy chủ được đặt.</p>
<p>Lưu ý rằng <em>IP address</em> không nhất thiết phải tĩnh. Trong phép ví von, nếu bạn chuyển đến một ngôi nhà khác, địa chỉ của bạn sẽ thay đổi. Tương tự, nếu máy tính của bạn di chuyển đến một vị trí khác, nó có thể được gán một <em>IP address</em> khác khi tham gia vào mạng (và <em>IP address</em> cũ của bạn cuối cùng sẽ hết hạn).</p>
<p>Độ dài của một <em>IP address</em> phụ thuộc vào phiên bản IP đang được sử dụng. Địa chỉ <em>IPv4</em> (Giao thức Internet phiên bản 4) dài 32 bit và địa chỉ <em>IPv6</em> (Giao thức Internet phiên bản 6) dài 128 bit. Các khái niệm định tuyến là tương tự cho cả hai phiên bản, nhưng chúng ta sẽ sử dụng <em>IPv4</em> khi có thể, vì địa chỉ nhỏ hơn dễ đọc hơn.</p>
<h2 id="Định-địa-chỉ-phân-cấp-hierarchical-addressing"><a class="header" href="#Định-địa-chỉ-phân-cấp-hierarchical-addressing">Định địa chỉ Phân cấp (Hierarchical Addressing)</a></h2>
<p>Hãy nhớ lại rằng Internet là một mạng của các mạng. Có nhiều mạng cục bộ, và chúng ta thêm các liên kết giữa các mạng cục bộ để tạo thành Internet rộng lớn hơn. Điều này mang lại cho chúng ta một hệ thống phân cấp tự nhiên mà chúng ta có thể sử dụng để tổ chức lược đồ định địa chỉ của mình.</p>
<img width="900px" src="routing/../assets/routing/2-100-address-intuition1.png">
<p>Đây là một hình dung trực quan về việc định địa chỉ. Chúng ta có thể gán một số cho mỗi mạng. Sau đó, trong mạng 3, chúng ta có thể gán các số máy chủ 3.1, 3.2, 3.3, v.v., và tương tự cho các máy chủ trong các mạng khác.</p>
<img width="900px" src="routing/../assets/routing/2-101-address-intuition2.png">
<p>Bây giờ, hãy xem xét <em>forwarding table</em> trong <em>router</em> R9. Trước đây, chúng ta sẽ có một mục cho mỗi máy chủ trong mạng 1, và tất cả chúng đều có cùng một chặng kế tiếp là R6. Với <em>hierarchical addressing</em> (định địa chỉ phân cấp) của chúng ta, thay vào đó, chúng ta có thể có một mục duy nhất cho toàn bộ mạng cục bộ, nói rằng tất cả các địa chỉ 1.* (trong đó * đại diện cho bất kỳ số nào) có chặng kế tiếp là R6. Chúng ta cũng có thể nói rằng tất cả các địa chỉ 2.* có chặng kế tiếp là R8.</p>
<p>Mô hình phân cấp này, nơi chúng ta sử dụng các ký tự đại diện để tóm tắt các tuyến đường, làm cho <em>forwarding table</em> của chúng ta nhỏ hơn.</p>
<p>Ngoài ra, mô hình này cũng làm cho các bảng của chúng ta ổn định hơn.</p>
<img width="900px" src="routing/../assets/routing/2-102-address-intuition3.png">
<p>Nếu cấu trúc liên kết bên trong mạng 1 thay đổi, chúng ta không cần cập nhật <em>forwarding table</em> của R9 (hoặc bất kỳ bảng nào khác trong các mạng khác). Trên thực tế, những thay đổi trong một mạng cục bộ (ví dụ: máy chủ mới tham gia mạng) xảy ra thường xuyên hơn nhiều so với những thay đổi giữa các mạng (ví dụ: lắp đặt cáp ngầm mới), vì vậy đây là một điều tốt khi các thay đổi cục bộ chỉ ảnh hưởng đến các bảng cục bộ.</p>
<p>Tổng quát hơn, địa chỉ của chúng ta có hai phần: <em>network ID</em> (định danh mạng) và <em>host ID</em> (định danh máy chủ). Điều này cho phép các giao thức <em>inter-domain routing</em> (định tuyến liên miền) tập trung vào <em>network ID</em> để tìm các tuyến đường giữa các mạng, và các giao thức <em>intra-domain routing</em> (định tuyến nội miền) tập trung vào <em>host ID</em> để tìm các tuyến đường bên trong các mạng. Điều này cũng làm cho các giao thức định tuyến của chúng ta ổn định hơn khi mạng thay đổi. Giao thức <em>inter-domain routing</em> không quan tâm đến những thay đổi bên trong các mạng, và giao thức <em>intra-domain routing</em> không quan tâm đến những thay đổi trong các mạng khác.</p>
<img width="900px" src="routing/../assets/routing/2-103-address-intuition4.png">
<p>Lưu ý rằng <em>forwarding table</em> trong R9 vẫn cần các mục cho từng máy chủ riêng lẻ bên trong mạng của chính nó (tức là mạng 2).</p>
<p>Tương tự, R4, một <em>router</em> nội bộ không có kết nối đến các mạng khác, cần cả hai mục cho các máy chủ riêng lẻ bên trong mạng 3 và các mục tổng hợp cho các mạng khác (ví dụ: 2.* có chặng kế tiếp là R9). Quy mô của một <em>forwarding table</em> phụ thuộc vào số lượng máy chủ nội bộ trong cùng một mạng, cộng với số lượng các mạng bên ngoài.</p>
<h2 id="tuyến-đường-mặc-định-default-routes"><a class="header" href="#tuyến-đường-mặc-định-default-routes">Tuyến đường Mặc định (Default Routes)</a></h2>
<p>Bây giờ chúng ta đã biết rằng các mục của chúng ta có thể đại diện cho toàn bộ dải địa chỉ, thay vì luôn đại diện cho một địa chỉ duy nhất. Chúng ta có thể mở rộng ý tưởng này hơn nữa để cải thiện quy mô.</p>
<img width="900px" src="routing/../assets/routing/2-104-aggregation1.png">
<p>Hãy xem xét R4. Nó có một mục cho mỗi mạng bên ngoài (1.<em>, 3.</em>, và 4.*), tất cả đều có cùng một chặng kế tiếp là R9. Chúng ta có thể tổng hợp mọi mạng bên ngoài thành một mục duy nhất. Chúng ta vẫn sẽ có các mục cho mỗi máy chủ nội bộ (2.1, 2.2, v.v.), nhưng cuối cùng, chúng ta sẽ nói: Đối với tất cả các máy chủ khác không có trong <em>forwarding table</em>, chặng kế tiếp là R9.</p>
<img width="900px" src="routing/../assets/routing/2-105-aggregation2.png">
<p>Chúng ta có thể sử dụng sự tổng hợp mạnh mẽ hơn tại R2. Một lần nữa, tất cả các mạng bên ngoài đều có chặng kế tiếp là R3. Nhưng, 2.1, 2.2, 2.3, 2.6, và 2.7 cũng có chặng kế tiếp là R3. Do đó, <em>forwarding table</em> chỉ cần các mục tĩnh cho 2.4 và 2.5. Sau đó, chúng ta có thể nói, đối với tất cả các máy chủ khác không có trong <em>forwarding table</em> (bao gồm một số máy chủ nội bộ và một số máy chủ bên ngoài), chặng kế tiếp là R3.</p>
<p>Để đại diện cho tất cả các máy chủ không có trong bảng, chúng ta có thể sử dụng ký tự đại diện <em>.</em> để khớp với mọi thứ. Khi chuyển tiếp đến một đích nhất định, <em>router</em> trước tiên sẽ kiểm tra các máy chủ cụ thể (ví dụ: 3.1) hoặc các dải (ví dụ: 2.*) để tìm kết quả khớp. Nếu <em>router</em> không thể tìm thấy bất kỳ kết quả khớp nào, cuối cùng nó sẽ khớp với ký tự đại diện <em>.</em>. Đây được gọi là <em><strong>default route</strong></em> (tuyến đường mặc định).</p>
<p>Hầu hết các máy chủ chỉ có một <em>default route</em> được mã hóa cứng duy nhất. Ví dụ, <em>forwarding table</em> của máy chủ 2.4 có một mục duy nhất, yêu cầu gửi mọi thứ đến R2. Trên thực tế, máy tính ở nhà của bạn có một mục duy nhất, yêu cầu gửi mọi thứ đến <em>router</em> tại nhà của bạn. Đây là lý do tại sao các máy chủ không cần tham gia vào các giao thức định tuyến.</p>
<h2 id="gán-địa-chỉ-ip-phân-cấp-thời-kỳ-đầu-của-internet"><a class="header" href="#gán-địa-chỉ-ip-phân-cấp-thời-kỳ-đầu-của-internet">Gán địa chỉ IP Phân cấp: Thời kỳ đầu của Internet</a></h2>
<p>Để có được định tuyến có khả năng mở rộng tốt hơn, chúng ta cần gán địa chỉ theo một cách phân cấp nào đó. Các địa chỉ cần chứa một số thông tin về vị trí của chúng (ví dụ: các máy chủ gần nhau cần chia sẻ một phần địa chỉ của chúng).</p>
<p>Trong thời kỳ đầu của Internet, địa chỉ <em>IPv4</em> có <em>network ID</em> 8-bit và <em>host ID</em> 24-bit, giống như trong phiên bản trực quan của chúng ta.</p>
<img width="800px" src="routing/../assets/routing/2-106-cidr1.png">
<p>Ví dụ, AT&amp;T có <em>network ID</em> 12, Apple có <em>network ID</em> 17, và Bộ Quốc phòng Hoa Kỳ có 13 <em>network ID</em> khác nhau.</p>
<p><em>Network ID</em> 8-bit có nghĩa là chúng ta chỉ có thể gán 256 <em>network ID</em> khác nhau, nhưng trong thực tế, có nhiều hơn 256 tổ chức có thể vận hành mạng cục bộ của riêng họ. Ngoài ra, <em>host ID</em> 24-bit của chúng ta có nghĩa là mỗi mạng nhận được 2^24 = 16,777,216 địa chỉ. Một mạng nhỏ (ví dụ: một công ty có 10 nhân viên) có lẽ không cần 16 triệu địa chỉ. Khi Internet ngày càng lớn mạnh, một phương pháp định địa chỉ mới đã trở nên cần thiết.</p>
<h2 id="gán-địa-chỉ-ip-phân-cấp-Định-địa-chỉ-theo-lớp-classful-addressing"><a class="header" href="#gán-địa-chỉ-ip-phân-cấp-Định-địa-chỉ-theo-lớp-classful-addressing">Gán địa chỉ IP Phân cấp: Định địa chỉ theo lớp (Classful Addressing)</a></h2>
<p>Nỗ lực đầu tiên để khắc phục điều này là <em><strong>classful addressing</strong></em> (định địa chỉ theo lớp), phương pháp này phân bổ các kích thước mạng khác nhau dựa trên nhu cầu. Trong phương pháp này, có 3 lớp địa chỉ, mỗi lớp có số bit khác nhau được phân bổ cho <em>network ID</em> và <em>host ID</em>. 1-3 bit đầu tiên xác định lớp nào đang được sử dụng.</p>
<img width="900px" src="routing/../assets/routing/2-107-cidr2.png">
<p>Địa chỉ Lớp A (Class A) bắt đầu bằng bit 0. 7 bit tiếp theo là <em>network ID</em> (128 mạng), và 24 bit tiếp theo là <em>host ID</em> (16 triệu máy chủ).</p>
<p>Địa chỉ Lớp B (Class B) bắt đầu bằng các bit 10. 14 bit tiếp theo là <em>network ID</em> (16,000 mạng), và 16 bit tiếp theo là <em>host ID</em> (65,000 máy chủ).</p>
<p>Địa chỉ Lớp C (Class C) bắt đầu bằng các bit 110. 21 bit tiếp theo là <em>network ID</em> (2 triệu mạng), và 8 bit tiếp theo là <em>host ID</em> (256 máy chủ).</p>
<p>Trong phương pháp này, chúng ta giờ đây có thể có 2 triệu + 16,000 + 128 mạng cục bộ khác nhau. Các tổ chức lớn hơn với nhiều máy chủ hơn có thể nhận được một mạng Lớp A, và các tổ chức nhỏ hơn có thể nhận được một mạng Lớp B hoặc Lớp C. Như trước đây, trong một mạng duy nhất, (các) bit lớp đứng đầu và các bit <em>network ID</em> là giống nhau, và mỗi máy chủ nhận được một <em>host ID</em> khác nhau.</p>
<p>Một vấn đề lớn với <em>classful addressing</em> là kích thước của mỗi lớp. Lớp A (16 triệu máy chủ) quá lớn đối với hầu hết các tổ chức, và Lớp C (256 máy chủ) quá nhỏ đối với hầu hết các tổ chức. Do đó, hầu hết các mạng cần phải thuộc Lớp B.</p>
<p>Thật không may, chỉ có 16,000 <em>network ID</em> Lớp B, và đến năm 1994, chúng ta đã cạn kiệt các mạng Lớp B. Một lần nữa, một phương pháp định địa chỉ mới đã trở nên cần thiết.</p>
<p>Lưu ý: <em>Classful addressing</em> hiện đã lỗi thời trên Internet hiện đại.</p>
<p>Lưu ý: Về mặt kỹ thuật, số lượng máy chủ trên mỗi mạng bị trừ đi 2, vì địa chỉ toàn số không và địa chỉ toàn số một được dành riêng cho các mục đích đặc biệt. Ví dụ, trong Lớp C, thực sự có 254 máy chủ trên mỗi mạng, không phải 256.</p>
<h2 id="gán-địa-chỉ-ip-phân-cấp-cidr"><a class="header" href="#gán-địa-chỉ-ip-phân-cấp-cidr">Gán địa chỉ IP Phân cấp: CIDR</a></h2>
<p>Phương pháp thứ ba của chúng ta để định địa chỉ phân cấp, và là phương pháp vẫn được sử dụng trên Internet hiện đại, là <em><strong>CIDR</strong></em> (Classless Inter-Domain Routing - Định tuyến liên miền không lớp). Trong <em>CIDR</em>, chúng ta vẫn có các <em>network ID</em> có độ dài thay đổi, nhưng thay vì chỉ có 3 độ dài <em>network ID</em> khác nhau (Lớp A, B, C), chúng ta làm cho số lượng bit cố định trở nên tùy ý.</p>
<p>Ví dụ, hãy xem xét công ty nhỏ với 10 nhân viên từ trước. Trong <em>classful addressing</em>, họ sẽ nhận được một mạng Lớp C với 256 địa chỉ máy chủ. Nếu họ chỉ cần 10 địa chỉ máy chủ, chúng ta có thể phân bổ ít địa chỉ hơn bằng cách cho họ một <em>network ID</em> dài hơn.</p>
<p>Nếu chúng ta phân bổ một <em>network ID</em> 28-bit, <em>host ID</em> sẽ dài 4 bit (16 địa chỉ khả dụng). Nếu chúng ta phân bổ một <em>network ID</em> 29-bit, <em>host ID</em> sẽ dài 3 bit (8 địa chỉ khả dụng). Chúng ta không thể phân bổ chính xác 10 địa chỉ, nhưng một <em>network ID</em> 28-bit sẽ đủ cho mục đích của công ty này. Có một chút lãng phí (6 địa chỉ không sử dụng), nhưng điều này vẫn tốt hơn nhiều so với việc phân bổ 256 địa chỉ.</p>
<p>Một ví dụ khác, hãy xem xét một tổ chức cần 450 địa chỉ máy chủ. Trong <em>classful addressing</em>, Lớp C (256 địa chỉ) không đủ, vì vậy họ sẽ nhận được một mạng Lớp B với 65,000 địa chỉ máy chủ, và hầu hết các địa chỉ sẽ không được sử dụng. Với các <em>network ID</em> có độ dài tùy ý, chúng ta có thể gán một <em>network ID</em> 23-bit, điều này cho phép 9 bit để định địa chỉ máy chủ (512 địa chỉ). Điều này đáp ứng nhu cầu của tổ chức và lãng phí ít địa chỉ hơn rất nhiều.</p>
<h2 id="gán-phân-cấp-Đa-tầng-multi-layered-hierarchical-assignment"><a class="header" href="#gán-phân-cấp-Đa-tầng-multi-layered-hierarchical-assignment">Gán Phân cấp Đa tầng (Multi-Layered Hierarchical Assignment)</a></h2>
<p>Trong thực tế, hệ thống phân cấp có thể có nhiều tầng. Ví dụ, bên trong một mạng, một tổ chức có thể chọn gán các dải địa chỉ cụ thể cho các tổ chức con cụ thể (ví dụ: các phòng ban trong một công ty hoặc trường đại học).</p>
<p>Trên thực tế, chúng ta khai thác các hệ thống phân cấp về tổ chức và địa lý đa tầng trong đời thực để gán địa chỉ. <em>ICANN</em> (Internet Corporation for Names and Numbers - Tập đoàn Internet quản lý tên miền và số hiệu) là tổ chức toàn cầu sở hữu tất cả các địa chỉ IP.</p>
<p><em>ICANN</em> cấp các khối địa chỉ cho <em>Regional Internet Registries (RIRs)</em> (Các cơ quan đăng ký Internet khu vực) đại diện cho các quốc gia hoặc châu lục cụ thể. Ví dụ, RIPE nhận tất cả các địa chỉ cho Liên minh Châu Âu, ARIN nhận địa chỉ Bắc Mỹ, APNIC nhận địa chỉ Châu Á/Thái Bình Dương, LACNIC nhận địa chỉ Nam Mỹ, và AFRINIC nhận địa chỉ Châu Phi. Ví dụ: <em>ICANN</em> cấp cho ARIN tất cả các địa chỉ bắt đầu bằng 1101.</p>
<p>Mỗi <em>RIR</em> sau đó cấp các phần trong dải của họ cho các tổ chức lớn (ví dụ: công ty, trường đại học) hoặc <em>ISPs</em> (Internet Service Providers - Nhà cung cấp dịch vụ Internet). Các tổ chức hoặc <em>ISP</em> này được gọi là <em>Local Internet Registries</em> (Các cơ quan đăng ký Internet địa phương). Ví dụ: ARIN kiểm soát tất cả các địa chỉ bắt đầu bằng 1101, và cấp cho AT&amp;T tất cả các địa chỉ bắt đầu bằng 1101 11001.</p>
<p>Cuối cùng, mỗi cơ quan đăng ký Internet địa phương gán các IP riêng lẻ cho các máy chủ cụ thể. Để có thêm hệ thống phân cấp, các cơ quan đăng ký địa phương cũng có thể gán các dải IP cho các tổ chức nhỏ, và các tổ chức nhỏ này đến lượt mình có thể gán các IP riêng lẻ.</p>
<img width="700px" src="routing/../assets/routing/2-108-cidr3.png">
<p>Ở mỗi cấp, số lượng bit cố định bổ sung được xác định bởi số lượng địa chỉ cần được phân bổ. Ví dụ, ARIN có thể muốn cấp cho AT&amp;T 8 triệu địa chỉ, và tính toán rằng việc cố định 9 bit sẽ cho ra 8 triệu địa chỉ máy chủ. ARIN đã có 4 bit được cố định sẵn, vì vậy nó cố định thêm 5 bit nữa và gán cho AT&amp;T tất cả các địa chỉ bắt đầu bằng 9 bit đó. AT&amp;T sau đó có thể cấp tiền tố 1101 11001 110100010 để cung cấp 16,000 địa chỉ cho UC Berkeley. Khi chúng ta phân bổ địa chỉ cho các tổ chức con, nhiều bit hơn được cố định, luôn giữ lại các bit cố định từ các tổ chức mẹ.</p>
<h2 id="viết-địa-chỉ-ip-writing-ip-addresses"><a class="header" href="#viết-địa-chỉ-ip-writing-ip-addresses">Viết địa chỉ IP (Writing IP Addresses)</a></h2>
<p>Chúng ta có thể viết địa chỉ IP dưới dạng một chuỗi 32-bit gồm các số 1 và 0, hoặc dưới dạng một số nguyên lớn duy nhất. Trên thực tế, để dễ đọc, chúng ta lấy mỗi chuỗi 8 bit và viết nó dưới dạng một số nguyên (từ 0 đến 255). Ví dụ, địa chỉ IP 00010001 00100010 10011110 00000101 có thể được viết là 17.34.158.5. Đôi khi, đây được gọi là biểu diễn <em>dotted quad</em> (bộ bốn dấu chấm).</p>
<p>Cho đến nay, chúng ta đã viết các dải địa chỉ dưới dạng bit (ví dụ: tất cả các IP bắt đầu bằng 1101). Để viết một dải địa chỉ, chúng ta có thể sử dụng <em>slash notation</em> (ký hiệu gạch chéo). Chúng ta viết tiền tố cố định, sau đó chúng ta viết các số 0 cho tất cả các bit không cố định còn lại, và chúng ta chuyển đổi giá trị 32-bit kết quả thành một địa chỉ IP dạng <em>dotted quad</em>. Sau đó, sau dấu gạch chéo, chúng ta viết số lượng bit cố định.</p>
<p>Ví dụ, nếu tiền tố là 11000000, chúng ta thêm các số không cho tất cả các bit không cố định để có được 11000000 00000000 00000000 00000000. Dưới dạng địa chỉ 32-bit, đây là 192.0.0.0. Sau đó, vì có 8 bit được cố định, chúng ta viết dải địa chỉ là 192.0.0.0/8.</p>
<p>Để viết một địa chỉ riêng lẻ dưới dạng một dải, chúng ta có thể viết một cái gì đó như 192.168.1.1/32, điều này chỉ ra rằng tất cả 32 bit đều được cố định. Ngoài ra, <em>default route</em> <em>.</em> có thể được viết là 0.0.0.0/0.</p>
<p><em>Slash notation</em> đôi khi có thể trông hơi khó hiểu vì chúng ta đang sử dụng các phép chia 8-bit tùy ý và viết các số ở dạng thập phân. Ví dụ, tiền tố 8-bit 11000000 và tiền tố 12-bit 11000000 0000 sẽ được viết là 192.0.0.0/8 và 192.0.0.0/12 (cùng một địa chỉ IP đại diện cho các dải khác nhau). Một ví dụ khác, nếu tôi sở hữu tiền tố 4-bit 1100, tôi có thể gán tiền tố 5-bit 11001. Dưới dạng dải, chúng được viết là 192.0.0.0/4 và 200.0.0.0/5. Thoạt nhìn, không rõ ràng rằng dải thứ hai thực sự là một tập hợp con của dải thứ nhất, và chúng ta sẽ phải viết ra các bit để xác nhận.</p>
<p>Một phương án thay thế cho dấu gạch chéo (ví dụ: /16) trong <em>slash notation</em> là <em>netmask</em> (mặt nạ mạng). Giống như con số sau dấu gạch chéo, <em>netmask</em> cho chúng ta biết những bit nào được cố định. Để viết một <em>netmask</em>, chúng ta viết các số 1 cho tất cả các bit cố định và số 0 cho tất cả các bit không cố định, và chuyển đổi kết quả thành dạng <em>dotted quad</em>. Ví dụ, nếu chúng ta có dải 192.168.1.0/29, chúng ta có thể viết 29 số một (bit cố định) và 3 số không (bit không cố định). 11111111 11111111 11111111 11111000 dưới dạng <em>dotted quad</em> là 255.255.255.248. Dải địa chỉ trong ký hiệu <em>netmask</em> là 192.168.1.0, với <em>netmask</em> 255.255.255.248 (thay thế dấu gạch chéo bằng một <em>netmask</em>).</p>
<p>Trong các ghi chú này, chúng ta sẽ thường sử dụng <em>slash notation</em> vì chúng tiện lợi hơn để đọc. Trên thực tế, <em>netmask</em> có thể hữu ích vì với một địa chỉ IP cụ thể, nếu bạn thực hiện phép toán AND bit giữa địa chỉ IP và <em>netmask</em>, tất cả các bit của máy chủ sẽ bị xóa về không, và chỉ còn lại các bit của mạng.</p>
<h2 id="tổng-hợp-các-tuyến-đường-với-cidr-aggregating-routes-with-cidr"><a class="header" href="#tổng-hợp-các-tuyến-đường-với-cidr-aggregating-routes-with-cidr">Tổng hợp các tuyến đường với CIDR (Aggregating Routes with CIDR)</a></h2>
<p>Trong mô hình ban đầu của chúng ta với <em>network ID</em> và <em>host ID</em>, chúng ta có thể tổng hợp tất cả các máy chủ trong cùng một mạng thành một tuyến đường duy nhất trong <em>forwarding table</em> (ví dụ: 2.* cho mọi thứ trong mạng 2).</p>
<p><em>Hierarchical addressing</em> đa tầng có nghĩa là chúng ta cũng có thể tổng hợp nhiều mạng thành một tuyến đường duy nhất.</p>
<img width="900px" src="routing/../assets/routing/2-109-aggregation1.png">
<p>Hãy xem xét sơ đồ mạng này. Trong mô hình ban đầu của chúng ta, R6 cần một mục chuyển tiếp riêng cho AT&amp;T, UCB, và Stanford.</p>
<img width="900px" src="routing/../assets/routing/2-110-aggregation2.png">
<p>Tuy nhiên, nếu chúng ta sử dụng <em>hierarchical addressing</em>, thì dải của UCB (4.12.0.0/16) và dải của Stanford (4.29.0.0/16) đều là tập hợp con của dải của AT&amp;T (4.0.0.0/8). Điều này có thể xảy ra nếu AT&amp;T phân bổ các dải đó cho các khách hàng cấp dưới của mình là UCB và Stanford.</p>
<p>Bây giờ, R6 chỉ cần một mục duy nhất cho AT&amp;T, UCB, và Stanford. Chúng ta đã tổng hợp hai dải nhỏ hơn thành dải rộng hơn mà cả hai đều thuộc về.</p>
<h2 id="Đa-kết-nối-multi-homing"><a class="header" href="#Đa-kết-nối-multi-homing">Đa kết nối (Multi-Homing)</a></h2>
<p>Việc tổng hợp các dải không phải lúc nào cũng hoạt động. Giả sử chúng ta thêm một liên kết từ R6 trực tiếp đến Stanford.</p>
<img width="900px" src="routing/../assets/routing/2-111-aggregation3.png">
<p>Tuyến đường tổng hợp của chúng ta nói rằng tất cả các gói tin đến AT&amp;T (và các cấp dưới của nó) có chặng kế tiếp là R2. Chúng ta cần thêm một mục bổ sung nói rằng Stanford có chặng kế tiếp là R7.</p>
<p>Lưu ý rằng <em>forwarding table</em> của chúng ta bây giờ có các dải chồng chéo lên nhau. Một đích đến có thể khớp với nhiều dải. Để chọn một tuyến đường, chúng ta sẽ chạy <em><strong>longest prefix matching</strong></em> (khớp tiền tố dài nhất), có nghĩa là chúng ta sẽ sử dụng dải cụ thể nhất khớp với địa chỉ IP đích của chúng ta. Ví dụ, nếu chúng ta có một gói tin đến một máy chủ UCM, chúng ta sẽ sử dụng mục dành riêng cho UCM vì nó có tiền tố 19-bit dài hơn. Mặc dù mục AT&amp;T 9-bit cũng khớp với đích, tiền tố của nó ngắn hơn, vì vậy chúng ta không sử dụng tuyến đường này.</p>
<p>Nếu thay vào đó chúng ta có một gói tin đến một máy chủ UCB, chúng ta không thể sử dụng mục dành riêng cho Stanford, vì tiền tố 16-bit sẽ không khớp với máy chủ UCB. Nhưng chúng ta vẫn có thể sử dụng mục AT&amp;T 8-bit, nó sẽ khớp với đích.</p>
<h2 id="lịch-sử-tóm-tắt-của-ipv6-brief-history-of-ipv6"><a class="header" href="#lịch-sử-tóm-tắt-của-ipv6-brief-history-of-ipv6">Lịch sử tóm tắt của IPv6 (Brief History of IPv6)</a></h2>
<p>Địa chỉ <em>IPv4</em> dài 32 bit, có nghĩa là chúng ta có khoảng 4 tỷ địa chỉ khả dụng. Điều này có đủ không?</p>
<img width="900px" src="routing/../assets/routing/2-112-ipv6-1.png">
<p>Biểu đồ này thể hiện số lượng địa chỉ IP chưa được phân bổ còn lại (trục y) cho mỗi cơ quan đăng ký khu vực theo thời gian.</p>
<p>Đến năm 2017, tất cả mọi người đều có ít hơn một khối /8 (tức là ít hơn 2^24 = 16 triệu địa chỉ) khả dụng. Mỗi cơ quan đăng ký khu vực giữ lại một khối địa chỉ /8 dự phòng phòng trường hợp cần thiết, nhưng đến năm 2017, tất cả mọi người đã phải bắt đầu sử dụng nguồn cung cấp địa chỉ dự phòng của mình. Đến năm 2021, ngay cả nguồn cung cấp địa chỉ dự phòng cũng sắp cạn kiệt.</p>
<p>Một sự thật thú vị: Vào tháng 2 năm 2011, đã có một buổi lễ trực tiếp khi khối /8 cuối cùng được phân bổ. Thậm chí còn có một giấy chứng nhận đặc biệt được cấp.</p>
<p>Khi Internet phát triển, chúng ta bắt đầu nhận ra rằng cuối cùng chúng ta sẽ hết địa chỉ. May mắn thay, điều này đã được nhận ra từ sớm, và <em>IPv6</em> đã được phát triển vào năm 1998 như một giải pháp cho sự cạn kiệt địa chỉ IP.</p>
<p>Về cơ bản, cấu trúc định địa chỉ <em>IPv6</em> giống như <em>IPv4</em>. Có một số thay đổi nhỏ về triển khai cần thiết cho <em>IPv6</em>, mặc dù chúng không liên quan ở đây.</p>
<p>Tính năng mới chính trong <em>IPv6</em> là địa chỉ dài hơn. Địa chỉ <em>IPv6</em> dài 128 bit, có nghĩa là có khoảng $$3.4 \times 10^{38}$$ địa chỉ khả dụng. Đây là một con số khổng lồ về mặt thiên văn học, vì vậy chúng ta sẽ không bao giờ cạn kiệt. Vũ trụ đã tồn tại $$10^{21}$$ giây, vì vậy chúng ta có thể gán một địa chỉ cho mỗi giây và vẫn chỉ sử dụng 0.000000000000001% tổng số địa chỉ khả dụng.</p>
<img width="900px" src="routing/../assets/routing/2-113-ipv6-2.png">
<p><em>IPv6</em> được phát triển vào những năm 1990, nhưng không được tất cả các máy tính chấp nhận ngay lập tức. Ngay cả trong năm 2010, về cơ bản không ai sử dụng <em>IPv6</em>. Kể từ năm 2024, <em>IPv6</em> được sử dụng bởi khoảng 45% người dùng cuối, và hầu hết những người dùng này đều ở các quốc gia phát triển với việc áp dụng Internet rộng rãi hơn. Lý do chính tại sao <em>IPv6</em> đang được áp dụng rộng rãi hơn là vì chúng ta đang cạn kiệt địa chỉ <em>IPv4</em>.</p>
<p>Tại sao việc áp dụng <em>IPv6</em> lại chậm như vậy? Người dùng, máy chủ, và các nhà khai thác Internet phải nâng cấp phần mềm và phần cứng của họ (ví dụ: <em>router</em>, liên kết, trình điều khiển thiết bị trên máy tính) để hỗ trợ <em>IPv6</em>. Các <em>router</em> giờ đây cần hai <em>forwarding table</em>, một với địa chỉ <em>IPv4</em> và một với địa chỉ <em>IPv6</em>.</p>
<p>Việc nâng cấp <em>IPv6</em> phải tương thích ngược. Nếu một máy chủ chỉ có địa chỉ <em>IPv6</em>, người dùng trên các máy tính cũ chỉ hỗ trợ <em>IPv4</em> không thể sử dụng máy chủ này. <em>IPv4</em> và <em>IPv6</em> về cơ bản là các hệ thống định địa chỉ riêng biệt, và không có cách nào để chuyển đổi giữa địa chỉ <em>IPv4</em> và <em>IPv6</em>. Kể từ năm 2024, nhiều máy tính vẫn không hỗ trợ <em>IPv6</em>, vì vậy nhiều dịch vụ cần phải hỗ trợ cả <em>IPv4</em> và <em>IPv6</em>.</p>
<p>Các máy tính hỗ trợ cả <em>IPv4</em> và <em>IPv6</em> cũng phải suy nghĩ về việc nên sử dụng cái nào. Liệu cái này có tốt hơn cái kia không? Trên thực tế, <em>IPv6</em> nhanh hơn, nhưng nhiều chi tiết triển khai khác có thể ảnh hưởng đến sự lựa chọn của bạn.</p>
<h2 id="ký-hiệu-địa-chỉ-ipv6-ipv6-address-notation"><a class="header" href="#ký-hiệu-địa-chỉ-ipv6-ipv6-address-notation">Ký hiệu địa chỉ IPv6 (IPv6 Address Notation)</a></h2>
<p>Địa chỉ <em>IPv6</em> thường được viết dưới dạng thập lục phân thay vì thập phân. Ví dụ:</p>
<p>2001:0D08:CAFE:BEEF:DEAD:1234:5678:9012</p>
<p>là một địa chỉ <em>IPv6</em> (32 chữ số thập lục phân = 128 bit). Chúng ta thêm dấu hai chấm vào giữa mỗi 4 chữ số thập lục phân (16 bit) để dễ đọc.</p>
<p>Để dễ đọc, chúng ta có thể bỏ qua các số không đứng đầu trong một khối 4 chữ số. Ví dụ:</p>
<p>2001:0DB8:0000:0000:0000:0000:0000:0001</p>
<p>có thể được rút ngắn thành 2001:DB8:0:0:0:0:0:1.</p>
<p>Để dễ đọc, chúng ta cũng có thể bỏ qua một chuỗi dài các số không, ví dụ: 2001:DB8::1. Dấu hai chấm kép cho biết hãy điền tất cả các khối 4 chữ số còn thiếu bằng 0000. Điều này chỉ có thể được thực hiện một lần cho mỗi địa chỉ. (Việc bỏ qua hai dải sẽ tạo ra sự mơ hồ, vì chúng ta không biết có bao nhiêu số không trong mỗi dải.)</p>
<p><em>Slash notation</em> vẫn có thể được sử dụng trong <em>IPv6</em>. Một địa chỉ riêng lẻ có /128 (tất cả các bit đều cố định). Một tiền tố 32-bit có thể trông giống như 2001:0DB8::/32.</p>
<p>Bởi vì không gian địa chỉ rất lớn, trong <em>IPv6</em>, bạn có thể cố định <em>network ID</em> là 64 bit và <em>host ID</em> là 64 bit, và vẫn không bao giờ hết <em>network ID</em> hoặc <em>host ID</em>. Trên thực tế, có các giao thức đặc biệt tồn tại nơi các mạng và máy chủ có thể tự chọn <em>network ID</em> 64-bit và <em>host ID</em> 64-bit của riêng mình (và kiểm tra xem không có ai khác đang sử dụng nó), mà không cần một tổ chức phải phân bổ các ID cụ thể.</p>
<p>Trên thực tế, các cơ quan đăng ký khu vực thường phân bổ các tiền tố 32-bit cho các <em>ISP</em>, và các <em>ISP</em> thường phân bổ các tiền tố 48-bit cho các tổ chức. Tổ chức sau đó có thể phân bổ các tiền tố 64-bit cho các mạng con nhỏ hơn. Trong <em>IPv6</em>, chúng ta thường không thấy các tiền tố dài hơn /64. Ngay cả các mạng con nhỏ nhất bên trong một tổ chức cũng có một tiền tố 64-bit, và 64 bit để định địa chỉ cho các máy chủ cụ thể. Việc sử dụng các kích thước tiền tố được tiêu chuẩn hóa này cho phép các tiền tố cung cấp nhiều thông tin hơn. Ví dụ, trong <em>IPv4</em>, không rõ ràng một tiền tố /19 đại diện cho cái gì, nhưng trong <em>IPv6</em>, chúng ta biết một tiền tố /32 thường đại diện cho một <em>ISP</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="phần-cứng-router"><a class="header" href="#phần-cứng-router">Phần cứng Router</a></h1>
<h2 id="router-làm-gì"><a class="header" href="#router-làm-gì">Router làm gì?</a></h2>
<p>Một Router (thiết bị định tuyến) chạy một routing protocol (giao thức định tuyến) nào đó để điền thông tin vào forwarding table (bảng chuyển tiếp).</p>
<p>Sau đó, khi một packet (gói tin) đi vào, Router sẽ xem xét destination IP (IP đích) của nó và sử dụng forwarding table để chọn một liên kết để chuyển tiếp packet đi. Hãy nhớ rằng, forwarding table có thể chứa các dải địa chỉ.</p>
<p>Đến giờ, chúng ta vẫn vẽ Router như những chiếc hộp trên sơ đồ. Trong thực tế, Router là một máy tính chuyên dụng được tối ưu hóa để thực hiện các tác vụ định tuyến và chuyển tiếp. Trong phần này, chúng ta sẽ khám phá phần cứng bên trong Router.</p>
<h2 id="router-ở-đâu"><a class="header" href="#router-ở-đâu">Router ở đâu?</a></h2>
<p>Trong đời thực, các gia đình và văn phòng có những chiếc Router nhỏ để kết nối các máy chủ (hosts) với Internet. Vậy tất cả những Router này kết nối với nhau ở đâu?</p>
<img width="700px" class="real-photo" src="routing/../assets/routing/2-114-carrier-hotel.png">
<p><strong>Colocation facilities (cơ sở hạ tầng chung)</strong> hay <strong>carrier hotels (khách sạn nhà mạng)</strong> là những tòa nhà nơi nhiều ISP (Nhà cung cấp dịch vụ Internet) lắp đặt Router để kết nối với nhau. Các tòa nhà này được thiết kế đặc biệt để có cơ sở hạ tầng về điện và làm mát, và các ISP có thể thuê không gian để lắp đặt Router và kết nối chúng với các Router khác trong cùng tòa nhà.</p>
<p>Bên trong một carrier hotel, các Router được xếp chồng lên nhau trong các rack (giá đỡ) (cao 6-7 feet, rộng 19 inch).</p>
<h2 id="kích-thước-và-dung-lượng-router"><a class="header" href="#kích-thước-và-dung-lượng-router">Kích thước và dung lượng Router</a></h2>
<p>Router có đủ mọi kích cỡ, tùy thuộc vào yêu cầu của người dùng. Router gia đình chỉ chuyển tiếp lưu lượng cho một vài người dùng, và forwarding table chỉ có một mục mặc định duy nhất. Router công nghiệp có thể cần chuyển tiếp lưu lượng từ hàng nghìn khách hàng, với một forwarding table khổng lồ.</p>
<img width="800px" class="real-photo" src="routing/../assets/routing/2-115-router-sizes.png">
<p>Có nhiều cách khác nhau để đo lường kích thước của một Router. Chúng ta có thể xem xét kích thước vật lý, số lượng port (cổng) vật lý mà nó có, và bandwidth (băng thông) của nó.</p>
<p>Chúng ta có thể đo dung lượng của một Router bằng số lượng port vật lý, nhân với bandwidth của mỗi port vật lý. Tốc độ hoặc bandwidth của một port vật lý thường được gọi là <strong>line rate (tốc độ đường truyền)</strong>.</p>
<p>Không phải tất cả các port vật lý đều cần có cùng một line rate. Ví dụ, một Router gia đình hiện đại có thể có 4 port vật lý có thể gửi ở tốc độ 100 Mbps, và 1 port vật lý có thể gửi ở tốc độ 1 Gbps. Tổng dung lượng của Router này là 1.4 Gbps.</p>
<img width="200px" class="real-photo" src="routing/../assets/routing/2-116-modern-router.png">
<p>Một Router hiện đại tiên tiến được các ISP sử dụng có thể có line rate lên tới 400 Gbps cho mỗi port vật lý.</p>
<p>Router này chứa nhiều <strong>line card (card đường truyền)</strong> có thể tháo rời, mỗi line card chứa một bộ các port vật lý. Một Router hiện đại có thể có 8 line card, với 36 port vật lý trên mỗi line card, tổng cộng là 288 port vật lý.</p>
<p>288 port vật lý, mỗi port có bandwidth 400 Gbps, mang lại cho Router của chúng ta tổng dung lượng là 115.2 Tbps.</p>
<p>Router này có thể có giá lên tới hơn 1 triệu đô la. Việc chia một Router thành các line card cho phép chúng ta lắp đặt thêm line card khi cần thêm dung lượng.</p>
<p>Trong tương lai, các Router thế hệ tiếp theo sẽ có các port vật lý 800 Gbps. Không gian vật lý cho Router bị hạn chế, vì vậy các cải tiến hiện đại tập trung vào việc cải thiện tốc độ trên mỗi port, thay vì tăng số lượng port. (Việc nhồi nhét thêm port vào cùng một không gian cũng khó khăn do các hạn chế về điện và làm mát.)</p>
<img width="700px" class="real-photo" src="routing/../assets/routing/2-117-router-evolution.png">
<p>Dung lượng Router đã tăng lên qua các năm để đáp ứng sự tăng trưởng nhu cầu của người dùng (ví dụ: chất lượng video đã tăng từ 720p lên 8K = 8000p). Vào năm 2010, các Router tiên tiến có dung lượng 1.7 Tbps, và con số đó đã tăng gấp 100 lần trong thập kỷ qua. Phần lớn sự cải thiện này đến từ việc tăng tốc độ liên kết, từ 10 Gbps vào năm 2010 lên 100 Gbps vào khoảng năm 2016 và 400 Gbps ngày nay. Những cải tiến này đang bắt đầu chậm lại do các hạn chế như Moore's law (định luật Moore) chậm lại và những thách thức vật lý trong việc gửi tín hiệu ở tốc độ cao. Cải tiến tiếp theo lên 800 Gbps chỉ là tăng gấp 2 lần (so với mức tăng 10 lần và 4 lần trước đó).</p>
<h2 id="các-mặt-phẳng-dữ-liệu-Điều-khiển-quản-lý"><a class="header" href="#các-mặt-phẳng-dữ-liệu-Điều-khiển-quản-lý">Các mặt phẳng Dữ liệu, Điều khiển, Quản lý</a></h2>
<p>Các thành phần phần cứng và phần mềm của Router có thể được phân chia về mặt khái niệm thành ba mặt phẳng. <strong>data plane (mặt phẳng dữ liệu)</strong> chủ yếu chịu trách nhiệm chuyển tiếp packet. data plane được sử dụng mỗi khi một packet đến và cần được chuyển tiếp. data plane hoạt động cục bộ, không phối hợp với các Router khác.</p>
<p><strong>control plane (mặt phẳng điều khiển)</strong> chủ yếu chịu trách nhiệm giao tiếp với các Router khác và chạy các routing protocol. Kết quả của các routing protocol đó (ví dụ: forwarding table) sau đó có thể được data plane sử dụng. control plane được sử dụng mỗi khi cấu trúc liên kết của mạng thay đổi (ví dụ: khi các liên kết được thêm vào hoặc loại bỏ).</p>
<p>Bởi vì data plane và control plane hoạt động ở các thang thời gian khác nhau và chạy các giao thức khác nhau, phần cứng và phần mềm của một Router được tối ưu hóa cho các nhiệm vụ khác nhau. Trong thực tế, các packet đến thường xuyên hơn nhiều so với việc cấu trúc liên kết mạng thay đổi. Do đó, data plane được tối ưu hóa để thực hiện các tác vụ rất đơn giản (tra cứu bảng và chuyển tiếp) rất nhanh. Ngược lại, control plane được tối ưu hóa cho các tác vụ phức tạp hơn (tính toán lại các đường đi trong mạng).</p>
<p><strong>management plane (mặt phẳng quản lý)</strong> được sử dụng để ra lệnh cho Router phải làm gì và xem chúng đang làm gì. Các hệ thống và con người tương tác với management plane để cấu hình và giám sát Router. Đây là nơi các nhà khai thác có thể cấu hình chức năng của thiết bị. Chi phí nào nên được gán cho mỗi liên kết? routing protocol nào nên được chạy? Những điều này cần được nhà khai thác quyết định thủ công.</p>
<p>Ngoài việc cấu hình, management plane cũng cung cấp các công cụ giám sát. Bao nhiêu lưu lượng đang được truyền qua mỗi liên kết? Có thành phần vật lý nào của Router bị lỗi không? Thông tin này có thể được chuyển lại cho nhà khai thác.</p>
<p>management plane là nơi chính mà các nhà khai thác truy cập và tương tác với Router từ bên ngoài thiết bị. Nếu nhà khai thác đang sử dụng một đoạn mã nào đó để tương tác với Router, chúng ta thường coi đó cũng là một phần của management plane.</p>
<p>data plane và control plane hoạt động trong thời gian thực, nhận và xử lý các packet theo thứ tự nano giây (dữ liệu) và giây (điều khiển). Ngược lại, management plane hoạt động theo thứ tự từ hàng chục đến hàng trăm giây. Nếu nhà khai thác thay đổi một cấu hình, Router có thể mất thời gian thực hiện kiểm tra xác thực và xử lý cấu hình trước khi áp dụng hoàn toàn bản cập nhật.</p>
<p><strong>network management system (NMS) (hệ thống quản lý mạng)</strong> là một phần mềm nào đó do nhà khai thác chạy để tương tác với các Router. Phần mềm này tính toán một cấu hình mạng (có thể với sự trợ giúp của đầu vào thủ công từ nhà khai thác), và sau đó áp dụng cấu hình đó cho các Router. Router công bố một số API (Giao diện lập trình ứng dụng) mà hệ thống có thể sử dụng để giao tiếp với Router.</p>
<p>network management system cũng cho phép đọc telemetry (dữ liệu đo lường từ xa) (thống kê và trạng thái hoạt động) từ các Router.</p>
<p>Sự phức tạp của network management system phụ thuộc vào những gì nhà khai thác đang cố gắng đạt được.</p>
<p>Cả ba mặt phẳng đều cần thiết để chạy một Router. Nếu chúng ta chỉ có data plane và không có control plane, chúng ta có thể chuyển tiếp các packet, nhưng chúng ta sẽ không biết phải chuyển tiếp chúng đi đâu.</p>
<h2 id="bên-trong-router-có-gì"><a class="header" href="#bên-trong-router-có-gì">Bên trong Router có gì?</a></h2>
<p>Chúng ta đã định nghĩa Router là một máy tính thực hiện các tác vụ định tuyến, nhưng trong thực tế, bên trong Router, có nhiều máy tính nhỏ hơn (ví dụ: CPU (bộ xử lý trung tâm), chip chuyên dụng) làm việc cùng nhau để thực hiện các tác vụ định tuyến.</p>
<p>Khung vật lý tạo nên một Router kích thước công nghiệp được gọi là <strong>chassis (khung máy)</strong>. Bên trong chassis, chúng ta lắp đặt nhiều <strong>line card</strong>, và chúng ta có một số port vật lý trên mỗi line card. Mỗi port vật lý có thể được sử dụng cho đầu vào hoặc đầu ra.</p>
<img width="900px" src="routing/../assets/routing/2-118-router1.png">
<p>Mỗi port vật lý phải được kết nối với mọi port vật lý khác trong Router (cả trong cùng linecard và các linecard khác). Bạn có thể nhận một packet qua một port, và cần phải chuyển tiếp nó ra khỏi một port trên một linecard khác.</p>
<p>Sẽ khá kém hiệu quả nếu nối dây vật lý từ mỗi port đến mọi port khác. Thay vào đó, chúng ta có một fabric (kết cấu chuyển mạch) gồm các dây để kết nối các linecard lại với nhau. Mỗi linecard cũng có các chip để tạo điều kiện kết nối với fabric.</p>
<p>Tách biệt với tất cả các linecard, chúng ta có một card điều khiển với CPU riêng, giao tiếp với các Router khác để thực hiện các routing protocol. Sau khi chạy một thuật toán nào đó để tính toán đường đi, bộ điều khiển sẽ lập trình các chip chuyển tiếp với các mục forwarding table chính xác.</p>
<img width="900px" src="routing/../assets/routing/2-119-router2.png">
<p>Mỗi linecard có CPU cục bộ riêng để điều khiển các chức năng của linecard (ví dụ: điền vào forwarding table). linecard cũng có phần cứng để xử lý cơ bản các packet (ví dụ: cập nhật TTL của nó trước khi gửi đi). linecard chứa một hoặc nhiều chip được tối ưu hóa đặc biệt cho việc chuyển tiếp.</p>
<img width="700px" src="routing/../assets/routing/2-120-router3.png">
<p>Chúng ta cũng có thể phân loại các thành phần của Router theo các mặt phẳng khác nhau. data plane được hỗ trợ bởi các chip chuyển tiếp trên các linecard, fabric kết nối các linecard, và các chip fabric kết nối các linecard với fabric. control plane và management plane được hỗ trợ bởi card điều khiển.</p>
<img width="800px" src="routing/../assets/routing/2-121-router4.png">
<p>Đây là hình ảnh của một Router công nghiệp. Router này có 6 khe cắm, trong đó 4 khe có line card, và 2 khe còn lại có card điều khiển. Ngoài ra còn có một khay quạt để làm mát. fabric kết nối các linecard nằm ở phía sau (không có trong ảnh).</p>
<img width="900px" src="routing/../assets/routing/2-122-router5.png">
<h2 id="các-loại-packet"><a class="header" href="#các-loại-packet">Các loại Packet</a></h2>
<p>Packet phổ biến nhất là <strong>user packet (gói tin người dùng)</strong>, chứa dữ liệu từ một máy chủ đầu cuối. Khi Router nhận packet này, chip chuyển tiếp đầu tiên sẽ đọc trường đích trong phần đầu và tra cứu port thích hợp. Nếu port đó nằm trên một linecard khác, packet sẽ được gửi qua fabric đến linecard thích hợp. Khi packet đến đúng linecard, packet sẽ được gửi đi theo port thích hợp.</p>
<img width="900px" src="routing/../assets/routing/2-123-user-traffic.png">
<p>Một số packet là <strong>control-plane traffic (lưu lượng mặt phẳng điều khiển)</strong>, được gửi đến chính Router. Cụ thể, khi chúng ta chạy các routing protocol, các thông điệp quảng bá sẽ được gửi đến chính Router. Khi Router nhận packet này, chip chuyển tiếp sẽ gửi packet lên card điều khiển. CPU trên card điều khiển sẽ xử lý packet tương ứng.</p>
<p>Loại lưu lượng cuối cùng là <strong>punt traffic (lưu lượng cần xử lý đặc biệt)</strong>. Đây là các user packet, nhưng chúng yêu cầu một số xử lý đặc biệt bổ sung. Ví dụ, nếu chúng ta nhận được một packet có TTL (Time-to-Live, thời gian sống của gói tin) là 1, packet đã hết hạn, và chúng ta không nên chuyển tiếp nó. Chúng ta cũng có thể cần gửi một thông báo lỗi trở lại cho người gửi. Khi Router nhận một packet loại &quot;punt&quot;, chip chuyển tiếp sẽ &quot;punt&quot; (chuyển) packet đó đến card điều khiển để xử lý đặc biệt.</p>
<img width="900px" src="routing/../assets/routing/2-124-punt-traffic.png">
<h2 id="mở-rộng-quy-mô-router"><a class="header" href="#mở-rộng-quy-mô-router">Mở rộng quy mô Router</a></h2>
<p>Tại sao Router của chúng ta lại được chia thành kiến trúc cụ thể này, với các chip chuyển tiếp và card điều khiển? Chẳng phải chúng ta có thể chạy mọi thứ trên một CPU đa dụng sao?</p>
<p>Vấn đề là, các Router tiên tiến cần phải hoạt động ở quy mô rất lớn. Với tốc độ hiện đại là 400 Gbps mỗi giây, và giả sử các packet có kích thước 64-byte, chúng ta phải xử lý 781 triệu packet mỗi giây, trên mỗi port. Trên 36 port, toàn bộ Router phải xử lý 56 tỷ packet mỗi giây. (Trong thực tế, con số này có thể thấp hơn một chút nếu một số packet lớn hơn.)</p>
<p>Quy mô này không thể đạt được bằng phần mềm trên một CPU đa dụng. Để có cảm nhận về quy mô, nếu chúng ta thử viết một chương trình để chuyển tiếp packet, và chúng ta chạy chương trình đó trên một CPU, sẽ rất ấn tượng nếu chúng ta có thể chuyển tiếp một packet mỗi 10 micro giây = 0.00001 giây. Một Router tiên tiến cần xử lý một packet trong khoảng 10 nano giây = 0.00000001 giây. Ngay cả phần mềm được tối ưu hóa nhất cũng không thể xử lý packet ở quy mô này. Thay vào đó, chúng ta cần triển khai chức năng của Router trực tiếp trên phần cứng.</p>
<p>Bằng cách chia Router thành các linecard chuyên dụng cho data plane và các card điều khiển cho control plane, chúng ta tạo ra một fast path (đường đi nhanh) và một slow path (đường đi chậm). fast path chỉ liên quan đến phần cứng chuyển tiếp và được tối ưu hóa để chuyển tiếp packet ở tốc độ rất cao. slow path với CPU điều khiển chỉ được sử dụng khi cần thiết, và hầu hết các packet được gửi qua fast path. Các thành phần chuyên dụng này làm cho Router hiệu quả hơn nhiều (sử dụng ít năng lượng hơn, rẻ hơn, chiếm ít không gian vật lý hơn).</p>
<h2 id="chức-năng-của-linecard"><a class="header" href="#chức-năng-của-linecard">Chức năng của Linecard</a></h2>
<p>Một linecard cần phải làm những nhiệm vụ cụ thể nào khi nó nhận một packet?</p>
<p>Đầu tiên, linecard cần phải lấy tín hiệu (ví dụ: quang, điện) và giải mã tín hiệu này thành các bit một và không tạo nên packet. Đây là phần <strong>PHY (lớp vật lý)</strong> của linecard, xử lý chức năng của lớp vật lý (Lớp 1).</p>
<p>Khi chúng ta đã có một chuỗi các bit một và không, chúng ta phải đọc các bit đó và phân tích chúng (ví dụ: tìm ra bit nào tương ứng với IP header (phần đầu của gói tin IP)). Chúng ta cũng có thể phải thực hiện các hoạt động khác ở lớp liên kết dữ liệu (ví dụ: nếu một liên kết được kết nối với hơn 2 máy). Phần <strong>MAC (lớp liên kết dữ liệu)</strong> của linecard xử lý chức năng của lớp liên kết dữ liệu (Lớp 2).</p>
<p>Bây giờ chúng ta đã có một packet IP, chúng ta phải phân tích packet đó. Ví dụ, chúng ta cần kiểm tra xem packet là IPv4 hay IPv6. Sau đó, chúng ta phải đọc địa chỉ đích và thực hiện tra cứu để chuyển tiếp (hoặc phát hiện ra rằng chúng ta cần &quot;punt&quot; packet).</p>
<p>Chúng ta cũng có thể cần cập nhật các trường IP header khác nhau. Chúng ta phải giảm TTL. Vì chúng ta đã cập nhật phần đầu, chúng ta cũng cần cập nhật checksum (tổng kiểm tra) trong phần đầu. Chúng ta cũng có thể cần cập nhật các trường khác như tùy chọn và phân mảnh (sẽ được thảo luận chi tiết hơn trong phần IP header).</p>
<img width="900px" src="routing/../assets/routing/2-125-pipeline.png">
<p>Tất cả các chức năng này phải diễn ra trong vài nano giây. Ngay cả khi chúng ta bằng cách nào đó thực hiện tất cả quá trình xử lý trong một chu kỳ xung nhịp, linecard vẫn phải hoạt động ở tốc độ 0.2 GHz. Trong thực tế, tất cả các hoạt động này sẽ mất nhiều hơn một chu kỳ xung nhịp. Ngoài ra, chúng ta phải thực hiện tất cả quá trình xử lý này cho mọi port trên linecard (một chip chuyển tiếp hỗ trợ tất cả các port).</p>
<p>Để làm cho các hoạt động này nhanh chóng, các chip chuyển tiếp cực kỳ chuyên dụng cho các nhiệm vụ hạn chế mà chúng thực hiện (ví dụ: đọc phần đầu packet, tra cứu bảng). Bạn không thể viết một chương trình đa dụng và chạy nó trên một chip chuyển tiếp. Nếu một packet yêu cầu chức năng mà chip chuyển tiếp không thể hỗ trợ, chúng ta luôn có thể &quot;punt&quot; packet đó đến CPU đa dụng trên card điều khiển.</p>
<p>Các hoạt động đơn giản, như giảm TTL, dễ dàng triển khai trong phần cứng. Các hoạt động phức tạp hơn, như các tùy chọn đặc biệt, thường yêu cầu &quot;punt&quot; đến card điều khiển. Trong Internet hiện đại, chúng ta tránh các tùy chọn đặc biệt bất cứ khi nào có thể, để tối đa hóa việc sử dụng fast path và tránh &quot;punt&quot; (nếu chúng ta &quot;punt&quot; mọi thứ, card điều khiển sẽ bị quá tải).</p>
<p>Các chip kết nối fabric cũng được chuyên môn hóa tương tự. Các chip này giúp gửi các packet qua fabric đến các linecard khác. Các chip này có xu hướng là những chip chuyên dụng nhất và hiệu năng cao nhất trong toàn bộ Router.</p>
<h2 id="hàng-đợi-packet"><a class="header" href="#hàng-đợi-packet">Hàng đợi Packet</a></h2>
<p>CẦN LÀM</p>
<img width="900px" src="routing/../assets/routing/2-126-queuing.png">
<h2 id="tra-cứu-bảng-chuyển-tiếp-hiệu-quả"><a class="header" href="#tra-cứu-bảng-chuyển-tiếp-hiệu-quả">Tra cứu Bảng chuyển tiếp hiệu quả</a></h2>
<p>Bây giờ chúng ta biết rằng các router cần thực hiện tra cứu trong các forwarding table ở tốc độ cực kỳ cao. Một thách thức lớn là các mục trong bảng của chúng ta có thể chứa các dải địa chỉ IP (192.0.1.0/24) ngoài các địa chỉ IP riêng lẻ. Ngoài ra, các dải này có thể chồng chéo lên nhau (một đích có thể khớp với nhiều dải). Làm thế nào chúng ta có thể làm cho việc tra cứu cực kỳ nhanh chóng?</p>
<p>Lý tưởng nhất, để có tốc độ tối đa, forwarding table có thể chứa một mục cho mỗi đích, không có dải nào. Khi đó, chúng ta chỉ cần lấy đích trong packet, và tra cứu một kết quả khớp chính xác để biết chặng tiếp theo.</p>
<p>Để đạt được cách tiếp cận lý tưởng này, chúng ta có thể mở rộng mọi dải thành các địa chỉ IP riêng lẻ của nó. Ví dụ, một mục cho tiền tố 24-bit 192.0.1.0/24 sẽ được mở rộng thành 256 mục.</p>
<img width="200px" class="real-photo" src="routing/../assets/routing/2-127-forwarding1.png">
<p>Điều này không hiệu quả về mặt không gian (hãy nhớ rằng, điều này đang được triển khai trong phần cứng). Ngoài ra, nếu một tuyến đường thay đổi, chúng ta sẽ phải cập nhật hàng tấn mục trong bảng. Việc mở rộng các tuyến đường sẽ không khả thi, vì vậy chúng ta sẽ phải làm việc với các dải.</p>
<p>Hãy nhớ lại rằng việc tra cứu forwarding table được thực hiện bằng cách sử dụng longest prefix matching (khớp tiền tố dài nhất). Nếu nhiều dải khớp với đích, chúng ta chọn dải cụ thể nhất (có nhiều bit tiền tố được cố định nhất). Nếu không có dải nào khớp, chúng ta chọn default route (tuyến đường mặc định) (<em>.</em>, 0.0.0.0/32, khớp với tất cả các đích). Nếu không có default route, chúng ta sẽ loại bỏ packet.</p>
<p>Làm thế nào để chúng ta triển khai longest prefix matching trong phần cứng một cách hiệu quả?</p>
<img width="900px" src="routing/../assets/routing/2-128-forwarding2.png">
<p>CẦN VIẾT LẠI ĐỂ KHỚP VỚI SƠ ĐỒ</p>
<p>Đầu tiên, để dễ đọc, chúng ta viết lại tất cả các dải và đích ở dạng nhị phân. Sau đó, chúng ta quét các bit của đích, từng bit một. Đối với 21 bit đầu tiên, cả bốn dải đều khớp, vì vậy cả bốn dải vẫn còn trong cuộc. Sau đó, bit thứ 22 là 1. Hàng đầu tiên có số 0 ở bit thứ 22, vì vậy chúng ta có thể loại bỏ hàng này (không khớp). Ba hàng còn lại vẫn khớp trong 21 bit đầu tiên, vì vậy chúng vẫn còn trong cuộc.</p>
<p>Tiếp theo, chúng ta kiểm tra bit thứ 23, cũng là 1. Hàng thứ hai và thứ ba có số 0 ở bit thứ 23, vì vậy chúng ta loại bỏ chúng (không khớp). Hàng thứ tư vẫn khớp.</p>
<p>Tại thời điểm này, chúng ta có thể xác nhận rằng hàng thứ tư là một kết quả khớp hoàn toàn, vì nó là một tiền tố 23-bit, và tất cả 23 bit đều khớp. Không cần kiểm tra thêm hàng này nữa.</p>
<p>Chúng ta tiếp tục kiểm tra từng bit, loại bỏ các hàng không khớp, và xác nhận các hàng là kết quả khớp hoàn toàn. Cuối cùng, chúng ta có một hoặc nhiều hàng khớp, và chúng ta chọn kết quả khớp có tiền tố dài nhất.</p>
<p>Nếu chúng ta triển khai điều này một cách ngây thơ, thì với mỗi bit, chúng ta sẽ phải so sánh bit đó với mọi mục trong forwarding table. Thời gian chạy tiệm cận sẽ tỷ lệ với số lượng mục trong forwarding table. Liệu chúng ta có thể làm tốt hơn không?</p>
<h2 id="tra-cứu-hiệu-quả-với-tries"><a class="header" href="#tra-cứu-hiệu-quả-với-tries">Tra cứu hiệu quả với Tries</a></h2>
<p>Nhớ lại một lớp về cấu trúc dữ liệu (như CS 61B ở UC Berkeley), bạn có thể nhớ rằng trie (cấu trúc cây tiền tố) là một cấu trúc dữ liệu lưu trữ hiệu quả các ánh xạ trong đó khóa là các chuỗi (trong trường hợp này là chuỗi bit). Trie lưu trữ các cặp khóa-giá trị bằng cách viết ra các khóa từng ký tự (bit) một, cho phép thực hiện longest prefix matching hiệu quả.</p>
<p>Ví dụ, trie này lưu trữ một ánh xạ từ các từ đến các số. Nếu bạn không nhớ về trie, cũng không sao.</p>
<img width="800px" src="routing/../assets/routing/2-129-trie1.png">
<p>Nếu chúng ta muốn tìm tiền tố dài nhất, cũng giống như trước đây, chúng ta đọc từng chữ cái của từ. Điều này cho phép chúng ta theo một đường đi xuống cây, từ gốc đến lá. Dọc theo con đường này, chúng ta tìm tất cả các tiền tố trong bảng (các nút có màu), và chọn tiền tố dài nhất.</p>
<img width="800px" src="routing/../assets/routing/2-130-trie2.png">
<p>Chúng ta có thể sử dụng một cách tiếp cận tương tự cho forwarding table của mình. Mỗi tầng của trie đại diện cho một trong các chữ số trong địa chỉ IP. Tầng thứ không là gốc (chuỗi rỗng), tầng thứ nhất đại diện cho bit đầu tiên, tầng thứ hai đại diện cho bit thứ hai, v.v.</p>
<p>Mỗi nút trong trie đại diện cho một tiền tố. Ví dụ, tiền tố 2-bit 11* ở tầng thứ hai của cây, và tiền tố 3-bit 100 ở tầng thứ ba của cây. trie có tất cả các tiền tố 3-bit có thể có. Nếu một tiền tố có trong forwarding table, tại nút tương ứng, chúng ta ghi chặng tiếp theo. Nếu tiền tố không có trong forwarding table, chúng ta không ghi gì vào nút đó (trong hình, được tô màu trắng).</p>
<img width="900px" src="routing/../assets/routing/2-131-trie3.png">
<p>Việc đi theo đường dẫn xuống cây có thể được thực hiện trong thời gian hằng số. Chúng ta duyệt một nút cho mỗi bit của địa chỉ đích, và địa chỉ đích luôn là 32 bit (hằng số). Ngay cả khi forwarding table có hàng triệu mục, chúng ta vẫn sẽ chỉ chọn ra 32 nút.</p>
<p>Nếu không có các dải chồng chéo, mỗi tiền tố hợp lệ tương ứng với một nút lá. Nếu các dải chồng chéo, một nút không phải lá cũng có thể là một tiền tố hợp lệ.</p>
<p>Như trước đây, chúng ta sử dụng địa chỉ đích để theo một đường đi xuống cây. Nếu chúng ta đi ra khỏi cây, chúng ta dừng lại sớm và chọn tiền tố dài nhất trong số các nút chúng ta đã duyệt qua.</p>
<p>Như một sự tối ưu hóa nhỏ, khi chúng ta đi xuống cây, chúng ta có thể theo dõi kết quả khớp tiền tố dài nhất đã thấy cho đến nay. Đây sẽ luôn là kết quả khớp gần đây nhất, vì các tiền tố trở nên dài hơn khi chúng ta đi xuống cây. Nếu chúng ta đi ra khỏi cây, chúng ta sử dụng kết quả khớp tiền tố dài nhất (kết quả khớp gần đây nhất chúng ta tìm thấy).</p>
<img width="900px" src="routing/../assets/routing/2-132-trie4.png">
<p>Lưu ý rằng default route sẽ được lưu trữ trong nút gốc (tiền tố có độ dài 0). Thuật toán đi xuống cây của chúng ta đảm bảo rằng chúng ta chỉ sử dụng default route nếu không có tiền tố nào khác khớp.</p>
<img width="900px" src="routing/../assets/routing/2-133-trie5.png">
<p>Tất cả các router đều có một dạng chức năng longest prefix matching, nhưng một số sử dụng các giải pháp tiên tiến hơn những router khác. Ví dụ, chúng ta có thể thêm các phương pháp phỏng đoán và tối ưu hóa dựa trên các giả định của Internet trong thế giới thực. Một số đích có thể phổ biến hơn, vì vậy chúng ta có thể muốn tra cứu chúng hiệu quả hơn. Một số port có thể được sử dụng cho nhiều dải hơn. Internet hiện đại có một số quy ước về kích thước tiền tố (ví dụ: tiền tố IPv4 dài nhất cho các tuyến đến các mạng khác là 24 bit). Chúng ta cũng có thể thực hiện các tối ưu hóa để cập nhật các forwarding table.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mô-hình-cho-Định-tuyến-liên-miền"><a class="header" href="#mô-hình-cho-Định-tuyến-liên-miền">Mô hình cho Định tuyến Liên miền</a></h1>
<h2 id="Định-tuyến-liên-miền"><a class="header" href="#Định-tuyến-liên-miền">Định tuyến Liên miền</a></h2>
<p>Như đã đề cập trước đó, việc định tuyến được thực hiện trong một mạng của các mạng. Chúng ta đã tìm hiểu về các giao thức <em>distance-vector</em> (véc-tơ khoảng cách) và <em>link-state</em> (trạng thái liên kết) có thể được sử dụng để triển khai <em>intra-domain routing</em> (định tuyến nội miền), cho phép các gói tin được gửi trong một mạng cục bộ.</p>
<p>Trong phần này, chúng ta sẽ xây dựng một mô hình cho phép định nghĩa các giao thức <em>inter-domain routing</em> (định tuyến liên miền), có thể gửi gói tin giữa các mạng cục bộ khác nhau. Chúng ta cũng sẽ thấy cách các giao thức <em>inter-domain routing</em> và <em>intra-domain routing</em> kết hợp với nhau để cho phép các gói tin được gửi đến bất kỳ máy chủ nào trong bất kỳ mạng nào.</p>
<h2 id="Định-nghĩa-các-hệ-thống-tự-trị"><a class="header" href="#Định-nghĩa-các-hệ-thống-tự-trị">Định nghĩa các Hệ thống Tự trị</a></h2>
<p>Chúng ta có thể chính thức hóa khái niệm về một mạng cục bộ bằng cách định nghĩa một <em><strong>autonomous system (AS)</strong></em> (hệ thống tự trị), là một hoặc nhiều mạng cục bộ được vận hành bởi cùng một nhà điều hành. Ví dụ, trong một công ty như Google, có thể có một mạng cục bộ cho máy tính của nhân viên và một mạng cục bộ khác cho các trung tâm dữ liệu, nhưng cả hai mạng này đều do cùng một công ty kiểm soát. Nhà điều hành có thể triển khai một giao thức <em>intra-domain routing</em> duy nhất để gửi tin nhắn giữa các máy trên bất kỳ mạng cục bộ nào trong số đó. Đôi khi, thuật ngữ <em><strong>domain</strong></em> (miền) được sử dụng một cách không chính thức để chỉ một <em>AS</em>, mặc dù thuật ngữ này cũng được sử dụng trong các giao thức khác, vì vậy chúng ta sẽ dùng <em>AS</em> khi có thể.</p>
<p>Để hình dung về việc định tuyến các gói tin giữa các <em>autonomous system</em>, chúng ta có thể trừu tượng hóa tất cả các <em>router</em> và máy chủ riêng lẻ trong <em>AS</em>, và coi <em>AS</em> như một thực thể duy nhất. Sau đó, chúng ta có thể vẽ một đồ thị trong đó mỗi nút đại diện cho một <em>AS</em>, và các cạnh giữa hai <em>AS</em> biểu thị một kết nối giữa chúng. Đồ thị này đôi khi được gọi là <em><strong>inter-domain topology</strong></em> (tô-pô liên miền) hoặc <em><strong>AS graph</strong></em> (đồ thị AS).</p>
<img width="900px" src="routing/../assets/routing/2-134-interdomain.png">
<h2 id="lịch-sử-tóm-tắt-của-các-hệ-thống-tự-trị"><a class="header" href="#lịch-sử-tóm-tắt-của-các-hệ-thống-tự-trị">Lịch sử Tóm tắt của các Hệ thống Tự trị</a></h2>
<p>Trong thực tế, một tổ chức có tên là <em>Internet Assigned Numbers Authority (IANA)</em> (Tổ chức cấp phát số hiệu Internet) quản lý một danh sách toàn cầu của tất cả các <em>autonomous system</em> tồn tại trên Internet. Để trở thành một <em>AS</em>, bạn phải đăng ký với tổ chức này và nhận một <em>autonomous system number (ASN)</em> (số hiệu hệ thống tự trị) duy nhất.</p>
<p>Một sự thật thú vị: Trong những ngày đầu, <em>IANA</em> được quản lý thủ công bởi một người duy nhất, Jon Postel. Điều này có nghĩa là bất kỳ ai trên thế giới muốn đăng ký một <em>AS</em> mới đều phải xin sự chấp thuận của ông.</p>
<p>Ngày nay, có hơn 90.000 <em>autonomous system</em>, trong đó Hoa Kỳ là quốc gia có nhiều <em>AS</em> nhất.</p>
<img width="600px" src="routing/../assets/routing/2-135-as-history1.png">
<img width="600px" src="routing/../assets/routing/2-136-as-history2.png">
<p>Một sự thật thú vị khác: UC Berkeley có <em>ASN</em> 25, một con số thấp đáng kể khi có rất nhiều <em>ASN</em>. Điều này phản ánh sự thật rằng UC Berkeley đã nhận được <em>ASN</em> của mình từ rất sớm trong lịch sử Internet (vào những năm 1980).</p>
<h2 id="các-loại-as"><a class="header" href="#các-loại-as">Các loại AS</a></h2>
<p>Hãy nhớ lại rằng khi mô hình hóa mạng cho <em>intra-domain routing</em>, chúng ta đã phân biệt giữa <em>end hosts</em> (máy chủ đầu cuối) và <em>routers</em> (bộ định tuyến). Chúng ta cũng sẽ có một sự phân biệt tương tự cho <em>inter-domain routing</em> bằng cách định nghĩa hai loại <em>AS</em>.</p>
<p>Một <em><strong>stub autonomous system</strong></em> (hệ thống tự trị cụt) chỉ tồn tại để cung cấp kết nối Internet cho các máy chủ trong các mạng cục bộ của nó. Một <em>stub AS</em> chỉ gửi và nhận các gói tin thay mặt cho các máy chủ bên trong <em>AS</em> đó, và không chuyển tiếp các gói tin giữa các <em>AS</em> khác nhau. Chúng tương tự như các <em>end hosts</em> trong mô hình <em>intra-domain routing</em> của chúng ta, vốn chỉ gửi và nhận các gói tin của riêng mình và không chuyển tiếp gói tin của người khác.</p>
<p>Các ví dụ thực tế về <em>stub AS</em> bao gồm các công ty không chuyên về Internet (ví dụ: một ngân hàng cung cấp kết nối cho nhân viên của mình) hoặc các trường đại học (ví dụ: UC Berkeley cung cấp kết nối cho sinh viên và nhân viên). Các tổ chức này không chịu trách nhiệm vận chuyển lưu lượng Internet từ các tổ chức khác. Đại đa số các <em>AS</em> trên thế giới là <em>stub AS</em>.</p>
<p>Ngược lại, một <em><strong>transit autonomous system</strong></em> (hệ thống tự trị chuyển tiếp) chuyển tiếp các gói tin thay mặt cho các <em>AS</em> khác. Một <em>transit AS</em> có thể vận chuyển một gói tin giữa hai <em>AS</em> khác nhau bằng cách nhận và chuyển tiếp gói tin đó.</p>
<p><em>Transit AS</em> tương ứng với các công ty trong thực tế có hoạt động kinh doanh bao gồm việc bán kết nối Internet cho các tổ chức khác. Các ví dụ thực tế về <em>transit AS</em> bao gồm AT&amp;T và Verizon, là những công ty mà bạn có thể trả tiền để họ cung cấp kết nối Internet cho bạn. Một số <em>transit AS</em> như AT&amp;T có quy mô toàn cầu, với cơ sở hạ tầng trên khắp thế giới. Những <em>AS</em> khác có thể chỉ hoạt động trong một khu vực cụ thể, như Sonic, một nhà cung cấp dịch vụ Internet chỉ chuyển tiếp lưu lượng đến và đi từ California.</p>
<p>Lưu ý rằng một <em>transit AS</em> vẫn có thể chứa các <em>end hosts</em> gửi và nhận các gói tin của riêng mình. Tuy nhiên, một <em>transit AS</em> tương tự như các <em>routers</em> trong mô hình <em>intra-domain routing</em> của chúng ta, vốn nhận các gói tin của người dùng khác và chuyển tiếp chúng thay mặt cho người dùng.</p>
<p>Mô hình về <em>stub AS</em> và <em>transit AS</em> này là những gì chúng ta sẽ sử dụng trong tài liệu này, mặc dù đôi khi, sự phân loại trong thực tế có thể không rõ ràng như vậy. Ví dụ, các công ty công nghệ lớn như Google, Microsoft và Amazon kiểm soát các <em>AS</em> khổng lồ vận chuyển lưu lượng nhiều như các <em>transit AS</em> (và thậm chí có thể nhiều hơn). Bởi vì vai trò chính của họ là vận chuyển lưu lượng đến và đi từ các dịch vụ của họ (ví dụ: nhận yêu cầu tìm kiếm Google và gửi kết quả tìm kiếm), họ có thể được phân loại là <em>stub AS</em>. Tuy nhiên, trong những năm gần đây, các công ty này cũng đã đề nghị vận chuyển lưu lượng giữa các <em>AS</em>, vì vậy họ cũng có thể được phân loại là <em>transit AS</em>.</p>
<h2 id="tô-pô-liên-miền-được-Định-nghĩa-bởi-các-mối-quan-hệ-kinh-doanh"><a class="header" href="#tô-pô-liên-miền-được-Định-nghĩa-bởi-các-mối-quan-hệ-kinh-doanh">Tô-pô Liên miền được Định nghĩa bởi các Mối quan hệ Kinh doanh</a></h2>
<p>Trong <em>inter-domain topology</em> của chúng ta, chúng ta vẽ một cạnh giữa hai <em>AS</em> nếu chúng trao đổi lưu lượng với nhau. Điều gì khiến hai tổ chức trong đời thực, chẳng hạn như một ngân hàng địa phương và Verizon, đồng ý trao đổi lưu lượng? Các cạnh trong <em>AS</em> được định nghĩa bởi các mối quan hệ kinh doanh thực tế giữa các <em>AS</em>.</p>
<p>Có hai cách khả dĩ mà một cặp <em>AS</em> có thể liên quan đến nhau.</p>
<p>Một cặp <em>AS</em> có thể có <em>customer-provider relationship</em> (mối quan hệ khách hàng-nhà cung cấp). Trong đời thực, <em><strong>customer</strong></em> (khách hàng) trả tiền cho dịch vụ, và <em><strong>provider</strong></em> (nhà cung cấp) cung cấp kết nối để đổi lấy tiền. Ví dụ, <em>AS</em> của ngân hàng địa phương có thể là <em>customer</em>, trả tiền cho <em>provider</em> là Verizon để sử dụng dịch vụ Internet.</p>
<p>Một cặp <em>AS</em> cũng có thể có mối quan hệ <em><strong>peer</strong></em> (ngang hàng). Hai <em>AS</em> ngang hàng thường gửi cho nhau một lượng lưu lượng xấp xỉ bằng nhau. Trong đời thực, hai <em>AS</em> có thể đồng ý trở thành <em>peer</em> bằng cách ký một hợp đồng pháp lý giữa các công ty. Thông thường, hai <em>peer</em> đồng ý không trả tiền cho nhau cho các dịch vụ kết nối, miễn là lưu lượng gửi theo cả hai hướng là tương đối bằng nhau.</p>
<h2 id="Đồ-thị-as-với-các-mối-quan-hệ-kinh-doanh"><a class="header" href="#Đồ-thị-as-với-các-mối-quan-hệ-kinh-doanh">Đồ thị AS với các Mối quan hệ Kinh doanh</a></h2>
<p>Chúng ta có thể vẽ các mối quan hệ này vào <em>AS graph</em> bằng cách thêm các mũi tên vào đồ thị. Một cạnh có hướng chỉ từ <em>provider</em> đến <em>customer</em>. Một cạnh không có hướng nối hai <em>peer</em>. Lưu ý rằng đồ thị có thể chứa cả cạnh có hướng và không có hướng (không phải tất cả các cạnh đều cần có mũi tên).</p>
<img width="500px" src="routing/../assets/routing/2-137-as-graph.png">
<p>Các <em>stub AS</em> trong đồ thị chỉ là <em>customer</em>. Chúng có các cạnh đi vào, cho thấy ai cung cấp kết nối cho chúng. Tuy nhiên, chúng không có bất kỳ cạnh đi ra nào, bởi vì chúng không cung cấp kết nối cho người khác.</p>
<p>Ngược lại, các <em>transit AS</em> trong đồ thị là các <em>provider</em>. Các mũi tên đi ra của chúng cho thấy rằng chúng đang bán kết nối cho các tổ chức khác.</p>
<p>Lưu ý rằng hướng của mũi tên không cho chúng ta biết gì về hướng mà các gói tin đang được gửi. Trên thực tế, các gói tin có thể được gửi theo cả hai hướng ngay cả trên một cạnh có hướng. <em>Customer</em> thường trả tiền cho <em>provider</em> để có khả năng gửi và nhận gói tin đến và từ phần còn lại của Internet.</p>
<h2 id="Đồ-thị-as-là-phi-chu-trình-acyclic"><a class="header" href="#Đồ-thị-as-là-phi-chu-trình-acyclic">Đồ thị AS là Phi chu trình (Acyclic)</a></h2>
<p>Đồ thị của các mối quan hệ <em>customer-provider</em> là phi chu trình. Đồ thị không chứa bất kỳ chu trình nào bao gồm các cạnh có hướng.</p>
<p>Thuộc tính phi chu trình này tồn tại do những hệ quả trong thế giới thực của việc có một chu trình. Trong đời thực, một chu trình có nghĩa là A trả tiền cho B, B trả tiền cho C, và sau đó C trả tiền cho A, và việc tiền chảy từ một người quay trở lại chính họ là không hợp lý. Ngoài ra, chu trình này cũng có nghĩa là A cung cấp dịch vụ cho C, C cung cấp dịch vụ cho B, và B cung cấp dịch vụ cho A. Việc một người tự cung cấp kết nối cho chính mình cũng không hợp lý.</p>
<p>Để dùng một phép loại suy, hãy tưởng tượng nếu bạn trả học phí cho UC Berkeley để học các lớp, sau đó UC Berkeley trả tiền cho hệ thống UC để học các lớp, và rồi hệ thống UC lại trả tiền cho bạn để học các lớp. Mối quan hệ kinh doanh này hoàn toàn vô lý!</p>
<img width="700px" src="routing/../assets/routing/2-138-acyclic.png">
<p>Lưu ý rằng thuộc tính phi chu trình chỉ áp dụng cho các mối quan hệ <em>customer-provider</em>. Sẽ không có vấn đề gì nếu các mối quan hệ <em>peer</em> tạo thành một chu trình. Ví dụ, không sao nếu A-B, B-C, và C-A đều là <em>peer</em>. Không ai trong số họ gửi tiền cho nhau, vì vậy chúng ta không có một mối quan hệ kinh doanh được định nghĩa sai.</p>
<h2 id="hệ-thống-phân-cấp-provider-và-các-as-cấp-1-tier-1"><a class="header" href="#hệ-thống-phân-cấp-provider-và-các-as-cấp-1-tier-1">Hệ thống phân cấp Provider và các AS Cấp 1 (Tier 1)</a></h2>
<p>Một hệ quả của việc đồ thị là phi chu trình là chúng ta có thể hình thành một hệ thống phân cấp các <em>provider</em>. Nói cách khác, chúng ta có thể sắp xếp các nút sao cho tất cả các mũi tên đều chỉ xuống dưới. Các <em>stub AS</em> ở dưới cùng, các <em>provider</em> ở trên cùng. Dịch vụ chảy từ các nút cao hơn xuống các nút thấp hơn. Các nút thấp hơn trả tiền lên cho các nút cao hơn.</p>
<p>Ở đỉnh cao nhất của hệ thống phân cấp là các <em><strong>Tier 1 autonomous systems</strong></em> (các hệ thống tự trị Cấp 1), không có <em>provider</em> nào (không có cạnh đi vào). Mọi <em>Tier 1 AS</em> đều có mối quan hệ <em>peer</em> với mọi <em>Tier 1 AS</em> khác.</p>
<img width="600px" src="routing/../assets/routing/2-139-tier1.png">
<p>Một hệ quả của hệ thống phân cấp này là: Mọi <em>AS</em> không phải <em>Tier 1</em> đều có ít nhất một <em>provider</em> (cạnh đi vào). Điều này hợp lý trong thực tế, vì bạn phải trả tiền cho ai đó để cung cấp kết nối cho bạn.</p>
<p>Trong hệ thống phân cấp này, bắt đầu từ bất kỳ <em>AS</em> nào và đi theo chuỗi các <em>provider</em> lên trên, luôn luôn dẫn đến một <em>Tier 1 AS</em>. Điều này cũng hợp lý trong thực tế. Việc tất cả các <em>Tier 1 AS</em> đều có quan hệ <em>peer</em> với nhau là lý do tại sao toàn bộ Internet được kết nối (thay vì, chẳng hạn, hai đồ thị con không kết nối đại diện cho hai Internet riêng biệt nơi bạn chỉ có thể nói chuyện với các máy chủ trong nửa của mình). Để đảm bảo có một đường dẫn đến mọi <em>AS</em> khác trong đồ thị, mọi <em>AS</em> phải có một đường dẫn đi lên mà cuối cùng sẽ dẫn đến một <em>Tier 1 AS</em>.</p>
<p>TODO-diagram</p>
<p>Một số ví dụ thực tế về các <em>Tier 1 AS</em> là AT&amp;T và Verizon (trụ sở tại Mỹ), France Telecom và Telecom Italia (trụ sở tại châu Âu), và NTT Communications (trụ sở tại Nhật Bản). Có khoảng 20 <em>AS</em> là <em>Tier 1</em> hoặc gần như <em>Tier 1</em> trong thực tế. Các <em>Tier 1 AS</em> này thường sở hữu cơ sở hạ tầng trải dài trên nhiều lục địa (ví dụ: cáp ngầm dưới biển).</p>
<p>Cấu trúc phân cấp của <em>AS graph</em> được định nghĩa bởi các động cơ kinh doanh và chính trị trong thế giới thực. Về lý thuyết, có thể vẽ một <em>AS graph</em> trông giống như một cây, với một <em>Tier 1 AS</em> duy nhất ở gốc cung cấp dịch vụ cho mọi <em>stub AS</em>. Tuy nhiên, điều này có nghĩa là một thực thể duy nhất trong đời thực kiểm soát toàn bộ quyền truy cập Internet của thế giới, điều này có thể không mong muốn vì lý do chính trị.</p>
<h2 id="Định-tuyến-dựa-trên-chính-sách"><a class="header" href="#Định-tuyến-dựa-trên-chính-sách">Định tuyến Dựa trên Chính sách</a></h2>
<p>Hãy nhớ lại rằng trong <em>intra-domain routing</em>, mục tiêu của chúng ta là tìm các đường dẫn hợp lệ (không có vòng lặp và không có ngõ cụt) và tốt (chi phí thấp nhất).</p>
<p>Trong <em>inter-domain routing</em>, chúng ta vẫn muốn các đường dẫn phải hợp lệ. Tuy nhiên, không giống như trong <em>intra-domain routing</em>, nơi không có gì đặc biệt về một <em>router</em> này so với <em>router</em> khác, mỗi <em>autonomous system</em> có các mục tiêu kinh doanh và mối quan hệ riêng với các <em>AS</em> khác (ví dụ: <em>customer</em>, <em>provider</em>, <em>peer</em>). Do đó, chúng ta sẽ cần định nghĩa lại &quot;tốt&quot; để phản ánh các mục tiêu và sở thích kinh doanh trong thế giới thực của các <em>AS</em>.</p>
<p>Để cho phép mỗi <em>AS</em> vận chuyển lưu lượng theo cách tương thích với các mục tiêu thực tế của mình, giao thức định tuyến của chúng ta sẽ cho phép mỗi <em>AS</em> đặt <em>policy</em> (chính sách) riêng. Sau đó, các đường dẫn được tính toán bởi giao thức phải tôn trọng đúng <em>policy</em> của mỗi <em>AS</em>.</p>
<p>Về lý thuyết, các <em>AS</em> có thể đặt bất kỳ loại <em>policy</em> nào mà họ thích, mặc dù các quy ước tiêu chuẩn vẫn tồn tại (chúng ta sẽ thảo luận tiếp theo). Dưới đây là một số ví dụ về các <em>policy</em> mà một <em>AS</em> có thể đặt:</p>
<ul>
<li>&quot;Tôi không muốn vận chuyển lưu lượng của AS#2046 qua mạng của mình.&quot; (Xác định cách tôi sẽ xử lý lưu lượng từ các <em>AS</em> khác.)</li>
<li>&quot;Tôi ưu tiên lưu lượng của mình được vận chuyển bởi AS#10 thay vì AS#4.&quot; (Xác định cách các <em>AS</em> khác nên xử lý lưu lượng của tôi.)</li>
<li>&quot;Đừng gửi lưu lượng của tôi qua AS#54 trừ khi thực sự cần thiết.&quot;</li>
<li>&quot;Tôi ưu tiên AS#12 vào các ngày trong tuần và AS#13 vào cuối tuần.&quot; (<em>Policy</em> có thể thay đổi theo thời gian!)</li>
</ul>
<p>Giao thức định tuyến không quan tâm tại sao <em>AS</em> có những sở thích này. Có thể tôi từ chối vận chuyển lưu lượng từ AS#2046 vì đó là một công ty đối thủ, nhưng giao thức không cần biết điều đó.</p>
<p>Các giao thức định tuyến chi phí thấp nhất của chúng ta cho đến nay không có cách nào hỗ trợ các <em>policy</em> này. Chi phí thấp nhất là một bài toán tối ưu hóa toàn cục, nơi mọi <em>router</em> đều cố gắng giải quyết cùng một vấn đề. Ngược lại, trong <em>Policy-Based Routing</em> (Định tuyến dựa trên chính sách), mỗi <em>AS</em> chỉ quan tâm đến <em>policy</em> của riêng mình, và không có một bài toán toàn cục nào mà mọi người cùng hợp tác để giải quyết.</p>
<h2 id="các-quy-tắc-gao-rexford-cho-chính-sách-Định-tuyến"><a class="header" href="#các-quy-tắc-gao-rexford-cho-chính-sách-Định-tuyến">Các quy tắc Gao-Rexford cho Chính sách Định tuyến</a></h2>
<p>Mặc dù giao thức định tuyến của chúng ta cho phép mỗi <em>AS</em> đặt bất kỳ <em>policy</em> tùy ý nào họ thích, trong thực tế, hầu hết các <em>AS</em> đặt <em>policy</em> của họ theo một số quy ước tiêu chuẩn, được gọi là <em><strong>Gao-Rexford rules</strong></em> (các quy tắc Gao-Rexford). Các quy ước này dựa trên giả định rằng các tổ chức trong thế giới thực thích kiếm tiền và không thích mất tiền.</p>
<p>Có hai quy tắc lớn mà các <em>AS</em> thường tuân theo. Đầu tiên, khi một <em>AS</em> có nhiều lựa chọn tuyến đường, <em>AS</em> đó ưu tiên chuyển tiếp gói tin đến chặng kế tiếp có lợi nhuận cao nhất. Cụ thể, <em>AS</em> ưu tiên một tuyến đường với chặng kế tiếp là một <em>customer</em>. Nếu không có tuyến đường nào như vậy, <em>AS</em> ưu tiên một tuyến đường với chặng kế tiếp là một <em>peer</em>. <em>AS</em> sẽ chỉ chọn một tuyến đường với chặng kế tiếp là một <em>provider</em> nếu buộc phải làm vậy, vì không có tuyến đường nào tốt hơn.</p>
<img width="900px" src="routing/../assets/routing/2-140-gaorexford1.png">
<p>Nguyên tắc này quyết định các tuyến đường mà <em>AS</em> lựa chọn. Bạn có thể coi nguyên tắc này như một phiên bản dựa trên sở thích của việc lựa chọn đường đi trong giao thức <em>distance-vector</em>. Thay vì chọn tuyến đường ngắn nhất mà tôi biết, tôi chọn tuyến đường mà chặng kế tiếp giúp tôi kiếm tiền (<em>customer</em> là tốt nhất), hoặc tiết kiệm tiền cho tôi (nếu không có <em>customer</em> thì là <em>peer</em>), và tránh mất tiền (nếu không có <em>customer</em> hoặc <em>peer</em> thì là <em>provider</em>).</p>
<img width="900px" src="routing/../assets/routing/2-141-gaorexford2.png">
<p>Thứ hai, các <em>AS</em> chỉ vận chuyển lưu lượng nếu họ được trả tiền cho việc đó. Không có động cơ nào để các <em>AS</em> làm việc miễn phí. Nguyên tắc này quyết định các đường dẫn mà <em>AS</em> sẵn sàng tham gia. Bạn có thể coi nguyên tắc này như một phiên bản hạn chế hơn của việc thông báo đường đi trong giao thức <em>distance-vector</em>. Thay vì quảng bá một tuyến đường đến mọi neighbour, cho phép bất kỳ ai chuyển tiếp gói tin qua tôi, tôi chỉ quảng bá các tuyến đường mà tôi được trả tiền để chuyển tiếp gói tin.</p>
<p>Một hệ quả của nguyên tắc thứ hai này là: Với tư cách là một <em>AS</em>, lưu lượng tôi vận chuyển phải đến từ một <em>customer</em>, hoặc đi đến một <em>customer</em>. Nói cách khác, đối với bất kỳ tuyến đường nào đi qua tôi, một trong những neighbour của tôi phải là một <em>customer</em>.</p>
<p>Hãy xem xét tất cả các trường hợp cụ thể.</p>
<p>Các tuyến đường mà cả hai neighbour của tôi đều là <em>customer</em> là tốt, bởi vì tôi đang được hai <em>customer</em> trả tiền để chuyển tiếp gói tin.</p>
<img width="900px" src="routing/../assets/routing/2-142-gaorexford3.png">
<p>Tương tự, các tuyến đường mà một trong những neighbour của tôi là <em>customer</em> và một neighbour là <em>peer</em> là tốt, bởi vì mặc dù <em>peer</em> không trả tiền cho tôi, nhưng <em>customer</em> thì có.</p>
<img width="900px" src="routing/../assets/routing/2-143-gaorexford4.png">
<p>Các tuyến đường mà một trong những neighbour của tôi là <em>customer</em>, và neighbour còn lại là <em>provider</em> là tốt. Thoạt nhìn, có vẻ như đường đi này không tốt, bởi vì <em>customer</em> đang trả tiền cho tôi, và sau đó tôi lại trả tiền cho <em>provider</em>. Liệu có khả năng tôi không kiếm được đồng nào, hoặc thậm chí lỗ vốn từ giao dịch này không? Điều đó có thể đúng, nhưng nếu chúng ta không tham gia vào các tuyến đường này, chúng ta sẽ trở thành một <em>AS</em> vô dụng không có <em>customer</em>. Công việc của một <em>AS</em> là cung cấp kết nối cho người dùng của mình, và việc tham gia vào các tuyến đường <em>customer-AS-provider</em> này sẽ mở ra nhiều tuyến đường hơn đến phần còn lại của Internet.</p>
<img width="900px" src="routing/../assets/routing/2-144-gaorexford5.png">
<p>Các tuyến đường mà cả hai neighbour của tôi đều là <em>peer</em> là không tốt, bởi vì không bên nào trả tiền cho tôi để chuyển tiếp gói tin.</p>
<p>Nói chung, các <em>peer</em> không cung cấp dịch vụ chuyển tiếp giữa các <em>peer</em> khác. Xét theo cấu trúc phân cấp, một đường dẫn không nên đi ngang ở một cấp độ nhất định qua nhiều chặng.</p>
<img width="900px" src="routing/../assets/routing/2-145-gaorexford6.png">
<p>Các tuyến đường mà một trong những neighbour của tôi là <em>peer</em> và neighbour còn lại là <em>provider</em> cũng không tốt, bởi vì một lần nữa, không bên nào trả tiền cho tôi để chuyển tiếp gói tin.</p>
<p>Nói chung, nếu một <em>AS</em> có một liên kết <em>peer</em>, liên kết đó sẽ chỉ vận chuyển lưu lượng đến/từ các <em>customer</em> của chính nó. Nói cách khác, khi các gói tin đến B qua liên kết <em>peer</em> đó, lựa chọn có lợi nhuận duy nhất của B là chuyển tiếp gói tin đến một <em>customer</em> (không phải <em>provider</em>, và không phải một <em>peer</em> khác). Tương tự, các gói tin từ <em>customer</em> có thể được chuyển tiếp qua liên kết <em>peer</em> (<em>customer</em> trả tiền), nhưng các gói tin từ <em>provider</em> và <em>peer</em> không thể được chuyển tiếp qua liên kết <em>peer</em> (không ai trả tiền).</p>
<img width="900px" src="routing/../assets/routing/2-146-gaorexford7.png">
<p>Tương tự, các tuyến đường mà cả hai neighbour của tôi đều là <em>provider</em> là không tốt, bởi vì tôi phải trả tiền cho cả hai bên để chuyển tiếp gói tin, và không ai trả tiền cho tôi để làm việc này.</p>
<img width="900px" src="routing/../assets/routing/2-147-gaorexford8.png">
<h2 id="ví-dụ-về-các-quy-tắc-gao-rexford"><a class="header" href="#ví-dụ-về-các-quy-tắc-gao-rexford">Ví dụ về các quy tắc Gao-Rexford</a></h2>
<p><em>Policy</em> để chọn tuyến đường (<em>customer</em> tốt nhất, <em>provider</em> tệ nhất), và <em>policy</em> để thông báo tuyến đường (chỉ thông báo và tham gia vào các tuyến đường mà một trong những neighbour của tôi là <em>customer</em>) sẽ được sử dụng trong giao thức đã sửa đổi của chúng ta để tính toán các tuyến đường tôn trọng <em>policy</em> của mỗi <em>AS</em>. Chúng ta chưa nói về cách tính toán tuyến đường, nhưng với một tuyến đường cho trước, chúng ta có thể kiểm tra xem nó có thỏa mãn hai <em>policy</em> này không.</p>
<img width="300px" src="routing/../assets/routing/2-148-gaorexford9.png">
<p>Trong ví dụ này, giả sử một máy tính trong D (một <em>stub AS</em>) muốn nói chuyện với một máy tính trong E (một <em>stub AS</em> khác). D và E có thể muốn trao đổi tin nhắn (hãy nhớ, mũi tên đại diện cho mối quan hệ <em>customer/provider</em>, không phải hướng của gói tin).</p>
<p>Một đường dẫn khả dĩ cho lưu lượng là D, B, A, C, E (và ngược lại cho các tin nhắn từ E đến D).</p>
<p>Ai đang trả tiền cho ai trong đường dẫn này? Vì lưu lượng đang được gửi dọc theo liên kết D-B, <em>customer</em> (D) phải trả tiền cho <em>provider</em> (B). Tương tự, E phải trả tiền cho C, và cả B và C đều phải trả tiền cho A.</p>
<p>Liệu các <em>transit AS</em> A, B, và C có đồng ý thông báo và tham gia vào tuyến đường này không? Hãy kiểm tra từng neighbour của chúng.</p>
<p>Các neighbour của A dọc theo đường dẫn này đều là <em>customer</em>, vì vậy A đang kiếm tiền và cho rằng đường dẫn này tốt.</p>
<p>Các neighbour của B là một <em>customer</em> (D) và một <em>provider</em> (A). B đang kiếm tiền từ <em>customer</em> (D), và cho rằng đường dẫn này tốt. (Hãy nhớ rằng, các đường dẫn có một neighbour là <em>customer</em> và một neighbour là <em>provider</em> là tốt, ngay cả khi <em>AS</em> có lợi nhuận ròng bằng 0, bởi vì chúng cho phép kết nối rộng hơn.)</p>
<p>Tương tự, C có ít nhất một neighbour là <em>customer</em> (E), vì vậy nó cũng cho rằng tuyến đường này tốt.</p>
<img width="600px" src="routing/../assets/routing/2-149-gaorexford10.png">
<p>Thay vì cả B và C đều trả tiền cho A, có lẽ họ chọn thiết lập một mối quan hệ <em>peer</em>, điều này làm thay đổi <em>AS graph</em>:</p>
<img width="300px" src="routing/../assets/routing/2-150-gaorexford11.png">
<p>Bây giờ, một đường dẫn khả dĩ khác cho lưu lượng là D, B, C, E. Lúc này, D vẫn cần trả tiền cho B, và E vẫn phải trả tiền cho C. Tuy nhiên, B và C không còn cần trả tiền cho A, và họ không trả tiền cho nhau (mối quan hệ <em>peer</em>).</p>
<p>Một lần nữa, chúng ta có thể kiểm tra xem các <em>transit AS</em> trên đường dẫn này, cụ thể là B và C, có đồng ý thông báo và tham gia vào tuyến đường này không. Các neighbour của B là một <em>customer</em> (D) và một <em>provider</em> (C). B đang kiếm tiền từ <em>customer</em> (D), và cho rằng đường dẫn này tốt. Tương tự, C có ít nhất một neighbour là <em>customer</em> (E), vì vậy C cũng cho rằng tuyến đường này tốt.</p>
<img width="600px" src="routing/../assets/routing/2-151-gaorexford12.png">
<p>Chúng ta vừa lý giải rằng có hai đường dẫn tốt có thể được sử dụng để gửi tin nhắn từ D đến E. Bây giờ, B phải quyết định chuyển tiếp qua đường dẫn B-A-C-E, hoặc đường dẫn B-C-E. B nên chọn đường dẫn nào? Theo nguyên tắc đầu tiên của chúng ta, B ưu tiên đường dẫn có lợi nhuận cao nhất (không phải đường dẫn ngắn nhất). Trong B-A-C-E, chặng kế tiếp là <em>provider</em> A (người mà chúng ta phải trả tiền), và trong B-C-E, chặng kế tiếp là <em>peer</em> C (không cần thanh toán). Do đó, B sẽ chọn đường dẫn qua C, cho ra đường dẫn cuối cùng là D-B-C-E.</p>
<p>Lưu ý: Dường như B và C đang tiết kiệm tiền với mối quan hệ <em>peer</em> bổ sung, vậy tại sao không phải mọi <em>AS</em> đều thiết lập mối quan hệ <em>peer</em> để tiết kiệm tiền? Trong thực tế, việc thiết lập một liên kết cũng đòi hỏi phải lắp đặt cơ sở hạ tầng vật lý (ví dụ: đặt cáp ngầm), vì vậy có một sự đánh đổi về chi phí khi thiết lập các mối quan hệ mới giữa các <em>AS</em>, để đổi lấy các tuyến đường rẻ hơn.</p>
<h2 id="các-tuyến-đường-không-có-dạng-thung-lũng-valley-free"><a class="header" href="#các-tuyến-đường-không-có-dạng-thung-lũng-valley-free">Các tuyến đường không có dạng Thung lũng (Valley-Free)</a></h2>
<p>Nói chung, các đường dẫn trong <em>AS graph</em> luôn <em><strong>valley-free</strong></em> (không có dạng thung lũng).</p>
<p>Xét theo cấu trúc phân cấp, nếu một đường dẫn bao gồm một chặng đi ngang qua một liên kết <em>peer</em>, chặng kế tiếp ngay lập tức cần phải đi xuống dốc đến một <em>customer</em>. Chặng kế tiếp không thể lại đi ngang (cả hai neighbour đều là <em>peer</em>), và chặng kế tiếp không thể đi lên dốc đến một <em>provider</em> (neighbour là <em>peer</em> và <em>provider</em>).</p>
<p>Xét theo cấu trúc phân cấp, nếu một đường dẫn bao gồm một chặng đi xuống dốc từ <em>provider</em> đến <em>customer</em>, chặng kế tiếp ngay lập tức phải tiếp tục đi xuống dốc đến một trong những <em>customer</em> của nó. Chặng kế tiếp không thể lại đi ngang (các neighbour là <em>provider</em> và <em>peer</em>), và chặng kế tiếp không thể đi lên dốc (cả hai neighbour đều là <em>provider</em>).</p>
<p>Nếu một liên kết đi xuống phải được theo sau bởi một liên kết đi xuống khác, thì chúng ta có thể kết luận rằng ngay khi bạn có một liên kết đi xuống trong một đường dẫn, tất cả các liên kết tiếp theo cũng phải đi xuống. Một thung lũng là một đường dẫn đi xuống, và sau đó quay đầu để bắt đầu đi lên. Các đường dẫn không thể chứa thung lũng, bởi vì một khi bạn bắt đầu đi xuống, bạn phải tiếp tục đi xuống cho đến tận đích.</p>
<img width="900px" src="routing/../assets/routing/2-152-singlepeak.png">
<p>Tóm lại, đây là các quy tắc chúng ta đã rút ra (mặc dù tốt hơn là nên hiểu chúng dưới góc độ tôn trọng sở thích về tiền bạc của <em>AS</em>, thay vì học thuộc lòng):</p>
<ul>
<li>Một liên kết đi lên có thể được theo sau bởi một liên kết <em>peer</em>, một liên kết đi xuống, hoặc một liên kết đi lên khác. (Nếu chặng trước trả tiền cho tôi, tôi sẵn lòng chuyển tiếp gói tin cho bất kỳ ai.)</li>
<li>Một liên kết <em>peer</em> chỉ có thể được theo sau bởi một liên kết đi xuống. (Nếu chặng trước không trả tiền cho tôi, tôi cần chặng kế tiếp là một <em>customer</em> trả tiền cho tôi.)</li>
<li>Một liên kết đi xuống chỉ có thể được theo sau bởi một liên kết đi xuống. (Nếu chặng trước là một <em>provider</em> mà tôi đang trả tiền, tôi cần chặng kế tiếp là một <em>customer</em> trả tiền cho tôi.)</li>
</ul>
<p>Những quy tắc này có nghĩa là các tuyến đường luôn <em>valley-free</em> và có một đỉnh duy nhất. Một tuyến đường có thể bắt đầu bằng 0 hoặc nhiều liên kết đi lên. Cuối cùng, nó sẽ đạt đến một đỉnh duy nhất, và đi qua 0 hoặc 1 liên kết <em>peer</em>. Sau đó, tuyến đường phải bắt đầu đi xuống cho đến tận đích (không còn di chuyển ngang hoặc lên nữa).</p>
<p>Các đường dẫn không thể có thung lũng (đi xuống rồi quay đầu đi lên). Ngoài ra, các đường dẫn không thể có các bước di chuyển ngang ở bất kỳ đâu ngoại trừ đỉnh. Ngay khi bạn thực hiện một bước di chuyển ngang, bạn phải quay đầu và đi xuống. Bạn không thể tiếp tục di chuyển ngang hoặc đi lên.</p>
<h2 id="các-as-muốn-quyền-tự-chủ-và-quyền-riêng-tư"><a class="header" href="#các-as-muốn-quyền-tự-chủ-và-quyền-riêng-tư">Các AS muốn Quyền tự chủ và Quyền riêng tư</a></h2>
<p>Khi thiết kế một giao thức để tính toán các tuyến đường liên miền, giao thức của chúng ta nên tôn trọng <em>autonomy</em> (quyền tự chủ) và <em>privacy</em> (quyền riêng tư) của mỗi <em>AS</em>.</p>
<p>Các <em>AS</em> muốn <em><strong>autonomy</strong></em>, sự tự do lựa chọn các <em>policy</em> tùy ý của riêng mình, mà không cần phối hợp với các <em>AS</em> khác, hoặc lo lắng về những <em>policy</em> mà giao thức cho phép. Trong thực tế, các <em>policy</em> thường tuân theo các nguyên tắc dựa trên tiền bạc mà chúng ta đã mô tả, nhưng giao thức không nên buộc <em>AS</em> phải tuân theo bất kỳ <em>policy</em> cụ thể nào.</p>
<p>Các <em>AS</em> cũng muốn <em><strong>privacy</strong></em>. Các <em>AS</em> không muốn phải nói rõ cho những người khác trong mạng về sở thích và <em>policy</em> của họ. Ví dụ, một <em>AS</em> không nên cần phải công khai cho mọi người biết về việc các neighbour của nó là <em>peer</em>, <em>customer</em>, hay <em>provider</em>. Điều này phản ánh các chiến lược kinh doanh trong thế giới thực. Với tư cách là một công ty, bạn có thể không muốn tiết lộ thông tin về <em>customer</em> và <em>provider</em> của mình cho các đối thủ.</p>
<p>Lưu ý rằng định nghĩa của chúng ta về <em>privacy</em> nói rằng các <em>AS</em> không cần phải tiết lộ <em>một cách rõ ràng</em> các <em>policy</em> của họ. Trong thực tế, các <em>AS</em> vẫn cần phối hợp với phần còn lại của mạng để thống nhất về các đường dẫn qua mạng, vì vậy một lượng thông tin bị rò rỉ là không thể tránh khỏi. Các kỹ thuật đảo ngược (reverse-engineering) tồn tại để theo dõi các tuyến đường mà gói tin đang đi qua mạng.</p>
<p>Ví dụ, việc những người khác trên mạng có thể khám phá ra một gói tin đang đi theo tuyến đường nào là không thể tránh khỏi. Tuy nhiên, giao thức của chúng ta không nên buộc một <em>AS</em> phải nói với thế giới rằng &quot;Tôi thích đường dẫn này hơn đường dẫn kia.&quot; Chúng ta cũng không nên buộc một <em>AS</em> phải tiết lộ ai là <em>provider</em>, <em>peer</em>, và <em>customer</em> của họ.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="border-gateway-protocol-bgp"><a class="header" href="#border-gateway-protocol-bgp">Border Gateway Protocol (BGP)</a></h1>
<h2 id="lược-sử-bgp"><a class="header" href="#lược-sử-bgp">Lược sử BGP</a></h2>
<p>Các <em>routing protocol</em> <em>least-cost routing</em> (định tuyến chi phí thấp nhất) có liên quan chặt chẽ đến bài toán đường đi ngắn nhất trong lý thuyết đồ thị, vốn đã được nghiên cứu trong khoa học máy tính ngay cả trước khi Internet tồn tại. Thuật toán của Dijkstra ra đời năm 1956, và thuật toán Bellman-Ford ra đời năm 1958. Khi phát triển các <em>routing protocol</em> sơ khai, các nhà thiết kế có thể áp dụng các ý tưởng từ những thuật toán này.</p>
<p>Trong những ngày đầu, Internet là một dự án do chính phủ tài trợ, nơi mạng lưới được kiểm soát tập trung bởi Bộ Quốc phòng Hoa Kỳ. Khái niệm về <em>AS</em> (hệ tự trị) chưa tồn tại, và các thuật toán <em>least-cost routing</em> có thể được mở rộng quy mô để phù hợp với kích thước nhỏ của Internet thời kỳ đầu. Dần dần, khi Internet phát triển, chính phủ đã chuyển giao quyền kiểm soát cho các thực thể thương mại khác nhau, những người đã phải phát triển các giao thức <em>inter-domain routing</em> (định tuyến liên miền) một cách nhanh chóng.</p>
<p>Không giống như các <em>routing protocol</em> <em>least-cost routing</em> sơ khai, khái niệm về các <em>AS</em> có <em>policy</em> (chính sách) riêng của mình không có tiền lệ trong khoa học máy tính. Các ý tưởng đằng sau các giao thức <em>inter-domain routing</em> phải được phát triển một cách nhanh chóng để đáp ứng nhu cầu của các công ty Internet mới này.</p>
<p><em>BGP</em> được tạo ra vào những năm 1989-1995, và quá trình phát triển đặc thù của nó có nghĩa là giao thức này không hoàn hảo. Nếu chúng ta có thể viết lại giao thức từ đầu ngày hôm nay, kết quả có thể sẽ khác. Tuy nhiên, giao thức này đã chứng tỏ được hiệu quả và khả năng phục hồi, và vẫn là <em>routing protocol</em> liên miền được sử dụng cho đến ngày nay. (Hãy nhớ rằng, mọi người đều phải đồng ý sử dụng cùng một <em>routing protocol</em> liên miền, vì vậy chỉ có một.)</p>
<h2 id="bgp-dựa-trên-distance-vector"><a class="header" href="#bgp-dựa-trên-distance-vector">BGP dựa trên Distance-Vector</a></h2>
<p>Hãy nhớ lại rằng chúng ta đã thấy hai lớp thuật toán định tuyến nội miền: thuật toán <em>distance-vector</em> (vector khoảng cách) và thuật toán <em>link-state</em> (trạng thái liên kết). Khi thiết kế <em>BGP</em>, lớp thuật toán nào sẽ là điểm khởi đầu tốt hơn cho thiết kế của chúng ta?</p>
<p>Hãy nhớ rằng trong <em>BGP</em>, chúng ta cần tôn trọng quyền riêng tư của từng <em>AS</em>. Nếu chúng ta sử dụng một giao thức <em>link-state</em>, thì mọi <em>AS</em> phải thông báo cho toàn bộ mạng về các <em>policy</em> của mình, để mọi người có đầy đủ kiến thức để tự tính toán các tuyến đường.</p>
<p>Ngoài ra, trong <em>BGP</em>, chúng ta cần tôn trọng quyền tự chủ và cho phép mỗi <em>AS</em> đưa ra quyết định <em>policy</em> của riêng mình. Tuy nhiên, một giao thức <em>link-state</em> yêu cầu mọi người phải tính toán các tuyến đường theo một cách nhất quán nào đó (ví dụ: mọi người đồng ý sử dụng các đường đi có chi phí thấp nhất).</p>
<p>Thuật toán <em>link-state</em> không tôn trọng quyền riêng tư hay quyền tự chủ của các <em>AS</em>, vì vậy <em>link-state</em> sẽ là một lựa chọn tồi để thiết kế <em>BGP</em>. Ngược lại, <em>distance-vector</em> sẽ cho phép mỗi <em>AS</em> riêng lẻ đưa ra quyết định của riêng mình về việc chấp nhận/từ chối tuyến đường nào, và quảng bá tuyến đường nào. Ngoài ra, vì <em>distance-vector</em> không phải là một giao thức toàn cục, mỗi <em>AS</em> không cần biết về <em>policy</em> của mọi người khác để tính toán các tuyến đường hợp lệ.</p>
<p>Nhiều ý tưởng cốt lõi trong các giao thức <em>distance-vector</em> vẫn sẽ được áp dụng trong <em>BGP</em>. Các thông điệp quảng bá mà chúng ta gửi và nhận vẫn sẽ dành riêng cho một đích. Giống như trong các phần trước, chúng ta sẽ nghĩ về các quảng bá và tuyến đường cho một đích duy nhất, nhưng hãy biết rằng giao thức đang được chạy cho nhiều đích đồng thời.</p>
<p>Trong cả giao thức <em>distance-vector</em> và <em>BGP</em>, mỗi <em>AS</em> tính toán các tuyến đường chỉ sử dụng thông tin từ các quảng bá mà nó nhận được, mà không thấy được bức tranh toàn cục về cấu trúc liên kết mạng. Ngoài ra, trong cả hai loại giao thức, <em>AS</em> sẽ gửi và nhận các quảng bá vô thời hạn, cho đến khi mọi người đã <em>convergence</em> (hội tụ) trên một tập hợp các tuyến đường.</p>
<p><em>BGP</em> tuân theo cùng một ý tưởng cốt lõi như các giao thức <em>distance-vector</em>, nhưng có một chút thay đổi về thuật ngữ. Thay vì nói rằng mỗi <em>AS</em> thông báo hoặc quảng bá các tuyến đường, chúng ta nói rằng <em>AS</em> đang <strong><em>exporting</em> (xuất)</strong> các tuyến đường. Sau đó, mỗi <em>AS</em> lắng nghe các quảng bá và chọn tuyến đường ưa thích của mình, chúng ta sẽ gọi là <strong><em>importing</em> (nhập)</strong> các tuyến đường.</p>
<p><em>Distance-vector</em> là một điểm khởi đầu tốt, nhưng còn thiếu gì?</p>
<p>Các giao thức <em>distance-vector</em> được thiết kế để tìm các tuyến đường <em>least-cost</em>, nhưng trong <em>BGP</em>, chúng ta muốn các tuyến đường được quyết định dựa trên các <em>policy</em> riêng của mỗi <em>AS</em>.</p>
<h2 id="nhập-và-xuất-dựa-trên-chính-sách"><a class="header" href="#nhập-và-xuất-dựa-trên-chính-sách">Nhập và Xuất dựa trên Chính sách</a></h2>
<p>Ở cấp độ cao, để hỗ trợ các <em>policy</em>, chúng ta sẽ thay đổi các quy tắc để <em>importing</em> và <em>exporting</em> các tuyến đường. Mỗi <em>AS</em> sẽ chỉ <em>export</em> (quảng bá) các tuyến đường mà <em>AS</em> đó thích (theo <em>policy</em> của nó). Ngoài ra, khi <em>importing</em> (lựa chọn) các tuyến đường, <em>AS</em> sẽ chọn tuyến đường tốt nhất theo <em>policy</em>, chứ không phải khoảng cách.</p>
<p>Khi một <em>AS</em> nhận được nhiều quảng bá cho cùng một đích, thay vì chọn tuyến đường ngắn nhất, <em>AS</em> giờ đây sẽ chọn (<em>import</em>) một tuyến đường dựa trên <em>policy</em>.</p>
<img width="500px" src="routing/../assets/routing/2-153-import-export.png">
<p>Hãy nhớ rằng các quảng bá lan truyền ra ngoài từ đích, và các thông điệp được chuyển tiếp đến gần đích hơn (hướng ngược lại với các quảng bá). Quyết định <em>import</em> quyết định nơi một <em>AS</em> sẽ gửi lưu lượng đi ra ngoài của mình. Ví dụ, nếu S nghe các quảng bá từ A, B, và C về cùng một đích, quyết định <em>import</em> của S (A hoặc B hoặc C) sẽ xác định nơi các <em>packet</em> cho đích đó sẽ được chuyển tiếp.</p>
<img width="900px" src="routing/../assets/routing/2-154-import-policy.png">
<p>Trong giao thức <em>distance-vector</em>, khi tôi nhận được một thông báo và cài đặt một tuyến đường mới, tôi luôn thông báo tuyến đường mới này cho tất cả các neighbour của mình.</p>
<p>Bây giờ các <em>AS</em> có <em>policy</em> riêng, chúng có thể chọn có muốn tham gia vào một tuyến đường hay không. Nếu một <em>AS</em> có một tuyến đường mà nó có thể không thích, nó có thể chọn không <em>export</em> tuyến đường đó cho một số neighbour nhất định.</p>
<p>Ví dụ, giả sử <em>policy</em> của tôi là tôi không muốn mang lưu lượng của C. Điều này có thể là do lý do tiền tệ, hoặc có thể là một quyết định <em>policy</em> khác của tôi. Khi tôi chấp nhận một quảng bá và cài đặt một tuyến đường, sẽ không sao nếu tôi không quảng bá tuyến đường đó cho C.</p>
<p>Một lần nữa, hãy nhớ rằng dữ liệu chảy theo hướng ngược lại với các quảng bá. Quyết định <em>export</em> quyết định lưu lượng đến mà một <em>AS</em> sẵn sàng mang theo. Nếu tôi <em>export</em> một tuyến đường, tôi đang đồng ý tham gia vào tuyến đường này và để người khác chuyển tiếp các <em>packet</em> đến tôi dọc theo tuyến đường này.</p>
<p>Một hệ quả của quy tắc này là, ngay cả khi đồ thị cơ bản được kết nối (tồn tại một đường đi giữa hai nút bất kỳ), không có gì đảm bảo rằng mọi <em>AS</em> đều có thể đến được mọi <em>AS</em> khác. Trong thực tế, chúng ta sẽ có thể đảm bảo <em>reachability</em> (khả năng kết nối) bằng cách thiết lập một số quy ước về <em>policy</em> của các <em>AS</em> và cấu trúc của đồ thị <em>AS</em>.</p>
<h2 id="triển-khai-các-quy-tắc-gao-rexford"><a class="header" href="#triển-khai-các-quy-tắc-gao-rexford">Triển khai các quy tắc Gao-Rexford</a></h2>
<p>Nói chung, <em>BGP</em> hỗ trợ các <em>policy</em> tùy ý, nhưng các <em>policy</em> tùy ý không cho chúng ta bất kỳ đảm bảo nào rằng Internet được kết nối đầy đủ (<em>packet</em> có thể đi từ bất kỳ nguồn nào đến bất kỳ đích nào).</p>
<p>Hãy nhớ lại rằng <strong><em>Gao-Rexford rules</em> (các quy tắc Gao-Rexford)</strong> thực thi một bộ <em>policy</em> hạn chế hơn, dựa trên các <em>policy</em> <em>import</em> và <em>export</em> phổ biến dựa trên tiền tệ. Không ai bắt buộc một <em>AS</em> phải tuân theo các quy tắc này. Tuy nhiên, nếu các <em>AS</em> đồng ý tuân theo các quy tắc này, chúng ta có thể đưa ra các giả định mạnh mẽ hơn về khả năng kết nối Internet.</p>
<p>Lược sử ngắn gọn: Các quy tắc được đặt theo tên của Lixin Gao và Jennifer Rexford tại AT&amp;T vào những năm 1990. Thời đó, mỗi <em>AS</em> tự đặt ra các <em>policy</em> của riêng mình một cách nhanh chóng. Gao và Rexford đã khảo sát các <em>AS</em> về <em>policy</em> của họ để đưa ra các quy tắc này, và sử dụng chúng để chứng minh các đảm bảo về Internet.</p>
<p>Khi <em>importing</em> các tuyến đường, <em>Gao-Rexford rules</em> nói rằng <em>AS</em> ưu tiên <em>import</em> một tuyến đường được quảng bá bởi một <em>customer</em> (khách hàng), hơn một tuyến đường được quảng bá bởi một <em>peer</em> (đối tác ngang hàng), hơn một tuyến đường được quảng bá bởi một <em>provider</em> (nhà cung cấp).</p>
<img width="900px" src="routing/../assets/routing/2-154-import-policy.png">
<p>Trong thực tế, các <em>AS</em> cũng triển khai thêm các quy tắc phá vỡ thế cân bằng ngoài <em>Gao-Rexford rules</em>. Ví dụ, nếu tôi nhận được quảng bá từ hai <em>customer</em>, tôi cần một số quy tắc phá vỡ thế cân bằng bổ sung để ưu tiên một trong số họ. Hiệu suất là một quy tắc phá vỡ thế cân bằng phổ biến, trong đó chúng ta chọn các tuyến đường có <em>bandwidth</em> cao hơn hoặc đường đi ngắn hơn.</p>
<p>Dựa trên <em>Gao-Rexford rules</em>, chúng ta nên <em>export</em> các đường đi như thế nào? Hãy nhớ lại rằng một <em>AS</em> đồng ý tham gia vào một tuyến đường nếu ít nhất một neighbour là một <em>customer</em>. Do đó, <em>AS</em> chỉ nên quảng bá các tuyến đường nếu tuyến đường kết quả, nếu được chấp nhận, có một neighbour ở một phía.</p>
<p>Hãy xem xét tất cả các trường hợp cụ thể.</p>
<p>Tôi nhận và cài đặt một tuyến đường từ một <em>customer</em>. Điều này có nghĩa là chặng tiếp theo trên tuyến đường này là <em>customer</em> đó. Tôi nên <em>export</em> tuyến đường này cho ai? Tôi đã đảm bảo rằng có một <em>customer</em> ở một phía đang trả tiền cho tôi, vì vậy tôi có thể <em>export</em> tuyến đường này cho mọi người (<em>customer</em>, <em>provider</em>, và <em>peer</em>).</p>
<img width="900px" src="routing/../assets/routing/2-155-export-policy1.png">
<img width="900px" src="routing/../assets/routing/2-156-export-policy2.png">
<p>Tôi nhận và cài đặt một tuyến đường từ một <em>peer</em> (chặng tiếp theo là một <em>peer</em>). Tôi nên <em>export</em> tuyến đường này cho ai? Chưa có ai trả tiền cho tôi, vì vậy tôi chỉ nên <em>export</em> tuyến đường này cho <em>customer</em>. Nếu tôi <em>export</em> tuyến đường này cho một <em>peer</em> hoặc <em>provider</em> chấp nhận, thì tôi đã tạo ra một tuyến đường mà không có bên nào trả tiền cho tôi.</p>
<img width="900px" src="routing/../assets/routing/2-157-export-policy3.png">
<img width="900px" src="routing/../assets/routing/2-158-export-policy3.png">
<p>Tương tự, nếu tôi nhận và cài đặt một tuyến đường từ một <em>provider</em>, tôi chỉ nên <em>export</em> tuyến đường này cho <em>customer</em>, vì tôi cần ít nhất một bên trả tiền cho tôi, và <em>provider</em> không trả tiền.</p>
<img width="900px" src="routing/../assets/routing/2-159-export-policy5.png">
<img width="900px" src="routing/../assets/routing/2-160-export-policy3.png">
<img width="800px" src="routing/../assets/routing/2-161-export-policy7.png">
<p><em>Gao-Rexford rules</em> cho phép chúng ta chứng minh được rằng mệnh đề này là đúng: Giả sử rằng đồ thị <em>AS</em> có cấu trúc phân cấp và không có chu trình, và tất cả các <em>AS</em> tuân theo <em>Gao-Rexford rules</em>, thì chúng ta có thể đảm bảo <em>reachability</em> và <em>convergence</em> ở trạng thái ổn định.</p>
<p>Phân tích các thuật ngữ cụ thể trong mệnh đề: <em>Reachability</em> có nghĩa là hai <em>AS</em> bất kỳ trong đồ thị có thể giao tiếp với nhau. <em>Convergence</em> có nghĩa là tất cả các <em>AS</em> cuối cùng sẽ ngừng cập nhật đường đi của chúng, và mạng sẽ đạt đến trạng thái ổn định với các đường đi hợp lệ giữa hai <em>AS</em> bất kỳ. &quot;Ở trạng thái ổn định&quot; có nghĩa là nếu cấu trúc liên kết mạng thay đổi, các đường đi có thể mất một thời gian để thay đổi và đạt lại trạng thái ổn định.</p>
<p>Hãy nhớ lại rằng phân cấp có nghĩa là bắt đầu từ bất kỳ <em>AS</em> nào, đi lên trong hệ thống phân cấp (từ <em>customer</em> đến <em>provider</em>) sẽ dẫn đến một <em>AS</em> Cấp 1. Không có chu trình có nghĩa là không có chu trình trong các mối quan hệ <em>customer</em>-<em>provider</em> (các cạnh có hướng).</p>
<p>Việc chứng minh mệnh đề này yêu cầu mọi người phải tuân theo <em>Gao-Rexford rules</em>. Nếu các <em>AS</em> chạy <em>policy</em> tùy ý của riêng mình, các đảm bảo sẽ không còn đúng nữa.</p>
<h2 id="sửa-đổi-bgp-tổng-hợp-các-đích"><a class="header" href="#sửa-đổi-bgp-tổng-hợp-các-đích">Sửa đổi: BGP tổng hợp các đích</a></h2>
<p>Có hai sửa đổi nữa chúng ta cần thực hiện đối với giao thức <em>distance-vector</em>.</p>
<p>Trong các giao thức <em>distance-vector</em>, chúng ta đã chỉ ra rằng mỗi đích có một địa chỉ duy nhất, và <em>forwarding table</em> ánh xạ mỗi đích đến một chặng tiếp theo và khoảng cách.</p>
<p>Trong <em>BGP</em>, mỗi <em>AS</em> được định danh bằng một <em>prefix</em> (tiền tố), chỉ ra rằng tất cả các máy bên trong <em>AS</em> đó đều chia sẻ cùng một <em>prefix</em>.</p>
<p>Các <em>forwarding table</em> này có thể trở nên rất lớn (hãy tưởng tượng nếu một <em>provider</em> có hàng trăm <em>customer</em>), và mỗi đích duy nhất sẽ cần được mô tả trong một quảng bá riêng biệt. Có cách nào chúng ta có thể thể hiện <em>forwarding table</em> này một cách ngắn gọn hơn không?</p>
<p>Để cải thiện khả năng mở rộng, <em>BGP</em> cho phép các <em>AS</em> <strong><em>aggregate</em> (tổng hợp)</strong> nhiều đích thành một mục <em>forwarding table</em> duy nhất, và quảng bá một <em>prefix</em> chung hơn bao gồm tất cả các đích được kết hợp.</p>
<img width="900px" src="routing/../assets/routing/2-162-bgp-aggregation.png">
<p>Lưu ý rằng trong thực tế, <em>BGP</em> có các quy ước về kích thước của các <em>prefix</em> được quảng bá. Ví dụ, các <em>AS</em> sẽ không tạo một quảng bá cho một địa chỉ IP riêng lẻ. Các <em>prefix</em> 24-bit (các khối 256 địa chỉ) thường là đơn vị địa chỉ nhỏ nhất được quảng bá.</p>
<h2 id="sửa-đổi-giao-thức-path-vector"><a class="header" href="#sửa-đổi-giao-thức-path-vector">Sửa đổi: Giao thức Path-Vector</a></h2>
<p>Trong các giao thức <em>least-cost</em> như <em>distance vector</em>, chúng ta không phải lo lắng về các vòng lặp. Mọi <em>Router</em> đều cố gắng tìm các tuyến đường <em>least-cost</em>, và theo định nghĩa, tuyến đường <em>least-cost</em> sẽ không chứa vòng lặp.</p>
<p>Bây giờ mỗi <em>AS</em> đang chọn các tuyến đường dựa trên sở thích của riêng mình, chúng ta đã mất đi sự đảm bảo không có vòng lặp. Ví dụ, giả sử B thích các đường đi qua C, và C thích các đường đi qua B. Chúng ta đã tạo ra một vòng lặp định tuyến!</p>
<img width="800px" src="routing/../assets/routing/2-163-bgp-loop.png">
<p>Để khắc phục vấn đề này, thay vì khoảng cách đến đích, các quảng bá <em>BGP</em> sẽ bao gồm toàn bộ đường đi <em>AS</em> đến đích. Điều này thay đổi giao thức từ một giao thức <em>distance-vector</em> thành một giao thức <strong><em>path-vector</em> (vector đường đi)</strong>.</p>
<p>Ví dụ, trong một giao thức <em>distance-vector</em>, A sẽ quảng bá: &quot;Tôi có thể đến đích với chi phí 1.&quot; Sau đó, B sẽ quảng bá: &quot;Tôi có thể đến đích với chi phí 2.&quot;</p>
<p>Trong một giao thức <em>path-vector</em>, A sẽ quảng bá: &quot;Tôi có thể đến đích với đường đi [A].&quot; Sau đó, B sẽ quảng bá: &quot;Tôi có thể đến đích với đường đi [B, A].&quot;</p>
<p>Với sửa đổi này, các <em>AS</em> có thể xác định xem một đường đi được quảng bá có chứa vòng lặp hay không bằng cách theo dõi qua đường đi trong quảng bá. Cụ thể, nếu tôi nhận được một quảng bá, tôi chỉ cần kiểm tra xem đường đi có bao gồm chính tôi hay không. Điều đó sẽ khiến <em>packet</em> được gửi lại cho tôi, tạo ra một vòng lặp, vì vậy tôi sẽ bỏ qua quảng bá đó và không chấp nhận hoặc quảng bá tuyến đường có vòng lặp.</p>
<p>Lưu ý: Nếu mọi người đồng ý loại bỏ các tuyến đường có vòng lặp, điều này đảm bảo rằng các quảng bá sẽ không chứa vòng lặp. Cách duy nhất mà một tuyến đường được quảng bá có thể tạo ra vòng lặp là nếu tôi thấy một tuyến đường đã bao gồm chính tôi, và việc thêm chính tôi vào là điều tạo ra vòng lặp.</p>
<p>Sự thay đổi từ <em>distance-vector</em> sang <em>path-vector</em> cũng cho phép các <em>AS</em> triển khai các <em>policy</em> tùy ý. Trong một giao thức <em>distance-vector</em>, tôi có thể có một <em>policy</em> như &quot;tránh AS#2063 khi có thể.&quot; Nếu tôi nhận được một quảng bá &quot;Tôi có thể đến đích với chi phí 12,&quot; tôi không biết liệu đường đi được quảng bá có đi qua AS#2063 hay không. Thay vào đó, nếu quảng bá chứa toàn bộ đường đi, tôi có thể kiểm tra xem đường đi có đi qua AS#2063 hay không trước khi quyết định chấp nhận hay từ chối nó.</p>
<p>Lưu ý: <em>policy</em> <em>import</em> <em>BGP</em> thông thường mà chúng ta đã thấy trước đó (ưu tiên chọn các tuyến đường đi đến <em>customer</em>, hơn <em>peer</em>, hơn <em>provider</em>) chỉ phụ thuộc vào chặng tiếp theo, không phải toàn bộ đường đi. Tuy nhiên, sự thay đổi sang <em>path-vector</em> rất hữu ích cho việc phát hiện vòng lặp, và cho phép chúng ta tổng quát hóa giao thức cho các <em>policy</em> tùy ý.</p>
<h2 id="stub-as-sử-dụng-default-route"><a class="header" href="#stub-as-sử-dụng-default-route">Stub AS sử dụng Default Route</a></h2>
<p>Một số <em>AS</em> không cần chạy <em>BGP</em> để xác định cách chuyển tiếp <em>packet</em> qua mạng. Cụ thể, nếu một <em>stub AS</em> (AS nhánh) chỉ được kết nối với một <em>provider</em> duy nhất, thì mọi <em>packet</em> hướng đến các <em>AS</em> khác nên được gửi đến <em>provider</em> đó. <em>stub AS</em> có thể cài đặt một <strong><em>default route</em> (tuyến đường mặc định)</strong> được mã hóa cứng duy nhất cho tất cả các đích ở các <em>AS</em> khác.</p>
<p>Vậy còn các <em>AS</em> khác cố gắng gửi <em>packet</em> đến <em>stub AS</em> thì sao? <em>stub AS</em> có thể yêu cầu <em>provider</em> cài đặt một <strong><em>static route</em> (tuyến đường tĩnh)</strong>, cho <em>provider</em> biết cách gửi <em>packet</em> đến <em>stub AS</em>. Bây giờ, <em>provider</em> có thể chạy <em>BGP</em> và quảng bá <em>static route</em> này cho phần còn lại của Internet. <em>stub AS</em> có thể yêu cầu <em>provider</em> mã hóa cứng <em>static route</em>, và <em>stub AS</em> không bao giờ phải chạy <em>BGP</em>, vì <em>provider</em> đang quảng bá các tuyến đường đến <em>stub AS</em> thay mặt cho <em>stub AS</em>.</p>
<img width="600px" src="routing/../assets/routing/2-164-stub-routes.png">
<p>Hầu hết các <em>AS</em> nhỏ trên Internet là các <em>stub AS</em> sử dụng <em>default route</em> và <em>static route</em>.</p>
<p>Các <em>stub AS</em> tương tự như các <em>end host</em> trong định tuyến nội miền. Chúng gửi và nhận <em>packet</em> cho <em>AS</em> của riêng mình, nhưng không chuyển tiếp <em>packet</em> của người khác và không tham gia vào quá trình định tuyến. Giống như trong định tuyến nội miền, chúng ta thường sẽ bỏ qua các <em>stub AS</em> và chỉ xem xét các <em>AS</em> chuyển tiếp thực sự tham gia vào <em>BGP</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="triển-khai-implementation-và-các-vấn-đề-của-bgp"><a class="header" href="#triển-khai-implementation-và-các-vấn-đề-của-bgp">Triển khai (Implementation) và các vấn đề của BGP</a></h1>
<h2 id="router-biên-và-router-nội-bộ"><a class="header" href="#router-biên-và-router-nội-bộ">Router Biên và Router Nội bộ</a></h2>
<p>Đến thời điểm này, chúng ta đã có một hình dung trực quan về cách <em>BGP</em> (Giao thức Cổng Biên giới - Border Gateway Protocol) hoạt động giữa các <em>AS</em> (Hệ tự trị - Autonomous System). Trong phần này, chúng ta sẽ xem cách <em>BGP</em> thực sự được triển khai ở cấp độ <em>Router</em>. Khi làm như vậy, chúng ta cũng sẽ chỉ ra cách <em>BGP</em> tương tác với các <em>routing protocol</em> nội miền đã học trước đó.</p>
<p>Cho đến nay, mô hình định tuyến liên miền của chúng ta đã coi toàn bộ một <em>AS</em> như một thực thể duy nhất, nhập và xuất các đường đi.</p>
<img width="900px" src="routing/../assets/routing/2-165-combining1.png">
<p>Tuy nhiên, trên thực tế, <em>AS</em> chứa nhiều <em>Router</em> (và các máy chủ) được kết nối bởi các liên kết.</p>
<img width="900px" src="routing/../assets/routing/2-166-combining2.png">
<p>Để thực sự triển khai <em>BGP</em>, chúng ta cần tất cả các <em>Router</em> bên trong <em>AS</em> hoạt động hợp tác để đóng vai trò như một nút duy nhất.</p>
<p>Trong một <em>AS</em>, chúng ta sẽ phân loại tất cả các <em>Router</em> thành hai loại. <strong><em>Border routers</em> (Router biên)</strong> có ít nhất một liên kết đến một <em>Router</em> trong một <em>AS</em> khác. <strong><em>Interior routers</em> (Router nội bộ)</strong> chỉ có liên kết đến các <em>Router</em> khác trong cùng một <em>AS</em>.</p>
<img width="900px" src="routing/../assets/routing/2-167-borders.png">
<p>Chỉ có <em>border routers</em> cần quảng bá các tuyến đường đến các <em>AS</em> khác. Đôi khi, chúng ta gọi các <em>Router</em> quảng bá các tuyến <em>BGP</em> là <strong><em>BGP speakers</em> (các bộ phát BGP)</strong>. Các <em>BGP speakers</em> cần hiểu ngữ nghĩa và cú pháp của giao thức <em>BGP</em> (cách đọc và tạo một thông báo <em>BGP</em>, phải làm gì khi nhận được một thông báo, v.v.).</p>
<h2 id="các-phiên-bgp-ngoài-và-bgp-nội-bộ"><a class="header" href="#các-phiên-bgp-ngoài-và-bgp-nội-bộ">Các phiên BGP Ngoài và BGP Nội bộ</a></h2>
<p>Một <strong><em>BGP session</em> (phiên BGP)</strong> bao gồm hai <em>Router</em> trao đổi thông tin với nhau.</p>
<img width="900px" src="routing/../assets/routing/2-168-bgp1.png">
<p>Một <strong><em>external BGP (eBGP) session</em> (phiên BGP ngoại)</strong> là giữa hai <em>Router</em> từ các <em>AS</em> khác nhau. Các <em>eBGP session</em> có thể được sử dụng để trao đổi các thông báo giữa các <em>AS</em> khác nhau và tìm hiểu về các tuyến đường đến các <em>AS</em> khác. Chỉ có <em>border routers</em> tham gia vào các <em>eBGP session</em> (vì <em>eBGP</em> yêu cầu giao tiếp với một <em>AS</em> khác).</p>
<img width="900px" src="routing/../assets/routing/2-169-bgp2.png">
<p>Ngược lại, một <strong><em>internal BGP (iBGP) session</em> (phiên BGP nội)</strong> là giữa hai <em>Router</em> trong cùng một <em>AS</em> (không nhất thiết phải kết nối trực tiếp bằng một liên kết). Cụ thể hơn, nếu một <em>border router</em> biết về một tuyến đường mới, nó có thể sử dụng <em>iBGP</em> để phân phối tuyến đường mới đó đến các <em>Router</em> khác trong <em>AS</em>. Điều này cho phép tất cả các <em>Router</em> trong <em>AS</em> phối hợp và hoạt động cùng nhau như một thực thể. Cả <em>border router</em> và <em>internal router</em> đều tham gia vào các <em>iBGP session</em>.</p>
<img width="900px" src="routing/../assets/routing/2-170-bgp3.png">
<p>Các <em>eBGP session</em> và <em>iBGP session</em> khác với <strong><em>interior gateway protocols (IGP)</em> (các giao thức cổng nội bộ)</strong>. Đây là các <em>routing protocol</em> nội miền (ví dụ: <em>distance-vector</em>, <em>link-state</em>) được triển khai trong một <em>AS</em> để định tuyến các <em>packet</em> bên trong <em>AS</em>.</p>
<img width="900px" src="routing/../assets/routing/2-171-bgp4.png">
<p>Rất dễ nhầm lẫn giữa <em>iBGP</em> và <em>IGP</em>. Cả hai đều trao đổi thông điệp trong cùng một <em>AS</em>. Tuy nhiên, <em>iBGP</em> là một phần của giao thức liên miền, giúp các <em>Router</em> tìm hiểu về các đường đi đến các <em>AS</em> khác. <em>IGP</em> là một giao thức nội miền, giúp các <em>Router</em> tìm hiểu về các đường đi đến các đích trong cùng một <em>AS</em>.</p>
<img width="900px" src="routing/../assets/routing/2-172-bgp5.png">
<p><em>eBGP</em>, <em>iBGP</em>, và <em>IGP</em> làm việc cùng nhau để thiết lập các tuyến đường từ bất kỳ <em>Router</em> nào đến bất kỳ <em>Router</em> nào khác trên Internet (ngay cả khi các <em>Router</em> ở trong các <em>AS</em> khác nhau).</p>
<p>Đầu tiên, mỗi <em>AS</em> chạy <em>IGP</em> để tìm hiểu các đường đi có chi phí thấp nhất giữa hai <em>Router</em> bất kỳ bên trong cùng một <em>AS</em>.</p>
<img width="900px" src="routing/../assets/routing/2-173-bgp6.png">
<p>Tiếp theo, các <em>AS</em> chạy <em>eBGP</em>, quảng bá các tuyến đường cho nhau để tìm hiểu về các tuyến đường đến các <em>AS</em> khác.</p>
<img width="900px" src="routing/../assets/routing/2-174-bgp7.png">
<p>Cuối cùng, các <em>AS</em> chạy <em>iBGP</em>, để một <em>Router</em> đã biết về một tuyến đường bên ngoài có thể phân phối tuyến đường đó đến tất cả các <em>Router</em> khác trong cùng <em>AS</em>.</p>
<img width="900px" src="routing/../assets/routing/2-175-bgp8.png">
<p>Các tuyến đường học được từ <em>eBGP</em>, <em>iBGP</em>, và <em>IGP</em> có thể được sử dụng để gửi <em>packet</em> đến bất kỳ đâu trên Internet. Nếu đích nằm trong cùng một <em>AS</em> (cùng tiền tố IP), chúng ta có thể sử dụng các tuyến đường học được từ <em>IGP</em> để chuyển tiếp <em>packet</em>. Nếu đích ở một <em>AS</em> khác (tiền tố IP khác), chúng ta có thể nghĩ lại về <em>iBGP</em>, thứ đã cho chúng ta biết về bất kỳ tuyến đường bên ngoài nào được phát hiện bởi bất kỳ ai trong <em>AS</em> của tôi. Sử dụng kết quả của <em>iBGP</em>, chúng ta có thể tìm ra <em>border router</em> nào nằm trên tuyến đường bên ngoài đó. Sau đó, chúng ta có thể sử dụng <em>IGP</em> để chuyển tiếp <em>packet</em> đến đúng <em>border router</em> (sau đó nó sẽ chuyển tiếp <em>packet</em> đến <em>AS</em> tiếp theo).</p>
<img width="900px" src="routing/../assets/routing/2-176-bgp9.png">
<p>Ví dụ cụ thể, giả sử E muốn gửi <em>packet</em> đến Z. Đầu tiên, mọi <em>Router</em> trong <em>AS</em> của E chạy <em>IGP</em>, học tất cả các tuyến đường nội bộ. Tiếp theo, một <em>Router</em> nào đó trong AS#5 quảng bá một tuyến đường đến Z bằng <em>eBGP</em>. Tại thời điểm này, chỉ có G biết rằng nó có thể đến được Z. Cuối cùng, G thông báo cho tất cả các <em>Router</em> trong <em>AS</em> của mình rằng nó có thể đến được Z, bằng cách sử dụng <em>iBGP</em>.</p>
<p>E đã nghe từ <em>iBGP</em> rằng G, một <em>Router</em> trong cùng <em>AS</em>, có thể đến được Z. Sử dụng các tuyến đường <em>IGP</em>, E có thể gửi <em>packet</em> đến G (chuyển tiếp đến F trước). Sau đó, G có thể sử dụng tuyến đường đã học trong <em>eBGP</em> để gửi <em>packet</em> đến Z.</p>
<p><em>border router</em> quảng bá một tuyến đường đến một đích bên ngoài đôi khi được gọi là <strong><em>egress router</em> (router đầu ra)</strong> cho đích đó. Đây là <em>Router</em> có thể giúp <em>packet</em> của bạn thoát khỏi mạng cục bộ và di chuyển đến các mạng khác gần đích hơn. Trong ví dụ trên, G là <em>egress router</em> cho đích Z.</p>
<p>Một hệ quả của các giao thức này là mọi <em>Router</em> đều có hai <em>forwarding table</em>. Một bảng là ánh xạ tất cả các đích nội bộ (cùng <em>AS</em>) tới một chặng tiếp theo, được điền thông tin từ <em>IGP</em>. Bảng còn lại là ánh xạ tất cả các đích bên ngoài tới một <em>egress router</em> (nơi biết một tuyến đường đến đích bên ngoài), được điền thông tin từ <em>eBGP</em>.</p>
<img width="900px" src="routing/../assets/routing/2-177-bgp10.png">
<p>Lưu ý rằng trong bảng <em>eBGP</em>, <em>egress router</em> không nhất thiết là một chặng tiếp theo. <em>egress router</em> có thể cách xa vài chặng cục bộ, nhưng chúng ta sử dụng <em>IGP</em> để đến được <em>egress router</em> đó.</p>
<img width="900px" src="routing/../assets/routing/2-178-bgp11.png">
<p>Chúng ta đã thấy cách <em>eBGP</em> (path-vector, quảng bá tuyến đường) và <em>IGP</em> (distance-vector hoặc link-state) được triển khai dưới dạng thuật toán. <em>iBGP</em> được triển khai như thế nào? Khi một <em>border router</em> cài đặt một tuyến đường mới đến một đích, nó phải thông báo cho các <em>Router</em> khác trong <em>AS</em>. Một giải pháp đơn giản là để <em>border router</em> trực tiếp thông báo cho mọi <em>Router</em> khác trong <em>AS</em>.</p>
<img width="900px" src="routing/../assets/routing/2-179-bgp12.png">
<p>Giải pháp này tương đối đơn giản, mặc dù nó yêu cầu mọi <em>border router</em> phải có một <em>iBGP session</em> với mọi <em>Router</em> khác. Trong một mạng có B <em>border router</em> và tổng cộng N <em>Router</em>, giao thức này sẽ yêu cầu BN kết nối <em>iBGP</em>, và có thể không mở rộng tốt khi các mạng cục bộ lớn hơn.</p>
<p>Lưu ý: Trong thực tế, có những cách khác để kết hợp các <em>router</em> liên miền và nội miền. Bạn có thể tìm hiểu về &quot;route reflectors&quot; nếu bạn quan tâm, mặc dù chúng sẽ không được đề cập trong lớp học này.</p>
<h2 id="nhiều-liên-kết-giữa-các-as-Định-tuyến-khoai-tây-nóng"><a class="header" href="#nhiều-liên-kết-giữa-các-as-Định-tuyến-khoai-tây-nóng">Nhiều liên kết giữa các AS: Định tuyến Khoai tây nóng</a></h2>
<p>Cho đến nay, trong biểu đồ <em>AS</em> của chúng ta, chúng ta đã thể hiện hai <em>AS</em> có một liên kết (cạnh) duy nhất giữa chúng nếu chúng được kết nối. Trong thực tế, vì một <em>AS</em> thực sự bao gồm nhiều <em>Router</em>, hai <em>AS</em> có thể được kết nối bởi nhiều liên kết.</p>
<p>Trong thực tế, việc có nhiều liên kết giữa các <em>AS</em> lớn có thể hữu ích. Ví dụ, Verizon và AT&amp;T là những <em>AS</em> rất lớn với cơ sở hạ tầng trên toàn nước Mỹ. Giả sử chỉ có một liên kết giữa hai <em>AS</em> ở bờ Tây. Nếu một <em>Router</em> của Verizon ở bờ Đông và một <em>Router</em> của AT&amp;T ở bờ Đông muốn liên lạc, <em>packet</em> sẽ phải đi xuyên quốc gia trên mạng của Verizon, đi qua liên kết vào mạng của AT&amp;T, và sau đó đi ngược lại xuyên quốc gia đến đích.</p>
<img width="800px" src="routing/../assets/routing/2-180-multilink1.png">
<p>Nhiều liên kết giữa hai <em>AS</em> cũng có nghĩa là có thể có nhiều đường đi giữa hai <em>Router</em> đi qua cùng các <em>AS</em>. Ở cấp độ <em>AS</em>, cả hai đường đi này đều đi qua cùng các <em>AS</em>, và mô hình trước đó của chúng ta không phân biệt giữa chúng. Tuy nhiên, trong mô hình chi tiết hơn của chúng ta, cả hai đường đi cần được xuất ra, và một tuyến đường ưu tiên phải được nhập vào.</p>
<img width="800px" src="routing/../assets/routing/2-181-multilink2.png">
<p>Nếu có hai tuyến đường, <em>AS</em> nhập sẽ ưu tiên tuyến đường nào?</p>
<img width="800px" src="routing/../assets/routing/2-182-multilink3.png">
<p><em>Bandwidth</em> tốn tiền, vì vậy tôi sẽ ưu tiên nếu lưu lượng này đi càng xa càng tốt trên cơ sở hạ tầng do người khác sở hữu và chi trả, và đi càng ít càng tốt trên cơ sở hạ tầng của riêng tôi. Do đó, đường màu cam được ưu tiên.</p>
<p>Chính thức hơn, <em>AS</em> nhập nhận được hai thông báo: một từ <em>router</em> phía Tây, và một từ <em>router</em> phía Đông.</p>
<img width="900px" src="routing/../assets/routing/2-183-multilink4.png">
<p>Sử dụng <em>iBGP</em>, mọi <em>Router</em> bên trong <em>AS</em> đều thấy cả hai thông báo. Một thông báo nói rằng, <em>egress router</em> là <em>router</em> phía Tây, và thông báo còn lại nói rằng, <em>egress router</em> là <em>router</em> phía Đông. Mọi <em>Router</em> phải quyết định nên nhập thông báo nào.</p>
<img width="900px" src="routing/../assets/routing/2-184-multilink5.png">
<p>Hãy tập trung vào <em>Router</em> E. Sử dụng <em>IGP</em>, <em>Router</em> này có thể tìm ra khoảng cách đến <em>egress router</em> phía Tây (F), và khoảng cách đến <em>egress router</em> phía Đông (I). Vì <em>egress router</em> phía Tây (F) gần hơn, việc định tuyến <em>packet</em> qua <em>egress router</em> phía Tây (F) sẽ sử dụng ít <em>bandwidth</em> của <em>AS</em> này hơn. Do đó, <em>Router</em> này sẽ nhập đường đi qua <em>egress router</em> phía Tây (F). Một <em>Router</em> khác, chẳng hạn như một <em>Router</em> gần <em>egress router</em> phía Đông (I) hơn, có thể quyết định nhập một đường đi khác.</p>
<img width="900px" src="routing/../assets/routing/2-185-multilink6.png">
<p>Chiến lược chọn <em>egress router</em> gần nhất này đôi khi được gọi là <strong><em>hot potato routing</em> (định tuyến khoai tây nóng)</strong>. Chúng ta muốn <em>packet</em> rời khỏi <em>AS</em> của mình càng sớm càng tốt, và bắt đầu di chuyển trên các liên kết của người khác càng sớm càng tốt.</p>
<h2 id="nhiều-liên-kết-giữa-các-router-med"><a class="header" href="#nhiều-liên-kết-giữa-các-router-med">Nhiều liên kết giữa các Router: MED</a></h2>
<p>Điều gì sẽ xảy ra nếu một <em>Router</em> cách đều cả hai <em>egress router</em> có thể có?</p>
<img width="800px" src="routing/../assets/routing/2-186-med1.png">
<p>Để phá vỡ thế cân bằng, <em>AS</em> xuất có thể thông báo ưu tiên cho một tuyến đường hơn tuyến đường kia.</p>
<p><em>AS</em> xuất ưu tiên tuyến đường nào? Một lần nữa, vì <em>bandwidth</em> tốn tiền, <em>AS</em> xuất ưu tiên đường màu hồng, vì nó sử dụng ít <em>bandwidth</em> của mình hơn. Trong thông báo của đường màu hồng, <em>AS</em> xuất có thể nói thêm &quot;Tôi ưu tiên nếu bạn sử dụng đường này,&quot; và trong thông báo của đường màu cam, <em>AS</em> xuất có thể nói thêm &quot;Tôi ưu tiên nếu bạn tránh đường này.&quot;</p>
<img width="900px" src="routing/../assets/routing/2-187-med2.png">
<p>Bây giờ, <em>Router</em> cách đều cả hai <em>egress router</em> có thể thấy thông tin bổ sung này trong thông báo <em>iBGP</em>.</p>
<img width="900px" src="routing/../assets/routing/2-188-med3.png">
<p>Sử dụng thông tin bổ sung này, <em>Router</em> có thể chọn <em>egress router</em> trên đường màu hồng, vì <em>AS</em> xuất đã ưu tiên đường này.</p>
<img width="800px" src="routing/../assets/routing/2-189-med4.png">
<p>Thông tin bổ sung này trong thông báo xuất được gọi là <strong><em>Multi-Exit Discriminator (MED)</em> (Bộ phân biệt đa lối ra)</strong>. Từ góc độ của bên xuất, nó chỉ ra <em>Router</em> ưu tiên của tôi để vào mạng của tôi. Từ góc độ của bên nhập, nó chỉ ra <em>Router</em> ưu tiên của <em>AS</em> khác để thoát khỏi mạng của tôi và vào mạng của <em>AS</em> kia.</p>
<p>Một cách khác để diễn giải <em>MED</em> là, khoảng cách đến đích, thông qua <em>Router</em> này. Bên xuất có thể nói, &quot; <em>router</em> bờ Tây cách đích 3 chặng,&quot; và &quot; <em>router</em> bờ Đông cách đích 12 chặng.&quot; Các số <em>MED</em> thấp hơn được ưu tiên, vì bên xuất muốn sử dụng càng ít <em>bandwidth</em> của mình càng tốt. Bên xuất thà sử dụng 3 liên kết của mình, thay vì 12 liên kết của mình.</p>
<h2 id="Ưu-tiên-chính-sách-nhập"><a class="header" href="#Ưu-tiên-chính-sách-nhập">Ưu tiên Chính sách Nhập</a></h2>
<p>Mô hình chi tiết hơn của chúng ta, nơi hai <em>AS</em> có thể được kết nối bằng nhiều liên kết, có nghĩa là bây giờ chúng ta có thêm các quy tắc chính sách nhập, ngoài các quy tắc Gao-Rexford. Khi bạn nhận được nhiều thông báo cho cùng một đích, hãy chọn một đường đi dựa trên các quy tắc phá vỡ thế cân bằng này, theo thứ tự sau:</p>
<ol>
<li>Sử dụng <strong><em>Gao-Rexford rules</em> (các quy tắc Gao-Rexford)</strong>. Chọn đường đi được quảng bá bởi một khách hàng, hơn đường đi được quảng bá bởi một đối tác ngang hàng, hơn đường đi được quảng bá bởi một nhà cung cấp.</li>
<li>Nếu nhiều đường đi có cùng mức độ ưu tiên Gao-Rexford (ví dụ: hai đường đi từ khách hàng), hãy chọn <strong>đường đi ngắn hơn</strong> (đường đi qua ít <em>AS</em> hơn).</li>
<li>Nếu nhiều đường đi có cùng độ dài, hãy chọn đường đi có <strong><em>egress router</em> gần hơn</strong> (sử dụng <em>IGP</em> để tìm khoảng cách đến mỗi <em>egress router</em>).</li>
<li>Nếu nhiều đường đi có cùng khoảng cách đến <em>egress router</em>, hãy chọn đường đi có <strong><em>MED</em> thấp hơn</strong> (trong đó <em>MED</em> được bao gồm trong quảng bá).</li>
<li>Nếu nhiều đường đi có cùng <em>MED</em>, <strong>phá vỡ thế cân bằng một cách tùy ý</strong> (ví dụ: chọn <em>Router</em> có địa chỉ IP thấp hơn).</li>
</ol>
<img width="900px" src="routing/../assets/routing/2-190-med5.png">
<p>Lưu ý rằng <em>egress router</em> gần nhất (<em>hot potato routing</em>) và <em>MED</em> thường mâu thuẫn với nhau. Mọi <em>AS</em> đều muốn giảm thiểu việc sử dụng <em>bandwidth</em> của mình, và muốn <em>packet</em> được vận chuyển trên <em>bandwidth</em> của các <em>AS</em> khác.</p>
<p>Với tư cách là <em>AS</em> xuất, tôi muốn <em>packet</em> vào <em>AS</em> của mình càng gần đích càng tốt. Điều này có nghĩa là tôi muốn <em>AS</em> nhập mang <em>packet</em> đi rất xa (đường dài đến <em>egress router</em>).</p>
<img width="900px" src="routing/../assets/routing/2-191-med6.png">
<p>Ngược lại, với tư cách là <em>AS</em> nhập, tôi muốn mang <em>packet</em> đi càng ít càng tốt (đường ngắn đến <em>egress router</em>). Điều này có nghĩa là tôi muốn <em>packet</em> vào <em>AS</em> kia càng xa đích càng tốt (buộc <em>AS</em> kia phải làm tất cả công việc).</p>
<img width="900px" src="routing/../assets/routing/2-192-med7.png">
<p>Một hệ quả của sự mâu thuẫn này là các đường đi qua Internet thường không đối xứng. Nếu hai máy chủ đang gửi <em>packet</em> qua lại, đường đi theo một hướng có thể khác với đường đi theo hướng ngược lại.</p>
<img width="800px" src="routing/../assets/routing/2-193-med8.png">
<p>Trong ví dụ này, đối với các <em>packet</em> đi về phía Đông, A chọn <em>egress router</em> phía Tây và buộc B phải mang lưu lượng đi gần hết quãng đường. Ở chiều ngược lại (về phía Tây), B chọn <em>egress router</em> phía Đông, và buộc A phải mang lưu lượng đi gần hết quãng đường.</p>
<p>Về cơ bản, <em>BGP</em> cho phép hành vi này vì mọi <em>AS</em> đều được cấp quyền tự chủ để đặt chính sách của riêng mình (ở đây, chính sách đó là <em>hot potato routing</em>).</p>
<p>Trong thực tế, đôi khi các <em>AS</em> sẽ cố gắng thực hiện các chiến lược thông minh hơn để lừa các <em>AS</em> khác mang <em>packet</em> đi xa hơn. Hoặc, một <em>AS</em> có <em>bandwidth</em> tốt hơn có thể đồng ý mang lưu lượng của bạn đi xa hơn, nếu bạn trả một khoản phí cao cấp.</p>
<h2 id="các-loại-thông-điệp-bgp-và-thuộc-tính-tuyến-đường"><a class="header" href="#các-loại-thông-điệp-bgp-và-thuộc-tính-tuyến-đường">Các loại thông điệp BGP và Thuộc tính tuyến đường</a></h2>
<p>Hãy nhớ lại rằng một giao thức phải xác định cú pháp và ngữ nghĩa. Cụ thể, <em>BGP</em> phải xác định cấu trúc của các thông điệp được gửi và nhận. <em>BGP</em> cũng phải xác định một <em>Router</em> nên làm gì khi nhận được một thông điệp.</p>
<p>Có bốn loại thông điệp <em>BGP</em> khác nhau. Thông điệp Open có thể được sử dụng để bắt đầu một phiên giữa hai <em>Router</em> để giao tiếp với nhau. Thông điệp KeepAlive có thể được sử dụng để xác nhận rằng một phiên vẫn đang mở, ngay cả khi các thông điệp không được gửi gần đây. Thông điệp Notification có thể được sử dụng để xử lý lỗi. Chúng ta sẽ không mô tả ba loại thông điệp đầu tiên này một cách chi tiết hơn.</p>
<p>Chúng ta sẽ tập trung vào loại thông điệp thứ tư và thú vị nhất, Update. Các thông điệp này được sử dụng để thông báo các tuyến đường mới, thay đổi các tuyến đường hiện có, hoặc xóa các tuyến đường không còn hoạt động.</p>
<p>Thông điệp Update chứa một đích, được biểu thị bằng một tiền tố IP. Thông điệp cũng chứa <strong><em>route attributes</em> (thuộc tính tuyến đường)</strong>, có thể được sử dụng để mã hóa bất kỳ thông tin hữu ích nào tương ứng với tiền tố IP đó. Các <em>route attributes</em> là một tập hợp các cặp tên-giá trị, trong đó tên cho biết loại thuộc tính, và giá trị cho biết giá trị của thuộc tính đó. Một ví dụ về các thuộc tính không liên quan đến mạng có thể là: color=red, shape=triangle. Tên thuộc tính là color và shape, và chúng tương ứng với các giá trị red và triangle.</p>
<p>Một số thuộc tính là cục bộ cho một <em>AS</em>, và chỉ được trao đổi trong các thông điệp <em>iBGP</em>. Các thuộc tính khác là toàn cục, và có thể được gửi trong các quảng bá <em>eBGP</em>.</p>
<p>Có nhiều thuộc tính <em>BGP</em>, nhưng chúng ta sẽ tập trung vào ba thuộc tính quan trọng, được sử dụng để mã hóa các quy tắc phá vỡ thế cân bằng khác nhau để nhập đường đi.</p>
<p>Thuộc tính <strong><em>LOCAL PREFERENCE</em> (Ưu tiên Cục bộ)</strong> mã hóa các quy tắc nhập Gao-Rexford (quy tắc phá vỡ thế cân bằng ưu tiên hàng đầu) bên trong một <em>AS</em> cụ thể. Một <em>AS</em> có thể gán một giá trị cao hơn cho các tuyến đường được ưu tiên hơn (ví dụ: từ khách hàng), và một giá trị thấp hơn cho các tuyến đường ít được ưu tiên hơn (ví dụ: từ các nhà cung cấp). Thuộc tính này là cục bộ, và chỉ được mang trong các thông điệp <em>iBGP</em>. Thuộc tính này không được gửi đến các <em>AS</em> khác trong các thông báo <em>eBGP</em>, vì các <em>AS</em> khác không cần biết về các ưu tiên của <em>AS</em> này.</p>
<img width="900px" src="routing/../assets/routing/2-194-attribute1.png">
<p>Ví dụ, giả sử <em>Router</em> E nhận được một thông báo <em>eBGP</em> từ AS#7, và <em>Router</em> A biết rằng AS#7 là một khách hàng. Sau đó, trong thông điệp <em>iBGP</em>, <em>Router</em> E có thể đặt giá trị <em>local preference</em> là 3000 (số cao). Bây giờ, mọi <em>Router</em> khác trong cùng <em>AS</em> đều biết rằng <em>Router</em> E có thể đến được đích mà nó đang thông báo, thông qua đường đi trong thuộc tính <em>ASPATH</em>, với <em>local preference</em> là 3000.</p>
<p>Ngược lại, nếu <em>Router</em> D nhận được một thông báo <em>eBGP</em> từ AS#79, và <em>AS</em> này là một đối tác ngang hàng, thì trong thông điệp <em>iBGP</em>, <em>Router</em> D có thể đặt giá trị <em>local preference</em> thấp hơn là 1000 và sau đó phân phối đường đi này (với <em>local preference</em> thấp hơn) đến các <em>Router</em> khác trong <em>AS</em>.</p>
<p>Các số <em>local preference</em> là tùy ý, và chỉ có thứ hạng tương đối của chúng là quan trọng. Trong ví dụ trên, các số có thể là 300 và 100 thay vì 3000 và 1000, và hành vi sẽ giống nhau. Các số <em>local preference</em> thường được các nhà khai thác đặt thủ công.</p>
<p>Thuộc tính <strong><em>ASPATH</em> (Đường đi AS)</strong> chứa một danh sách các <em>AS</em> dọc theo tuyến đường đang được quảng bá (theo thứ tự ngược lại). Thuộc tính này là toàn cục, và có thể được gửi trong các thông báo <em>eBGP</em>.</p>
<img width="800px" src="routing/../assets/routing/2-195-attribute2.png">
<p>Ví dụ, một thông báo sẽ có tiền tố IP của đích (128.112.0.0/16), và một thuộc tính <em>ASPATH</em> là.</p>
<p><em>ASPATH</em> là quy tắc phá vỡ thế cân bằng ưu tiên thứ hai khi nhập đường đi. Nếu hai thông báo có cùng <em>local preference</em> (ví dụ: cả hai đều từ khách hàng), thì chúng ta sẽ chọn đường đi ngắn hơn. <em>ASPATH</em> cho chúng ta biết độ dài của mỗi đường đi, được đo bằng số lượng <em>AS</em> mà đường đi đó đi qua.</p>
<p>Nếu <em>local preference</em> và độ dài đường đi bằng nhau, quy tắc phá vỡ thế cân bằng ưu tiên thứ ba là chi phí <em>IGP</em> đến <em>egress router</em>. Chi phí này được lưu trữ trong <em>forwarding table</em> cục bộ của <em>Router</em> (ví dụ: một giao thức distance-vector cục bộ sẽ lưu trữ chi phí đến mọi <em>Router</em> khác trong cùng <em>AS</em>).</p>
<p>Thuộc tính <em><strong>MED</strong></em> mã hóa các ưu tiên của <em>AS</em> xuất. Tương đương, thuộc tính này đại diện cho khoảng cách từ <em>Router</em> xuất đến đích (số thấp hơn được ưu tiên).</p>
<img width="900px" src="routing/../assets/routing/2-196-attribute3.png">
<p>Ví dụ, nếu có hai liên kết giữa hai <em>AS</em> này, cả hai <em>border router</em> từ <em>AS</em> xuất sẽ thông báo một đường đi. <em>ASPATH</em> và đích là giống nhau, vì đường đi của các <em>AS</em> đến đích là giống nhau trong cả hai trường hợp. Tuy nhiên, <em>router</em> phía Tây sẽ bao gồm một số thuộc tính <em>MED</em> thấp hơn, so với <em>router</em> phía Đông. Điều này nói rằng: khi có thể, vui lòng định tuyến các <em>packet</em> cho đích thông qua <em>router</em> phía Tây của tôi (số thấp hơn), vì <em>router</em> này gần đích hơn.</p>
<p>Nếu <em>local preference</em>, độ dài đường đi, và khoảng cách đến <em>egress router</em> đều bằng nhau, quy tắc phá vỡ thế cân bằng ưu tiên thứ tư là số <em>MED</em> bên trong mỗi thông báo.</p>
<h2 id="các-vấn-đề-với-bgp"><a class="header" href="#các-vấn-đề-với-bgp">Các vấn đề với BGP</a></h2>
<p><em>BGP</em> không có đảm bảo bảo mật tích hợp. Một <em>AS</em> độc hại có thể nói dối và quảng bá một tuyến đường đến một đích, ngay cả khi <em>AS</em> đó không thể đến được đích đó. Một <em>AS</em> độc hại cũng có thể quảng bá một tuyến đường rất rẻ đến một đích, ngay cả khi tuyến đường rẻ đó thực sự không tồn tại. Điều này có thể khuyến khích các <em>AS</em> khác định tuyến <em>packet</em> qua <em>AS</em> độc hại, nơi kẻ tấn công có thể xóa hoặc sửa đổi các <em>packet</em> đi qua <em>AS</em> độc hại. Các cuộc tấn công này được gọi là <strong><em>prefix hijacking</em> (chiếm đoạt tiền tố)</strong>. Hiện có nghiên cứu tích cực về việc sử dụng mật mã để bảo mật <em>BGP</em>, mặc dù các giao thức như vậy chưa được triển khai rộng rãi.</p>
<p><em>BGP</em> ưu tiên chính sách hơn là chi phí thấp nhất khi chọn đường đi. Ngoài ra, vì <em>BGP</em> đo độ dài đường đi bằng số lượng <em>AS</em>, độ dài đường đi có thể gây hiểu nhầm (ví dụ: một <em>AS</em> có thể chứa 2 <em>Router</em> hoặc 200 <em>Router</em> dọc theo đường đi đang được quảng bá). Điều này có thể dẫn đến các vấn đề trong đó các <em>packet</em> không phải lúc nào cũng đi theo đường có chi phí thấp nhất, và rất khó để lý giải về hiệu suất trên Internet. Một số người có thể phân loại đây là các vấn đề, mặc dù chúng có thể là một sự đánh đổi thiết kế có chủ ý. Các nhà thiết kế <em>BGP</em> đã đưa ra một lựa chọn thiết kế có ý thức để ưu tiên chính sách và che giấu cấu trúc liên kết nội bộ của một <em>AS</em>, đổi lại là hiệu suất.</p>
<p><em>BGP</em> phức tạp để triển khai. Có nhiều chi tiết triển khai tinh vi mà chúng ta không đề cập đến. Ngay cả trong các chủ đề chúng ta đã đề cập, một số cấu hình nhất định như <em>local preference</em> hoặc số <em>MED</em> phải được nhà khai thác đặt thủ công, và các cấu hình không chính xác có thể dẫn đến các đường đi không chính xác lan truyền qua mạng. Cấu hình sai <em>BGP</em> thường có thể dẫn đến sự cố mất mạng Internet, và có nghiên cứu tích cực về các công cụ để xác minh rằng <em>BGP</em> được cấu hình đúng.</p>
<p><em>BGP</em> yêu cầu một số giả định nhất định (mọi người đều tuân theo các quy tắc Gao-Rexford, biểu đồ <em>AS</em> tạo thành một hệ thống phân cấp, không có chu trình nhà cung cấp-khách hàng) để đảm bảo khả năng tiếp cận và hội tụ. Nếu các giả định này không được đáp ứng (ví dụ: một <em>AS</em> chọn chính sách riêng vi phạm Gao-Rexford), <em>BGP</em> có thể tạo ra hành vi không ổn định, trong đó các tuyến đường không bao giờ hội tụ, hoặc các chu trình và ngõ cụt xuất hiện.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ip-header"><a class="header" href="#ip-header">IP Header</a></h1>
<h2 id="mục-tiêu-thiết-kế-ip-header"><a class="header" href="#mục-tiêu-thiết-kế-ip-header">Mục tiêu thiết kế IP Header</a></h2>
<p>Hãy nhớ lại rằng một giao thức như <em>IP</em> (Giao thức Internet) bao gồm <em>syntax</em> (cú pháp) và <em>semantics</em> (ngữ nghĩa). <em>syntax</em> xác định các trường có trong <em>IP header</em> (phần đầu IP), và <em>semantics</em> xác định cách các trường đó được xử lý.</p>
<p>Cũng hãy nhớ lại rằng <em>packet</em> <em>IP</em> bao gồm một <em>header</em> (phần đầu) và <em>payload</em> (phần dữ liệu). <em>header</em> chứa siêu dữ liệu liên quan mà giao thức <em>IP</em> có thể xử lý. <em>payload</em> chứa bất kỳ dữ liệu nào sẽ được chuyển lên các giao thức lớp cao hơn, và không được giao thức <em>IP</em> phân tích.</p>
<p>Cuối cùng, hãy nhớ lại rằng các <em>header</em> được thêm vào khi chúng ta đi xuống chồng giao thức, và được bóc đi khi chúng ta chuyển các <em>packet</em> lên trên chồng giao thức. <em>IP header</em> được xử lý ở cả các <em>end hosts</em> (máy chủ đầu cuối) và ở mọi <em>Router</em> trung gian.</p>
<p><em>IP header</em> nên càng nhỏ càng tốt. Mỗi <em>packet</em> được gửi qua Internet đều cần đính kèm <em>IP header</em>, vì vậy việc tăng kích thước <em>IP header</em>, dù chỉ một byte, sẽ làm tăng đáng kể tổng lượng <em>bandwidth</em> trên toàn Internet.</p>
<p><em>IP header</em> nên càng đơn giản càng tốt. Mọi <em>Router</em> và <em>end host</em> đều phải xử lý các <em>packet</em> <em>IP</em> khi chúng được gửi và nhận, vì vậy một <em>header</em> phức tạp để xử lý sẽ làm chậm toàn bộ Internet. Lý tưởng nhất, chúng ta muốn <em>header</em> được xử lý hoàn toàn bằng phần cứng, vì vậy chúng ta không thể giả định rằng chúng ta có quyền truy cập vào các hoạt động <em>CPU</em> đa dụng khi xử lý <em>header</em> này.</p>
<h2 id="các-trường-của-ip-header"><a class="header" href="#các-trường-của-ip-header">Các trường của IP Header</a></h2>
<p>Một giao thức <em>IP</em> cần phải làm bốn việc:</p>
<p>Mọi người (các <em>end host</em>, <em>Router</em>) cần có khả năng <strong>phân tích</strong> <em>packet</em> và hiểu các bit có ý nghĩa gì. Để hỗ trợ điều này, <em>header</em> sẽ bao gồm <strong><em>IP version</em> (phiên bản IP)</strong> (giá trị 4-bit), <strong><em>header length</em> (độ dài phần đầu)</strong> (giá trị 4-bit, được đo bằng các từ 4-byte, cần thiết vì độ dài <em>IP header</em> không cố định), và <strong><em>packet length</em> (độ dài gói tin)</strong> (giá trị 16-bit, được đo bằng byte).</p>
<p>Các <em>Router</em> (không phải <em>end host</em>) cần <strong>chuyển tiếp</strong> <em>packet</em> đến <em>Router</em> tiếp theo. Để hỗ trợ điều này, <em>header</em> sẽ bao gồm <strong><em>destination IP address</em> (địa chỉ IP đích)</strong> (giá trị 32-bit).</p>
<p>Các <em>end host</em> (không phải <em>Router</em>) cần <strong>chuyển <em>packet</em> lên</strong> các lớp cao hơn. Để hỗ trợ điều này, <em>header</em> sẽ bao gồm một <strong><em>protocol number</em> (số hiệu giao thức)</strong> (giá trị 8-bit), cho chúng ta biết giao thức Lớp 4 nào (<em>TCP</em> (Giao thức Điều khiển Truyền vận) hoặc <em>UDP</em> (Giao thức Gói Dữ liệu Người dùng)) nên được sử dụng để xử lý <em>payload</em>. Ví dụ, <em>protocol number</em> là 6 có nghĩa là sử dụng giao thức <em>TCP</em> để đọc <em>payload</em> còn lại (đọc các bit đầu tiên của <em>payload</em> là <em>header</em> <em>TCP</em>, v.v.). <em>protocol number</em> là 17 tương ứng với giao thức <em>UDP</em>.</p>
<img width="800px" src="routing/../assets/routing/2-197-demultiplex.png">
<p>Các <em>end host</em> và <em>Router</em> cần có khả năng <strong>gửi các gói tin trả lời</strong> lại cho nguồn. Để hỗ trợ điều này, <em>header</em> sẽ bao gồm <strong><em>source IP address</em> (địa chỉ IP nguồn)</strong> (giá trị 32-bit).</p>
<h2 id="xử-lý-lỗi-ip"><a class="header" href="#xử-lý-lỗi-ip">Xử lý lỗi IP</a></h2>
<p>Các <em>end host</em> và <em>Router</em> cũng cần có khả năng <strong>chỉ định các vấn đề hoặc các trường hợp đặc biệt</strong> trong trường hợp một <em>packet</em> cần xử lý bổ sung.</p>
<p>Các <em>packet</em> <em>IP</em> có thể bị kẹt trong các vòng lặp (ví dụ: nếu <em>routing protocol</em> chưa hội tụ). Một lựa chọn khả dĩ là để <em>packet</em> lặp vô hạn cho đến khi các tuyến đường hội tụ, nhưng việc chuyển tiếp <em>packet</em> diễn ra ở quy mô nano giây, và sự hội tụ định tuyến diễn ra ở quy mô mili giây hoặc giây. Việc để <em>packet</em> lặp cho đến khi các tuyến đường hội tụ có thể mất nhiều thời gian và lãng phí rất nhiều <em>bandwidth</em>. Để ngăn chặn vòng lặp vô hạn, <em>IP header</em> có một <em><strong>time to live (TTL)</strong></em> (giá trị 8-bit), được giảm đi ở mỗi chặng. Nếu <em>TTL</em> về 0, <em>packet</em> sẽ bị loại bỏ, và một thông báo lỗi được gửi lại cho nguồn. (Thông báo lỗi là yêu cầu của đặc tả <em>IP</em>, mặc dù không phải lúc nào cũng được gửi trong thực tế.)</p>
<p>Các <em>packet</em> <em>IP</em> có thể bị hỏng (ví dụ: các bit trên đường truyền có thể bị hỏng do các quá trình điện). Để phát hiện lỗi, <em>IP header</em> chứa một <strong><em>checksum</em> (tổng kiểm tra)</strong> (giá trị 16-bit), và loại bỏ các <em>packet</em> nếu <em>checksum</em> không chính xác.</p>
<p>Lưu ý rằng <em>IP checksum</em> chỉ được tính toán trên <em>IP header</em>. <em>checksum</em> chỉ có thể phát hiện lỗi trong <em>IP header</em>, không phải lỗi trong <em>IP payload</em>. Điều này phản ánh <strong><em>end-to-end principle</em> (nguyên tắc đầu cuối-đầu cuối)</strong>, trong đó chúng ta bắt buộc rằng <em>payload</em> được kiểm tra bởi <em>end host</em>, chứ không phải bởi các <em>Router</em> trung gian.</p>
<p><em>IP checksum</em> được cập nhật tại mỗi <em>Router</em>, vì <em>TTL</em> thay đổi, và <em>checksum</em> phải được tính toán lại. Một thiết kế thay thế khả thi là loại trừ <em>TTL</em> trong <em>checksum</em>, để tiết kiệm cho các <em>Router</em> công việc bổ sung.</p>
<p>Các <em>packet</em> <em>IP</em> có thể quá lớn đối với một liên kết cụ thể. Mỗi liên kết có một <strong><em>maximum transmission unit (MTU)</em> (đơn vị truyền tải tối đa)</strong>, chỉ ra kích thước <em>packet</em> lớn nhất (tính bằng byte) mà liên kết đó có thể mang theo như một đơn vị. Ví dụ, liên kết có thể có bộ nhớ hạn chế để ghi nhớ một <em>packet</em> trong khi nó gửi các bit đi trên đường truyền.</p>
<p><em>end host</em> không biết liên kết nào sẽ mang <em>packet</em>, vì vậy <em>end host</em> có thể gửi một <em>packet</em> quá lớn đối với một trong các liên kết. Để giải quyết vấn đề này, một <em>Router</em> có thể thực hiện <strong><em>fragmentation</em> (phân mảnh)</strong>, chia <em>packet</em> thành nhiều mảnh nhỏ, mà <em>Router</em> ở đầu kia của liên kết phải tập hợp lại để phục hồi <em>packet</em> ban đầu. Các trường <em>identification</em> (định danh) (16-bit), <em>flags</em> (cờ) (3-bit), và <em>offset</em> (độ lệch) (13-bit) trong <em>header</em> được sử dụng để triển khai <em>fragmentation</em>.</p>
<img width="900px" src="routing/../assets/routing/2-198-fragment.png">
<p><em>Fragmentation</em> có thể thực hiện được trong phần cứng (ví dụ: một <em>Router</em> có thể nhanh chóng phân mảnh các <em>packet</em> mà không cần &quot;punt&quot; <em>packet</em> để xử lý đặc biệt), nhưng nó gây ra thêm chi phí. Internet hiện đại tránh <em>fragmentation</em> bất cứ khi nào có thể. Ví dụ, chúng ta cố gắng chuẩn hóa <em>MTU</em> càng nhiều càng tốt (một tiêu chuẩn hiện đại là 1500 byte).</p>
<p>Các nhà thiết kế ban đầu của <em>IP</em> đã không hoàn toàn đi theo thiết kế nỗ lực tối đa (best-effort), và nghĩ rằng có thể hữu ích nếu cho phép các ứng dụng gửi các loại <em>packet</em> khác nhau dựa trên nhu cầu của ứng dụng. Để thực hiện điều này, <em>IP header</em> có các bit <strong><em>Type of Service (ToS)</em> (Loại dịch vụ)</strong> (giá trị 8-bit), có thể được sử dụng để yêu cầu các hình thức phân phối <em>packet</em> khác nhau. Ví dụ, một số <em>packet</em> có thể được đánh dấu là nhạy cảm với độ trễ hoặc ưu tiên cao. Qua nhiều năm, các bit này đã được định nghĩa lại để đại diện cho các giao thức khác nhau, và <em>ToS</em> không còn tồn tại ở dạng ban đầu. Thay vào đó, các bit này bây giờ đại diện cho một khái niệm nào đó về mức độ ưu tiên. Ví dụ về các giao thức sử dụng các bit này là <em>Differentiated Services Code Point (DSCP)</em> (Điểm mã Dịch vụ Phân biệt), định nghĩa các loại lưu lượng nhất định, và <em>Explicit Congestion Notification (ECN)</em> (Thông báo Tắc nghẽn Tường minh), sẽ giúp xử lý tắc nghẽn lưu lượng (sẽ được thảo luận sau).</p>
<p>Trong thiết kế <em>IP</em> ban đầu, các <strong><em>option bits</em> (các bit tùy chọn)</strong> bổ sung có thể được thêm vào <em>IP header</em> để yêu cầu xử lý nâng cao hơn trên <em>packet</em>. Ví dụ, người gửi có thể yêu cầu các <em>Router</em> ghi lại tuyến đường mà <em>packet</em> đang đi (ví dụ: để chẩn đoán). Người gửi có thể bao gồm một tuyến đường nguồn trong <em>header</em> của <em>packet</em> và buộc <em>packet</em> phải đi theo một tuyến đường nhất định. <em>header</em> của <em>packet</em> cũng có thể bao gồm một dấu thời gian. Trong các triển khai hiện đại, các tùy chọn này hầu như luôn bị vô hiệu hóa, vì chúng dẫn đến các triển khai phức tạp không cần thiết làm tăng chi phí xử lý <em>packet</em>. Ví dụ, các tùy chọn này buộc <em>IP header</em> phải có độ dài thay đổi, điều này khó xử lý hơn một <em>header</em> có độ dài cố định.</p>
<img width="900px" src="routing/../assets/routing/2-199-ip-header.png">
<h2 id="các-thay-đổi-trong-header-ipv6"><a class="header" href="#các-thay-đổi-trong-header-ipv6">Các thay đổi trong Header IPv6</a></h2>
<p><em>IPv6</em> (Giao thức Internet phiên bản 6) được thúc đẩy bởi lo ngại rằng cuối cùng chúng ta sẽ hết địa chỉ <em>IPv4</em> (Giao thức Internet phiên bản 4) 32-bit. <em>IPv6</em> <strong>mở rộng địa chỉ</strong> để địa chỉ dài 128 bit. Số lượng địa chỉ <em>IPv6</em> khả dụng là cực lớn (hãy nghĩ đến: số lượng nguyên tử trong vũ trụ), vì vậy chúng ta gần như chắc chắn sẽ không bao giờ hết địa chỉ <em>IPv6</em>.</p>
<p>Các nhà thiết kế <em>IPv6</em> đã nhân cơ hội này để dọn dẹp và hiện đại hóa <em>IP header</em>, loại bỏ và cập nhật các trường đã lỗi thời. Ban đầu, <em>IPv6</em> được dự định là một giao thức tham vọng hơn với nhiều tính năng địa chỉ mới, nhưng hầu hết các tính năng này chưa bao giờ được hiện thực hóa. Trong thực tế, ngoài việc &quot;dọn dẹp mùa xuân&quot; loại bỏ các tính năng lỗi thời này, không có nhiều thay đổi đáng kể đối với giao thức so với <em>IPv4</em>, vì vậy kết quả là một giao thức <em>IP</em> thanh lịch hơn, không có nhiều thay đổi tham vọng.</p>
<p>Lưu ý: Trong trường hợp bạn tò mò, <em>IPv5</em> (Giao thức Internet phiên bản 5) đã được công bố vào năm 1990 (trước <em>IPv6</em> vào năm 1998). Nó là một giao thức thử nghiệm chưa bao giờ được triển khai rộng rãi.</p>
<p><em>IPv6</em> <strong>loại bỏ <em>checksum</em></strong> trong <em>header</em> của <em>packet</em> <em>IP</em>. Lập luận ủng hộ việc bao gồm <em>checksum</em> là: nếu một <em>packet</em> bị hỏng và không được phát hiện, <em>packet</em> hỏng đó tiếp tục được gửi đi, lãng phí <em>bandwidth</em>. Việc bao gồm <em>checksum</em> đảm bảo rằng <em>packet</em> bị loại bỏ và <em>bandwidth</em> không bị lãng phí cho một <em>packet</em> bị hỏng. Trong thời hiện đại, <em>bandwidth</em> ít bị tắc nghẽn hơn, vì vậy <em>checksum</em> không còn cần thiết nữa, và không ảnh hưởng lớn đến hiệu suất nếu một số <em>packet</em> bị hỏng được gửi đi hết mạng.</p>
<p><em>IPv6</em> <strong>loại bỏ <em>fragmentation</em></strong>. Nếu một <em>packet</em> <em>IPv6</em> quá lớn đối với một liên kết cụ thể, <em>Router</em> sẽ loại bỏ <em>packet</em> và gửi một thông báo lỗi trở lại nguồn với kích thước <em>packet</em> tối đa cho phép (<em>MTU</em>). Người gửi ban đầu chịu trách nhiệm chia dữ liệu thành các <em>packet</em> nhỏ hơn và gửi lại các <em>packet</em> nhỏ hơn đó. Các <em>end host</em> (ví dụ: máy tính cá nhân của bạn) xử lý ít <em>packet</em> hơn các <em>Router</em> (ví dụ: trong các trung tâm dữ liệu), vì vậy việc chuyển khối lượng công việc <em>fragmentation</em> từ các <em>Router</em> sang các <em>end host</em> cải thiện khả năng mở rộng tổng thể của Internet.</p>
<p><em>IPv6</em> thay thế phần tùy chọn có độ dài thay đổi bằng một triển khai đã được sửa đổi của trường giao thức. Trong <em>IPv4</em>, các tùy chọn có vấn đề vì chúng tạo ra các <em>header</em> có độ dài thay đổi, khó phân tích hơn. Trong <em>IPv6</em>, <em>header</em> có độ dài cố định. Điều này cũng có nghĩa là trường <em><strong>header length</strong></em> có thể được loại bỏ.</p>
<p>Để tiếp tục hỗ trợ các tùy chọn, <em>IPv6</em> tổng quát hóa trường giao thức để cho phép <em>packet</em> <em>IP</em> được chuyển lên để xử lý đặc biệt trước khi đến Lớp 4. (Hãy nhớ lại, <em>header</em> giao thức trong <em>IPv4</em> được đặt thành 7 hoặc 19, để chỉ ra giao thức Lớp 4 nào sẽ xử lý <em>packet</em> tiếp theo.) Trường này được đổi tên từ protocol thành <strong><em>next header</em> (phần đầu tiếp theo)</strong> trong <em>IPv6</em>.</p>
<img width="800px" src="routing/../assets/routing/2-200-next-header.png">
<p>Nếu bạn muốn một giao thức bổ sung xử lý <em>packet</em> <em>IP</em>, bạn có thể đặt số tương ứng của giao thức đó vào trường <em>next header</em>. Các nhà thiết kế và người dùng của các giao thức bổ sung này cần phải đồng ý về việc số nào tương ứng với giao thức nào, và một tổ chức tiêu chuẩn cần quản lý các số này. Sau đó, <em>payload</em> có thể được chuyển đến giao thức bổ sung, giao thức này có thể đọc một <em>header</em> bổ sung (sau <em>header</em> <em>IPv6</em> Lớp 3, nhưng trước <em>header</em> Lớp 4) và thực hiện xử lý bổ sung, trước khi chuyển <em>payload</em> còn lại đến Lớp 4.</p>
<p>Nếu <em>packet</em> không có tùy chọn bổ sung nào, thì trường <em>next header</em> giống như trường protocol cũ, cho phép <em>packet</em> <em>IP</em> được chuyển trực tiếp lên một giao thức Lớp 4 mà không cần xử lý thêm.</p>
<p>Ý tưởng về các <em>next header</em> có thể được tổng quát hóa để cho phép nhiều giao thức xử lý <em>packet</em> sau <em>IPv6</em>, nhưng trước Lớp 4. Ví dụ, <em>IPv6</em> có thể có một <em>next header</em> để xử lý đặc biệt. Sau đó, <em>header</em> của giao thức xử lý đặc biệt cũng có thể chứa một trường <em>next header</em>, chỉ định một giao thức Lớp 4, hoặc một giao thức xử lý đặc biệt khác nữa. Cách tiếp cận này có khả năng tương thích với tương lai, vì nó hỗ trợ các giao thức trong tương lai chưa được phát minh. Các giao thức trong tương lai đó có thể được thêm vào theo cách tiếp cận <em>next-header</em> này, mà không làm hỏng <em>IPv6</em> hoặc yêu cầu cập nhật <em>IPv6</em>.</p>
<p><em>IPv6</em> thêm một trường <strong><em>flow label</em> (nhãn luồng)</strong> vào <em>header</em>. Ở lớp 3, các <em>packet</em> được gửi độc lập (cách một <em>packet</em> được gửi không ảnh hưởng đến các <em>packet</em> khác), nhưng trong thực tế, thường có nhiều <em>packet</em> liên quan đến nhau theo một cách nào đó. Ví dụ, trong một luồng video giữa hai máy chủ, có thể có nhiều <em>packet</em> được gửi giữa hai ứng dụng giống nhau. Lớp 3 được cho là sẽ xử lý các <em>packet</em> này một cách riêng biệt, nhưng trong thực tế, các <em>Router</em> đã thêm các hệ thống tiên tiến hơn gọi là <strong><em>middleboxes</em> (các hộp trung gian)</strong> (ví dụ: <em>firewalls</em> (tường lửa), <em>intrusion detection systems</em> (hệ thống phát hiện xâm nhập)) có thể quan tâm đến việc các <em>packet</em> này là một phần của cùng một luồng, hoặc kết nối. Ví dụ, một <em>firewall</em> có thể cần đọc nhiều <em>packet</em> từ một kết nối để quyết định xem kết nối đó có nên được cho phép hay chặn. Khi tất cả các <em>packet</em> được gửi độc lập, các <em>middlebox</em> này phải đoán xem hai <em>packet</em> có liên quan đến nhau hay không (ví dụ: nó nhận thấy các <em>packet</em> có cùng địa chỉ IP nguồn/đích). <em>IPv6</em> thêm một cách tường minh để biểu thị rằng nhiều <em>packet</em> có liên quan đến nhau.</p>
<img width="900px" src="routing/../assets/routing/2-201-ipv6-header.png">
<p>Số phiên bản không thay đổi giữa <em>IPv4</em> và <em>IPv6</em>. Độ dài <em>packet</em> không thay đổi (mặc dù được đổi tên từ Total Length thành Payload Length). <em>TTL</em> được đổi tên thành <em>Hop Limit</em> (Giới hạn Chặng), mặc dù chức năng không thay đổi.</p>
<p>Các bit <em>Type of Service</em> được đổi tên thành <em>Traffic Class</em> (Lớp Lưu lượng), và vẫn có thể được sử dụng để thực hiện một số khái niệm về ưu tiên <em>packet</em>.</p>
<p>Nói chung, <em>IPv6</em> đi theo <em>end-to-end principle</em> và yêu cầu <em>end host</em> thực hiện công việc (phân mảnh, xác minh <em>checksum</em> và gửi lại các <em>packet</em> bị hỏng) khi có thể. Một số trường, như <em>hop limit</em> hoặc <em>TTL</em>, về cơ bản là một vấn đề ở cấp độ <em>IP</em>, và không thể được thực hiện bởi các <em>end host</em>. (<em>end host</em> sẽ giúp xử lý một <em>packet</em> đang lặp trong mạng như thế nào?)</p>
<p><em>IPv6</em> cũng cố gắng đơn giản hóa <em>header</em> (loại bỏ các tùy chọn có độ dài thay đổi), trong khi vẫn cho phép khả năng mở rộng cho các cải tiến trong tương lai (cách tiếp cận <em>next-header</em>, <em>flow label</em>).</p>
<h2 id="bảo-mật-ip-header"><a class="header" href="#bảo-mật-ip-header">Bảo mật IP Header</a></h2>
<p><em>IP</em> không có bất kỳ cơ chế bảo mật tích hợp nào để chống lại những kẻ tấn công. Kẻ tấn công có thể gửi một <em>packet</em> với địa chỉ IP nguồn không chính xác, cho phép kẻ tấn công mạo danh người khác. Điều này có thể khiến máy chủ bị mạo danh bị đổ lỗi oan cho một <em>packet</em>. Hoặc, nếu kẻ tấn công gửi một <em>packet</em> giả mạo, gói tin trả lời có thể được gửi đến máy chủ bị mạo danh. Việc nói dối về địa chỉ nguồn được gọi là <strong><em>IP spoofing</em> (giả mạo IP)</strong>.</p>
<p><em>IP spoofing</em> có thể được sử dụng cho các cuộc <strong><em>denial-of-service (DoS) attacks</em> (tấn công từ chối dịch vụ)</strong>. Một cuộc tấn công DoS có thể được sử dụng để làm quá tải một máy chủ và khiến nó bị sập bằng cách làm ngập máy chủ với các <em>packet</em>. Nếu tất cả các <em>packet</em> đến từ cùng một người gửi, máy chủ có thể ngăn chặn cuộc tấn công bằng cách bỏ qua các <em>packet</em> từ địa chỉ IP của kẻ tấn công. Tuy nhiên, nếu kẻ tấn công nói dối về địa chỉ IP nguồn, máy chủ sẽ khó phân biệt hơn giữa lưu lượng của kẻ tấn công và lưu lượng hợp pháp.</p>
<p>Các cuộc tấn công tinh vi hơn liên quan đến giả mạo tồn tại, mặc dù chúng ta sẽ không đề cập chi tiết trong lớp học này (xem ghi chú của CS 161 tại UC Berkeley để biết thêm chi tiết).</p>
<p>Trường <em>ToS</em> trong <em>IP header</em> cho phép người gửi đặt mức độ ưu tiên cho các <em>packet</em> của họ. Nếu chúng ta cho phép mọi người tự đặt mức độ ưu tiên, những người dùng độc hại có thể đặt mức độ ưu tiên cao hơn và lừa mạng ưu tiên lưu lượng của kẻ tấn công.</p>
<p>Nếu mạng tính phí bổ sung cho lưu lượng ưu tiên cao, kẻ tấn công có thể gửi một <em>packet</em> ưu tiên cao giả mạo, và máy chủ bị mạo danh sẽ phải trả tiền cho lưu lượng của kẻ tấn công.</p>
<p>Thiết kế Internet ban đầu không ngăn chặn các cuộc tấn công này, mặc dù các <em>ISP</em> (nhà cung cấp dịch vụ Internet) hiện đại đã triển khai các biện pháp bảo mật bổ sung để giảm thiểu các cuộc tấn công ở lớp <em>IP</em>. Trong Internet hiện đại, các <em>ISP</em> không cho phép các <em>end host</em> đặt trường <em>ToS</em>, và nhiều <em>ISP</em> có các công cụ để phát hiện và chặn các <em>packet</em> giả mạo.</p>
<p>Trong <em>IPv4</em>, kẻ tấn công có thể cố tình gửi các <em>packet</em> lớn, buộc các <em>Router</em> phải thực hiện thêm công việc phân mảnh các <em>packet</em> đó. Hoặc, kẻ tấn công có thể cố tình thêm các tùy chọn bổ sung, buộc các <em>Router</em> phải xử lý các tùy chọn bổ sung đó. Điều này có thể được sử dụng để thực hiện các cuộc tấn công DoS và làm quá tải khả năng xử lý của một <em>Router</em>.</p>
<p>Trường <em>TTL</em> có thể bị khai thác để tìm hiểu về cấu trúc liên kết mạng. Bạn có thể gửi một <em>packet</em> với <em>TTL</em> là 1. <em>packet</em> sẽ hết hạn ở chặng đầu tiên, và <em>Router</em> đầu tiên sẽ gửi cho bạn một thông báo lỗi, cho phép bạn biết được danh tính của <em>Router</em> đầu tiên.</p>
<img width="600px" src="routing/../assets/routing/2-202-traceroute1.png">
<p>Sau đó, bạn có thể gửi một <em>packet</em> với <em>TTL</em> là 2, nó sẽ hết hạn ở chặng thứ hai. <em>Router</em> thứ hai sẽ gửi cho bạn một thông báo lỗi, cho phép bạn cũng khám phá ra <em>Router</em> thứ hai.</p>
<img width="600px" src="routing/../assets/routing/2-203-traceroute2.png">
<p>Bằng cách lặp lại điều này với <em>TTL</em> là 3, <em>TTL</em> là 4, v.v., bạn có thể khám phá tất cả các <em>Router</em> trên đường đi của mình. Cuộc tấn công này được gọi là <strong><em>traceroute</em> (công cụ theo dõi đường đi)</strong>, mặc dù những người khác cho rằng nó không phải là một cuộc tấn công và hữu ích cho việc chẩn đoán.</p>
<img width="600px" src="routing/../assets/routing/2-204-traceroute3.png">
<p>Việc lặp lại cuộc tấn công này trên các nguồn và đích khác nhau cho phép bạn tìm hiểu thêm về cấu trúc liên kết mạng. Một số <em>Router</em> không gửi thông báo lỗi khi <em>TTL</em> bị vượt quá, điều này có thể hạn chế việc khai thác này.</p>
<p>Về mặt lý thuyết, kẻ tấn công có thể giả mạo trường giao thức hoặc <em>checksum</em>, nhưng điều này có khả năng khiến <em>packet</em> bị loại bỏ vì giao thức hoặc <em>checksum</em> không hợp lệ, vì vậy các cuộc tấn công thực tế với hai trường này không thực sự tồn tại.</p>
<img width-="800px" src="routing/../assets/routing/2-205-attacks.png"><div style="break-before: page; page-break-before: always;"></div><h1 id="nguyên-lý-của-tầng-vận-chuyển-transport-layer-principles"><a class="header" href="#nguyên-lý-của-tầng-vận-chuyển-transport-layer-principles">Nguyên lý của Tầng Vận chuyển (<em>Transport Layer Principles</em>)</a></h1>
<h2 id="trừu-tượng-hóa-và-mục-tiêu-của-Độ-tin-cậy-reliability-abstraction-and-goals"><a class="header" href="#trừu-tượng-hóa-và-mục-tiêu-của-Độ-tin-cậy-reliability-abstraction-and-goals">Trừu tượng hóa và Mục tiêu của Độ tin cậy (<em>Reliability Abstraction and Goals</em>)</a></h2>
<p>Nhiều ứng dụng yêu cầu độ tin cậy (<em>reliability</em>). Ví dụ, khi gửi một tệp qua Internet, chúng ta muốn bên nhận nhận được đúng các byte theo đúng thứ tự mà bên gửi đã gửi.</p>
<p>Tuy nhiên, <em>Layer 3</em> (tầng 3) chỉ cung cấp dịch vụ truyền gói tin (<em>packet</em>) không đáng tin cậy, theo cơ chế <em>best-effort</em> (nỗ lực tối đa nhưng không đảm bảo). Gói tin có thể bị mất (<em>dropped</em>), bị hỏng (<em>corrupted</em>), và bị thay đổi thứ tự (thứ tự gói tin gửi không khớp với thứ tự gói tin nhận). Gói tin cũng có thể bị trễ (ví dụ: bị kẹt trong hàng đợi chờ qua một liên kết).</p>
<p>Trong một số trường hợp hiếm, gói tin thậm chí có thể bị nhân bản (<em>duplicated</em>), khi bên gửi chỉ gửi một gói tin nhưng bên nhận lại nhận được nhiều bản sao của gói đó. Điều này thường xảy ra nếu một <em>router</em> trên đường truyền gặp lỗi nào đó. Trên thực tế, lỗi này rất hiếm.</p>
<p>Thông tin thú vị: Vern Paxson, giảng viên tại UC Berkeley, là một trong những người đầu tiên phát hiện và báo cáo hiện tượng gói tin bị nhân bản ở tầng liên kết (<em>link layer</em>).</p>
<p>Chúng ta sẽ sử dụng <em>Layer 4</em> (tầng vận chuyển – <em>transport layer</em>) để lấp đầy khoảng trống này bằng cách phát triển các giao thức dựa trên trừu tượng hóa truyền gói tin <em>best-effort</em> do mạng cung cấp, và cung cấp một trừu tượng hóa đáng tin cậy mà lập trình viên ứng dụng có thể sử dụng.</p>
<p>Vì lý do thực tiễn (được thảo luận ở phần khác), độ tin cậy được triển khai tại các <em>end host</em> (máy đầu cuối), không phải tại các <em>router</em> trung gian. Ngoài ra, độ tin cậy được triển khai trong hệ điều hành (<em>operating system</em>) để thuận tiện, giúp các ứng dụng không phải tự triển khai lại cơ chế này.</p>
<img width="900px" src="transport//assets/transport/3-007-reliability-at-end-hosts.png">
<p>Chúng ta sẽ chính thức hóa khái niệm độ tin cậy bằng cách định nghĩa <strong>at-least-once delivery</strong> (giao hàng ít nhất một lần). Trong mô hình này, đích đến phải nhận được mọi gói tin, không bị hỏng, ít nhất một lần, nhưng có thể nhận nhiều bản sao của cùng một gói. <em>Transport layer</em> sẽ sử dụng truyền <em>best-effort</em> để cung cấp <em>at-least-once delivery</em>. Sau đó, dựa trên <em>at-least-once delivery</em>, giao thức của chúng ta có thể loại bỏ các bản sao và cung cấp <em>exactly-once delivery</em> (giao hàng chính xác một lần) cho ứng dụng.</p>
<p>Lưu ý rằng truyền tin đáng tin cậy không đảm bảo rằng gói tin sẽ được gửi đi. Một máy tính không kết nối mạng thì không thể gửi dữ liệu đến đích, bất kể chúng ta dùng giao thức độ tin cậy nào. Các giao thức độ tin cậy được phép từ bỏ và không gửi một gói tin, nhưng lỗi này phải được báo cho ứng dụng. Giao thức không được phép báo sai rằng đã gửi thành công một gói tin.</p>
<p>Giao thức của chúng ta cũng cần hiệu quả. Cụ thể hơn, giao thức nên truyền dữ liệu nhanh nhất có thể, đồng thời giảm thiểu việc sử dụng <em>bandwidth</em> (băng thông) và tránh gửi gói tin không cần thiết. Ví dụ, chúng ta có thể đảm bảo gói tin đến nơi bằng cách gửi lại mỗi gói hàng trăm lần, nhưng điều này sẽ vi phạm yêu cầu sử dụng <em>bandwidth</em> hiệu quả.</p>
<h2 id="mục-tiêu-của-tầng-vận-chuyển-transport-layer-goals"><a class="header" href="#mục-tiêu-của-tầng-vận-chuyển-transport-layer-goals">Mục tiêu của Tầng Vận chuyển (<em>Transport Layer Goals</em>)</a></h2>
<p>Tại <em>transport layer</em>, mục tiêu của chúng ta là cung cấp cho ứng dụng một trừu tượng hóa tiện lợi, giúp lập trình viên dễ dàng hơn. <em>Transport layer</em> cho phép lập trình viên nghĩ theo khái niệm kết nối (<em>connection</em>), thay vì từng gói tin riêng lẻ được gửi qua mạng. Lý tưởng nhất, lập trình viên không cần quan tâm đến các chi tiết mạng cấp thấp như chia nhỏ dữ liệu dài thành gói tin, gửi lại gói tin bị mất, <em>timeout</em> (hết thời gian chờ), v.v.</p>
<p><em>Reliability</em> chỉ là một trong nhiều mục tiêu mà chúng ta muốn đạt được ở <em>transport layer</em>.</p>
<p><em>Transport layer</em> triển khai <strong>demultiplexing</strong> (tách luồng) giữa các tiến trình khác nhau tại <em>end host</em>, bằng cách sử dụng số <em>port</em> (cổng) để liên kết mỗi luồng (<em>flow</em> hoặc <em>connection</em>) với một tiến trình khác nhau trên <em>end host</em>.</p>
<p><em>Transport layer</em> cũng triển khai <em>flow control</em> (điều khiển luồng) và <em>congestion control</em> (điều khiển tắc nghẽn), giúp giới hạn tốc độ gửi gói tin để tránh làm quá tải bộ nhận và mạng.</p>
<h2 id="tách-luồng-bằng-port-demultiplexing-with-ports"><a class="header" href="#tách-luồng-bằng-port-demultiplexing-with-ports">Tách luồng bằng <em>Port</em> (<em>Demultiplexing with Ports</em>)</a></h2>
<p>Giả sử máy tính cá nhân của tôi có hai ứng dụng cùng kết nối đến một máy chủ. Khi các gói tin đến máy tính của tôi, chúng có cùng địa chỉ <em>IP</em> nguồn (máy chủ) và cùng địa chỉ <em>IP</em> đích (máy tính của tôi). Làm sao tôi biết gói tin nào dành cho ứng dụng nào?</p>
<img width="900px" src="transport//assets/transport/3-001-demultiplex.png">
<p>Để phân biệt, hay <strong>demultiplex</strong>, gói tin nào dành cho ứng dụng nào, <em>transport layer</em> thêm vào tiêu đề một <strong>port number</strong> (số cổng), dùng để xác định một ứng dụng cụ thể trên <em>end host</em>.</p>
<img width="900px" src="transport//assets/transport/3-002-ports.png">
<p>Khi <em>transport layer</em> nhận một gói tin, nó có thể dùng số <em>port</em> để quyết định ứng dụng tầng cao nào sẽ nhận phần dữ liệu (<em>payload</em>). Vì <em>transport layer</em> được triển khai trong <em>operating system</em>, các <em>port</em> (đôi khi gọi là <strong>logical ports</strong> – cổng logic) là điểm kết nối nơi ứng dụng liên kết với ngăn xếp mạng (<em>network stack</em>) của hệ điều hành. Ứng dụng biết số <em>port</em> của mình, và hệ điều hành biết số <em>port</em> của tất cả ứng dụng, nhờ đó dữ liệu được truyền chính xác giữa ứng dụng và hệ điều hành (không bị lẫn với dữ liệu của ứng dụng khác).</p>
<img width="800px" src="transport//assets/transport/3-003-port-attachment.png">
<p>Số <em>port</em> dài 16 bit. Internet hiện đại thường sử dụng mô hình <em>client-server</em> (máy khách – máy chủ), trong đó <em>client</em> truy cập dịch vụ và <em>server</em> cung cấp dịch vụ. <em>Server</em> thường lắng nghe yêu cầu trên các <em>well-known ports</em> (cổng nổi tiếng, số từ 0–1023). <em>Client</em> biết các cổng này và có thể truy cập để yêu cầu dịch vụ. Ví dụ, các giao thức tầng ứng dụng với cổng nổi tiếng gồm <em>HTTP</em> (cổng 80) và <em>SSH</em> (cổng 22).</p>
<p>Ngược lại, <em>client</em> có thể chọn số <em>port</em> ngẫu nhiên (thường từ 1024–65535). Các số <em>port</em> này có thể được chọn ngẫu nhiên vì <em>client</em> là bên khởi tạo kết nối, và không ai cần <em>client</em> có số <em>port</em> cố định (vì <em>client</em> không cung cấp dịch vụ). Số <em>port</em> của <em>client</em> là <strong>ephemeral</strong> (tạm thời), vì có thể bỏ sau khi kết nối kết thúc.</p>
<h2 id="trừu-tượng-hóa-luồng-byte-bytestream-abstraction"><a class="header" href="#trừu-tượng-hóa-luồng-byte-bytestream-abstraction">Trừu tượng hóa luồng byte (<em>Bytestream Abstraction</em>)</a></h2>
<p>Việc triển khai <em>reliability</em> (độ tin cậy) ở <em>transport layer</em> (tầng vận chuyển) có nghĩa là lập trình viên ứng dụng không còn phải nghĩ đến từng <em>packet</em> (gói tin) kích thước giới hạn được gửi qua mạng. Thay vào đó, lập trình viên có thể nghĩ theo khái niệm <strong>reliable in-order bytestream</strong> (luồng byte đáng tin cậy, đúng thứ tự).</p>
<p>Phía gửi có một luồng byte không giới hạn độ dài và cung cấp luồng này cho <em>transport layer</em>. Sau đó, phía nhận sẽ nhận được chính xác cùng luồng byte đó, theo đúng thứ tự, không mất byte nào. Bạn có thể hình dung <em>bytestream</em> như một đường ống: phía gửi đưa từng byte vào một đầu ống, và các byte đó xuất hiện ở đầu kia của ống theo đúng thứ tự.</p>
<p>Phía gửi và phía nhận không cần quan tâm đến việc gửi lại các <em>packet</em> bị mất hay xử lý <em>packet</em> đến sai thứ tự, vì giao thức <em>transport layer</em> sẽ đảm nhiệm điều đó cho lập trình viên.</p>
<img width="900px" src="transport//assets/transport/3-004-bytestream.png">
<h2 id="udp-và-datagram"><a class="header" href="#udp-và-datagram"><em>UDP</em> và <em>Datagram</em></a></h2>
<p>Đôi khi, ứng dụng không cần <em>reliability</em>. Ví dụ, hãy xem xét một cảm biến đo áp suất nước trong nhà bạn. Cảm biến này gửi một bản ghi (thông điệp nhỏ, kích thước cố định, gồm thời gian và áp suất nước) đến công ty cấp nước mỗi phút.</p>
<p>Hệ thống này có thể không cần các <em>packet</em> đến đúng thứ tự (ví dụ: nếu bản ghi đã bao gồm dấu thời gian), và cũng có thể không cần khả năng chia nhỏ thông điệp dài thành nhiều <em>packet</em> (mỗi bản ghi vốn đã nhỏ). Hệ thống thậm chí có thể không cần <em>reliability</em>, miễn là phần lớn bản ghi đến được công ty cấp nước.</p>
<p>Các ứng dụng không cần <em>reliability</em> có thể sử dụng <strong>UDP</strong> (<em>User Datagram Protocol</em> – Giao thức gói tin người dùng) thay vì <em>TCP</em> ở <em>transport layer</em>. <em>UDP</em> không cung cấp đảm bảo <em>reliability</em>. Nếu ứng dụng cần một <em>packet</em> đến nơi, ứng dụng phải tự xử lý việc gửi lại (vì <em>transport layer</em> sẽ không gửi lại).</p>
<p>Thông điệp trong <em>UDP</em> bị giới hạn trong một <em>packet</em>. Nếu ứng dụng muốn gửi thông điệp lớn hơn, ứng dụng phải tự chia nhỏ và ghép lại. Lưu ý rằng <em>UDP</em> vẫn sử dụng khái niệm <em>port</em> để <em>demultiplexing</em> (tách luồng).</p>
<img width="900px" src="transport//assets/transport/3-005-datagram.png">
<p>Ở <em>transport layer</em>, bạn có thể chọn dùng <em>UDP</em> hoặc <em>TCP</em> tùy nhu cầu, nhưng không thể dùng cả hai cùng lúc. <em>UDP</em> và <em>TCP</em> là các giao thức <em>transport layer</em> tiêu chuẩn trên Internet hiện đại.</p>
<img width="300px" src="transport//assets/transport/3-006-tcp-features.png">
<h2 id="các-thiết-kế-reliability-khác-other-reliability-designs"><a class="header" href="#các-thiết-kế-reliability-khác-other-reliability-designs">Các thiết kế <em>Reliability</em> khác (<em>Other Reliability Designs</em>)</a></h2>
<p><em>TCP</em> ban đầu được triển khai bởi Vint Cerf và Bob Kahn khi họ còn là sinh viên tại UCLA. Sau này, họ đã nhận Giải thưởng Turing, Huân chương Tự do của Tổng thống, v.v. cho công trình của mình.</p>
<p>Điều đáng chú ý là thiết kế ban đầu của <em>TCP</em> khá giống với những gì đang được sử dụng trong thực tế ngày nay và đã đứng vững trước thử thách của thời gian. Các ý tưởng cốt lõi của <em>TCP</em> rất đơn giản, thiết kế thanh thoát (dù không hoàn hảo). Tuy nhiên, việc triển khai có thể phức tạp để làm đúng, và rủi ro cao vì gần như toàn bộ Internet hiện đại chạy trên <em>TCP</em>.</p>
<p>Kể từ khi ra đời, nhiều thành phần riêng lẻ của <em>TCP</em> đã được cải tiến (ví dụ: thuật toán ước lượng bộ định thời tốt hơn, cơ chế <em>acknowledgement</em> thông minh hơn, lựa chọn <em>ISN</em> tốt hơn, <em>congestion control</em> thông minh hơn), nhưng các quyết định kiến trúc và trừu tượng hóa cốt lõi (luồng byte theo kết nối, cửa sổ truyền) vẫn giữ nguyên.</p>
<p><em>TCP</em> là giao thức <em>reliability</em> tiêu chuẩn trên Internet, nhưng vẫn tồn tại các cách tiếp cận hoàn toàn khác.</p>
<p>Ví dụ, phía gửi có thể tận dụng ý tưởng <strong>redundancy</strong> (dư thừa – như trong mã sửa lỗi (<em>error-correcting codes</em>) hoặc <em>RAID</em>) để gửi dữ liệu đáng tin cậy hơn. Thay vì gửi nguyên dữ liệu, phía gửi mã hóa dữ liệu thành nhiều <em>packet</em> hơn, với phần dư thừa được chèn vào mỗi <em>packet</em>.</p>
<p>Ví dụ: người dùng có 10 <em>packet</em>, và một thuật toán có thể mã hóa dữ liệu đó thành 20 <em>packet</em>. Thuật toán có thể đảm bảo rằng chỉ cần nhận được bất kỳ 15 trong số 20 <em>packet</em>, dữ liệu gốc gồm 10 <em>packet</em> có thể được khôi phục.</p>
<p>Một cách mô tả chính xác hơn: thuật toán mã hóa nhận vào <em>k</em> <em>packet</em>, mã hóa thành <em>n</em> <em>packet</em> (với <em>n</em> &gt; <em>k</em>), sao cho dữ liệu gốc có thể được khôi phục nếu nhận được bất kỳ <em>k'</em> <em>packet</em> nào (với <em>k'</em> &gt; <em>k</em> nhưng <em>k'</em> &lt; <em>n</em>).</p>
<p>Các sơ đồ mã hóa (<em>coding schemes</em>) là một chủ đề sâu rộng với nhiều thuật toán (ví dụ: <em>fountain codes</em>, <em>raptor codes</em>), dù ở đây chúng ta sẽ không đi sâu. Chúng có thể được ứng dụng thực tế trong các nền tảng truyền phát video (<em>video streaming</em>).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="thiết-kế-tcp-tcp-design"><a class="header" href="#thiết-kế-tcp-tcp-design">Thiết kế TCP (TCP Design)</a></h1>
<h2 id="gửi-một-gói-tin-duy-nhất-một-cách-Đáng-tin-cậy-reliably-delivering-a-single-packet"><a class="header" href="#gửi-một-gói-tin-duy-nhất-một-cách-Đáng-tin-cậy-reliably-delivering-a-single-packet">Gửi một Gói tin Duy nhất một cách Đáng tin cậy (Reliably Delivering a Single Packet)</a></h2>
<p>Thời gian để một gói tin di chuyển từ người gửi đến người nhận là <strong>one-way delay</strong> (độ trễ một chiều). Thời gian để một gói tin di chuyển từ người gửi đến người nhận, cộng với thời gian để một gói tin trả lời di chuyển từ người nhận đến người gửi, là <strong>round-trip time (RTT)</strong> (thời gian trọn vòng).</p>
<img width="800px" src="transport/../assets/transport/3-008-tcpdemo1.png">
<p>Hãy xây dựng trực giác bằng cách thiết kế một giao thức đơn giản hóa để gửi một gói tin duy nhất một cách đáng tin cậy.</p>
<p>Người gửi cố gắng gửi một gói tin. Làm thế nào người gửi biết được gói tin đã được nhận thành công hay chưa?</p>
<img width="800px" src="transport/../assets/transport/3-009-tcpdemo2.png">
<p>Người nhận có thể gửi một tin nhắn <strong>acknowledgment (ack)</strong> (tin báo nhận), xác nhận rằng gói tin đã được nhận.</p>
<p>Điều gì xảy ra nếu gói tin bị mất?</p>
<p>Chúng ta có thể gửi lại gói tin nếu nó bị mất. Làm thế nào chúng ta biết khi nào cần gửi lại gói tin?</p>
<img width="600px" src="transport/../assets/transport/3-010-tcpdemo3.png">
<p>Người gửi có thể duy trì một bộ đếm thời gian. Khi bộ đếm thời gian hết hạn, chúng ta có thể gửi lại gói tin.</p>
<p>Khi người gửi nhận được một ack, người gửi có thể hủy bộ đếm thời gian và không cần phải gửi lại gói tin.</p>
<p>Điều gì xảy ra nếu ack bị mất?</p>
<img width="600px" src="transport/../assets/transport/3-011-tcpdemo4.png">
<p>Giao thức vẫn hoạt động mà không cần sửa đổi. Người gửi sẽ hết thời gian chờ (không nhận được ack) và gửi lại gói tin cho đến khi ack được gửi thành công. Trong trường hợp này, đích đến đã nhận được hai bản sao của cùng một gói tin, nhưng điều đó không sao cả. Đích đến có thể nhận thấy bản sao trùng lặp và loại bỏ nó.</p>
<p>Bộ đếm thời gian nên được đặt như thế nào? Nếu bộ đếm thời gian quá dài, gói tin có thể mất nhiều thời gian hơn cần thiết để được gửi đi. Nếu bộ đếm thời gian quá ngắn, gói tin có thể được gửi lại khi không cần thiết. Việc đặt sai bộ đếm thời gian có thể ảnh hưởng đến các mục tiêu hiệu quả của chúng ta.</p>
<p>Một khoảng thời gian tốt cho bộ đếm sẽ là round-trip time. Đây là lúc người gửi mong đợi nhận được ack, vì vậy nếu ack chưa đến vào thời điểm đó, người gửi nên gửi lại gói tin.</p>
<p>Trên thực tế, việc ước tính RTT có thể khó khăn. RTT có thể thay đổi tùy thuộc vào đường đi mà gói tin đi qua mạng, và ngay cả trên một đường đi cụ thể, RTT có thể bị ảnh hưởng bởi tải và tắc nghẽn trên đường đi đó.</p>
<p>Một cách để ước tính RTT là đo thời gian giữa việc gửi một gói tin và nhận được ack cho gói tin đó. Chúng ta có thể nhận được một phép đo RTT ước tính từ mỗi gói tin được gửi, và áp dụng một thuật toán nào đó (ví dụ: trung bình động hàm mũ) để kết hợp các phép đo này thành một ước tính RTT. Thuật toán của chúng ta cũng sẽ phải tính đến việc các tin nhắn được gửi lại (sự biến thiên trong các phép đo).</p>
<p>Trên thực tế, các nhà khai thác thường có xu hướng đặt bộ đếm thời gian dài hơn. Nếu bộ đếm thời gian quá ngắn, và việc hết thời gian chờ liên tục xảy ra, kết nối của bạn có lẽ đang hoạt động kém (liên tục gửi lại các gói tin).</p>
<p>Điều gì sẽ xảy ra nếu các bit bị hỏng?</p>
<img width="600px" src="transport/../assets/transport/3-012-tcpdemo5.png">
<p>Chúng ta có thể thêm một checksum (tổng kiểm) trong phần đầu của lớp vận chuyển (khác với checksum của lớp IP). Khi người nhận thấy một gói tin bị hỏng, nó có thể làm hai việc: Hoặc người nhận có thể gửi lại một cách tường minh một <strong>negative acknowledgement (nack)</strong> (tin báo nhận tiêu cực), yêu cầu người gửi gửi lại gói tin.</p>
<p>Hoặc, người nhận có thể bỏ gói tin bị hỏng và không làm gì cả (không gửi ack hay nack). Sau đó, người gửi sẽ hết thời gian chờ và gửi lại gói tin.</p>
<img width="600px" src="transport/../assets/transport/3-013-tcpdemo6.png">
<p>Cả hai cách tiếp cận (nack hoặc chờ hết thời gian) đều hoạt động, mặc dù TCP sử dụng cách thứ hai (chờ hết thời gian) và không triển khai nack.</p>
<p>Điều gì sẽ xảy ra nếu các gói tin bị trễ?</p>
<img width="500px" src="transport/../assets/transport/3-014-tcpdemo7.png">
<p>Không cần sửa đổi gì. Nếu độ trễ rất dài, người gửi có thể hết thời gian chờ trước khi ack đến. Người gửi sẽ gửi lại gói tin (vì vậy người nhận có thể nhận được hai bản sao), và người gửi có thể nhận được hai ack, nhưng điều đó không sao cả.</p>
<p>Điều gì sẽ xảy ra nếu người gửi gửi một gói tin, nhưng nó bị nhân đôi trong mạng, và người nhận nhận được hai bản sao?</p>
<img width="500px" src="transport/../assets/transport/3-015-tcpdemo8.png">
<p>Không cần sửa đổi gì. Người nhận sẽ gửi hai ack, nhưng cả người gửi và người nhận đều có thể xử lý các bản sao một cách an toàn.</p>
<p>Lưu ý: Từ giao thức đơn giản hóa này, chúng ta có thể thấy rằng đôi khi người nhận nhận được hai bản sao của gói tin. Nếu một liên kết cụ thể đang triển khai một giao thức đảm bảo độ tin cậy, phía nhận của liên kết có thể nhận được hai bản sao. Thông thường, bản sao sẽ bị loại bỏ và chỉ một gói tin được chuyển tiếp đến đích. Nhưng, nếu router bị treo và khởi động lại trong khoảng thời gian giữa hai bản sao đến, router có thể chuyển tiếp cả hai bản sao đến đích.</p>
<p>Tóm lại, giao thức đảm bảo độ tin cậy cho một gói tin duy nhất là:</p>
<p>Nếu bạn là người gửi: Gửi gói tin, và đặt một bộ đếm thời gian. Nếu không có ack nào đến trước khi bộ đếm thời gian kết thúc, hãy gửi lại gói tin và đặt lại bộ đếm thời gian. Dừng và hủy bộ đếm thời gian khi ack đến.</p>
<p>Nếu bạn là người nhận: Nếu bạn nhận được gói tin không bị hỏng, hãy gửi một ack. (Bạn có thể gửi nhiều ack nếu bạn nhận được gói tin nhiều lần.)</p>
<p>Các ý tưởng cốt lõi trong ví dụ này cũng sẽ được áp dụng cho các giao thức sau này: checksum (để chống lỗi), acknowledgements, gửi lại gói tin, và hết thời gian chờ.</p>
<p>Lưu ý rằng giao thức này đảm bảo việc gửi ít nhất một lần, vì có thể tồn tại các bản sao.</p>
<h2 id="gửi-nhiều-gói-tin-một-cách-Đáng-tin-cậy-reliably-delivering-multiple-packets"><a class="header" href="#gửi-nhiều-gói-tin-một-cách-Đáng-tin-cậy-reliably-delivering-multiple-packets">Gửi Nhiều Gói tin một cách Đáng tin cậy (Reliably Delivering Multiple Packets)</a></h2>
<p>Giao thức này sẽ được mở rộng cho nhiều gói tin như thế nào?</p>
<img width="500px" src="transport/../assets/transport/3-016-tcpdemo9.png">
<p>Chúng ta có thể tuân theo các quy tắc truyền tin tương tự (gửi lại khi hết thời gian chờ) cho mỗi gói tin. Để phân biệt các gói tin, chúng ta có thể đính kèm một <strong>sequence number</strong> (số thứ tự) duy nhất cho mỗi gói tin. Mỗi ack sẽ liên quan đến một gói tin cụ thể. Sequence numbers cũng có thể giúp chúng ta sắp xếp lại các gói tin nếu chúng đến không đúng thứ tự.</p>
<p>Người gửi sẽ gửi mỗi gói tin khi nào? Cách tiếp cận đơn giản nhất là giao thức <strong>stop and wait</strong> (dừng và chờ), trong đó người gửi đợi gói tin i được xác nhận trước khi gửi gói tin i+1. Điều này sẽ cung cấp độ tin cậy một cách chính xác, nhưng rất chậm. Mỗi gói tin mất ít nhất một RTT để được gửi đi (nhiều hơn nếu một gói tin bị mất hoặc bị hỏng).</p>
<img width="600px" src="transport/../assets/transport/3-017-tcpdemo10.png">
<p>Giao thức này có thể hoạt động trong các môi trường nhỏ hơn nơi hiệu quả ít được quan tâm hơn, nhưng điều này quá chậm đối với Internet. Làm thế nào chúng ta có thể làm cho nó nhanh hơn?</p>
<img width="600px" src="transport/../assets/transport/3-018-tcpdemo11.png">
<p>Chúng ta có thể gửi các gói tin song song. Cụ thể hơn, chúng ta có thể gửi nhiều gói tin hơn trong khi chờ ack đến. Khi một gói tin được gửi đi, nhưng ack tương ứng của nó chưa được nhận, chúng ta gọi gói tin đó là <strong>in flight</strong> (đang trên đường truyền).</p>
<p>Cách tiếp cận đơn giản nhất là gửi tất cả các gói tin ngay lập tức, nhưng điều này có thể làm quá tải mạng (ví dụ: liên kết đến máy tính của bạn có thể có bandwidth hạn chế).</p>
<h2 id="thuật-toán-dựa-trên-cửa-sổ-window-based-algorithms"><a class="header" href="#thuật-toán-dựa-trên-cửa-sổ-window-based-algorithms">Thuật toán dựa trên Cửa sổ (Window-Based Algorithms)</a></h2>
<p>Gửi từng gói tin một thì quá chậm, nhưng gửi tất cả các gói tin cùng một lúc sẽ làm quá tải mạng. Để giải quyết vấn đề này, chúng ta sẽ đặt một giới hạn W và nói rằng chỉ có thể có W gói tin in flight tại bất kỳ thời điểm nào. Đây là ý tưởng chính đằng sau <strong>window-based protocols</strong> (các giao thức dựa trên cửa sổ), trong đó W là kích thước của cửa sổ.</p>
<p>Nếu W là số lượng gói tin in flight tối đa, thì người gửi có thể bắt đầu bằng cách gửi W gói tin. Khi một ack đến, chúng ta gửi gói tin tiếp theo trong hàng đợi.</p>
<img width="500px" src="transport/../assets/transport/3-019-window1.png">
<p>W nên được chọn như thế nào?</p>
<p>Chúng ta muốn sử dụng hết công suất mạng hiện có của mình (&quot;lấp đầy đường ống&quot;). Nếu W quá thấp, chúng ta không sử dụng hết bandwidth có sẵn cho mình.</p>
<p>Tuy nhiên, chúng ta không muốn làm quá tải các liên kết, vì những người khác cũng có thể đang sử dụng liên kết đó (congestion control (kiểm soát tắc nghẽn)). Chúng ta cũng không muốn làm quá tải người nhận, người cần nhận và xử lý tất cả các gói tin từ người gửi (flow control (kiểm soát luồng)).</p>
<h2 id="kích-thước-cửa-sổ-lấp-đầy-Đường-ống-window-size-filling-the-pipe"><a class="header" href="#kích-thước-cửa-sổ-lấp-đầy-Đường-ống-window-size-filling-the-pipe">Kích thước Cửa sổ: Lấp đầy Đường ống (Window Size: Filling the Pipe)</a></h2>
<p>Hãy tập trung vào RTT đầu tiên, từ thời điểm gói tin đầu tiên được gửi, đến thời điểm ack đầu tiên đến. Giả sử thời gian này là 5 giây (không phải là một con số thực tế, chỉ để làm ví dụ). Cũng giả sử rằng liên kết đi ra cho phép người gửi gửi 10 gói tin mỗi giây (cũng không phải là một con số thực tế). Tổng cộng, trong khoảng thời gian RTT đầu tiên này, người gửi sẽ có thể gửi tổng cộng 50 gói tin. Do đó, 50 sẽ là một kích thước cửa sổ hợp lý, để người gửi luôn gửi các gói tin và không bao giờ ở trạng thái nhàn rỗi.</p>
<p>Nếu chúng ta đặt W thấp hơn 50, thì người gửi sẽ gửi xong tất cả các gói tin ban đầu trước khi ack đầu tiên đến. Sau đó, người gửi sẽ buộc phải ngồi nhàn rỗi trong khi chờ ack đến, và một phần bandwidth của mạng sẽ bị lãng phí. Tổng quát hơn, chúng ta muốn người gửi gửi các gói tin trong toàn bộ RTT.</p>
<img width="600px" src="transport/../assets/transport/3-020-window2.png">
<p>Trong ví dụ này, W là 4. Nhưng, sau khi gửi 4 gói tin, người gửi đang nhàn rỗi và lãng phí bandwidth trong khi chờ ack đầu tiên đến.</p>
<img width="600px" src="transport/../assets/transport/3-021-window3.png">
<p>Trong ví dụ này, W được tăng lên để người gửi liên tục gửi các gói tin. Khi ack đầu tiên đến, người gửi sắp đạt đến giới hạn W gói tin in flight, và có thể ngay lập tức tiếp tục gửi các gói tin khi nhiều ack hơn đến.</p>
<p>Đường đi đến đích có thể có nhiều liên kết, với các dung lượng khác nhau. Gọi B là bandwidth của liên kết tối thiểu (bottleneck - nút cổ chai) trên đường đi. Chúng ta không nên gửi các gói tin nhanh hơn B, để tránh làm quá tải liên kết. Chúng ta cũng không muốn gửi các gói tin chậm hơn B (tức là chúng ta muốn sử dụng tốc độ B mọi lúc).</p>
<p>Ngoài ra, giả sử R là round-trip time giữa người gửi và người nhận. Chúng ta có thể nhân R với B để có được tổng số gói tin có thể được gửi trong RTT. (Chúng ta có thể gửi B gói tin mỗi giây, trong R giây.) Điều này cho chúng ta biết kích thước cửa sổ, tính bằng gói tin.</p>
<p>Trong thực tế, B được đo bằng bit trên giây, không phải gói tin trên giây. Khi chúng ta nhân R với B, chúng ta nhận được số bit có thể được gửi trong RTT. (B bit mỗi giây, trong R giây.) Điều này cho chúng ta biết kích thước cửa sổ, tính bằng byte. Tổng cộng, chúng ta có thể viết:</p>
<p>Kích thước cửa sổ W * kích thước gói tin = R * B</p>
<p>Vế bên trái cho chúng ta biết số byte được gửi trong cửa sổ (W gói tin, nhân với số byte mỗi gói tin), và vế bên phải cho chúng ta biết số byte có thể được gửi trong RTT.</p>
<p>Để có một ví dụ cụ thể, chúng ta có thể đặt RTT = 1 giây, và B = 8 Mbits/giây. Khi đó, R nhân B là 8 Mbits, hoặc 1 megabyte, hoặc 1,000,000 byte.</p>
<p>Nếu kích thước gói tin của chúng ta là 100 byte, thì chúng ta muốn W = 10,000 gói tin, để chúng ta sử dụng hết bandwidth và gửi 1,000,000 byte trong RTT.</p>
<img width="900px" src="transport/../assets/transport/3-022-window4.png">
<img width="900px" src="transport/../assets/transport/3-023-window5.png">
<p>Chúng ta cũng có thể vẽ kích thước cửa sổ theo chính liên kết đó. Trong hình này, chúng ta đang hiển thị hướng đi ra và hướng đi vào của một liên kết cụ thể. Khi người gửi đẩy các gói tin qua liên kết với công suất tối đa, ack đầu tiên sẽ đến ngay sau khi gói tin thứ 6 được gửi. Do đó, kích thước cửa sổ của chúng ta nên là 6.</p>
<p>Lưu ý rằng kích thước cửa sổ không phải là 3. Khi gói tin 6 được gửi, 3 gói tin đang được gửi, nhưng có thêm 3 gói tin nữa mà ack của chúng chưa đến, vì vậy có tổng cộng 6 gói tin in flight.</p>
<p>Nếu chúng ta đặt kích thước cửa sổ là 3, đường ống đi ra sẽ không được sử dụng trong khi các ack cho 1, 2, 3 đang in flight.</p>
<img width="900px" src="transport/../assets/transport/3-024-window6.png">
<p>Lưu ý rằng các ack không lấp đầy toàn bộ đường ống đi vào vì các gói tin không chứa bất kỳ dữ liệu thực tế nào ngoài việc xác nhận đã nhận được một gói tin.</p>
<h2 id="kích-thước-cửa-sổ-kiểm-soát-luồng-window-size-flow-control"><a class="header" href="#kích-thước-cửa-sổ-kiểm-soát-luồng-window-size-flow-control">Kích thước Cửa sổ: Kiểm soát Luồng (Window Size: Flow Control)</a></h2>
<p>Hãy xem xét giao thức lớp vận chuyển trong hệ điều hành của người nhận. Người nhận có thể nhận các gói tin không đúng thứ tự, nhưng trừu tượng hóa bytestream (luồng byte) yêu cầu các gói tin phải được giao theo đúng thứ tự. Điều này có nghĩa là việc triển khai lớp vận chuyển phải giữ lại các gói tin không đúng thứ tự bằng cách <strong>buffering</strong> (đệm) chúng (giữ chúng trong bộ nhớ) cho đến khi đến lượt chúng được giao.</p>
<p>Ví dụ, giả sử người nhận đã nhận và xử lý các gói tin 1 và 2. Sau đó, người nhận thấy các gói tin 4 và 5. Việc triển khai lớp vận chuyển chưa thể giao 4 và 5 cho ứng dụng. Thay vào đó, chúng ta phải đợi gói tin 3 đến, và trong thời gian chờ đợi, chúng ta phải giữ các gói tin 4 và 5 được lưu trữ trong bộ nhớ của việc triển khai lớp vận chuyển.</p>
<img width="900px" src="transport/../assets/transport/3-025-buffer1.png">
<p>Tuy nhiên, bộ nhớ không phải là vô hạn, và kích thước bộ đệm của người nhận để lưu trữ các gói tin không đúng thứ tự là hữu hạn. Người nhận phải lưu trữ mọi gói tin không đúng thứ tự trong bộ nhớ cho đến khi các gói tin bị thiếu ở giữa đến. Nếu kết nối có nhiều mất mát và sắp xếp lại gói tin, người nhận có thể hết bộ nhớ.</p>
<p><strong>Flow control</strong> đảm bảo rằng bộ đệm của người nhận không bị hết bộ nhớ. Để đạt được điều này, chúng ta để người nhận thông báo cho người gửi biết còn bao nhiêu dung lượng trống trong bộ đệm. Lượng dung lượng trống còn lại trong bộ đệm của người nhận được gọi là <strong>advertised window</strong> (cửa sổ được quảng bá). Trong acknowledgment, người nhận nói &quot;Tôi đã nhận được các gói tin này, và tôi còn lại X byte dung lượng để chứa các gói tin.&quot;</p>
<img width="900px" src="transport/../assets/transport/3-026-buffer2.png">
<p>Khi người gửi biết về advertised window, người gửi sẽ điều chỉnh cửa sổ của mình cho phù hợp. Cụ thể, số lượng gói tin in flight không thể vượt quá advertised window của người nhận. Nếu người nhận nói &quot;bộ đệm của tôi có đủ dung lượng cho 5 gói tin,&quot; người gửi phải đặt cửa sổ tối đa là 5 gói tin (ngay cả khi bandwidth có thể cho phép nhiều gói tin hơn in flight).</p>
<h2 id="kích-thước-cửa-sổ-kiểm-soát-tắc-nghẽn-window-size-congestion-control"><a class="header" href="#kích-thước-cửa-sổ-kiểm-soát-tắc-nghẽn-window-size-congestion-control">Kích thước Cửa sổ: Kiểm soát Tắc nghẽn (Window Size: Congestion Control)</a></h2>
<p>Hãy nhớ lại rằng để tận dụng tối đa bandwidth, người gửi đặt kích thước cửa sổ để tiêu thụ hoàn toàn bandwidth của liên kết bottleneck. Ví dụ, nếu liên kết bottleneck có bandwidth là 1Gbps, chúng ta sẽ đặt kích thước cửa sổ sao cho người gửi liên tục gửi dữ liệu ở tốc độ 1Gbps trong toàn bộ RTT (không nhàn rỗi).</p>
<p>Trên thực tế, không có khả năng liên kết 1Gbps chỉ được sử dụng bởi một kết nối duy nhất. Các kết nối khác cũng có thể đang sử dụng dung lượng trên liên kết đó. Thay vì tiêu thụ toàn bộ bandwidth trên liên kết đó, người gửi chỉ nên tiêu thụ phần bandwidth của riêng mình trong dung lượng đó.</p>
<img width="600px" src="transport/../assets/transport/3-027-cc.png">
<p>Nhưng, phần bandwidth nào sẽ thuộc về mỗi kết nối?</p>
<p>Giả sử chúng ta có hai kết nối đang sử dụng lần lượt là 400MBps và 250MBps. Nếu một kết nối khác sau đó cố gắng sử dụng cùng một liên kết đó, có lẽ phần của người gửi là 350MBps còn lại. Nhưng một lập luận khác là bandwidth không được chia sẻ một cách công bằng, vì vậy có lẽ mọi người nên điều chỉnh để sử dụng 333MBps.</p>
<p>Xác định và tính toán lượng bandwidth chính xác mà mỗi kết nối được phép sử dụng là mục tiêu của congestion control. Các thuật toán cho congestion control là một chủ đề hoàn toàn riêng (sẽ được đề cập trong phần tiếp theo). Bây giờ, chúng ta sẽ trừu tượng hóa congestion control và nói rằng như một phần của lớp vận chuyển, người gửi đang triển khai một thuật toán congestion control, có nhiệm vụ tính toán động phần của người gửi trên liên kết bottleneck của kết nối.</p>
<p>Kết quả của việc chạy thuật toán là congestion window (cwnd) (cửa sổ tắc nghẽn) của người gửi. Bây giờ, tất cả những gì bạn cần biết là thuật toán sẽ đưa ra con số này, đại diện cho một bandwidth tối đa hóa hiệu suất, không làm quá tải một liên kết, trong khi chia sẻ bandwidth một cách công bằng với các kết nối khác.</p>
<p>Bây giờ chúng ta đã biết cách đặt cửa sổ để đạt được ba mục tiêu của mình từ trước. Để tận dụng hết công suất mạng, chúng ta sẽ đặt kích thước cửa sổ theo RTT và bandwidth của liên kết bottleneck.</p>
<p>Để tránh làm quá tải người nhận, chúng ta sẽ giới hạn kích thước cửa sổ theo advertised window của người nhận. Để tránh làm quá tải các liên kết, chúng ta sẽ giới hạn kích thước cửa sổ theo congestion window của người gửi (một con số được đưa ra bởi người gửi chạy một thuật toán congestion control).</p>
<p>Để đáp ứng cả ba mục tiêu, chúng ta sẽ đặt kích thước cửa sổ bằng giá trị nhỏ nhất trong cả ba giá trị. Trên thực tế, lưu ý rằng congestion window (mục tiêu thứ ba) luôn nhỏ hơn hoặc bằng kích thước cửa sổ từ việc sử dụng hết bandwidth (mục tiêu đầu tiên). Nếu không có tắc nghẽn, chúng ta sẽ sử dụng hết bandwidth của bottleneck, vì vậy hai con số sẽ bằng nhau. Trong hầu hết các trường hợp, tắc nghẽn sẽ buộc chúng ta phải sử dụng ít hơn toàn bộ bandwidth của bottleneck, vì vậy con số thứ ba sẽ nhỏ hơn con số đầu tiên. Không có trường hợp nào bandwidth của congestion window lớn hơn bandwidth của bottleneck.</p>
<p>Ngoài ra, trên thực tế, rất khó để khám phá ra bandwidth của bottleneck. Người gửi sẽ phải bằng cách nào đó đi qua network topology và tìm hiểu về bandwidth của mỗi liên kết. Bởi vì con số đầu tiên khó tìm hiểu, và luôn lớn hơn hoặc bằng con số thứ ba, chúng ta có thể đặt kích thước cửa sổ của mình bằng giá trị nhỏ nhất của hai con số sau (bỏ qua con số đầu tiên). Kích thước cửa sổ là giá trị nhỏ nhất của congestion window của người gửi và advertised window của người nhận.</p>
<h2 id="các-tin-báo-nhận-thông-minh-hơn-smarter-acknowledgments"><a class="header" href="#các-tin-báo-nhận-thông-minh-hơn-smarter-acknowledgments">Các tin báo nhận Thông minh hơn (Smarter Acknowledgments)</a></h2>
<p>Cho đến nay, mỗi gói tin ack tương ứng với một gói tin duy nhất. Chúng ta có thể làm tốt hơn việc xác nhận từng gói tin một không? Một số vấn đề với việc xác nhận từng gói tin một là gì?</p>
<img width="600px" src="transport/../assets/transport/3-028-ack1.png">
<p>Trong ví dụ này, một trong các ack bị mất, mặc dù người nhận đã nhận thành công tất cả 4 gói tin. Điều này sẽ buộc người gửi phải gửi lại gói tin 2, mặc dù việc gửi lại này là không cần thiết.</p>
<p>Thay vì gửi một acknowledgment cho một gói tin cụ thể, mỗi lần chúng ta gửi một acknowledgment, chúng ta thực sự có thể liệt kê mọi gói tin mà chúng ta đã nhận được. Điều này được gọi là <strong>full information ack</strong> (tin báo nhận đầy đủ thông tin).</p>
<img width="600px" src="transport/../assets/transport/3-029-ack2.png">
<p>Trong ví dụ này, các ack bây giờ nói: &quot;Tôi đã nhận 1,&quot; và &quot;Tôi đã nhận 1 và 2&quot;, và &quot;Tôi đã nhận 1, 2, 3&quot;, và &quot;Tôi đã nhận 1, 2, 3, 4.&quot;</p>
<p>Mặc dù ack thứ hai đã bị mất, ack thứ ba và thứ tư giúp người gửi xác nhận rằng gói tin 2 đã được nhận, và gói tin 2 không cần phải được gửi lại nữa.</p>
<p>Khi nhiều gói tin hơn được gửi, danh sách tất cả các gói tin đã nhận sẽ trở nên rất dài. Full information acks có thể viết tắt thông tin này bằng cách nói: &quot;Tôi đã nhận tất cả các gói tin cho đến #12. Ngoài ra, tôi đã nhận #14 và #15.&quot; Về mặt hình thức, chúng ta cung cấp ack tích lũy cao nhất (tất cả các gói tin nhỏ hơn hoặc bằng số này đã được nhận), cộng với danh sách bất kỳ gói tin bổ sung nào đã nhận được.</p>
<p>Ngay cả với việc viết tắt này, full information acks có thể trở nên dài. Ví dụ, nếu tất cả các gói tin có số thứ tự chẵn bị mất, thì ack tích lũy cao nhất sẽ luôn là 1 (chúng ta chỉ có thể nói tất cả các gói tin cho đến 1 đã được nhận, vì 2 bị mất). Phần còn lại của các gói tin đã nhận sẽ phải nằm trong một danh sách như [1, 3, 5, 7, 9, ...] có thể trở nên rất dài.</p>
<img width="600px" src="transport/../assets/transport/3-030-ack3.png">
<p>Một sự thỏa hiệp giữa các ack riêng lẻ (mỗi lần mất ack buộc phải gửi lại) và full information acks (ack có thể trở nên dài) là <strong>cumulative acks</strong> (tin báo nhận tích lũy), trong đó chúng ta chỉ cung cấp ack tích lũy cao nhất, và loại bỏ danh sách bổ sung. Về mặt hình thức, ack mã hóa sequence number cao nhất mà tất cả các gói tin trước đó đã được nhận.</p>
<img width="900px" src="transport/../assets/transport/3-031-ack4.png">
<p>Trong ví dụ này, nơi các gói tin có số thứ tự chẵn bị mất, mỗi cumulative ack sẽ nói: &quot;Tôi đã nhận tất cả các gói tin cho đến và bao gồm 1.&quot; Mặc dù 3 và 5 đã được nhận, cumulative ack sẽ không mã hóa thông tin này, bởi vì nó chỉ xác nhận việc nhận các gói tin liên tiếp bắt đầu từ 1.</p>
<p>Cumulative acks không còn có vấn đề về khả năng mở rộng (chúng ta luôn gửi một số, không phải một danh sách các số). Tuy nhiên, chúng có thể mơ hồ hơn, như trong trường hợp trên. Người gửi thấy ba acknowledgements đều nói &quot;Tôi đã nhận mọi thứ cho đến và bao gồm 1,&quot; và có thể suy ra rằng 3 gói tin đã được nhận (gói tin 1, và hai gói tin khác), nhưng không thể suy ra hai gói tin khác đó là gì.</p>
<h2 id="phát-hiện-mất-mát-sớm-detecting-loss-early"><a class="header" href="#phát-hiện-mất-mát-sớm-detecting-loss-early">Phát hiện Mất mát Sớm (Detecting Loss Early)</a></h2>
<p>Chúng ta có thể làm tốt hơn việc chờ hết thời gian chờ, và sử dụng các thông tin khác mà chúng ta nhận được để phát hiện mất mát sớm hơn và gửi lại các gói tin sớm hơn không? Ví dụ, trong mô hình ack riêng lẻ của chúng ta, nếu chúng ta nhận được ack cho các gói tin 1, 3, 4, 5, 6, chúng ta có thể suy ra rằng gói tin 2 bị mất và gửi lại nó, ngay cả trước khi bộ đếm thời gian của gói tin 2 hết hạn.</p>
<p>Một cách chính thức hơn, chúng ta có thể đặt một giá trị K (không liên quan đến cửa sổ), và nói rằng nếu K gói tin tiếp theo được xác nhận sau gói tin bị thiếu, chúng ta sẽ coi gói tin đó là bị mất (ngay cả khi bộ đếm thời gian chưa hết hạn). Ví dụ, nếu K=3, chúng ta đang chờ ack của gói tin 5, và chúng ta nhận được ack cho 6, 7, và 8, thì chúng ta có thể coi gói tin 5 là bị mất.</p>
<img width="900px" src="transport/../assets/transport/3-032-fast-retransmit1.png">
<p>Trên thực tế, việc phát hiện mất mát từ các ack tiếp theo nhanh hơn nhiều so với việc chờ hết thời gian chờ. Nếu thời gian chờ của chúng ta được tính từ RTT, nó có thể lên đến hàng giây. Mặt khác, bandwidth hiện đại có thể cho phép các ack đến vài micro giây một lần.</p>
<p>Chiến lược phát hiện mất mát này trông khác nhau tùy thuộc vào chiến lược gửi ack của chúng ta. Các ví dụ trên giả định rằng chúng ta đang gửi các ack riêng lẻ, nhưng còn hai mô hình ack kia thì sao?</p>
<p>Nếu chúng ta sử dụng full-information acks, chiến lược khá giống nhau, và các ack thực sự sẽ cho thấy gói tin bị thiếu một cách rõ ràng hơn.</p>
<img width="900px" src="transport/../assets/transport/3-033-fast-retransmit2.png">
<p>Nếu gói tin 5 bị mất, các ack có thể nói &quot;cho đến 4&quot;, sau đó &quot;cho đến 4, cộng với 6&quot;, sau đó &quot;cho đến 4, cộng với 6, 7&quot;, sau đó &quot;cho đến 4, cộng với 6, 7, 8.&quot; Tại thời điểm này, nếu K=3, thì K gói tin sau 5 đã được xác nhận, vì vậy chúng ta có thể tuyên bố rằng gói tin 5 bị mất.</p>
<p>Nếu chúng ta sử dụng cumulative acks, chiến lược này có thể mơ hồ hơn. Nếu gói tin 5 bị mất, thì các ack có thể nói &quot;cho đến 4&quot; (xác nhận 4), &quot;cho đến 4&quot; (xác nhận 6), &quot;cho đến 4&quot; (xác nhận 7), &quot;cho đến 4&quot; (xác nhận 8). Người gửi đang thấy <strong>duplicate acks</strong> (tin báo nhận trùng lặp) vì có khoảng trống trong các gói tin liên tiếp. Nếu K=3, thì chúng ta có thể tuyên bố gói tin 5 bị mất sau khi nhận được 3 gói tin trùng lặp (tương ứng với 3 gói tin nữa được xác nhận sau khoảng trống), tổng cộng là 4 bản sao.</p>
<img width="900px" src="transport/../assets/transport/3-034-fast-retransmit3.png">
<p>Khi chúng ta có các ack riêng lẻ và full-information, chúng ta có thể thấy rõ gói tin nào cần được gửi lại. Có một gói tin bị thiếu ack (và K ack tiếp theo đến). Tuy nhiên, quyết định gửi lại gói tin nào sẽ mơ hồ hơn với cumulative acks, đặc biệt là khi nhiều gói tin bị mất.</p>
<p>Làm ví dụ, hãy xem xét một người gửi có kích thước cửa sổ W=6, và K=3. Cho đến nay, các gói tin 1 và 2 đã được xác nhận, và các gói tin 3-8 đang in flight. Giả sử các gói tin 3 và 5 đã bị mất. Trước tiên, hãy xem qua ví dụ này với các ACK riêng lẻ.</p>
<p>4 đến, và người nhận gửi một ack cho 4. Người gửi bây giờ có thể gửi 9.</p>
<p>6 đến, và người nhận gửi một ack cho 6. Người gửi bây giờ có thể gửi 10.</p>
<p>7 đến, và người nhận gửi một ack cho 7. Người gửi bây giờ có thể gửi 11.</p>
<p>Tại thời điểm này, người gửi nhận thấy rằng K=3 gói tin sau gói tin 3 (cụ thể là 4, 6, và 7) đã được xác nhận. Người gửi có thể tuyên bố 3 bị mất, và gửi lại 3.</p>
<p>Lưu ý rằng mặc dù người gửi đã gửi lại 3 và gửi 11 để phản hồi ack cho 7, vẫn có tổng cộng 6 gói tin in flight với việc gửi lại này, vì vậy cửa sổ không bị vi phạm. Điều này là do 3 đã là một trong những gói tin in flight khi chúng ta gửi lại nó.</p>
<p>8 đến, và người nhận gửi một ack cho 8. Người gửi bây giờ có thể gửi 12.</p>
<p>Ngoài ra, người gửi nhận thấy rằng K=3 gói tin sau gói tin 5 (cụ thể là 6, 7, và 8) đã được xác nhận, vì vậy người gửi cũng có thể gửi lại 5.</p>
<p>9 đến, và người nhận gửi một ack cho 9. Người gửi bây giờ có thể gửi 13.</p>
<p>Bây giờ, hãy làm lại ví dụ này với các ACK tích lũy.</p>
<p>4 đến, và người nhận gửi một ack cho 4, trong đó nói &quot;ack mọi thứ cho đến 2.&quot; Tại thời điểm này, người gửi biết một gói tin phải đã đến, nhưng không biết đó là 4. Tuy nhiên, người gửi vẫn có thể gửi 9 tiếp theo. Lưu ý rằng cửa sổ không bị vi phạm, bởi vì mặc dù người gửi dường như có 7 gói tin chưa được xác nhận, một trong số chúng đã được xác nhận bởi duplicate &quot;ack mọi thứ cho đến 2,&quot; vì vậy chỉ có 6 gói tin in flight.</p>
<p>6 đến, và người nhận gửi một ack cho 6, trong đó vẫn nói &quot;ack mọi thứ cho đến 2.&quot; Một lần nữa, người gửi suy ra rằng một gói tin khác đã đến, và có thể gửi 10 tiếp theo.</p>
<p>7 đến, và người nhận gửi một ack cho 7, trong đó vẫn nói &quot;ack mọi thứ cho đến 2.&quot; Người gửi suy ra rằng một gói tin khác đã đến, và có thể gửi 10.</p>
<p>Tại thời điểm này, người gửi nhận thấy rằng &quot;ack mọi thứ cho đến 2&quot; đã đến 3 lần trùng lặp (ngoài ack ban đầu cho 2). Gói tin chưa được xác nhận tiếp theo là 3, vì vậy người gửi sẽ gửi lại 3.</p>
<p>Đây là lúc mọi thứ trở nên mơ hồ. Khi 8, 9, và 10 đến người nhận, người gửi sẽ nhận được thêm ba bản sao của &quot;ack mọi thứ cho đến 2.&quot; (Chúng ta đang giả định người nhận chưa nhận được 3, vì nó được gửi lại sau 9 và 10).</p>
<p>Người gửi bây giờ có thể gửi 12, 13, và 14, vì ba ack nữa đã đến, nhưng gói tin nào nên được gửi lại tiếp theo? Người gửi nên gửi lại 3, 4, 5, hay một cái gì đó khác?</p>
<p>Ví dụ này cho thấy rằng cumulative acks không phải lúc nào cũng chỉ ra chính xác những gói tin nào đã được nhận. Tuy nhiên, số lượng ack (có thể bao gồm cả các bản sao) có thể được sử dụng để xác định có bao nhiêu gói tin đã được nhận (mà không biết chính xác những gói tin nào đã được nhận), điều này cho phép chúng ta tiếp tục gửi theo kích thước cửa sổ. Tuy nhiên, sự mơ hồ phát sinh khi chúng ta nhận được quá nhiều duplicate acks và không thể biết gói tin nào cần gửi lại.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="triển-khai-tcp-tcp-implementation"><a class="header" href="#triển-khai-tcp-tcp-implementation">Triển khai TCP (TCP Implementation)</a></h1>
<h2 id="phân-đoạn-tcp-tcp-segments"><a class="header" href="#phân-đoạn-tcp-tcp-segments">Phân đoạn TCP (TCP Segments)</a></h2>
<p>Cho đến nay, chúng ta đã nói về TCP một cách khái niệm, dưới dạng các gói tin riêng lẻ được gửi đi. Nhưng ứng dụng không cung cấp cho chúng ta các gói tin được tạo sẵn để chúng ta có thể gửi trực tiếp vào mạng Lớp 3. Ứng dụng đang dựa vào một trừu tượng hóa bytestream, và thay vào đó đang gửi cho chúng ta một luồng byte liên tục. Để triển khai đầy đủ TCP, chúng ta sẽ cần phải suy nghĩ lại tất cả các ý tưởng trước đây của mình (ví dụ: sequence numbers, kích thước cửa sổ, v.v.) dưới dạng byte, chứ không phải gói tin. (Tuy nhiên, bạn vẫn nên có khả năng lý giải về các lựa chọn thiết kế dưới cả hai góc độ byte hoặc gói tin.)</p>
<img width="900px" src="transport/../assets/transport/3-035-segment1.png">
<p>Để tạo thành các gói tin từ các byte trong bytestream, chúng ta sẽ giới thiệu một đơn vị dữ liệu được gọi là <strong>TCP segment</strong> (phân đoạn TCP). Việc triển khai TCP ở phía người gửi sẽ thu thập các byte từ bytestream, từng byte một, và đặt các byte đó vào một TCP segment. Khi TCP segment đầy (đạt đến một kích thước phân đoạn tối đa cố định), chúng ta gửi TCP segment đó, và sau đó bắt đầu một TCP segment mới.</p>
<p>Đôi khi, người gửi muốn gửi ít dữ liệu hơn kích thước phân đoạn tối đa. Trong trường hợp đó, chúng ta sẽ không muốn TCP segment phải chờ đợi mãi mãi để có thêm các byte không bao giờ đến. Để khắc phục điều này, chúng ta sẽ bắt đầu một bộ đếm thời gian mỗi khi chúng ta bắt đầu điền vào một phân đoạn trống mới. Nếu bộ đếm thời gian hết hạn, chúng ta sẽ gửi TCP segment, ngay cả khi nó chưa đầy.</p>
<img width="900px" src="transport/../assets/transport/3-036-segment2.png">
<p>Trước khi gửi dữ liệu trong một TCP segment, việc triển khai TCP của người gửi sẽ thêm một TCP header (phần đầu TCP) với các siêu dữ liệu liên quan (ví dụ: sequence number, số cổng). Sau đó, phân đoạn và phần đầu được chuyển xuống IP layer (lớp IP), lớp này sẽ đính kèm một IP header (phần đầu IP) và gửi gói tin qua mạng.</p>
<p>TCP segment, với một TCP header và IP header ở trên, đôi khi được gọi là <strong>TCP/IP packet</strong> (gói tin TCP/IP). Tương đương, đây là một gói tin IP có phần tải (payload) bao gồm một TCP header và dữ liệu.</p>
<img width="600px" src="transport/../assets/transport/3-037-segment3.png">
<p><strong>Maximum segment size (MSS)</strong> (kích thước phân đoạn tối đa) nên được đặt như thế nào? Hãy nhớ lại rằng kích thước của một gói tin IP bị giới hạn bởi maximum transmission unit (MTU) (đơn vị truyền tải tối đa) dọc theo mỗi liên kết. Tuy nhiên, gói tin IP cũng phải chứa IP header và TCP header, vì vậy maximum segment size của TCP sẽ nhỏ hơn một chút so với maximum transmission unit của IP. Cụ thể:</p>
<p>MSS (giới hạn TCP segment) = MTU (giới hạn gói tin IP) - kích thước IP header - kích thước TCP header</p>
<h2 id="số-thứ-tự-sequence-numbers"><a class="header" href="#số-thứ-tự-sequence-numbers">Số Thứ tự (Sequence Numbers)</a></h2>
<p>Cho đến nay, chúng ta đã gán nhãn cho mỗi gói tin bằng một con số, để người nhận có thể nhận các gói tin theo đúng thứ tự.</p>
<p>Trên thực tế, thay vì đánh số các phân đoạn riêng lẻ, chúng ta gán một số cho mỗi byte trong bytestream. TCP header của mỗi phân đoạn sẽ chứa một <strong>sequence number</strong> tương ứng với số của byte đầu tiên trong phân đoạn đó. Người nhận vẫn có thể sử dụng sequence numbers để xác định vị trí của mỗi phân đoạn trong bytestream, và lắp ráp lại các phân đoạn theo đúng thứ tự.</p>
<p>Mỗi bytestream bắt đầu với một <strong>initial sequence number (ISN)</strong> (số thứ tự ban đầu). Người gửi chọn một ISN và gán nhãn cho byte đầu tiên với số ISN+1, byte tiếp theo với số ISN+2, byte tiếp theo với ISN+3, và cứ thế tiếp tục.</p>
<img width="900px" src="transport/../assets/transport/3-038-seq-num1.png">
<p>Vì bây giờ chúng ta đang đánh số các byte thay vì các gói tin, số acknowledgement bây giờ cũng sẽ được tính theo byte, chứ không phải gói tin. Cụ thể, số acknowledgement cho biết, tôi đã nhận được tất cả các byte cho đến, nhưng không bao gồm, con số này. Tương đương, số acknowledgement đại diện cho byte tiếp theo mà nó mong đợi nhận được (nhưng chưa nhận được). Lưu ý rằng TCP đang sử dụng mô hình cumulative ack (thay vì full-information acks hoặc ack cho từng byte riêng lẻ).</p>
<p>Làm ví dụ, giả sử ISN đã được chọn ngẫu nhiên là 50. Khi đó, một vài byte đầu tiên có các số 51, 52, 53, v.v. Một TCP segment cụ thể có thể chứa các byte từ 140 đến 219, bao gồm cả hai. Sequence number của phân đoạn này là 140 (đại diện cho byte đầu tiên trong phân đoạn). Nếu người nhận đã nhận được mọi thứ cho đến nay, người nhận có thể xác nhận phân đoạn này bằng cách gửi một số ack là 220, là byte tiếp theo chưa được nhận.</p>
<img width="900px" src="transport/../assets/transport/3-039-seq-num2.png">
<p>Tổng quát hơn, giả sử chúng ta có một gói tin trong đó byte đầu tiên có sequence number là X, và gói tin có B byte. Gói tin này có các byte X, X+1, X+2, ..., X+B-1. Nếu gói tin này (và tất cả dữ liệu trước đó) được nhận, ack sẽ xác nhận X+B (byte tiếp theo được mong đợi). Nếu gói tin này không được nhận, hoặc gói tin này được nhận nhưng một số gói tin trước đó không được nhận, thì ack sẽ xác nhận một số nhỏ hơn (bởi vì TCP sử dụng cumulative acks).</p>
<p>Tổng quát hơn nữa, giả sử chúng ta có nhiều gói tin, tất cả đều dài B byte. ISN là X, và kích thước cửa sổ là 1 (giao thức stop-and-wait, chỉ có một gói tin hoặc ack được gửi tại một thời điểm). Giả sử không có gói tin nào bị mất. Khi đó, các sequence number và số ack sẽ tiến hành như sau: Gói tin đầu tiên có sequence number X. Ack đầu tiên có số ack là X+B. Gói tin thứ hai có sequence number là X+B. Ack thứ hai có số ack là X+2B. Gói tin thứ ba có sequence number là X+2B, và cứ thế tiếp tục. Cụ thể, lưu ý rằng khi không có mất mát, số ack tương ứng với sequence number của gói tin tiếp theo.</p>
<img width="500px" src="transport/../assets/transport/3-040-seq-num3.png">
<p>Trong lịch sử, ISN được chọn là ngẫu nhiên vì các nhà thiết kế lo ngại về các sequence number không rõ ràng nếu tất cả các bytestream đều bắt đầu đánh số từ 0. Cụ thể, giả sử một kết nối TCP gửi một số dữ liệu bắt đầu từ ISN 0, và sau đó người gửi bị treo. Nếu người gửi khởi động lại một kết nối mới, và ISN lại bắt đầu từ 0, người nhận có thể bị nhầm lẫn nếu thấy một gói tin có sequence number là 0. Gói tin này là từ kết nối đầu tiên trước khi bị treo, hay kết nối thứ hai sau khi bị treo?</p>
<p>Trên thực tế, ISN được chọn là ngẫu nhiên vì lý do bảo mật. Nếu ISN được chọn một cách có thể dự đoán được, những kẻ tấn công có thể suy ra ISN và gửi các gói tin giả mạo trông giống như chúng đến từ người gửi. Khi ISN được chọn ngẫu nhiên, kẻ tấn công khó suy ra ISN và gửi các gói tin giả mạo hơn.</p>
<h2 id="trạng-thái-của-tcp-tcp-state"><a class="header" href="#trạng-thái-của-tcp-tcp-state">Trạng thái của TCP (TCP State)</a></h2>
<p>Trong TCP, cả người gửi và người nhận đều cần duy trì trạng thái. Trạng thái được duy trì tại các máy chủ cuối triển khai TCP, chứ không phải trong mạng.</p>
<p>Người gửi phải nhớ những byte nào đã được gửi nhưng chưa được xác nhận. Người gửi cũng phải theo dõi các bộ đếm thời gian khác nhau, ví dụ: một bộ đếm thời gian cho việc khi nào gửi một phân đoạn chưa đầy, và một bộ đếm thời gian cho việc khi nào gửi lại các byte.</p>
<p>Người nhận phải nhớ các byte không theo thứ tự mà chưa thể được giao cho ứng dụng.</p>
<p>Bởi vì TCP yêu cầu lưu trữ trạng thái, mỗi bytestream được gọi là một <strong>connection</strong> (kết nối) hoặc <strong>session</strong> (phiên), và TCP là một giao thức hướng kết nối. Không giống như Lớp 3, nơi mọi gói tin có thể được xem xét riêng biệt, TCP yêu cầu cả hai bên phải thiết lập một connection và khởi tạo trạng thái trước khi có thể gửi dữ liệu. TCP cũng cần một cơ chế để hủy các connection để giải phóng bộ nhớ được phân bổ cho trạng thái trên cả hai máy chủ cuối.</p>
<h2 id="tcp-là-duplex-toàn-phần"><a class="header" href="#tcp-là-duplex-toàn-phần">TCP là Duplex toàn phần</a></h2>
<p>Cho đến nay, chúng ta đã xem TCP như một bytestream từ một máy chủ cuối (người gửi) đến máy chủ cuối kia (người nhận). Trên thực tế, hai máy chủ cuối thường muốn gửi tin nhắn theo cả hai hướng.</p>
<p>Để hỗ trợ gửi tin nhắn theo cả hai hướng, các connection TCP là <strong>full duplex</strong> (song công toàn phần). Thay vì chỉ định một người gửi và một người nhận, cả hai máy chủ cuối trong connection có thể gửi và nhận dữ liệu đồng thời, trong cùng một connection.</p>
<img width="900px" src="transport/../assets/transport/3-041-duplex.png">
<p>Để hỗ trợ gửi dữ liệu theo cả hai hướng, mỗi connection TCP có hai bytestream: một chứa dữ liệu từ A đến B, và cái còn lại chứa dữ liệu từ B đến A. Mỗi gói tin có thể chứa cả dữ liệu và thông tin acknowledgement. Sequence number sẽ tương ứng với bytestream của người gửi (các byte tôi đang gửi), và số acknowledgement sẽ tương ứng với bytestream của người nhận (các byte tôi đã nhận từ bạn).</p>
<h2 id="tcp-handshake"><a class="header" href="#tcp-handshake">TCP Handshake</a></h2>
<p>Hãy nhớ lại rằng TCP là hướng kết nối, vì vậy các connection phải được tạo và hủy một cách tường minh. Cũng hãy nhớ lại rằng các bytestream bắt đầu tại một initial sequence number (ISN) được chọn ngẫu nhiên, và mỗi connection TCP là full-duplex (hai bytestream, một theo mỗi hướng). Khi chúng ta tạo một connection mới, chúng ta cần cả hai bên đồng ý về hai ISN khởi đầu (một cho mỗi hướng).</p>
<p>Để thiết lập một connection TCP, hai máy chủ thực hiện một <strong>three-way handshake</strong> (bắt tay ba bước) để đồng ý về các ISN ở mỗi hướng.</p>
<img width="500px" src="transport/../assets/transport/3-042-handshake.png">
<p>Gói tin đầu tiên (từ A đến B) là tin nhắn <strong>SYN</strong> (tin nhắn SYN). Tin nhắn này chứa ISN của A (dữ liệu từ A đến B sẽ bắt đầu đếm từ ISN này), trong sequence number.</p>
<p>Gói tin thứ hai (từ B đến A) là tin nhắn <strong>SYN-ACK</strong> (tin nhắn SYN-ACK). Tin nhắn này chứa ISN của B (dữ liệu từ B đến A sẽ bắt đầu đếm từ ISN này), trong sequence number. Tin nhắn này cũng xác nhận rằng B đã nhận được ISN của A, trong số ack.</p>
<p>Gói tin thứ ba (lại từ A đến B) là tin nhắn <strong>ACK</strong> (tin nhắn ACK). Tin nhắn này xác nhận rằng A đã nhận được ISN của B, trong số ack.</p>
<p>Cái handshake này là lý do tại sao các bytestream bắt đầu đếm từ ISN+1. Khi tôi gửi một ISN, ack là ISN+1, cho biết rằng ISN đã được nhận, và byte (đầu tiên) tiếp theo được mong đợi là ISN+1.</p>
<p>Sau khi three-way handshake kết thúc, B có thể bắt đầu gửi dữ liệu.</p>
<h2 id="kết-thúc-kết-nối-ending-connections"><a class="header" href="#kết-thúc-kết-nối-ending-connections">Kết thúc Kết nối (Ending Connections)</a></h2>
<p>Có hai cách để kết thúc một connection.</p>
<p>Trong trường hợp bình thường, khi tôi gửi xong tin nhắn, tôi có thể gửi một FIN packet (gói tin FIN) đặc biệt, có nội dung: Tôi sẽ không gửi thêm bất kỳ dữ liệu nào nữa, nhưng tôi sẽ tiếp tục nhận dữ liệu nếu bạn còn gì để gửi. Tại thời điểm này, connection được đóng một nửa. Gói tin này sẽ được xác nhận, giống như bất kỳ gói tin nào khác.</p>
<p>Cuối cùng, phía bên kia cũng sẽ gửi xong dữ liệu và gửi một FIN packet. Khi FIN packet này được xác nhận, connection sẽ được đóng.</p>
<img width="500px" src="transport/../assets/transport/3-043-fin.png">
<p>Đôi khi, chúng ta phải chấm dứt một connection một cách đột ngột, mà không có sự đồng ý của phía bên kia. Để đơn phương kết thúc một connection, tôi có thể gửi một RST packet (gói tin RST) đặc biệt, có nội dung: Tôi sẽ không gửi hoặc nhận thêm bất kỳ dữ liệu nào nữa. Gói tin này không cần phải được xác nhận, và tôi có thể hủy connection của mình ngay khi tôi gửi dữ liệu này.</p>
<p>Các RST packet thường được sử dụng khi một máy chủ gặp lỗi và không thể tiếp tục gửi hoặc nhận các gói tin. Lưu ý rằng bất kỳ dữ liệu nào đang in-flight sẽ bị mất nếu một RST xảy ra và máy chủ cuối bị treo và mất trạng thái của nó.</p>
<p>Nếu tôi đã gửi một RST, và ai đó tiếp tục gửi dữ liệu cho tôi, nếu có thể, tôi sẽ tiếp tục gửi các bản sao của RST packet để liên tục cố gắng chấm dứt connection.</p>
<p>Các RST packet cũng có thể được những kẻ tấn công sử dụng để kiểm duyệt các connection. Một kẻ tấn công có thể giả mạo và tiêm một RST packet, điều này khiến toàn bộ connection bị chấm dứt.</p>
<img width="500px" src="transport/../assets/transport/3-044-rst.png">
<p>Sơ đồ trạng thái TCP đầy đủ khá phức tạp, với nhiều trạng thái trung gian trong quá trình mở hoặc đóng một connection. Ví dụ về các trạng thái trung gian bao gồm: Tôi đã gửi một SYN, và đang chờ một SYN-ACK. Hoặc, tôi đã nhận một FIN, đã gửi FIN của mình, nhưng đang chờ FIN của mình được xác nhận. Hầu hết các connection TCP dành phần lớn thời gian của chúng ở trạng thái Established (Đã thiết lập), nơi connection đã bắt đầu (nhưng chưa kết thúc), và dữ liệu đang được trao đổi qua lại. Bạn không cần phải hiểu toàn bộ sơ đồ trạng thái này cho các ghi chú này.</p>
<img width="900px" src="transport/../assets/transport/3-045-state-diagram.png">
<p>Trong sơ đồ trạng thái đơn giản hóa, chúng ta bắt đầu ở trạng thái đóng (không có connection nào đang diễn ra). Để bắt đầu một connection, chúng ta gửi một SYN. Cuối cùng, chúng ta nhận được một SYN-ACK và trả lời bằng một ACK, chuyển sang một connection đã được thiết lập. Khi chúng ta gửi xong dữ liệu, chúng ta gửi một FIN, và nhận một ACK. Cuối cùng, chúng ta nhận được một FIN, và connection lại được đóng.</p>
<img width="900px" src="transport/../assets/transport/3-046-simplified-state.png">
<h2 id="gửi-ké-piggybacking"><a class="header" href="#gửi-ké-piggybacking">Gửi ké (Piggybacking)</a></h2>
<p>Bởi vì TCP là full duplex, có thể một gói tin vừa xác nhận một số dữ liệu vừa gửi dữ liệu mới.</p>
<p>Khi người nhận nhận được một gói tin, nếu nó không có dữ liệu để gửi, người nhận có hai lựa chọn. Người nhận có thể gửi ngay ack, mà không có dữ liệu để gửi. Hoặc, người nhận có thể đợi cho đến khi có dữ liệu để gửi, và sau đó gửi ack cùng với dữ liệu mới. Cách tiếp cận thứ hai này được gọi là <strong>piggybacking</strong> (gửi ké).</p>
<p>Trên thực tế, một lý do chúng ta có thể không piggybacking là vì TCP được triển khai trong hệ điều hành, tách biệt với ứng dụng.</p>
<p>Hãy xem xét hệ điều hành, không biết ứng dụng đang làm gì. Khi hệ điều hành nhận được một gói tin, nó không biết khi nào người gửi sẽ có thêm dữ liệu để gửi (hoặc liệu người gửi có bao giờ có thêm dữ liệu để gửi hay không), vì vậy nó có thể bị kẹt trong việc chờ đợi một thời gian dài trước khi có thể piggybacking ack với một số dữ liệu mới.</p>
<p>Ở phía bên kia, hãy xem xét ứng dụng, không biết hệ điều hành đang làm gì. Ứng dụng đang chạy trên trừu tượng hóa bytestream, và hoàn toàn không nghĩ về các gói tin, vì vậy nó không có cách nào để nghĩ về piggybacking.</p>
<p>Piggybacking còn phức tạp hơn bởi thực tế là hệ điều hành không chạy mọi chương trình đồng thời. Nhớ lại một khóa học kiến trúc máy tính (như CS 61C tại UC Berkeley), CPU liên tục chuyển đổi giữa các tiến trình khác nhau trên máy tính của bạn, tùy thuộc vào những gì cần chú ý. Sẽ khá ngớ ngẩn nếu, mỗi khi một gói tin TCP đến, CPU ngắt những gì nó đang làm để chuyển gói tin đó cho ứng dụng, và cho ứng dụng một chút thời gian để phản hồi. Thay vào đó, khi một gói tin TCP đến, hệ điều hành có thể gửi đi ack, trước khi ứng dụng có cơ hội piggybacking dữ liệu mới trên ack.</p>
<p>Một trường hợp mà dữ liệu luôn được piggybacked là gói tin SYN-ACK trong handshake. Ngoài ack, chúng ta đang piggybacking initial sequence number của chính mình. Điều này không có vấn đề đã thảo luận ở trên, vì TCP handshake hoàn toàn được thực hiện bởi hệ điều hành. (Ứng dụng hoàn toàn không nghĩ về các gói tin SYN hoặc SYN-ACK.)</p>
<h2 id="sliding-window"><a class="header" href="#sliding-window">Sliding Window</a></h2>
<p>Khi chúng ta thảo luận về các gói tin, chúng ta đã định nghĩa cửa sổ là số lượng gói tin có thể in flight tại bất kỳ thời điểm nào. Bây giờ chúng ta đang triển khai TCP dưới dạng byte, chúng ta sẽ định nghĩa <strong>sliding window</strong> (cửa sổ trượt) là số lượng byte liên tục tối đa có thể in flight tại bất kỳ thời điểm nào.</p>
<p>Việc hạn chế các byte in flight phải liên tục là khác so với trước đây. Định nghĩa cửa sổ dựa trên gói tin của chúng ta cho phép các gói tin không liên tục (ví dụ: 5, 7, 8) được in-flight. Tuy nhiên, các byte in flight được yêu cầu phải liên tiếp, không có khoảng trống. Yêu cầu này tạo ra một cửa sổ (phạm vi các byte) trong luồng byte.</p>
<p>Bên trái của cửa sổ là byte đầu tiên chưa được xác nhận (được xác định bởi số ack từ người nhận). Bắt đầu từ byte này, W byte tiếp theo, cho đến bên phải của cửa sổ, có thể in-flight.</p>
<img width="900px" src="transport/../assets/transport/3-047-window1.png">
<p>Lưu ý rằng ngay cả khi một số byte trung gian trong cửa sổ này đã được xác nhận, chúng ta vẫn không thể gửi thêm byte nào ngoài cửa sổ. Cách duy nhất chúng ta có thể gửi thêm byte là nếu cửa sổ trượt sang phải, tức là khi số ack tăng lên (các byte ở bên trái của cửa sổ được xác nhận).</p>
<img width="900px" src="transport/../assets/transport/3-048-window2.png">
<p>Hãy nhớ lại rằng kích thước cửa sổ (xác định cạnh phải của cửa sổ) bị giới hạn bởi flow control và congestion control. Trong trường hợp flow control, kích thước cửa sổ được quyết định bởi cửa sổ được quảng bá bởi người nhận. Người nhận quyết định advertised window dựa trên lượng không gian bộ đệm có sẵn ở phía người nhận.</p>
<h2 id="phát-hiện-mất-mát-và-hửi-lại-dữ-liệu-detecting-loss-and-re-sending-data"><a class="header" href="#phát-hiện-mất-mát-và-hửi-lại-dữ-liệu-detecting-loss-and-re-sending-data">Phát hiện mất mát và hửi lại Dữ liệu (Detecting Loss and Re-Sending Data)</a></h2>
<p>Có hai điều kiện để dữ liệu được gửi lại. Chỉ cần một điều kiện (không phải cả hai) là đúng để kích hoạt việc gửi lại.</p>
<img width="900px" src="transport/../assets/transport/3-049-window3.png">
<p>Tác nhân kích hoạt đầu tiên cho việc truyền lại là một bộ đếm thời gian (dữ liệu không được xác nhận sau một khoảng thời gian). Trong TCP dựa trên gói tin, mỗi gói tin có một bộ đếm thời gian, và khi bộ đếm thời gian hết hạn mà gói tin đó chưa được xác nhận, chúng ta sẽ gửi lại gói tin đó.</p>
<p>Trong TCP dựa trên byte, thay vì một bộ đếm thời gian cho mỗi byte hoặc mỗi gói tin, chúng ta sẽ chỉ có một bộ đếm thời gian duy nhất, tương ứng với byte đầu tiên chưa được xác nhận (bên trái của cửa sổ). Nếu bộ đếm thời gian hết hạn, chúng ta sẽ gửi lại phân đoạn chưa được xác nhận ở ngoài cùng bên trái. Hãy nhớ lại rằng độ dài bộ đếm thời gian dựa trên RTT, và RTT được ước tính bằng cách sử dụng các phép đo thời gian giữa việc gửi dữ liệu và nhận ack. Cũng hãy nhớ lại rằng bộ đếm thời gian được đặt lại mỗi khi một ack mới đến (và cửa sổ thay đổi).</p>
<p>Tác nhân kích hoạt thứ hai cho việc truyền lại là giả định rằng dữ liệu bị mất khi chúng ta nhận được ack cho các gói tin tiếp theo. Trong TCP dựa trên gói tin với cumulative acks (là những gì TCP sử dụng), chúng ta sẽ gửi lại một gói tin nếu chúng ta nhận được K duplicate acks (K=3 là phổ biến), điều này cho thấy rằng ba gói tin tiếp theo đã được xác nhận.</p>
<p>Trong TCP dựa trên byte, nếu chúng ta nhận được K duplicate acks, chúng ta sẽ gửi lại phân đoạn chưa được xác nhận ở ngoài cùng bên trái.</p>
<h2 id="tcp-header"><a class="header" href="#tcp-header">TCP Header</a></h2>
<img width="800px" src="transport/../assets/transport/3-050-tcp-header.png">
<p>TCP header có các source and destination ports (cổng nguồn và cổng đích) 16-bit.</p>
<p>TCP header có một sequence number 32-bit (độ lệch byte của byte đầu tiên trong gói tin này), và một số acknowledgement 32-bit (số thứ tự liên tục cao nhất đã nhận, cộng một).</p>
<p>TCP header có một checksum trên toàn bộ dữ liệu (không chỉ phần đầu), để phát hiện dữ liệu bị hỏng.</p>
<p>TCP header có advertised window, được sử dụng để hỗ trợ flow control và congestion control.</p>
<p>Header length (độ dài phần đầu) chỉ định số lượng từ 4-byte trong TCP header. Giả sử không có tùy chọn bổ sung nào, độ dài này là 5.</p>
<p>Các flags (cờ) là một chuỗi các bit có thể được đặt thành 1 hoặc 0. Khi một bit được đặt thành 1, cờ tương ứng được bật. Mọi người đều hiểu ngữ nghĩa của phần đầu, vì vậy họ biết bit nào tương ứng với cờ nào. Có bốn cờ liên quan cho các ghi chú này.</p>
<p>Cờ SYN (synchronize - đồng bộ hóa) được bật khi máy chủ đang gửi ISN của nó. Cờ này thường chỉ được bật trong hai tin nhắn đầu tiên của three-way handshake.</p>
<p>Cờ ACK (acknowledge - xác nhận) được bật khi số acknowledgement có liên quan và đang được sử dụng để xác nhận dữ liệu. Nếu tôi muốn gửi dữ liệu, nhưng không nhận được bất kỳ dữ liệu nào cần được xác nhận, tôi có thể tắt cờ này, điều này cho máy chủ khác biết để bỏ qua số ack.</p>
<p>Có 6 bit dành riêng sau header length luôn được đặt thành 0. Bạn có thể bỏ qua chúng một cách an toàn.</p>
<p>Urgent pointer (con trỏ khẩn) có thể được sử dụng để đánh dấu một số byte là khẩn cấp, điều này cho người nhận biết để gửi dữ liệu này đến ứng dụng càng sớm càng tốt. Đây là một trường lịch sử mà chúng ta sẽ không đề cập thêm.</p>
<p>TCP header có thể có các tùy chọn bổ sung được nối vào cuối (điều này sẽ làm cho phần đầu dài hơn), nhưng chúng ta sẽ bỏ qua các tùy chọn cho lớp học này. Ví dụ, nếu bạn muốn triển khai full-information acks, có một tùy chọn gọi là selective acknowledgements (SACK) (tin báo nhận chọn lọc) có thể được thêm vào phần đầu.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="các-nguyên-tắc-kiểm-soát-tắc-nghẽn"><a class="header" href="#các-nguyên-tắc-kiểm-soát-tắc-nghẽn">Các Nguyên tắc Kiểm soát Tắc nghẽn</a></h1>
<h2 id="tắc-nghẽn-gây-hại"><a class="header" href="#tắc-nghẽn-gây-hại">Tắc nghẽn Gây hại</a></h2>
<p>Hãy nhớ lại rằng nếu nhiều packet (gói tin) đến một router (bộ định tuyến) cùng một lúc (ví dụ: bursty traffic (lưu lượng truy cập dồn dập)), và router đó cần gửi tất cả các packet qua cùng một link, thì router sẽ gửi một packet và đặt các packet còn lại vào một queue (hàng đợi) (để được gửi sau).</p>
<img width="800px" src="transport/../assets/transport/3-051-congestion1.png">
<p>Tổng quát hơn, nếu tốc độ packet đầu vào vượt quá tốc độ đầu ra mà link có thể duy trì, router sẽ không thể theo kịp tốc độ của các packet đến. Router này đang bị congested (bị tắc nghẽn), và cần phải giữ các packet trong một queue trong khi chúng chờ đến lượt được gửi. Queue có thể gây ra packet delay (độ trễ gói tin). Nếu chính queue trở nên quá đầy mà các packet vẫn tiếp tục đến, thì các packet có thể bị dropped (bị loại bỏ/rớt).</p>
<img width="500px" src="transport/../assets/transport/3-052-congestion2.png">
<p>Biểu đồ này cho thấy hiệu suất của một hệ thống hàng đợi với lượng truy cập đến dồn dập. Đường đứt nét biểu thị dung lượng (tải tối đa) của link. Khi chúng ta tăng load (tải), các packet sẽ bị trễ nhiều hơn.</p>
<p>Khi lượng truy cập đến là bursty traffic, chúng ta không thể thực tế sử dụng hết dung lượng tối đa của link. Chúng ta phải tìm một sự cân bằng hiệu suất phù hợp giữa load và packet delay.</p>
<p>Lưu ý rằng biểu đồ bắt đầu dốc lên ngay cả trước khi chúng ta chạm đến đường đứt nét. Điều này có nghĩa là queue đã làm trễ các packet, ngay cả khi chưa có packet nào bị dropped. Vào thời điểm chúng ta đạt đến mức utilization (mức độ sử dụng) tối đa và bắt đầu mất packet, chúng ta đã phải gánh chịu độ trễ packet rất lớn từ queue.</p>
<h2 id="lược-sử-về-tắc-nghẽn"><a class="header" href="#lược-sử-về-tắc-nghẽn">Lược sử về Tắc nghẽn</a></h2>
<p>Vào những năm 1980, TCP (Transmission Control Protocol - Giao thức Điều khiển Truyền vận) không triển khai bất kỳ cơ chế kiểm soát tắc nghẽn nào. Tốc độ gửi chỉ bị giới hạn bởi flow control (điều khiển luồng) (dung lượng bộ đệm của người nhận).</p>
<p>Nếu các packet bị dropped, bên gửi sẽ gửi lại các bản sao của packet đó nhiều lần, với cùng tốc độ nhanh, cho đến khi packet đến nơi. Một cách tiếp cận thông minh hơn là giảm tốc độ để tránh packet bị dropped và giảm số lượng bản sao làm tắc nghẽn mạng, nhưng các triển khai TCP thời kỳ đầu đã không làm điều này.</p>
<p>Vào tháng 10 năm 1986, Internet bắt đầu hứng chịu một loạt các sự kiện congestion collapse (sụp đổ do tắc nghẽn), khi dung lượng của Internet giảm đáng kể. Một link giữa UC Berkeley và Lawrence Berkeley Lab (hai địa điểm cách nhau khoảng 400 yard) đã chứng kiến throughput (thông lượng) của nó giảm từ 32 Kbps = 32.000 bps xuống còn 40 bps.</p>
<p>Michael Karels (sinh viên đại học UC Berkeley) và Van Jacobson (nhà nghiên cứu tại Lawrence Berkeley Lab) đang làm việc trên chồng giao thức mạng trong hệ thống Unix Berkeley (một operating system (hệ điều hành) có ảnh hưởng thời kỳ đầu), và họ nhận ra rằng mạng có hàng ngàn bản sao của cùng một packet, bởi vì mọi người đều đang cố gắng gửi lại các packet bị dropped.</p>
<p>Karels và Jacobson đã phát triển một thuật toán để khắc phục sự cố, thuật toán này đã phát triển thành thuật toán kiểm soát tắc nghẽn TCP hiện đại. Giải pháp của họ là một sửa đổi đối với chính TCP, trong đó window size (kích thước cửa sổ) (quyết định tốc độ gửi packet) được điều chỉnh linh hoạt để phản ứng với việc mất packet.</p>
<p>Bởi vì giải pháp của họ là một sửa đổi logic của TCP (hãy nhớ lại, TCP được triển khai trong operating system), không cần phải nâng cấp router hay các ứng dụng.</p>
<p>Kiểm soát tắc nghẽn TCP là một trong nhiều ví dụ về thiết kế Internet mang tính đặc thù (ad-hoc). Bản vá của Karels và Jacobson chỉ là vài dòng mã bổ sung trong việc triển khai TCP của hệ điều hành BSD. Bản vá đã hoạt động hiệu quả, vì vậy nó nhanh chóng được chấp nhận. Kể từ đó, chủ đề kiểm soát tắc nghẽn đã được nghiên cứu rộng rãi và một số cải tiến đã được thực hiện, nhưng cuối cùng, những ý tưởng cốt lõi trong bản vá ban đầu vẫn tồn tại cho đến ngày nay. Internet đã không còn xảy ra congestion collapse kể từ đó, vì vậy giải pháp ban đầu đã đứng vững trước thử thách của thời gian.</p>
<h2 id="tại-sao-kiểm-soát-tắc-nghẽn-lại-khó"><a class="header" href="#tại-sao-kiểm-soát-tắc-nghẽn-lại-khó">Tại sao Kiểm soát Tắc nghẽn lại Khó?</a></h2>
<p>Để có cảm nhận về lý do tại sao kiểm soát tắc nghẽn là một vấn đề khó khăn, hãy xem xét network graph (đồ thị mạng) sau đây. Host (thiết bị đầu cuối) A nên gửi lưu lượng với tốc độ nào?</p>
<img width="700px" src="transport/../assets/transport/3-053-congestion3.png">
<p>Điều đó phụ thuộc vào đích đến, vì vậy A không thể chỉ đưa ra một tốc độ cố định cho tất cả các đích. Ví dụ, nếu A đang giao tiếp với C, thì A có thể gửi packet ở tốc độ 10 Gbps.</p>
<p>Nếu A đang giao tiếp với F thì sao? Bottleneck link (liên kết thắt cổ chai) (dung lượng thấp nhất) trên đường đi này là 2Gbps, vì vậy A có lẽ nên gửi packet ở tốc độ 2 Gbps.</p>
<img width="700px" src="transport/../assets/transport/3-054-congestion4.png">
<p>Nếu A đang giao tiếp với E thì sao?</p>
<p>Điều đó phụ thuộc vào đường đi mà lưu lượng đang di chuyển giữa A và E. Nếu lưu lượng đang đi theo đường dưới qua R3, thì A có thể gửi packet ở tốc độ 10 Gbps. Nhưng nếu lưu lượng đang đi theo đường trên qua R2, thì A bây giờ chỉ có thể gửi packet ở tốc độ 1 Gbps.</p>
<img width="700px" src="transport/../assets/transport/3-055-congestion5.png">
<p>Một điểm có thể rút ra cho đến nay là thuật toán kiểm soát tắc nghẽn của chúng ta sẽ cần phải tìm hiểu bằng cách nào đó về bandwidth (băng thông) và các bottleneck link trên đường đi mà packet đang di chuyển.</p>
<p>Ngoài ra, hãy nhớ lại rằng network graph thay đổi theo thời gian khi các link mới được thêm vào hoặc các link bị hỏng. Điều này có nghĩa là việc tìm hiểu về các đường đi một lần là không đủ. Thuật toán của chúng ta cần phải thích ứng với những thay đổi trong cấu trúc liên kết mạng.</p>
<p>Cho đến nay, chúng ta đã giả định rằng A là host duy nhất gửi lưu lượng trên mạng và A có thể sử dụng toàn bộ dung lượng của mọi link. Nhưng nếu các connection (kết nối) khác cũng đang sử dụng bandwidth thì sao?</p>
<img width="700px" src="transport/../assets/transport/3-056-congestion6.png">
<p>Trong ví dụ này, A và F có một connection, và B và E có một connection. Hai connection này có vẻ hoàn toàn tách biệt (người gửi khác nhau, người nhận khác nhau), nhưng thực tế, đường đi của chúng chia sẻ chung một link trong mạng.</p>
<p>Nếu chúng ta muốn hai connection này chia sẻ dung lượng trên link này một cách công bằng, có lẽ A và B mỗi bên nên gửi ở tốc độ 1 Gbps.</p>
<p>Điều gì sẽ xảy ra nếu một connection mới bắt đầu giữa G và D? A có nên thay đổi tốc độ 1 Gbps của mình không? (Chưa có thuật toán chính thức, chỉ cần suy nghĩ về việc sử dụng bandwidth một cách hợp lý.)</p>
<img width="700px" src="transport/../assets/transport/3-057-congestion7.png">
<p>Đầu tiên, hãy lưu ý rằng các connection G-D và B-E đang chia sẻ chung một link. Điều này có nghĩa là hai connection này phải giảm tốc độ xuống còn 0.5 Gbps.</p>
<p>Bây giờ, nếu chúng ta nhìn lại link 2 Gbps mà A-F và B-E có chung, B-E chỉ đang sử dụng 0.5 Gbps trên link này. Điều này có nghĩa là A có thể tăng tốc độ của mình lên 1.5 Gbps.</p>
<p>Chuyện gì đã xảy ra ở đây? Connection G-D được tạo ra, và đường đi của nó không có link nào chung với connection A-F. Tuy nhiên, connection tưởng chừng như không liên quan này lại khiến tốc độ của connection A-F tăng lên. Các connection có thể gián tiếp ảnh hưởng đến các connection khác, ngay cả khi hai connection đó không chia sẻ chung bất kỳ link nào!</p>
<p>Tóm lại: Khi bên gửi đang cố gắng xác định tốc độ gửi packet, nó phải xem xét: Đích đến, đường đi đến đích đó, các connection chia sẻ link trên đường đi đó, và các connection chia sẻ link với những connection đó (cạnh tranh gián tiếp), và cứ thế tiếp diễn. Kiểm soát tắc nghẽn là một vấn đề khó khăn vì tất cả các connection trong mạng đều phụ thuộc lẫn nhau để xác định tốc độ gửi tối ưu của chúng.</p>
<p>Về cơ bản hơn, kiểm soát tắc nghẽn là một bài toán resource allocation (phân bổ tài nguyên). Bandwidth là một tài nguyên có hạn, mỗi connection muốn một lượng tài nguyên nhất định, và chúng ta cần quyết định phân bổ bao nhiêu bandwidth cho mỗi connection.</p>
<p>Resource allocation là một bài toán kinh điển trong khoa học máy tính. (Ví dụ bao gồm các thuật toán lập lịch CPU và phân bổ bộ nhớ.) Tuy nhiên, không giống như một số bài toán resource allocation, sự thay đổi trong việc phân bổ của một connection có thể có tác động toàn cục đến tất cả các connection khác. Ngoài ra, việc phân bổ phải thay đổi mỗi khi một connection được tạo hoặc hủy. Do đó, kiểm soát tắc nghẽn phức tạp hơn bài toán resource allocation truyền thống, và trên thực tế, chúng ta thậm chí không có một mô hình chính thức để định nghĩa bài toán.</p>
<p>Không giống như một bài toán resource allocation truyền thống, nơi thuật toán biết trước về tài nguyên (ví dụ: thời gian CPU) và các công việc (ví dụ: các tiến trình), không có một bộ não trung tâm nào có thể nhìn thấy toàn bộ mạng để phân bổ tài nguyên. Giải pháp của chúng ta phải là decentralized (phân tán), nơi mỗi người gửi tự quyết định việc phân bổ của mình (mặc dù các quyết định của mọi người phụ thuộc rất nhiều vào nhau).</p>
<h2 id="các-mục-tiêu-cho-một-thuật-toán-kiểm-soát-tắc-nghẽn-tốt"><a class="header" href="#các-mục-tiêu-cho-một-thuật-toán-kiểm-soát-tắc-nghẽn-tốt">Các Mục tiêu cho một Thuật toán Kiểm soát Tắc nghẽn Tốt</a></h2>
<p>Từ góc độ resource allocation, có ba mục tiêu chúng ta muốn đạt được từ một thuật toán kiểm soát tắc nghẽn tốt.</p>
<p>Chúng ta muốn việc resource allocation phải efficient (hiệu quả). Các link không nên bị quá tải, và phải có packet delay và mất mát packet ở mức tối thiểu. Ngoài ra, các link nên được tận dụng càng nhiều càng tốt.</p>
<p>Chúng ta cũng muốn việc resource allocation phải fair (công bằng) giữa các connection. Chúng ta sẽ định nghĩa chính thức khái niệm công bằng sau, nhưng nói một cách gần đúng, mỗi connection nên chia sẻ một phần bằng nhau của dung lượng có sẵn.</p>
<p>Chúng ta muốn một giải pháp đạt được sự cân bằng tốt giữa các mục tiêu này. Có thể tối ưu hóa một mục tiêu bằng cách hy sinh các mục tiêu khác, nhưng điều đó dẫn đến các giải pháp tồi. Ví dụ, chúng ta có thể đảm bảo utilization link tối đa bằng cách để mọi người gửi packet cực nhanh (giải pháp tồi, gây tắc nghẽn). Hoặc, chúng ta có thể đảm bảo mất packet tối thiểu bằng cách để mọi người gửi packet cực chậm (giải pháp tồi, không tận dụng hết dung lượng).</p>
<p>Từ góc độ hệ thống thực tế hơn, giải pháp mà chúng ta đưa ra cần phải scalable (có khả năng mở rộng) và decentralized. Giải pháp của chúng ta cũng phải có khả năng thích ứng với những thay đổi trong mạng (ví dụ: cấu trúc liên kết thay đổi, các connection được tạo và hủy).</p>
<h2 id="không-gian-thiết-kế-của-các-giải-pháp"><a class="header" href="#không-gian-thiết-kế-của-các-giải-pháp">Không gian Thiết kế của các Giải pháp</a></h2>
<p>Như chúng ta đã thấy trước đó, Karels và Jacobson đã sửa lỗi kiểm soát tắc nghẽn TCP bằng cách vá lại việc triển khai TCP trong operating system. Nhưng, nếu chúng ta có thể quay lại và thiết kế lại Internet từ đầu, những thiết kế khả thi nào khác cho kiểm soát tắc nghẽn tồn tại?</p>
<p>Một thiết kế thay thế khả thi là dựa trên reservations (dành riêng/đặt trước). Người gửi có thể yêu cầu bandwidth trước, và sau đó giải phóng bandwidth đó sau khi connection kết thúc. Như đã thảo luận trước đó, việc duy trì một reservation trên toàn bộ mạng đi kèm với nhiều khó khăn kỹ thuật. Cách tiếp cận này cũng có vấn đề vì nó giả định rằng người gửi biết trước mình cần bao nhiêu bandwidth, điều này không nhất thiết phải đúng.</p>
<p>Một thiết kế thay thế khác là dựa trên pricing (định giá). Tương tự như vậy, hãy xem xét các làn đường thu phí nhanh trên đường cao tốc (các làn đường dành riêng chỉ dành cho những người lái xe trả phí). Giá để sử dụng làn đường thu phí nhanh phụ thuộc vào mức độ tắc nghẽn của đường cao tốc. Khi đường cao tốc có rất ít xe, việc sử dụng làn thu phí rất rẻ, và khi có lưu lượng giao thông đông đúc, việc sử dụng làn thu phí sẽ đắt hơn. Một hình thức pricing tắc nghẽn khác xảy ra trong vé máy bay, giá sẽ cao hơn vào những thời điểm bận rộn hơn (ví dụ: ngày lễ).</p>
<p>Để áp dụng pricing tắc nghẽn cho Internet, ISP (Internet Service Provider - Nhà cung cấp dịch vụ Internet) của bạn có thể thêm một nút trong trình duyệt web cho phép tốc độ Internet cao hơn với một khoản phí bổ sung, và khoản phí này có thể thay đổi tùy thuộc vào mức độ tắc nghẽn của Internet. Sau đó, các router có thể ưu tiên gửi packet từ những người dùng trả nhiều tiền hơn, và drop các packet từ những người dùng không trả tiền. Đã có nghiên cứu về pricing tắc nghẽn trên Internet, và các nhà kinh tế đôi khi cho rằng nếu bandwidth là một mặt hàng khan hiếm, thì cấu trúc thị trường sẽ dẫn đến một giải pháp tối ưu. Pricing tắc nghẽn chưa được triển khai rộng rãi, vì nó đòi hỏi một mô hình kinh doanh nào đó kết nối việc thanh toán với tình trạng tắc nghẽn.</p>
<p>Tất cả các thuật toán kiểm soát tắc nghẽn hiện đại (bao gồm cả những thuật toán chúng ta sẽ nghiên cứu) đều dựa trên dynamic adjustment (điều chỉnh động). Các host tự động tìm hiểu mức độ tắc nghẽn hiện tại và điều chỉnh tốc độ gửi của chúng cho phù hợp. Trong thực tế, dynamic adjustment là một giải pháp thiết thực vì nó có thể được tổng quát hóa một cách dễ dàng. Cách tiếp cận này không giả định bất kỳ mô hình kinh doanh nào (cần thiết cho pricing), và không giả định bất cứ điều gì về việc người dùng biết trước bandwidth họ cần (cần thiết cho reservations).</p>
<p>Dynamic adjustment đòi hỏi ý thức công dân tốt. TCP cần mọi người trên mạng làm việc cùng nhau để chia sẻ tài nguyên một cách công bằng. Ví dụ, khi một connection mới bắt đầu sử dụng các link, các connection khác cần phải giảm tốc độ và chia sẻ bandwidth.</p>
<p>Trong cách tiếp cận dynamic adjustment, có hai lớp giải pháp chính. Trong các thuật toán kiểm soát tắc nghẽn host-based (dựa trên host), người gửi giám sát hiệu suất và điều chỉnh tốc độ của mình cho phù hợp. Các thuật toán này được triển khai hoàn toàn tại người gửi, và không có sự hỗ trợ đặc biệt nào từ các router. Việc sửa đổi TCP là một thuật toán host-based, và được triển khai rộng rãi ngày nay.</p>
<p>Trong các thuật toán kiểm soát tắc nghẽn router-assisted (có sự hỗ trợ từ router), các router sẽ gửi thông tin rõ ràng về tắc nghẽn trở lại cho người gửi, để giúp người gửi điều chỉnh tốc độ của mình. Tắc nghẽn xảy ra tại các router, vì vậy các router ở một vị trí tốt để cung cấp thông tin về tắc nghẽn. Các thuật toán router-assisted đã được triển khai trong những năm gần đây, đặc biệt là trong các trung tâm dữ liệu.</p>
<p>Một số thuật toán router-assisted gửi rất ít thông tin, ví dụ: một bit duy nhất cho biết có tắc nghẽn, trong khi các thuật toán khác gửi thông tin chi tiết hơn, ví dụ: tốc độ chính xác mà người gửi nên sử dụng.</p>
<p>Lưu ý rằng trong cả hai trường hợp, các router đều đang báo hiệu tắc nghẽn trở lại cho người gửi. Trong các thuật toán router-assisted, router đang gửi một thông điệp rõ ràng về mức độ tắc nghẽn của nó. Ngược lại, trong các thuật toán host-based, người gửi không nhận được phản hồi rõ ràng từ các router. Thay vào đó, người gửi sử dụng các manh mối ngầm từ router (ví dụ: packet bị dropped hoặc bị trễ) để suy luận rằng router đang bị congested.</p>
<img width="600px" src="transport/../assets/transport/3-058-taxonomy.png">
<p>Trong sơ đồ phân loại các phương pháp kiểm soát tắc nghẽn này, chúng ta sẽ tập trung vào phương pháp dynamic adjustment, và trong không gian các giải pháp dynamic adjustment, chúng ta sẽ tập trung vào các giải pháp host-based.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="thiết-kế-kiểm-soát-tắc-nghẽn-cc-design"><a class="header" href="#thiết-kế-kiểm-soát-tắc-nghẽn-cc-design">Thiết kế Kiểm soát Tắc nghẽn (CC Design)</a></h1>
<h2 id="phác-thảo-thuật-toán-dựa-trên-máy-chủ"><a class="header" href="#phác-thảo-thuật-toán-dựa-trên-máy-chủ">Phác thảo Thuật toán dựa trên Máy chủ</a></h2>
<p>Hầu hết các thuật toán dựa trên máy chủ đều tuân theo cùng một phương pháp chung, và sự khác biệt nảy sinh ở ba điểm lựa chọn chính.</p>
<p>Mỗi nguồn chạy độc lập logic sau đây một cách lặp đi lặp lại trong một vòng lặp: Thử gửi ở một rate (tốc độ) R trong một khoảng thời gian nào đó. Sau đó, tự hỏi: Liệu tôi có gặp phải congestion (sự tắc nghẽn) trong khoảng thời gian này không? Nếu có, thì giảm R. Nếu không, thì tăng R.</p>
<p>Một mảnh ghép còn thiếu là: chúng ta bắt đầu gửi ở rate ban đầu nào? Chúng ta sẽ cần một cách nào đó để chọn rate ban đầu R.</p>
<p>Ba điểm lựa chọn chính là: Làm thế nào để chúng ta chọn rate ban đầu? Làm thế nào để chúng ta phát hiện congestion? Chúng ta nên tăng và giảm bao nhiêu mỗi lần?</p>
<h2 id="phát-hiện-tắc-nghẽn"><a class="header" href="#phát-hiện-tắc-nghẽn">Phát hiện Tắc nghẽn</a></h2>
<p>Làm thế nào người gửi phát hiện ra nếu mạng bị tắc nghẽn? Có hai cách tiếp cận phổ biến.</p>
<p>Người gửi có thể kiểm tra packet loss (mất gói tin). Đây là phương pháp thường được TCP sử dụng. Cách tiếp cận này tốt vì tín hiệu là rõ ràng. Mỗi packet hoặc được đánh dấu là bị mất (timeout (hết thời gian chờ) hoặc duplicate ack (ack trùng lặp)), hoặc không bị mất. Ngoài ra, TCP đã phát hiện các packet bị mất để gửi lại chúng, vì vậy chúng ta không cần phải triển khai lại điều này từ đầu.</p>
<p>Cách tiếp cận này có thể không tốt vì đôi khi, packet loss là do corruption (lỗi dữ liệu) (checksum không hợp lệ), chứ không phải do congestion. Trên thực tế, TCP bị nhầm lẫn và hoạt động kém khi một liên kết không bị tắc nghẽn, nhưng thường xuyên làm hỏng các packet. Ngoài ra, TCP có thể bị nhầm lẫn bởi các packet bị reordered (sắp xếp lại thứ tự). Một packet đến muộn có thể bị coi nhầm là đã mất.</p>
<p>Một nhược điểm quan trọng khác của cách tiếp cận này là, chúng ta phát hiện congestion muộn. Vào thời điểm các packet bắt đầu bị loại bỏ, hàng đợi của router đã đầy và các packet đang bị trễ.</p>
<p>Thay vì kiểm tra packet loss, người gửi có thể phát hiện congestion bằng cách kiểm tra packet delay (độ trễ gói tin). Người gửi có thể đo thời gian giữa việc gửi một packet và nhận được ack cho packet đó. Nếu người gửi nhận thấy rằng độ trễ đang tăng lên, đó có thể là một dấu hiệu của congestion.</p>
<p>Trong lịch sử, việc đo lường độ trễ một cách chính xác được coi là khó khăn. Packet delay có thể thay đổi tùy thuộc vào kích thước hàng đợi và lưu lượng khác. Trong nhiều năm, phương pháp dựa trên độ trễ không được triển khai rộng rãi, mặc dù trong những năm gần đây, giao thức BBR của Google (2016) đã cho thấy rằng các thuật toán dựa trên độ trễ là khả thi, và một số dịch vụ (ví dụ: các dịch vụ của Google) đã áp dụng các thuật toán dựa trên độ trễ.</p>
<img width="600px" src="transport/../assets/transport/3-059-taxonomy2.png">
<h2 id="khám-phá-tốc-độ-ban-đầu"><a class="header" href="#khám-phá-tốc-độ-ban-đầu">Khám phá Tốc độ ban đầu</a></h2>
<p>Khi một kết nối mới bắt đầu, chúng ta phải tìm ra một rate ban đầu để gửi các packet. Chúng ta có thể tìm ra một rate ban đầu bằng cách sử dụng một quy trình khám phá, trong đó chúng ta thử một vài rate khác nhau để có được ước tính về bandwidth khả dụng.</p>
<p>Chúng ta muốn quy trình khám phá này phải an toàn, vì vậy chúng ta nên bắt đầu với các rate chậm. Chúng ta không muốn ngay lập tức làm ngập mạng với các packet.</p>
<p>Đồng thời, chúng ta muốn quy trình khám phá nhanh chóng tìm ra bandwidth khả dụng, vì lý do hiệu quả. Để đạt được điều này, chúng ta sẽ nhanh chóng tăng rate trong mỗi lần thử tiếp theo. Nếu quá trình khám phá mất nhiều thời gian, chúng ta đã lãng phí thời gian mà lẽ ra có thể dành để gửi các packet ở rate tối ưu. Ví dụ, giả sử chúng ta cộng thêm 0.5 Mbps vào rate mỗi 100ms, cho đến khi chúng ta phát hiện congestion (mất mát). Nếu bandwidth khả dụng là 1 Mbps, giai đoạn khám phá sẽ mất 2 lần lặp = 200 ms. Tuy nhiên, nếu bandwidth khả dụng là 1 Gbps = 1000 Mbps, thì giai đoạn khám phá sẽ mất 2000 lần lặp = 200 giây trước khi chúng ta tăng tốc đến một rate tốt, điều này quá dài. Internet có rất nhiều tốc độ liên kết khác nhau, vì vậy cả hai khả năng đều có thể xảy ra trong thực tế.</p>
<p>Để hỗ trợ việc bắt đầu chậm nhưng tăng tốc nhanh, chúng ta sẽ tăng bandwidth theo một hệ số nhân mỗi lần (thay vì một hệ số cộng). Giải pháp này được gọi là <strong>slow start (khởi động chậm)</strong>, mặc dù đây có thể là một cái tên không trực quan. Trong slow start, chúng ta bắt đầu với một rate nhỏ mà gần như luôn luôn nhỏ hơn nhiều so với bandwidth thực tế. Sau đó, chúng ta tăng rate theo cấp số nhân (ví dụ: nhân đôi rate mỗi lần) cho đến khi gặp phải packet loss. Một rate an toàn để sử dụng là rate ngay trước khi chúng ta gặp packet loss (chúng ta không muốn sử dụng một rate mà chúng ta đã gặp packet loss). Về mặt hình thức, nếu packet loss xảy ra ở rate R, thì rate an toàn là R/2.</p>
<img width="700px" src="transport/../assets/transport/3-060-slow-start.png">
<h2 id="Điều-chỉnh-phản-ứng-với-tắc-nghẽn"><a class="header" href="#Điều-chỉnh-phản-ứng-với-tắc-nghẽn">Điều chỉnh: Phản ứng với Tắc nghẽn</a></h2>
<p>Hãy nhớ lại rằng sau giai đoạn khám phá, chúng ta sẽ liên tục điều chỉnh bandwidth, vì bản thân mạng đang thay đổi, và bandwidth khả dụng không phải là hằng số.</p>
<p>Điểm lựa chọn cuối cùng là quyết định chúng ta nên giảm bandwidth bao nhiêu nếu phát hiện congestion, và tăng bandwidth bao nhiêu nếu không phát hiện congestion.</p>
<p>Quyết định của chúng ta sẽ xác định tốc độ một máy chủ thích ứng với những thay đổi về bandwidth khả dụng, điều này lại quyết định hiệu quả tiêu thụ bandwidth. Nếu chúng ta mất nhiều thời gian để thích ứng với những thay đổi và tìm ra một rate tốt, chúng ta sẽ dành nhiều thời gian hoạt động ở bandwidth dưới mức tối ưu, điều này không hiệu quả. Sự thích ứng chậm cũng có thể dẫn đến các vấn đề về tính công bằng. Ví dụ, nếu tôi đang sử dụng toàn bộ bandwidth của một liên kết, và một kết nối khác được mở, tôi cần phải nhanh chóng thích ứng và giảm bandwidth của mình để chia sẻ liên kết.</p>
<p>Hãy nhớ lại rằng các mục tiêu chính của chúng ta trong một thuật toán kiểm soát tắc nghẽn là efficiency (hiệu quả) (sử dụng tất cả bandwidth khả dụng) và fairness (tính công bằng) (các kết nối chia sẻ bandwidth một cách bình đẳng). Chúng ta sẽ cần chọn các quy tắc tăng và giảm để đạt được cả hai mục tiêu này.</p>
<p>Chúng ta có thể chọn những quy tắc nào? Ở cấp độ cao, chúng ta có thể phản ứng nhanh hoặc chậm. Cụ thể hơn, những thay đổi nhanh là theo cấp số nhân, ví dụ: nhân đôi hoặc chia đôi rate trong mỗi lần lặp. Những thay đổi chậm là theo cấp số cộng, ví dụ: cộng 1 vào rate hoặc trừ 1 khỏi rate trong mỗi lần lặp. Những tùy chọn này tạo ra bốn phương án khả thi:</p>
<p><strong>AIAD</strong>: additive increase (tăng tuyến tính), additive decrease (giảm tuyến tính)</p>
<p><strong>AIMD</strong>: additive increase, multiplicative decrease (giảm theo cấp số nhân)</p>
<p><strong>MIAD</strong>: multiplicative increase (tăng theo cấp số nhân), additive decrease</p>
<p><strong>MIMD</strong>: multiplicative increase, multiplicative increase</p>
<p>Trong bốn phương án này, hóa ra AIMD (tăng chậm, giảm nhanh) là tốt nhất để đạt được efficiency và fairness.</p>
<p>Về mặt trực quan, AIMD là một lựa chọn hợp lý vì gửi quá nhiều còn tệ hơn gửi quá ít. Khi rate của chúng ta quá cao, chúng ta gây ra congestion, và các packet bị loại bỏ. Khi rate của chúng ta quá thấp, chúng ta không sử dụng hết bandwidth, nhưng ít nhất chúng ta không gây ra congestion.</p>
<p>AIMD dẫn đến hành vi mà chúng ta từ từ tăng rate khi không có congestion, dần dần tiến đến bandwidth tối đa. Sau đó, ngay khi chúng ta vượt quá bandwidth tối đa và phát hiện congestion, chúng ta nhanh chóng giảm xuống. Bằng cách này, chúng ta dành phần lớn thời gian với rate quá thấp (được ưu tiên hơn), và khi rate quá cao (không được ưu tiên), chúng ta nhanh chóng giảm để tránh congestion.</p>
<img width="700px" src="transport/../assets/transport/3-061-sawtooth.png">
<h2 id="Điều-chỉnh-mô-hình"><a class="header" href="#Điều-chỉnh-mô-hình">Điều chỉnh: Mô hình</a></h2>
<p>Tại sao AIMD là lựa chọn tốt nhất để đạt được efficiency và fairness? Hãy thực hiện một phân tích chi tiết hơn.</p>
<p>Đầu tiên, hãy lưu ý rằng cả bốn tùy chọn đều làm khá tốt trong việc đạt được efficiency. Bằng cách tăng khi chúng ta ở dưới rate tối ưu (không bị tắc nghẽn), và giảm khi chúng ta ở trên rate tối ưu (bị tắc nghẽn), rate của chúng ta sẽ luôn dao động quanh rate tối ưu trong dài hạn.</p>
<p>Tuy nhiên, hóa ra trong bốn tùy chọn này, AIMD là tùy chọn duy nhất dẫn đến fairness. Để hiểu tại sao, hãy xem xét một mô hình đơn giản trong đó có hai kết nối đi qua một liên kết duy nhất có capacity (dung lượng) C. Hai kết nối đang gửi ở các rate X1 và X2, tương ứng. Chúng ta biết rằng nếu X1+X2 lớn hơn C, mạng bị tắc nghẽn, và nếu X1+X2 nhỏ hơn C, thì mạng đang bị underloaded (sử dụng dưới tải).</p>
<p>Để đạt được efficiency, chúng ta muốn liên kết được sử dụng hết, tức là X1+X2 = C. Để đạt được fairness, chúng ta muốn X1 = X2, để cả hai kết nối đều chia sẻ capacity một cách bình đẳng.</p>
<p>Để hình dung không gian các khả năng, hãy xem xét một biểu đồ 2D, trong đó trục x là X1 (rate của người dùng 1), và trục y là X2 (rate của người dùng 2). Mỗi điểm trên biểu đồ này đại diện cho một kịch bản khả thi trong đó mỗi người dùng đang gửi ở một rate cụ thể.</p>
<p>Giả sử C=1. Để đạt được efficiency tối đa, chúng ta muốn X1+X2 = 1. Chúng ta có thể vẽ đường thẳng này trên đồ thị. Mọi điểm dọc theo đường thẳng này đều đang sử dụng toàn bộ bandwidth khả dụng.</p>
<img width="500px" src="transport/../assets/transport/3-062-graph1.png">
<p>Chúng ta biết rằng mạng bị tắc nghẽn khi X1+X2 lớn hơn 1. Trên biểu đồ, bất đẳng thức này là nửa mặt phẳng phía trên đường thẳng. Chúng ta cũng biết rằng mạng đang được sử dụng dưới mức khi X1+X2 nhỏ hơn 1, được biểu thị bằng nửa mặt phẳng bên dưới đường thẳng. Điều này có nghĩa là tất cả các điểm phía trên đường thẳng đại diện cho trạng thái tắc nghẽn, và tất cả các điểm bên dưới đường thẳng đại diện cho trạng thái sử dụng dưới mức.</p>
<img width="500px" src="transport/../assets/transport/3-063-graph2.png">
<p>Để đạt được fairness, chúng ta muốn X1 = X2. Chúng ta cũng có thể vẽ đường thẳng này. Mọi điểm dọc theo đường thẳng này đại diện cho một trạng thái công bằng, trong đó cả hai người dùng đang sử dụng cùng một lượng bandwidth. Bất kỳ điểm nào không nằm trên đường này là không công bằng.</p>
<p>Trạng thái lý tưởng xảy ra tại giao điểm của hai đường thẳng, khi X1 = X2 = 0.5. Điểm này nằm trên cả hai đường thẳng, vì vậy nó vừa công bằng vừa hiệu quả.</p>
<p>Điểm (0.2, 0.5) là không hiệu quả, vì chúng ta chỉ đang sử dụng 0.7 bandwidth. Về mặt đồ thị, chúng ta đang ở dưới đường hiệu quả. Điểm (0.7, 0.5) bị tắc nghẽn và do đó ở trên đường hiệu quả. Điểm (0.7, 0.3) là hiệu quả (nằm trên đường hiệu quả), nhưng không công bằng (không nằm trên đường công bằng).</p>
<img width="500px" src="transport/../assets/transport/3-064-graph3.png">
<p>Hãy nhớ lại rằng trong thuật toán điều chỉnh động của chúng ta, mỗi người gửi đều chạy độc lập cùng một thuật toán để xác định rate của riêng mình. Điều này có nghĩa là nếu hai người dùng phát hiện việc sử dụng dưới mức, cả hai sẽ tăng rate của họ theo cùng một cách (cộng hoặc nhân, tùy thuộc vào lựa chọn quy tắc của chúng ta). Tương tự, nếu hai người dùng phát hiện congestion, cả hai sẽ giảm rate của họ theo cùng một cách.</p>
<p>Điều gì xảy ra nếu cả hai người dùng tăng hoặc giảm rate của họ theo phép cộng? Nếu cả hai người dùng tăng rate của họ bằng cách cộng thêm b, trạng thái (x1, x2) sẽ trở thành (x1+b, x2+b). Nếu cả hai người dùng giảm rate của họ bằng cách trừ đi a, trạng thái (x1, x2) sẽ trở thành (x1-a, x2-a).</p>
<p>Trên đồ thị, nếu chúng ta thực hiện một thay đổi cộng, điểm đại diện cho trạng thái của chúng ta sẽ di chuyển dọc theo một đường thẳng có độ dốc là 1.</p>
<img width="500px" src="transport/../assets/transport/3-065-graph4.png">
<p>Điều gì xảy ra nếu cả hai người dùng tăng hoặc giảm rate của họ theo phép nhân? Nhân với c biến (x1, x2) thành (cx1, cx2), và chia cho d biến (x1, x2) thành (x1/d, x2/d).</p>
<p>Trên đồ thị, nếu chúng ta thực hiện một thay đổi nhân, điểm đại diện cho trạng thái của chúng ta sẽ di chuyển dọc theo một đường thẳng có độ dốc x2/x1. Tương đương, đây là đường thẳng nối (x1, x2) với gốc tọa độ (0, 0).</p>
<img width="500px" src="transport/../assets/transport/3-066-graph5.png">
<p>Bây giờ, chúng ta có thể áp dụng mô hình này cho từng tùy chọn tăng/giảm trong bốn tùy chọn, và xem liệu chúng có khiến điểm tiến đến, hay di chuyển ra xa, đường công bằng hay không. Mục tiêu của chúng ta là điểm tiến đến đường công bằng khi chúng ta điều chỉnh rate.</p>
<h2 id="Điều-chỉnh-Động-học-aiad"><a class="header" href="#Điều-chỉnh-Động-học-aiad">Điều chỉnh: Động học AIAD</a></h2>
<p>Hãy xem xét việc cộng 1 cho mỗi lần tăng, và trừ 2 cho mỗi lần giảm. Giả sử chúng ta có capacity là C = 5. Thì từ một điểm xuất phát cho trước, điểm của chúng ta sẽ di chuyển như sau:</p>
<p>X1 = 1, X2 = 3 (điểm bắt đầu, 4 nhỏ hơn 5, tăng)</p>
<p>X1 = 2, X2 = 4 (6 lớn hơn 5, giảm)</p>
<p>X1 = 0, X2 = 2 (2 nhỏ hơn 5, tăng)</p>
<p>X1 = 1, X2 = 3</p>
<p>Chúng ta đã quay trở lại nơi chúng ta bắt đầu! Phân bổ ban đầu của chúng ta không công bằng, và sau một vài lần lặp, chúng ta đã quay trở lại cùng một phân bổ không công bằng.</p>
<p>Trên thực tế, nếu chúng ta nhìn vào sự khác biệt giữa X1 và X2 (khoảng cách công bằng là 0), khoảng cách này là như nhau (2) trong mỗi lần lặp. Các lần lặp không làm cho phân bổ của chúng ta công bằng hơn hay kém công bằng hơn.</p>
<p>Chúng ta có thể thấy hành vi này trên đồ thị. Từ một điểm xuất phát cho trước, nếu chúng ta tăng và giảm theo phép cộng, chúng ta sẽ luôn di chuyển dọc theo một đường thẳng có độ dốc là 1, không bao giờ tiến gần hơn đến đường công bằng.</p>
<img width="500px" src="transport/../assets/transport/3-067-aiad.png">
<p>Tuy nhiên, hãy lưu ý rằng điểm của chúng ta dao động quanh đường hiệu quả, như mong muốn. Tất cả bốn tùy chọn sẽ có hành vi này.</p>
<p>Chúng ta cũng có thể thấy hành vi này về mặt đại số. Giả sử X1 và X2 cách nhau 5 đơn vị (phân bổ không công bằng). Nếu chúng ta cộng cùng một số vào X1 và X2, kết quả X1' và X2' vẫn cách nhau 5 đơn vị (cũng không công bằng). Điều tương tự cũng xảy ra nếu chúng ta trừ cùng một số khỏi cả X1 và X2.</p>
<p>Tóm lại, không có cách nào để thu hẹp khoảng cách công bằng trong cách tiếp cận này. Nếu phân bổ ban đầu không công bằng, nó sẽ vẫn không công bằng.</p>
<p>Bạn có thể hỏi: Điều gì sẽ xảy ra nếu chúng ta tăng X1 nhiều hơn (ví dụ: +2), và X2 ít hơn (ví dụ: +1)? Hãy nhớ rằng, cách tiếp cận phi tập trung của chúng ta có nghĩa là mọi người đều đang chạy cùng một thuật toán. Về mặt thực tế, chúng ta cũng không có cách nào để một máy chủ biết nó nên cộng thêm bao nhiêu so với các máy chủ khác.</p>
<h2 id="Điều-chỉnh-Động-học-mimd"><a class="header" href="#Điều-chỉnh-Động-học-mimd">Điều chỉnh: Động học MIMD</a></h2>
<p>Hãy xem xét việc tăng bằng cách nhân đôi, và giảm bằng cách chia cho 4. Một lần nữa, capacity là C = 5. Từ một điểm xuất phát cho trước, một vài lần lặp đầu tiên sẽ là:</p>
<p>X1 = 0.5, X2 = 1 (1.5 nhỏ hơn 5, tăng)</p>
<p>X1 = 1, X2 = 2 (3 nhỏ hơn 5, tăng)</p>
<p>X1 = 2, X2 = 4 (6 lớn hơn 5, giảm)</p>
<p>X1 = 0.5, X2 = 1</p>
<p>Một lần nữa, chúng ta đã quay trở lại nơi chúng ta bắt đầu, không có sự cải thiện nào về fairness!</p>
<p>Chúng ta có thể thấy hành vi này trên biểu đồ. Khi chúng ta tăng hoặc giảm rate theo phép nhân, chúng ta đang di chuyển dọc theo đường thẳng giữa điểm đó và gốc tọa độ, và chúng ta không bao giờ tiến gần hơn đến đường công bằng.</p>
<img width="500px" src="transport/../assets/transport/3-068-mimd.png">
<p>Về mặt đại số, hãy xem xét tỷ lệ giữa X2 và X1, tức là X2/X1 (tỷ lệ công bằng sẽ là 1). Trong ví dụ trên, tỷ lệ luôn là 2, tức là X2 luôn có bandwidth gấp đôi X1. Tỷ lệ này không đổi ngay cả khi chúng ta nhân hoặc chia cả X1 và X2 cho một hệ số không đổi. Các điều chỉnh của chúng ta không đưa chúng ta đến gần hơn với tỷ lệ công bằng là 1.</p>
<h2 id="Điều-chỉnh-Động-học-miad"><a class="header" href="#Điều-chỉnh-Động-học-miad">Điều chỉnh: Động học MIAD</a></h2>
<p>Cái này phức tạp hơn một chút. Hãy xem xét việc tăng bằng cách nhân đôi, và giảm bằng cách trừ đi 1. Với C = 5, một vài lần lặp đầu tiên là:</p>
<p>X1 = 1, X2 = 3 (4 nhỏ hơn 5, tăng)</p>
<p>X1 = 2, X2 = 6 (8 lớn hơn 5, giảm)</p>
<p>X1 = 1, X2 = 5 (6 lớn hơn 5, giảm)</p>
<p>X1 = 0, X2 = 4 (4 nhỏ hơn 5, tăng)</p>
<p>X1 = 0, X2 = 8</p>
<p>Tại thời điểm này, X1 có bandwidth bằng không. Mỗi lần chúng ta tăng bằng cách nhân đôi, X1 vẫn sẽ có bandwidth bằng không. Chúng ta thực sự đã tạo ra tình huống không công bằng nhất, trong đó X2 có tất cả bandwidth, và X1 không có gì.</p>
<p>Nói chung, nếu bạn bắt đầu với một phân bổ không công bằng, MIAD sẽ làm cho phân bổ đó trở nên không công bằng hơn nữa, cuối cùng đạt đến một điểm mà một người có tất cả bandwidth, và người kia có không.</p>
<p>Để thấy điều này về mặt đại số, hãy xem xét khoảng cách giữa X1 và X2. Khi chúng ta tăng bằng cách nhân đôi, kích thước của khoảng cách cũng tăng gấp đôi, từ (X2 - X1) thành (2 X2 - 2 X1) = 2(X2 - X1). Nhưng, khi chúng ta trừ 1 khỏi cả X1 và X2, khoảng cách vẫn giữ nguyên. Khoảng cách hoặc tăng lên hoặc giữ nguyên, và với đủ các lần lặp tăng và giảm, khoảng cách sẽ đạt đến mức độ không công bằng tối đa (một người có bandwidth bằng không mãi mãi).</p>
<h2 id="Điều-chỉnh-Động-học-aimd"><a class="header" href="#Điều-chỉnh-Động-học-aimd">Điều chỉnh: Động học AIMD</a></h2>
<p>Cuối cùng, hãy xem xét việc tăng bằng cách cộng 1, và giảm bằng cách chia đôi. Với C = 5, một vài lần lặp đầu tiên là:</p>
<p>X1 = 1, X2 = 2 (3 nhỏ hơn 5, tăng)</p>
<p>X1 = 2, X2 = 3 (5 không lớn hơn 5, tăng)</p>
<p>X1 = 3, X2 = 4 (7 lớn hơn 5, giảm)</p>
<p>X1 = 1.5, X2 = 2 (3.5 nhỏ hơn 5, tăng)</p>
<p>X1 = 2.5, X2 = 3 (5.5 lớn hơn 5, giảm)</p>
<p>X1 = 1.25, X2 = 1.5 (2.75 nhỏ hơn 5, tăng)</p>
<p>X1 = 2.25, X2 = 2.5 (4.75 nhỏ hơn 5, tăng)</p>
<p>X1 = 3.25, X2 = 3.5 (6.75 lớn hơn 5, giảm)</p>
<p>X1 = 1.625, X2 = 1.75 (nhỏ hơn 5, tăng)</p>
<p>X2 = 2.625, X2 = 2.75</p>
<p>Chúng ta có thể thấy rằng X1 và X2 đang tiến lại gần nhau hơn, và trên thực tế, chúng đang tiến đến phân bổ công bằng X1 = X2 = 2.5.</p>
<p>Về mặt đại số, chúng ta có thể thấy rằng khoảng cách giữa X1 và X2 đang giảm. Cụ thể, khi chúng ta cộng một hằng số vào cả hai số, khoảng cách vẫn giữ nguyên. Nhưng, khi chúng ta chia đôi cả hai số, khoảng cách cũng giảm đi một nửa, từ (X1 - X2) thành (X1 / 2 - X2 / 2) = (X1 - X2) / 2. Khi chúng ta xen kẽ việc tăng và giảm, khoảng cách sẽ tiếp tục giảm đi một nửa và tiến đến 0.</p>
<img width="500px" src="transport/../assets/transport/3-069-aimd.png">
<p>Chúng ta cũng có thể thấy điều này trên đồ thị. Khi chúng ta giảm theo phép nhân, chúng ta đang di chuyển dọc theo đường thẳng qua gốc tọa độ. Đường thẳng này nghiêng về phía đường công bằng, và việc di chuyển xuống dưới dọc theo đường này có nghĩa là chúng ta đang tiến đến đường công bằng. Như trước đây, việc tăng theo phép cộng không đưa chúng ta đến gần đường công bằng hơn, vì chúng ta đang di chuyển dọc theo một đường thẳng có độ dốc là 1 (song song với đường công bằng). Nhưng nhận thức quan trọng là việc cộng không làm chúng ta đi xa hơn. Hai hoạt động duy nhất của chúng ta là tiến lại gần hơn, hoặc không tiến gần hơn hay xa hơn. Sau nhiều lần lặp, điểm của chúng ta sẽ từ từ di chuyển đến gần đường công bằng hơn.</p>
<p>Tóm lại: AIAD và MIMD giữ nguyên sự không công bằng, và không có cải thiện nào về fairness. MIAD làm tăng sự không công bằng, và AIMD hội tụ về fairness.</p>
<img width="800px" src="transport/../assets/transport/3-070-aimd-sawtooth.png"><div style="break-before: page; page-break-before: always;"></div><h1 id="triển-khai-kiểm-soát-tắc-nghẽn"><a class="header" href="#triển-khai-kiểm-soát-tắc-nghẽn">Triển khai Kiểm soát Tắc nghẽn</a></h1>
<h2 id="tóm-tắt-lại-các-cửa-sổ-tcp"><a class="header" href="#tóm-tắt-lại-các-cửa-sổ-tcp">Tóm tắt lại: Các Cửa sổ TCP</a></h2>
<p>Cho đến nay, chúng ta đã thiết kế một phác thảo khái niệm về một thuật toán điều chỉnh động, dựa trên <em>host</em>, nơi mỗi nguồn chạy cùng một thuật toán một cách độc lập để đạt được một phần <em>bandwidth</em> hiệu quả và công bằng.</p>
<p>Đầu tiên, sử dụng <em>slow-start (khởi động chậm)</em> (bắt đầu ở tốc độ thấp, tăng theo cấp số nhân) để khám phá ra một tốc độ ban đầu. Sau đó, trong mỗi vòng lặp, nếu chúng ta phát hiện tắc nghẽn (phát hiện mất mát), chúng ta giảm R theo cấp số nhân. Nếu chúng ta không phát hiện tắc nghẽn, chúng ta tăng R theo cấp số cộng.</p>
<p>Trong phần này, chúng ta sẽ xem cách <em>TCP</em> triển khai thuật toán này. Dù tốt hay xấu, các cơ chế <em>Congestion Control (Kiểm soát tắc nghẽn)</em> của <em>TCP</em> rất gắn liền với các cơ chế độ tin cậy của <em>TCP</em>. (Đây là kết quả của thiết kế ban đầu, nơi <em>TCP</em> được vá để tính đến tắc nghẽn.) Trong phần này, chúng ta sẽ xem cách triển khai của <em>TCP</em> hoạt động để đạt được cả độ tin cậy và <em>congestion control</em> cùng một lúc.</p>
<p>Hãy nhớ lại rằng trong <em>TCP</em>, bên gửi duy trì một <em>sliding window (cửa sổ trượt)</em> gồm các byte/packet liên tiếp đang trên đường truyền. Kích thước của cửa sổ được quyết định bởi <em>flow control (kiểm soát luồng)</em> (do không gian bộ đệm ở bên nhận quyết định) và <em>congestion control</em> (tốc độ do bên gửi tính toán).</p>
<p>Cụ thể hơn, trong <em>flow control</em>, bên nhận gửi một cửa sổ quảng bá, cho biết có thể gửi thêm bao nhiêu byte nữa mà không làm tràn bộ nhớ của bên nhận. Giá trị cửa sổ quảng bá này đôi khi được viết tắt là <em><strong>RWND (cửa sổ phía nhận)</strong></em>.</p>
<p>Trong <em>congestion control</em>, bên gửi duy trì một giá trị, đôi khi được viết tắt là <em><strong>CWND (cửa sổ tắc nghẽn)</strong></em>, biểu thị tốc độ mà bên gửi có thể gửi các <em>packet</em> mà không làm quá tải các liên kết. Giá trị này sẽ được đặt và điều chỉnh động bởi thuật toán <em>congestion control</em>.</p>
<p>Cửa sổ của bên gửi được tính bằng giá trị nhỏ nhất của <em>CWND</em> và <em>RWND</em>. Trong bài giảng này, chúng ta sẽ giả định rằng <em>RWND</em> lớn hơn <em>CWND</em>, do đó nút thắt cổ chai là mạng, chứ không phải bộ nhớ của bên nhận. Điều này thường đúng, nhưng không phải lúc nào cũng đúng trong thực tế.</p>
<img width="900px" src="transport/../assets/transport/3-047-window1.png">
<p>Hãy nhớ lại rằng chúng ta có thể xem <em>sliding window</em> như một khoảng trong luồng byte. Cạnh trái của cửa sổ là byte đầu tiên chưa được xác nhận (mọi thứ bên trái cửa sổ đã được gửi và xác nhận). Cạnh phải của cửa sổ được xác định bởi kích thước cửa sổ. Chỉ các <em>packet</em> bên trong cửa sổ này mới được phép đang trên đường truyền.</p>
<p>Khi dữ liệu ở cạnh trái của cửa sổ được xác nhận, cửa sổ trượt sang phải, và dữ liệu bổ sung bây giờ có thể được gửi đi.</p>
<p>Để phát hiện mất mát, chúng ta duy trì một bộ đếm thời gian duy nhất cho <em>packet</em> ngoài cùng bên trái trong cửa sổ. Nếu bộ đếm thời gian hết hạn mà <em>packet</em> đó chưa được xác nhận, chúng ta sẽ gửi lại <em>packet</em> ngoài cùng bên trái trong cửa sổ. Ngoài ra, để phát hiện mất mát, chúng ta đếm số lượng <em>duplicate acks (ack trùng lặp)</em>, và gửi lại <em>packet</em> ngoài cùng bên trái nếu chúng ta thấy 3 <em>duplicate acks</em>. Cách tiếp cận dựa trên <em>ack</em> trùng lặp này đôi khi được gọi là <em><strong>fast retransmit (truyền lại nhanh)</strong></em>.</p>
<h2 id="cửa-sổ-và-tốc-độ"><a class="header" href="#cửa-sổ-và-tốc-độ">Cửa sổ và Tốc độ</a></h2>
<p>Làm thế nào để chúng ta điều chỉnh tốc độ cho <em>congestion control</em>, và làm thế nào để chúng ta tính toán <em>congestion window</em>? Hóa ra hai giá trị này có liên quan trực tiếp, và việc điều chỉnh cửa sổ được thực hiện bằng cách điều chỉnh tốc độ. Kích thước cửa sổ và tốc độ gửi dữ liệu có tương quan với nhau theo phương trình sau: tốc độ nhân với <em>RTT</em> = kích thước cửa sổ.</p>
<p>Về mặt trực quan, bạn có thể nghĩ kích thước cửa sổ và tốc độ là cùng một đại lượng, được biểu thị bằng hai &quot;đơn vị đo&quot; khác nhau. Kích thước cửa sổ tăng có nghĩa là chúng ta đang gửi dữ liệu nhanh hơn, và ngược lại.</p>
<p>Để thấy tại sao phương trình này đúng, hãy xem xét <em>RTT</em> đầu tiên. Chúng ta có thể gửi [kích thước cửa sổ] <em>packet</em> trong <em>RTT</em> đầu tiên này (trước khi bất kỳ <em>ack</em> nào đến), cho tốc độ là kích thước cửa sổ / <em>RTT</em>.</p>
<p>Hãy nhớ lại rằng thiết kế <em>TCP</em> khái niệm của chúng ta đo dữ liệu bằng <em>packet</em> cho đơn giản, nhưng trong thực tế, <em>TCP</em> suy nghĩ theo byte. Trong một triển khai thực tế, kích thước cửa sổ được đo bằng byte, nhưng để đơn giản, chúng ta sẽ xem xét kích thước cửa sổ theo <em>packet</em>.</p>
<p>Để chuyển đổi giữa <em>packet</em> và byte, hãy nhớ lại rằng chúng ta đã định nghĩa <em>Maximum Segment Size (MSS) (Kích thước Phân đoạn Tối đa)</em>, là số byte trên mỗi <em>packet</em>. Điều này cho chúng ta biết rằng <em>MSS</em> nhân với số lượng <em>packet</em> = số lượng byte. Một lần nữa, về mặt trực quan, bạn có thể nghĩ byte và <em>packet</em> là hai đơn vị đo khác nhau cho cùng một đại lượng (lượng dữ liệu).</p>
<h2 id="cập-nhật-theo-sự-kiện-1"><a class="header" href="#cập-nhật-theo-sự-kiện-1">Cập nhật theo Sự kiện</a></h2>
<p>Trong mô hình khái niệm của chúng ta, mục tiêu là điều chỉnh tốc độ/cửa sổ một lần mỗi &quot;vòng lặp&quot;, nhưng chúng ta chưa hình thức hóa cách đo mỗi vòng lặp. Chúng ta có thể định nghĩa sơ bộ mỗi vòng lặp là một <em>RTT</em>, nhưng bản thân <em>RTT</em> là một giá trị thay đổi động mà chúng ta không thể đo chính xác.</p>
<p>Để cập nhật kích thước cửa sổ một cách dễ dự đoán và đo lường hơn, chúng ta có thể xem xét các sự kiện khác nhau mà việc triển khai <em>TCP</em> hiện có phản ứng lại, và cập nhật cửa sổ mỗi khi một trong những sự kiện này xảy ra. Đây được gọi là <em><strong>event-driven updates (cập nhật theo sự kiện)</strong></em>.</p>
<p>Ba sự kiện <em>TCP</em> mà chúng ta cần cập nhật kích thước cửa sổ là: <em>ack</em> mới, 3 <em>duplicate acks</em>, và hết thời gian chờ.</p>
<p>Khi chúng ta thấy một <em>ack</em> mới (cho dữ liệu chưa được xác nhận trước đó), đây là một dấu hiệu cho thấy dữ liệu của chúng ta đã đi qua mạng mà không bị mất. Trong mô hình của chúng ta, chúng ta phát hiện tắc nghẽn bằng cách kiểm tra mất mát, vì vậy một <em>ack</em> mới là một dấu hiệu cho thấy mạng không bị tắc nghẽn. Do đó, khi chúng ta thấy một <em>ack</em> mới, chúng ta có thể tăng kích thước cửa sổ (hoặc trong quá trình khám phá <em>slow-start</em>, hoặc điều chỉnh <em>AIMD</em>).</p>
<p>Khi chúng ta thấy 3 <em>duplicate acks</em>, chúng ta đánh dấu một <em>packet</em> bị mất. Đây là một tín hiệu của mất mát đơn lẻ, cho thấy tắc nghẽn nhẹ. Chúng ta đã mất một <em>packet</em>, nhưng các <em>packet</em> tiếp theo vẫn đang được nhận. Để phản ứng với sự mất mát này, chúng ta sẽ giảm kích thước cửa sổ (trong quá trình điều chỉnh <em>AIMD</em>).</p>
<p>Khi chúng ta gặp phải một lần hết thời gian chờ, chúng ta đánh dấu một <em>packet</em> bị mất. Việc chúng ta phát hiện mất mát sau khi hết thời gian chờ, chứ không phải <em>duplicate acks</em>, là một tín hiệu của việc nhiều <em>packet</em> bị mất (tắc nghẽn nặng). Để thấy tại sao, hãy xem xét kích thước cửa sổ là 100 <em>packet</em>. Nếu chúng ta gặp phải một lần hết thời gian chờ, điều này có nghĩa là chúng ta không nhận được <em>ack</em> cho <em>packet</em> ngoài cùng bên trái trong cửa sổ. Nhưng nó cũng có nghĩa là chúng ta đã không nhận được 3 <em>duplicate acks</em> cho bất kỳ <em>packet</em> nào khác trong cửa sổ trong suốt thời gian của bộ đếm. Một lần hết thời gian chờ có nghĩa là rất ít, nếu có, <em>packet</em> đang được nhận, và có điều gì đó tồi tệ đã xảy ra.</p>
<p>Nếu chúng ta phát hiện một lần hết thời gian chờ, có điều gì đó không mong muốn đã xảy ra (ví dụ: mạng đã thay đổi), và chúng ta không nên tin tưởng vào kích thước cửa sổ hiện tại của mình nữa. Để phản ứng, chúng ta nên quay lại giai đoạn <em>slow-start</em> và khám phá lại một kích thước cửa sổ tốt. Đây không phải là cách duy nhất để phản ứng với việc hết thời gian chờ, nhưng đây là những gì <em>TCP</em> đã quyết định.</p>
<h2 id="slow-start-theo-sự-kiện"><a class="header" href="#slow-start-theo-sự-kiện">Slow-Start theo Sự kiện</a></h2>
<p>Trong mô hình khái niệm của chúng ta, chúng ta đã triển khai <em>slow-start</em> bằng cách chọn một tốc độ chậm, và tăng tốc độ theo cấp số nhân (ví dụ: nhân đôi trong mỗi vòng lặp) cho đến khi chúng ta gặp phải lần mất mát đầu tiên. Bây giờ chúng ta cần một cách theo sự kiện để nhân đôi cửa sổ một lần mỗi <em>RTT</em>.</p>
<p><em>TCP</em> bắt đầu với một cửa sổ nhỏ là 1 <em>packet</em>. Hãy nhớ, chúng ta có thể chuyển đổi <em>packet</em> thành byte với <em>maximum segment size (MSS)</em>, và sau đó chuyển đổi byte thành tốc độ bằng cách chia <em>MSS/RTT</em>.</p>
<p>Mỗi khi chúng ta nhận được một xác nhận, chúng ta sẽ tăng kích thước cửa sổ thêm 1 <em>packet</em>. Trực giác về những gì sẽ xảy ra là:</p>
<p>Ban đầu, kích thước cửa sổ là 1 <em>packet</em>. Chúng ta gửi 1 <em>packet</em>, và sau một <em>RTT</em>, nhận lại 1 <em>ack</em>. <em>Ack</em> đó cho phép chúng ta tăng cửa sổ lên 2 <em>packet</em>.</p>
<p>Bây giờ chúng ta gửi 2 <em>packet</em>, và sau một <em>RTT</em>, chúng ta nhận lại 2 <em>ack</em>. 2 <em>ack</em> đó cho phép chúng ta tăng cửa sổ thêm 2 <em>packet</em> nữa, cho kích thước cửa sổ mới là 4 <em>packet</em>.</p>
<p>Bây giờ chúng ta gửi 4 <em>packet</em>, và sau một <em>RTT</em>, chúng ta nhận lại 4 <em>ack</em>. 4 <em>ack</em> đó cho phép chúng ta tăng cửa sổ thêm 4 <em>packet</em> nữa, cho kích thước cửa sổ mới là 8 <em>packet</em>.</p>
<img width="500px" src="transport/../assets/transport/3-071-event-driven-ss.png">
<p>Tuy nhiên, bức tranh trực quan này giả định chúng ta đang gửi tất cả 4 <em>packet</em> và nhận tất cả 4 <em>ack</em> đồng thời. Trong thực tế, hành vi <em>sliding window</em> khiến cửa sổ của chúng ta tăng thêm 1 mỗi khi chúng ta nhận được một <em>ack</em>, mặc dù hành vi cuối cùng (nhân đôi cửa sổ mỗi <em>RTT</em>) là như nhau.</p>
<p>Như trước đây, chúng ta bắt đầu với kích thước cửa sổ là 1 <em>packet</em>. Chúng ta gửi 1 <em>packet</em> (A), và sau một <em>RTT</em>, nhận lại <em>ack</em> cho A. <em>Ack</em> đó cho phép chúng ta tăng cửa sổ lên 2 <em>packet</em>, và không có <em>packet</em> nào đang trên đường truyền.</p>
<p>Tiếp theo, chúng ta có thể gửi ra 2 <em>packet</em> (B và C). Khi chúng ta nhận được <em>ack</em> cho B, chúng ta tăng cửa sổ lên 3 <em>packet</em>. Vẫn còn 1 <em>packet</em> đang trên đường truyền (C), vì vậy chúng ta có thể gửi thêm 2 <em>packet</em> nữa (D và E).</p>
<p>Khi chúng ta nhận được <em>ack</em> cho C, chúng ta có thể tăng cửa sổ lên 4 <em>packet</em>. Vẫn còn 2 <em>packet</em> đang trên đường truyền (D và E), vì vậy chúng ta có thể gửi thêm 2 <em>packet</em> nữa (F và G).</p>
<p>Nói chung, giả sử không có mất mát và không có sắp xếp lại thứ tự, mỗi khi chúng ta nhận được một <em>ack</em>, <em>sliding window</em> cho phép chúng ta gửi thêm một <em>packet</em>, và cửa sổ được tăng lên cho phép chúng ta gửi thêm một <em>packet</em> nữa. Bởi vì mỗi <em>ack</em> dẫn đến việc 2 <em>packet</em> được gửi đi, chúng ta có được hành vi mà cửa sổ nhân đôi mỗi <em>RTT</em>. Ví dụ, trong một khoảng <em>RTT</em> mà chúng ta nhận được 16 <em>ack</em>, mỗi <em>ack</em> kích hoạt hai <em>packet</em> được gửi đi, tổng cộng là 32 <em>packet</em>. Sau đó, trong khoảng <em>RTT</em> tiếp theo, 32 <em>packet</em> đó sẽ được xác nhận, kích hoạt 64 <em>packet</em> được gửi đi.</p>
<p>Cuối cùng, sau một thời gian nhân đôi cửa sổ mỗi <em>RTT</em> (tăng cửa sổ thêm 1 cho mỗi <em>ack</em>), chúng ta sẽ gặp phải mất mát. Điều này cũng có nghĩa là chúng ta đã học được tốc độ &quot;an toàn&quot; tối đa cho phép để gửi các <em>packet</em> mà không gặp phải mất mát. Chúng ta sẽ ghi nhớ tốc độ này trong một tham số mới gọi là <em>SSTHRESH (ngưỡng khởi động chậm)</em>. Cụ thể, ngay khi chúng ta gặp phải mất <em>packet</em>, chúng ta sẽ đặt <em>SSTHRESH</em> bằng một nửa kích thước cửa sổ. Ví dụ, nếu một cửa sổ 16 <em>packet</em> không gây ra mất mát, nhưng một cửa sổ 32 <em>packet</em> lại gây ra mất mát, thì chúng ta sẽ đặt <em>SSTHRESH</em> là 16.</p>
<img width="700px" src="transport/../assets/transport/3-072-ssthresh-ss.png">
<p>Hãy nhớ lại rằng sau <em>slow-start</em>, chúng ta sẽ liên tục điều chỉnh kích thước cửa sổ (<em>AIMD</em>). <em>SSTHRESH</em> cho phép chúng ta ghi nhớ tốc độ an toàn mà chúng ta đã học được từ <em>slow-start</em>, ngay cả khi tốc độ bắt đầu thay đổi sau này.</p>
<h2 id="triển-khai-tăng-cộng"><a class="header" href="#triển-khai-tăng-cộng">Triển khai Tăng Cộng</a></h2>
<p>Trong mô hình khái niệm của chúng ta, sau <em>slow-start</em>, chúng ta muốn tăng tốc độ một cách từ từ (cộng tính) khi không có mất mát. Chúng ta cần một cách theo sự kiện để tăng cửa sổ thêm 1 <em>packet</em> cho mỗi <em>RTT</em>.</p>
<p>Chúng ta không có một con số chính xác cho <em>RTT</em>, nhưng chúng ta biết rằng trong một <em>RTT</em> duy nhất, chúng ta mong đợi một lượng <em>packet</em> bằng kích thước cửa sổ sẽ được xác nhận. Ví dụ, với kích thước cửa sổ là 10, chúng ta nhận được 10 <em>ack</em> mỗi <em>RTT</em>. Nếu chúng ta tăng cửa sổ thêm 1/10 <em>packet</em> cho mỗi <em>ack</em>, thì trong suốt một <em>RTT</em>, cửa sổ sẽ tăng thêm 1 <em>packet</em>, như mong muốn.</p>
<p>Mỗi khi chúng ta nhận được một xác nhận, chúng ta sẽ lấy kích thước cửa sổ hiện tại <em>CWND</em> và gán lại nó thành <em>CWND</em> + (1/<em>CWND</em>). Điều này tăng cửa sổ thêm một phần nhỏ của một <em>packet</em> trên mỗi <em>ack</em>. Sau một lượng <em>packet</em> bằng kích thước cửa sổ (tức là sau một <em>RTT</em>), cửa sổ tăng thêm 1 <em>packet</em>.</p>
<p>Về mặt hình thức, <em>TCP</em> đo cửa sổ bằng byte, không phải <em>packet</em>, vì vậy (1/<em>CWND</em>) tương đương với <em>MSS</em> * (<em>MSS</em>/<em>CWND</em>) bằng byte. Trong (1/<em>CWND</em>), tử số là 1 <em>packet</em> (tổng mức tăng trong một <em>RTT</em>), và mẫu số là <em>CWND</em> được đo bằng <em>packet</em>. Vì mẫu số bây giờ được đo bằng <em>packet</em>, chúng ta cũng phải đo tử số bằng <em>packet</em>: 1 <em>packet</em> = <em>MSS</em> byte.</p>
<p>Nhưng phân số 1/<em>CWND</em> hoặc <em>MSS</em>/<em>CWND</em> vẫn là một tỷ lệ (không có thứ nguyên), đại diện cho phần trăm cần tăng trên mỗi <em>ack</em>. Tổng mức tăng chúng ta muốn là 1 <em>packet</em> = <em>MSS</em> byte, vì vậy chúng ta phải nhân phân số này với <em>MSS</em> byte.</p>
<p>Ví dụ, giả sử <em>CWND</em> của chúng ta là 3 <em>packet</em> = 150 byte (giả sử <em>MSS</em> = 50 byte). Trong chế độ xem <em>packet</em>, chúng ta sẽ thêm 1/3 <em>packet</em> vào cửa sổ mỗi lần, cho tổng mức tăng là 1 <em>packet</em>.</p>
<p>Trong chế độ xem byte, chúng ta có thể chia <em>MSS</em>/<em>CWND</em> = 50/150 để có được cùng một tỷ lệ 1/3 mà chúng ta cần để tăng mỗi lần, cho tổng mức tăng là 1. Nhưng chúng ta vẫn cần nhân với <em>MSS</em> để tổng mức tăng là <em>MSS</em> thay vì 1.</p>
<img width="900px" src="transport/../assets/transport/3-073-event-driven-aimd.png">
<p>Lưu ý rằng mức tăng không hoàn toàn tuyến tính, nhưng cung cấp một sự xấp xỉ đủ tốt. Ví dụ, bắt đầu với <em>CWND</em> = 4, lần cập nhật đầu tiên là 4 + 1/4 = 4.25, và lần tăng thứ hai là 4.25 + 1/4.25 = 4.49. Sau bốn lần cập nhật, kích thước cửa sổ sẽ là 4.92 trong phép xấp xỉ này (chúng ta muốn nó là 5 trong mô hình chính xác).</p>
<h2 id="triển-khai-giảm-nhân"><a class="header" href="#triển-khai-giảm-nhân">Triển khai Giảm Nhân</a></h2>
<p>Nếu chúng ta phát hiện mất mát từ 3 <em>duplicate acks</em>, chúng ta chia kích thước cửa sổ cho 2.</p>
<p>Hãy nhớ lại rằng nếu bộ đếm thời gian truyền lại hết hạn, chúng ta hiểu việc hết thời gian chờ là nhiều <em>packet</em> bị mất (chúng ta thậm chí không nhận được <em>duplicate acks</em>). Chúng ta giả định rằng cửa sổ hiện tại có thể sai lệch rất nhiều, và để thận trọng, chúng ta sẽ khám phá lại một tốc độ tốt từ đầu.</p>
<p>Đầu tiên, chúng ta sẽ ghi nhận rằng tốc độ hiện tại quá cao, và tốc độ an toàn tốt nhất đã biết là một nửa tốc độ hiện tại của chúng ta (theo nguyên tắc giảm nhân). Để ghi lại tốc độ an toàn này, chúng ta sẽ đặt <em>SSTHRESH</em> bằng một nửa cửa sổ hiện tại.</p>
<p>Sau đó, chúng ta sẽ đặt lại kích thước cửa sổ về 1 <em>packet</em>, và lặp lại quá trình <em>slow-start</em> một lần nữa.</p>
<p>Lưu ý rằng khi chúng ta thử lại <em>slow-start</em>, chúng ta cần cẩn thận để không quay trở lại tốc độ nguy hiểm với việc hết thời gian chờ từ trước đó. May mắn thay, chúng ta đã đặt <em>SSTHRESH</em> ngay dưới tốc độ nguy hiểm. Do đó, trong các lần thử lại <em>slow-start</em> tiếp theo (nơi <em>SSTHRESH</em> được đặt), ngay khi cửa sổ của chúng ta vượt quá <em>SSTHRESH</em>, chúng ta nên chuyển từ tăng nhân sang tăng cộng. Trong lần <em>slow-start</em> đầu tiên, <em>SSTHRESH</em> không được đặt (hoặc là vô cực).</p>
<p>Tóm lại: Trong <em>slow-start</em>, chúng ta tăng cửa sổ thêm 1 <em>packet</em> cho mỗi <em>ack</em> (dẫn đến nhân đôi tốc độ mỗi <em>RTT</em>). Khi ở chế độ <em>AIMD</em>, chúng ta tăng cửa sổ thêm một phần nhỏ của kích thước cửa sổ cho mỗi <em>ack</em> (dẫn đến tăng thêm 1 cho mỗi lượng dữ liệu bằng kích thước cửa sổ). Chúng ta giảm cửa sổ bằng cách chia đôi nó khi nhận được 3 <em>duplicate acks</em>, và thay đổi nó thành 1 khi hết thời gian chờ.</p>
<p>Lưu ý rằng khi giảm, chúng ta không bao giờ giảm kích thước cửa sổ xuống dưới 1 <em>packet</em>. Trong trường hợp xấu nhất, chúng ta cần cho phép 1 <em>packet</em> được đang trên đường truyền.</p>
<h2 id="mô-hình-răng-cưa-tcp"><a class="header" href="#mô-hình-răng-cưa-tcp">Mô hình Răng cưa TCP</a></h2>
<img width="900px" src="transport/../assets/transport/3-074-sawtooth-ssthresh.png">
<p>Nếu chúng ta vẽ đồ thị tốc độ theo thời gian, chúng ta sẽ thấy sự tăng trưởng theo cấp số nhân ban đầu (<em>slow-start</em>). Ngay khi chúng ta gặp phải mất mát, chúng ta cắt giảm một nửa tốc độ, và chuyển sang chế độ <em>AIMD</em>. Bây giờ, chúng ta tăng tuyến tính cho đến khi gặp phải mất mát, và chúng ta giảm một nửa tốc độ mỗi khi gặp phải mất mát.</p>
<h2 id="fast-recovery-ví-dụ-thực-tế"><a class="header" href="#fast-recovery-ví-dụ-thực-tế">Fast Recovery: Ví dụ Thực tế</a></h2>
<p>Còn một vấn đề cuối cùng chúng ta phải giải quyết trong việc triển khai <em>congestion control</em> của mình. Khi chúng ta gặp phải một <em>packet</em> bị mất đơn lẻ, <em>congestion window</em> bị giảm đi một nửa, như dự định. Tuy nhiên, điều này có tác dụng phụ không mong muốn là khiến bên gửi bị đình trệ một thời gian trước khi có thể tiếp tục gửi các <em>packet</em>.</p>
<p>Để thấy điều này hoạt động, hãy xem xét một ví dụ thực tế. Chúng ta gửi 10 <em>packet</em>, được đánh số từ 101 đến 110. <em>Packet</em> đầu tiên (101) bị mất.</p>
<p>Kết quả là, 9 <em>packet</em> còn lại, từ 102 đến 110, đều được xác nhận là ack(101), bởi vì byte tiếp theo được mong đợi vẫn là 101.</p>
<p>Sau <em>duplicate ack</em>(101) thứ ba (được tạo ra khi nhận 102, 103, và 104), bên gửi sẽ gửi lại 101.</p>
<p>Cuối cùng, <em>ack</em> cho <em>packet</em> 101 được gửi lại sẽ đến. Nó ghi ack(111), bởi vì các <em>packet</em> từ 102 đến 110 đều đã được nhận trước đó, và với việc nhận được 101, byte tiếp theo được mong đợi là 111.</p>
<img width="700px" src="transport/../assets/transport/3-075-fastrecovery1.png">
<p>Tóm lại: Ở phía bên gửi, chúng ta gửi từ 101 đến 110, và 101 bị mất. Chúng ta nhận được ack(101) từ 102, ack(101) từ 103, và ack(101) từ 104. Tại thời điểm này, chúng ta gửi lại 101. Sau đó, chúng ta nhận được ack(101) từ 105 đến 110. Cuối cùng, chúng ta nhận được ack(111) từ 101.</p>
<p>Ở phía bên nhận, chúng ta nhận từ 102 đến 110, và gửi lại ack(101) mỗi lần, vì byte chưa nhận tiếp theo vẫn là 101. Cuối cùng, chúng ta nhận được <em>packet</em> 101 được gửi lại, và chúng ta gửi lại ack(111) bởi vì byte chưa nhận tiếp theo là 111.</p>
<p><em>CWND</em> trông như thế nào trong ví dụ thực tế này? Hãy nhớ rằng cửa sổ bắt đầu từ byte đầu tiên chưa được xác nhận, và kéo dài cho <em>CWND</em> byte liên tiếp. Cách duy nhất để dịch chuyển cửa sổ về phía trước là nhận được byte đầu tiên chưa được xác nhận. Nếu chúng ta nhận được <em>ack</em> cho một số byte khác trong cửa sổ, cửa sổ vẫn giữ nguyên, bởi vì cửa sổ được xác định bởi byte đầu tiên chưa được xác nhận.</p>
<h2 id="fast-recovery-vấn-đề"><a class="header" href="#fast-recovery-vấn-đề">Fast Recovery: Vấn đề</a></h2>
<p>Hãy giả sử rằng <em>CWND</em> bắt đầu là 10. Các <em>packet</em> từ 101 đến 110 được phép đang trên đường truyền. Bên gửi gửi từ 101 đến 110, nhưng 101 bị mất.</p>
<img width="900px" src="transport/../assets/transport/3-076-fastrecovery2.png">
<p>Bên gửi thấy ack(101), được tạo ra từ việc phía bên kia nhận 102. Tại thời điểm này, byte đầu tiên chưa được xác nhận vẫn là 101, vì vậy cửa sổ không thay đổi. Các <em>packet</em> duy nhất được phép đang trên đường truyền vẫn là từ 101 đến 110, và bên gửi không thể gửi bất cứ thứ gì mới (ví dụ: 111 không thể được gửi).</p>
<p>Tiếp theo, bên gửi thấy ack(101), được tạo ra từ việc phía bên kia nhận 103. Một lần nữa, byte đầu tiên chưa được xác nhận vẫn là 101, vì vậy cửa sổ không thay đổi. Cửa sổ vẫn bắt đầu từ 101 và kéo dài đến 110, và bên gửi không thể gửi bất cứ thứ gì mới.</p>
<p>Tiếp theo, bên gửi thấy ack(101), được tạo ra từ việc phía bên kia nhận 104. Đây là <em>duplicate ack</em> thứ ba, vì vậy chúng ta phải giảm <em>CWND</em> xuống 5. Byte đầu tiên chưa được xác nhận vẫn là 101, và <em>CWND</em> là 5, vì vậy các <em>packet</em> từ 101 đến 105 được phép đang trên đường truyền. Bên gửi vẫn không thể gửi bất cứ thứ gì mới. Chúng ta gửi lại 101 (<em>packet</em> ngoài cùng bên trái trong cửa sổ) vì chúng ta đã thấy <em>duplicate ack</em> thứ ba.</p>
<p>Tiếp theo, bên gửi thấy ack(101), được tạo ra từ việc phía bên kia nhận 105. Cửa sổ vẫn là 101 (byte đầu tiên chưa được xác nhận) đến 105 (<em>CWND</em> byte sau đó), vì vậy chúng ta không thể gửi bất cứ thứ gì mới.</p>
<img width="800px" src="transport/../assets/transport/3-077-fastrecovery3.png">
<p>Tiếp theo, bên gửi thấy ack(101), được tạo ra từ việc phía bên kia nhận 106. Một lần nữa, cửa sổ không thay đổi, và chúng ta không thể gửi bất cứ thứ gì mới.</p>
<p>Bên gửi nhận được ack(101), ack(101), ack(101), ack(101) từ việc phía bên kia nhận 107, 108, 109, 110. Trong mọi trường hợp, 101 vẫn là byte đầu tiên chưa được xác nhận, vì vậy cửa sổ vẫn là 101 đến 105, và bên gửi không thể gửi bất cứ thứ gì mới.</p>
<p>Chuyện gì đã xảy ra ở đây? Chỉ có một <em>packet</em> duy nhất bị mất, nhưng kết quả là bên gửi đã phải ngừng gửi hoàn toàn trong một thời gian dài.</p>
<p>Cửa sổ được định nghĩa bởi byte đầu tiên chưa được xác nhận, vì vậy cửa sổ không chịu di chuyển về phía trước cho đến khi 101 được gửi lại và xác nhận. Mặc dù tất cả các <em>packet</em> khác (từ 102 đến 110) đều đến, cửa sổ vẫn bị kẹt ở 101, và các <em>packet</em> sau đó (từ 111 trở đi) không thể được gửi. Bên gửi bị đình trệ!</p>
<p>Cuối cùng, bên gửi nhận được ack(111) từ <em>packet</em> 101 được gửi lại. Điều này khiến cửa sổ nhảy về phía trước và trượt đến <em>packet</em> đầu tiên chưa được xác nhận mới, 111. <em>CWND</em> vẫn là 5, vì vậy bên gửi bây giờ có thể gửi từ 111 đến 115.</p>
<img width="800px" src="transport/../assets/transport/3-078-fastrecovery4.png">
<p>Chuyện gì đã xảy ra ở đây? Bây giờ chúng ta có một vấn đề thứ hai. Bên gửi đã bị đình trệ một thời gian dài, nhưng ngay khi 101 được xác nhận với ack(111), cửa sổ đã nhảy về phía trước đến tận 111-115, và bên gửi đột nhiên phải vội vàng gửi 111-115 cùng một lúc.</p>
<p>Bên gửi đã bị đình trệ một thời gian dài, không gửi gì cả, và sau đó đột nhiên vội vàng gửi 111-115 cùng một lúc. Bây giờ, bên gửi phải đợi thêm một <em>round-trip</em> đầy đủ để 111-115 được xác nhận, trước khi có thể gửi 116 và xa hơn nữa.</p>
<img width="900px" src="transport/../assets/transport/3-079-fastrecovery5.png">
<p>Tóm lại: Việc mất <em>packet</em> đơn lẻ đã khiến cửa sổ bị kẹt, điều này khiến bên gửi bị đình trệ và không gửi gì cả. Cuối cùng, khi <em>packet</em> đó được gửi lại và xác nhận, cửa sổ nhảy về phía trước, khiến bên gửi phải vội vàng gửi một loạt <em>packet</em> mới cùng một lúc. Bên gửi bây giờ phải đợi thêm một <em>round-trip</em> nữa để những <em>packet</em> mới đó được xác nhận, trước khi có thể tiếp tục hoạt động như bình thường.</p>
<img width="900px" src="transport/../assets/transport/3-080-fastrecovery6.png">
<p>Một vài lưu ý về vấn đề này:</p>
<p>Nếu vấn đề vẫn còn khó hiểu, có thể hữu ích khi lưu ý rằng vấn đề này chủ yếu là do lược đồ <em>sliding window</em> của <em>TCP</em>, và không thực sự là do lược đồ <em>congestion control</em>. <em>Congestion control</em> khiến cửa sổ thu nhỏ lại, nhưng ngay cả khi cửa sổ không thu nhỏ, bên gửi vẫn sẽ bị buộc phải đình trệ cho đến khi 101 được nhận và cửa sổ nhảy về phía trước.</p>
<p>Khi chúng ta suy nghĩ về vấn đề này một cách trực quan, việc vẽ các sơ đồ về cửa sổ của bên gửi, đánh dấu các byte đã được xác nhận sẽ hữu ích. Ví dụ, sau ba <em>duplicate acks</em>, chúng ta đánh dấu 102, 103, 104 là đã nhận, và cửa sổ cho phép 101 (byte đầu tiên chưa được xác nhận) đến 105 được đang trên đường truyền.</p>
<p>Tuy nhiên, đây không thực sự là những gì bên gửi thấy. Hãy nhớ rằng, bên gửi chỉ thấy các <em>cumulative acks (xác nhận tích lũy)</em>, vì vậy nó không thực sự biết rằng 102, 103, và 104 đã được nhận. Bên gửi có thể suy luận rằng 3 <em>packet</em> trong cửa sổ (không phải là 101) đã được nhận, nhưng nó không biết chính xác là 3 <em>packet</em> nào.</p>
<p>Cuối cùng, lưu ý rằng sau khi chúng ta nhận được 3 thông điệp <em>duplicate ack</em>(101), chúng ta gửi lại 101, và chúng ta không bao giờ gửi lại 101 một lần nữa, ngay cả khi có thêm các thông điệp <em>duplicate ack</em>(101) đến. Đây chỉ là quy tắc của <em>TCP</em> để gửi lại khi có <em>duplicate acks</em>.</p>
<h2 id="fast-recovery-Ý-tưởng"><a class="header" href="#fast-recovery-Ý-tưởng">Fast Recovery: Ý tưởng</a></h2>
<p>Vậy, làm thế nào để chúng ta giải quyết vấn đề này? Lý tưởng nhất, chúng ta không muốn bên gửi bị đình trệ, và chúng ta muốn bên gửi tiếp tục gửi các <em>packet</em> sau đó (từ 111 trở đi), ngay cả khi 101 bị mất.</p>
<p>Lưu ý rằng mặc dù bên gửi không thể suy luận chính xác <em>packet</em> nào đến, bên gửi có thể suy luận rằng các <em>packet</em> sau đó (không phải 101) đang được nhận.</p>
<p>Khi chúng ta thấy ack(101), được tạo ra từ việc 102 được nhận, chúng ta không thực sự biết rằng 102 đã được nhận, nhưng chúng ta biết một <em>packet</em> nào đó (không phải 101) đã được nhận. Do đó, chỉ còn 9 <em>packet</em> đang trên đường truyền.</p>
<p>Khi chúng ta thấy một ack(101) khác, được tạo ra từ việc 103 được nhận, chúng ta lại không biết rằng cụ thể là 103 đã được nhận, nhưng chúng ta biết rằng một <em>packet</em> khác (không phải 101) đã được nhận. Do đó, chỉ còn 8 <em>packet</em> đang trên đường truyền.</p>
<p>Khi chúng ta tiếp tục nhận các thông điệp <em>duplicate ack</em>(101), chúng ta có thể suy luận rằng còn ít <em>packet</em> hơn đang trên đường truyền:</p>
<p>Sau ack(101) từ 102: 9 <em>packet</em> đang trên đường truyền.</p>
<p>Sau ack(101) từ 103: 8 <em>packet</em> đang trên đường truyền.</p>
<p>Sau ack(101) từ 104: 7 <em>packet</em> đang trên đường truyền.</p>
<p>Sau ack(101) từ 105: 6 <em>packet</em> đang trên đường truyền.</p>
<p>Sau ack(101) từ 106: 5 <em>packet</em> đang trên đường truyền.</p>
<p>Sau ack(101) từ 107: 4 <em>packet</em> đang trên đường truyền.</p>
<p>Sau ack(101) từ 108: 3 <em>packet</em> đang trên đường truyền.</p>
<p>Sau ack(101) từ 109: 2 <em>packet</em> đang trên đường truyền.</p>
<p>Sau ack(101) từ 110: 1 <em>packet</em> đang trên đường truyền.</p>
<p>Cuối cùng, sau khi chúng ta nhận được ack(101) chín lần (từ việc 102 đến 110 được nhận), chúng ta biết rằng chỉ còn 1 <em>packet</em> đang trên đường truyền, đó là 101.</p>
<p>Sau khi mất mát đơn lẻ, chúng ta thực sự muốn <em>CWND</em> là 5, có nghĩa là chúng ta muốn có 5 <em>packet</em> đang trên đường truyền tại bất kỳ thời điểm nào. Đến khi chúng ta nhận được ack(101) từ 107, chúng ta có thể suy luận rằng chỉ còn 4 <em>packet</em> đang trên đường truyền. (Thực tế, chúng là 101, 108, 109, 110, mặc dù bên gửi không biết điều đó.)</p>
<p>Tại thời điểm này, chúng ta muốn có thể gửi 111, để có tổng cộng 5 <em>packet</em> đang trên đường truyền. Nhưng cửa sổ sẽ không cho phép chúng ta làm điều đó, bởi vì cửa sổ vẫn bị kẹt ở 101 (byte đầu tiên chưa được xác nhận) đến 105 (<em>CWND</em> byte sau đó).</p>
<p>Ý tưởng chính sẽ giúp bên gửi không bị đình trệ là: Hãy cấp cho bên gửi tín dụng tạm thời cho mỗi <em>duplicate ack</em>.</p>
<p>Khi một <em>duplicate ack</em> đến, chúng ta có thể suy luận rằng có ít hơn một <em>packet</em> đang trên đường truyền, mặc dù chúng ta không biết là <em>packet</em> nào. Để giải quyết điều này, chúng ta sẽ mở rộng cửa sổ một cách nhân tạo thêm 1 <em>packet</em>, để cho phép bên gửi gửi thêm một <em>packet</em> nữa.</p>
<h2 id="fast-recovery-giải-pháp"><a class="header" href="#fast-recovery-giải-pháp">Fast Recovery: Giải pháp</a></h2>
<p>Hãy lấy ý tưởng mở rộng cửa sổ một cách nhân tạo cho mỗi <em>duplicate ack</em>, và áp dụng nó vào ví dụ từ trước.</p>
<p>Như trước đây, cửa sổ bắt đầu từ 101 đến 110, và chúng ta gửi đi 10 <em>packet</em>.</p>
<img width="900px" src="transport/../assets/transport/3-081-fastrecovery7.png">
<p>Như trước đây, chúng ta nhận được ack(101) từ 102, cửa sổ không thay đổi, và chúng ta không thể gửi bất cứ thứ gì mới.</p>
<p>Như trước đây, chúng ta nhận được ack(101) từ 103, cửa sổ không thay đổi, và chúng ta không thể gửi bất cứ thứ gì mới.</p>
<img width="900px" src="transport/../assets/transport/3-082-fastrecovery8.png">
<p>Như trước đây, chúng ta nhận được ack(101) từ 104, cửa sổ không thay đổi, và chúng ta không thể gửi bất cứ thứ gì mới.</p>
<p><em>Duplicate ack</em> thứ ba có nghĩa là chúng ta giảm <em>CWND</em> xuống 5, vì vậy cửa sổ bây giờ là 101 đến 105.</p>
<p>Tuy nhiên, chúng ta đã nhận được 3 <em>ack</em>, vì vậy chúng ta mở rộng cửa sổ một cách nhân tạo thêm 3 để tính đến những <em>ack</em> đó. Do đó, <em>CWND</em> thực sự được đặt thành 5 + 3 = 8.</p>
<p>Tiếp theo, chúng ta nhận được ack(101) từ 105. Điều này cho phép chúng ta mở rộng cửa sổ một lần nữa, lên 9. Bây giờ cửa sổ kéo dài từ 101 đến 109, vì vậy chúng ta vẫn không thể gửi các <em>packet</em> mới.</p>
<img width="900px" src="transport/../assets/transport/3-083-fastrecovery9.png">
<p>Tiếp theo, chúng ta nhận được ack(101) từ 106. Chúng ta lại mở rộng cửa sổ lên 10, kéo dài từ 101 đến 110, và chúng ta không thể gửi bất cứ thứ gì mới.</p>
<p>Tiếp theo, chúng ta nhận được ack(101) từ 107. Chúng ta lại mở rộng cửa sổ lên 11, kéo dài từ 101 đến 111. Bây giờ chúng ta có thể gửi đi 111!</p>
<p>Tiếp theo, chúng ta nhận được ack(101) từ 108. Chúng ta lại mở rộng cửa sổ lên 12, kéo dài từ 101 đến 112. Bây giờ chúng ta có thể gửi đi 112!</p>
<p>Tiếp theo, chúng ta nhận được ack(101) từ 109. Chúng ta lại mở rộng cửa sổ lên 13, kéo dài từ 101 đến 113. Bây giờ chúng ta có thể gửi đi 113!</p>
<p>Tiếp theo, chúng ta nhận được ack(101) từ 110. Chúng ta lại mở rộng cửa sổ lên 14, kéo dài từ 101 đến 114. Bây giờ chúng ta có thể gửi đi 114!</p>
<img width="900px" src="transport/../assets/transport/3-084-fastrecovery10.png">
<p>Cuối cùng, chúng ta nhận được ack(111) từ <em>packet</em> 101 được gửi lại. Tại thời điểm này, chúng ta có thể đặt lại <em>CWND</em> về giá trị dự định ban đầu là 5, để cửa sổ kéo dài từ 111 đến 115. Điều này cho phép chúng ta gửi đi 115!</p>
<p>Với sửa lỗi này, chúng ta đã giải quyết được vấn đề bên gửi bị đình trệ. Ban đầu, bên gửi phải đợi <em>packet</em> 101 được gửi lại được xác nhận trước khi gửi các <em>packet</em> mới. Bây giờ, bên gửi có thể tiếp tục gửi các <em>packet</em> trước khi <em>packet</em> 101 được gửi lại được xác nhận.</p>
<img width="900px" src="transport/../assets/transport/3-085-fastrecovery11.png">
<p>Chúng ta cũng đã giải quyết vấn đề thứ hai từ trước đó, nơi cửa sổ nhảy về phía trước và chúng ta gửi một loạt <em>packet</em> mới (từ 111 đến 115). Bây giờ, từ 111 đến 114 đã được gửi đi sớm hơn, và khi cửa sổ nhảy về phía trước, chúng ta chỉ phải gửi đi 115.</p>
<p>Nếu không có sửa lỗi này, chúng ta đã phải đình trệ thêm một <em>round-trip</em> nữa trong khi chờ đợi loạt <em>packet</em> từ 111 đến 115 được xác nhận. Bây giờ, bởi vì chúng ta đã bận rộn hơn và gửi đi từ 111 đến 114, chúng sẽ được xác nhận sớm hơn, và chúng ta có thể tiếp tục gửi 116 và xa hơn nữa mà không cần cả <em>RTT</em> đình trệ đó.</p>
<img width="900px" src="transport/../assets/transport/3-086-fastrecovery12.png">
<p>Một cách khác để nhìn vào sửa lỗi này là tập trung vào các <em>packet</em> trong cửa sổ được mở rộng nhân tạo.</p>
<p>Khi chúng ta nhận được <em>duplicate ack</em> thứ ba, <em>CWND</em> thu nhỏ xuống 5, nhưng chúng ta mở rộng nhân tạo cho 3 <em>duplicate acks</em> để có <em>CWND</em> là 8. Nếu bạn nhìn vào cửa sổ mở rộng này, 3 trong số các <em>packet</em> đã được xác nhận (102, 103, 104, mặc dù chúng ta không biết đó là những <em>packet</em> này), và 5 <em>packet</em> còn lại đang trên đường truyền. Điều này đạt được cửa sổ dự định của chúng ta là 5 <em>packet</em> đang trên đường truyền.</p>
<p>Tiếp theo, khi chúng ta nhận được một ack(101) khác từ 105, cửa sổ mở rộng lên 9. Một lần nữa, nếu bạn nhìn vào cửa sổ này, 4 trong số các <em>packet</em> đã được xác nhận (chúng ta không biết là <em>packet</em> nào), và 5 <em>packet</em> còn lại đang trên đường truyền, cho chúng ta cửa sổ dự định là 5 <em>packet</em> đang trên đường truyền.</p>
<p>Khi chúng ta nhận được ack(101) từ 106, cửa sổ mở rộng lên 10, bao gồm 5 <em>packet</em> đã nhận (từ 5 <em>duplicate acks</em>), cộng với 5 <em>packet</em> đang trên đường truyền (kích thước cửa sổ dự định).</p>
<p>Ở mỗi bước, trong cửa sổ mở rộng của chúng ta, nếu bạn không tính các <em>packet</em> đã được xác nhận, có chính xác 5 <em>packet</em> đang trên đường truyền trong cửa sổ. Một lần nữa, chúng ta không biết chính xác <em>packet</em> nào trong cửa sổ đã được xác nhận, nhưng chúng ta có thể sử dụng các <em>duplicate acks</em> để đếm có bao nhiêu <em>packet</em> đã được xác nhận, và sử dụng số đếm đó để giữ 5 <em>packet</em> đang trên đường truyền.</p>
<p>Khi chúng ta nhận được ack(101) từ 107, cửa sổ mở rộng lên 11, bao gồm 6 <em>packet</em> đã nhận (từ 6 <em>duplicate acks</em>). 5 <em>packet</em> còn lại trong cửa sổ được phép đang trên đường truyền.</p>
<p>Tại thời điểm này, chúng ta đã gửi 10 <em>packet</em> ban đầu, và chúng ta đã nhận được 6 <em>duplicate acks</em>, điều này cho chúng ta biết rằng chỉ còn 4 <em>packet</em> đang trên đường truyền. Điều này cho phép chúng ta gửi đi 111. Cửa sổ mở rộng nhân tạo nắm bắt được lý luận này, bởi vì nó mở rộng cửa sổ để bao gồm 111.</p>
<p>Khi chúng ta nhận được ack(101) từ 108, chúng ta suy luận rằng bây giờ, có ít hơn một <em>packet</em> đang trên đường truyền. Vì vậy, chúng ta lại mở rộng cửa sổ một cách nhân tạo lên 12, cho phép 112 được gửi đi.</p>
<h2 id="fast-recovery-triển-khai"><a class="header" href="#fast-recovery-triển-khai">Fast Recovery: Triển khai</a></h2>
<p>Khi chúng ta phát hiện mất <em>packet</em> từ các <em>duplicate acks</em>, chúng ta tạm thời vào chế độ <em><strong>fast recovery (phục hồi nhanh)</strong></em>, nơi các <em>duplicate acks</em> bổ sung sẽ mở rộng cửa sổ một cách nhân tạo để ngăn chặn việc đình trệ.</p>
<p>Chế độ <em>fast recovery</em> được kích hoạt khi chúng ta nhận được 3 <em>duplicate acks</em>. Thay vì chỉ giảm một nửa <em>CWND</em>, như chúng ta đã làm trước đây, bây giờ chúng ta đặt <em>CWND</em> thành <em>CWND</em>/2 + 3, nơi cửa sổ được mở rộng nhân tạo thêm 3 cho 3 <em>duplicate acks</em> mà chúng ta đã nhận. Chúng ta cũng đặt <em>SSTHRESH</em> thành <em>CWND</em>/2, để chúng ta ghi nhớ tốc độ an toàn mới cho sau này.</p>
<p>Khi ở trong chế độ <em>fast recovery</em>, mỗi <em>duplicate ack</em> bổ sung khiến <em>CWND</em> tăng thêm 1, cho phép cửa sổ mở rộng một cách nhân tạo.</p>
<p>Cuối cùng, khi chúng ta nhận được một <em>ack</em> mới, không trùng lặp, chúng ta rời khỏi chế độ <em>fast recovery</em> và đặt <em>CWND</em> thành <em>SSTHRESH</em>. Lưu ý rằng trong khi chúng ta đang mở rộng cửa sổ một cách nhân tạo, <em>SSTHRESH</em> luôn giúp chúng ta ghi nhớ tốc độ ban đầu đã giảm đi một nửa mà chúng ta cuối cùng muốn gửi ở đó.</p>
<h2 id="máy-trạng-thái-tcp"><a class="header" href="#máy-trạng-thái-tcp">Máy trạng thái TCP</a></h2>
<p>Cuối cùng, chúng ta đã sẵn sàng để kết hợp tất cả các mảnh ghép lại và triển khai <em>TCP</em>, với <em>congestion control</em>.</p>
<p>Bên gửi duy trì 5 giá trị:</p>
<p>Số đếm <em>duplicate ack</em> giúp chúng ta phát hiện mất mát sớm hơn so với việc hết thời gian chờ. Nó được khởi tạo là 0.</p>
<p>Bộ đếm thời gian được sử dụng để phát hiện mất mát. Chỉ có một bộ đếm thời gian duy nhất.</p>
<p><em>RWND</em> được sử dụng cho <em>flow control</em> (không làm quá tải bộ đệm của bên nhận).</p>
<p><em>CWND</em> được sử dụng cho <em>congestion control</em>. Nó được khởi tạo là 1 <em>packet</em>.</p>
<p><em>SSTHRESH</em> giúp thuật toán <em>congestion control</em> ghi nhớ tốc độ an toàn mới nhất. Nó được khởi tạo là vô cực.</p>
<p>Bên nhận duy trì một bộ đệm gồm các <em>packet</em> không theo thứ tự.</p>
<p>Bên gửi phản ứng với 3 sự kiện: <em>Ack</em> cho dữ liệu mới (chưa được <em>ack</em> trước đó), <em>duplicate ack</em>, và hết thời gian chờ.</p>
<p>Bên nhận phản ứng với việc nhận một <em>packet</em>, bằng cách trả lời bằng một <em>ack</em> và một giá trị <em>RWND</em>.</p>
<p>Hãy xem cách bên gửi phản ứng với mỗi trong 3 sự kiện.</p>
<p>Khi chúng ta nhận được một <em>ack</em> cho dữ liệu mới, chưa được <em>ack</em> trước đó: Nếu ở trong chế độ <em>slow-start</em>, chúng ta tăng <em>CWND</em> thêm 1. Điều này cho phép <em>CWND</em> nhân đôi mỗi <em>RTT</em>. Nếu chúng ta đang ở trong chế độ <em>fast-recovery</em>, chúng ta đặt <em>CWND</em> thành <em>SSTHRESH</em>, để chúng ta rời khỏi <em>fast recovery</em> (vì chúng ta vừa nhận được một <em>ack</em> mới). Nếu chúng ta đang ở trong chế độ tránh tắc nghẽn, chúng ta thêm 1/<em>CWND</em> vào <em>CWND</em>, để <em>CWND</em> tăng thêm 1 mỗi <em>RTT</em> (tăng cộng). Chúng ta cũng đặt lại bộ đếm thời gian, đặt lại số đếm <em>duplicate ack</em>, và, nếu cửa sổ cho phép, gửi dữ liệu mới.</p>
<p>Khi chúng ta nhận được một <em>duplicate ack</em>, chúng ta tăng số đếm <em>duplicate ack</em>. Nếu số đếm đạt 3, chúng ta gửi lại <em>packet</em> ngoài cùng bên trái trong cửa sổ. Điều này đôi khi được gọi là <em>fast retransmit</em>. Chúng ta cũng vào chế độ <em>fast-recovery</em> bằng cách đặt <em>SSTHRESH</em> thành <em>CWND</em>/2 (ghi nhớ tốc độ an toàn cuối cùng) và đặt <em>CWND</em> thành <em>CWND</em>/2 + 3 (thêm 3 để mở rộng cửa sổ một cách nhân tạo cho các <em>duplicate acks</em>). Nếu số đếm vượt quá 3, chúng ta ở lại trong chế độ <em>fast-recovery</em> và mở rộng <em>CWND</em> một cách nhân tạo thêm 1 cho mỗi <em>duplicate ack</em> tiếp theo.</p>
<p>Khi bộ đếm thời gian hết hạn, chúng ta gửi lại <em>packet</em> ngoài cùng bên trái trong cửa sổ. Chúng ta cũng quay trở lại chế độ <em>slow-start</em>, đặt <em>SSTHRESH</em> thành <em>CWND</em>/2 (ghi nhớ tốc độ an toàn cuối cùng), và đặt lại <em>CWND</em> về 1 <em>packet</em>.</p>
<p>Máy trạng thái <em>congestion control</em> cho thấy 3 chế độ có thể có mà <em>TCP</em> có thể ở, và các điều kiện kích hoạt sự chuyển đổi giữa các chế độ.</p>
<img width="900px" src="transport/../assets/transport/3-087-state-machine.png">
<p>Chúng ta vào chế độ <em>fast-recovery</em> nếu chúng ta nhận được 3 <em>duplicate acks</em>. Một khi chúng ta ở trong chế độ này, bất kỳ <em>duplicate acks</em> nào nữa cũng sẽ giữ chúng ta ở trong chế độ <em>fast-recovery</em> (tiếp tục mở rộng cửa sổ một cách nhân tạo). Để rời khỏi chế độ <em>fast-recovery</em>, hoặc là một lần hết thời gian chờ sẽ chuyển chúng ta trở lại chế độ <em>slow-start</em>, hoặc một <em>ack</em> mới cho phép chúng ta quay trở lại chế độ tránh tắc nghẽn.</p>
<p>Một lần hết thời gian chờ sẽ kích hoạt chế độ <em>slow-start</em>. Bất kỳ <em>ack</em> nào nữa (trùng lặp hoặc mới) cũng sẽ giữ chúng ta ở trong <em>slow-start</em>. Cuối cùng, nếu <em>CWND</em> vượt quá <em>SSTHRESH</em> (tốc độ an toàn), chúng ta sẽ vào chế độ tránh tắc nghẽn. Hoặc, nếu chúng ta phát hiện mất mát, chúng ta sẽ giảm một nửa tốc độ và vào chế độ <em>fast-recovery</em> một chút trước khi chuyển sang chế độ tránh tắc nghẽn.</p>
<p>Trong chế độ tránh tắc nghẽn, các <em>ack</em> mới sẽ giữ chúng ta ở trong chế độ này (tăng cộng), nhưng các <em>duplicate acks</em> sẽ gửi chúng ta đến chế độ <em>fast-recovery</em>, và việc hết thời gian chờ sẽ gửi chúng ta đến chế độ <em>slow-start</em>.</p>
<h2 id="các-biến-thể-kiểm-soát-tắc-nghẽn-tcp"><a class="header" href="#các-biến-thể-kiểm-soát-tắc-nghẽn-tcp">Các Biến thể Kiểm soát Tắc nghẽn TCP</a></h2>
<p>Có một số biến thể của thuật toán <em>congestion control</em> <em>TCP</em>, tất cả đều được triển khai trong hệ điều hành của <em>host</em> cuối. Sự thật thú vị: Các tên này liên quan đến hệ điều hành Berkeley Software Distribution (BSD).</p>
<p>Trong <em>TCP Tahoe</em>, nếu chúng ta nhận được ba <em>duplicate acks</em>, chúng ta đặt lại <em>CWND</em> về 1, thay vì giảm một nửa <em>CWND</em>.</p>
<p>Trong <em>TCP Reno</em>, nếu chúng ta nhận được ba <em>duplicate acks</em>, chúng ta giảm một nửa <em>CWND</em>. Khi hết thời gian chờ, chúng ta đặt lại <em>CWND</em> về 1.</p>
<p><em>TCP New Reno</em> giống như Reno, nhưng thêm <em>fast recovery</em>. Đây là những gì chúng ta vừa triển khai.</p>
<p>Các biến thể khác cũng tồn tại. Trong <em>TCP-SACK</em>, chúng ta thêm các <em>selective acknowledgments (xác nhận chọn lọc)</em> nơi các <em>ack</em> chứa nhiều chi tiết hơn (ví dụ: đã nhận tất cả đến 13, và cả 18 nữa).</p>
<p>Làm thế nào mà tất cả các biến thể khác nhau này có thể cùng tồn tại? Tại sao chúng ta không cần một giao thức thống nhất duy nhất mà mọi người đều nói? Hãy nhớ rằng, <em>congestion control</em> được triển khai ở các <em>host</em> cuối, vì vậy bên gửi có thể làm bất cứ điều gì họ muốn để điều chỉnh tốc độ của mình. Cuối cùng, mạng và các <em>host</em> cuối khác chỉ thấy các <em>packet</em> <em>TCP</em> được gửi ở một tốc độ (hy vọng là hợp lý), và họ không quan tâm tốc độ đang được tính toán như thế nào. Định dạng <em>packet</em> <em>TCP</em> cơ bản không thay đổi với các thuật toán <em>congestion control</em> khác nhau.</p>
<p>Tuy nhiên, không phải tất cả các giao thức đều tương thích. Nếu bạn sử dụng biến thể <em>TCP-SACK</em> với các <em>selective acknowledgements</em>, và tôi sử dụng <em>TCP Tahoe</em>, chúng ta có một vấn đề. Bạn mong đợi các <em>ack</em> chọn lọc, nhưng tôi chỉ cung cấp các <em>cumulative acks</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mô-hình-thông-lượng-tcp-tcp-throughput-model"><a class="header" href="#mô-hình-thông-lượng-tcp-tcp-throughput-model">Mô hình Thông lượng TCP (<em>TCP Throughput Model</em>)</a></h1>
<h2 id="các-giả-định-mô-hình-hóa"><a class="header" href="#các-giả-định-mô-hình-hóa">Các giả định mô hình hóa</a></h2>
<p>Trong các phần trước, chúng ta đã xây dựng một thuật toán điều khiển tắc nghẽn (<em>congestion control</em>). Thuật toán này cho chúng ta biết cách điều chỉnh tốc độ truyền dữ liệu khi gặp tắc nghẽn, nhưng nó không thực sự cho biết tốc độ đó là bao nhiêu.</p>
<p>Trong phần này, chúng ta sẽ xây dựng một mô hình để ước lượng <strong>throughput</strong> (<em>thông lượng</em>) của một kết nối TCP trên một tuyến đường cụ thể. Cụ thể, chúng ta muốn có một phương trình đơn giản thể hiện thông lượng dưới dạng hàm của <strong>RTT</strong> (<em>Round-Trip Time – thời gian khứ hồi</em>) và <strong>loss rate</strong> (<em>tỷ lệ mất gói</em>). Phương trình này cho phép các nhà vận hành và khách hàng ước lượng tốc độ của một kết nối TCP.</p>
<p>Để đơn giản hóa mô hình, chúng ta sẽ đưa ra một vài giả định: Chỉ có một kết nối TCP duy nhất. Chúng ta bỏ qua giai đoạn khởi động chậm (<em>slow-start</em>). Chúng ta giả định RTT là một hằng số cố định.</p>
<p>Khi kích thước cửa sổ truyền đạt đến giới hạn băng thông cổ chai cực đại $$W_\text{max}$$ (một hằng số), chúng ta giả định sẽ xảy ra đúng một lần mất gói. Vì chỉ mất một gói tin, nên việc mất gói sẽ được phát hiện thông qua các <strong>duplicate ACKs</strong> (<em>ACK trùng lặp</em>), không phải qua timeout.</p>
<h2 id="thông-lượng-theo-kích-thước-cửa-sổ"><a class="header" href="#thông-lượng-theo-kích-thước-cửa-sổ">Thông lượng theo Kích thước Cửa sổ</a></h2>
<p>Trong mô hình đơn giản này, chúng ta phát hiện mất gói khi kích thước cửa sổ đạt $$W_\text{max}$$, và sau đó cửa sổ bị giảm xuống còn $$\frac{1}{2} W_\text{max}$$.</p>
<p>Sau đó, với mỗi RTT tiếp theo, kích thước cửa sổ sẽ tăng thêm 1: $$\frac{1}{2} W_\text{max} + 1$$, rồi $$\frac{1}{2} W_\text{max} + 2$$, rồi $$\frac{1}{2} W_\text{max} + 3$$, v.v. Cuối cùng, cửa sổ sẽ đạt lại $$W_\text{max}$$ và bị giảm một nửa, quá trình này sẽ lặp lại.</p>
<p>Bắt đầu từ $$\frac{1}{2} W_\text{max}$$ và tăng lên đến $$W_\text{max}$$ mất $$\frac{1}{2} W_\text{max}$$ RTT (mỗi lần tăng 1, mỗi lần là một RTT). Điều này cũng cho thấy có $$\frac{1}{2} W_\text{max}$$ RTT giữa mỗi lần mất gói.</p>
<img width="900px" src="transport/../assets/transport/3-088-equation1.png">
<p>Trong mỗi RTT, kích thước cửa sổ trung bình là $$\frac{3}{4} W_\text{max}$$ (nằm giữa $$\frac{1}{2} W_\text{max}$$ và $$W_\text{max}$$).</p>
<p>Kích thước cửa sổ được đo bằng số gói tin (vì mỗi lần tăng là thêm 1 gói). Mỗi gói tin có thể chứa $$\text{MSS}$$ byte (<em>Maximum Segment Size – kích thước đoạn tối đa</em>), nên kích thước cửa sổ trung bình tính theo byte là $$\frac{3}{4} W_\text{max} \times \text{MSS}$$.</p>
<p>Kích thước cửa sổ cho biết lượng dữ liệu có thể gửi trong mỗi RTT. Do đó, để tính tốc độ truyền, ta chia kích thước cửa sổ (dữ liệu) cho RTT (thời gian), thu được tốc độ trung bình là $$\frac{3}{4} W_\text{max} \times \frac{\text{MSS}}{\text{RTT}}$$.</p>
<h2 id="thông-lượng-theo-tỷ-lệ-mất-gói"><a class="header" href="#thông-lượng-theo-tỷ-lệ-mất-gói">Thông lượng theo Tỷ lệ Mất gói</a></h2>
<p>Phương trình thông lượng hiện tại là:<br />
$$\frac{3}{4} W_\text{max} \times \frac{\text{MSS}}{\text{RTT}}$$.</p>
<p>Nhưng mục tiêu của chúng ta là biểu diễn thông lượng theo RTT và tỷ lệ mất gói $$p$$. Vì vậy, ta cần biểu diễn $$W_\text{max}$$ theo $$p$$.</p>
<p>Từ trước, ta đã suy ra rằng một gói tin bị mất sau mỗi $$\frac{1}{2} W_\text{max}$$ RTT. Đây là thời gian cần thiết để tăng cửa sổ từ $$\frac{1}{2} W_\text{max}$$ lên $$W_\text{max}$$ và gặp lại mất gói.</p>
<p>Vậy để xác định tỷ lệ mất gói, ta cần biết có bao nhiêu gói tin được gửi trong $$\frac{1}{2} W_\text{max}$$ RTT.</p>
<img width="900px" src="transport/../assets/transport/3-089-equation2.png">
<p>Về mặt đồ họa, số gói tin gửi được là diện tích của hình này (tốc độ × thời gian), hay chính là diện tích dưới đường cong (đường cong biểu diễn tốc độ, và ta cần tích phân của tốc độ).</p>
<p>Ta đã biết kích thước cửa sổ trung bình là $$\frac{3}{4} W_\text{max}$$, tức là số gói tin gửi mỗi RTT. Vậy trong $$\frac{1}{2} W_\text{max}$$ RTT, ta gửi được:<br />
$$(\frac{1}{2} W_\text{max}) \times \frac{3}{4} W_\text{max} = \frac{3}{8} W_\text{max}^2$$ gói tin.</p>
<p>Giờ ta biết số gói tin gửi giữa các lần mất gói, nên tỷ lệ mất gói là một gói bị mất chia cho số gói gửi giữa các lần mất. (Ví dụ: nếu gửi 100 gói giữa các lần mất, thì tỷ lệ mất gói là khoảng 1/100).</p>
<p>Vậy tỷ lệ mất gói là:<br />
$$p = \frac{1}{\frac{3}{8} W_\text{max}^2} = \frac{8}{3W_\text{max}^2}$$.</p>
<p>Giờ ta có mối quan hệ giữa $$W_\text{max}$$ và $$p$$, ta chỉ cần biến đổi đại số để biểu diễn $$W_\text{max}$$ theo $$p$$:</p>
<p>$$\begin{align*}
p &amp;= \frac{8}{3W_\text{max}^2} \
3W_\text{max}^2 p &amp;= 8 \
W_\text{max}^2 &amp;= \frac{8}{3p} \
W_\text{max} &amp;= \frac{2\sqrt{2}}{\sqrt{3p}}
\end{align*}$$</p>
<p>Giờ ta thay $$W_\text{max}$$ vào phương trình thông lượng ban đầu:</p>
<p>$$\begin{align*}
\text{throughput} &amp;= \frac{3}{4} W_\text{max} \times \frac{\text{MSS}}{\text{RTT}} \
&amp;= \frac{3}{4} \left(\frac{2\sqrt{2}}{\sqrt{3p}}\right) \times \frac{\text{MSS}}{\text{RTT}} \
&amp;= \sqrt{\frac{3}{2}} \times \frac{\text{MSS}}{\text{RTT}\sqrt{p}}
\end{align*}$$</p>
<h2 id="Ý-nghĩa-của-phương-trình"><a class="header" href="#Ý-nghĩa-của-phương-trình">Ý nghĩa của Phương trình</a></h2>
<p>Giờ ta có phương trình thông lượng biểu diễn theo RTT và tỷ lệ mất gói. Nó cho ta biết điều gì?</p>
<p>Thông lượng tỷ lệ nghịch với căn bậc hai của tỷ lệ mất gói. Trực giác cho thấy nếu tỷ lệ mất gói cao hơn, thì thông lượng thấp hơn. Điều này hợp lý, vì mất nhiều gói hơn khiến cửa sổ bị giảm một nửa thường xuyên hơn.</p>
<p>Thông lượng cũng tỷ lệ nghịch với RTT. Trực giác cho thấy nếu RTT thấp hơn, thì thông lượng cao hơn. Điều này hợp lý, vì cửa sổ tăng mỗi khi nhận được ACK, và RTT thấp giúp nhận ACK nhanh hơn.</p>
<p>Mối quan hệ giữa RTT và thông lượng có thể gây vấn đề nếu có nhiều kết nối với RTT khác nhau.</p>
<img width="600px" src="transport/../assets/transport/3-090-multi-flow.png">
<p>Kết nối có RTT thấp hơn sẽ nhận ACK nhanh hơn, đồng nghĩa với việc tăng cửa sổ nhanh hơn và gửi gói nhanh hơn. Trong trường hợp này, kết nối có RTT thấp hơn sẽ chiếm gấp đôi băng thông so với kết nối có RTT cao hơn.</p>
<p>Về bản chất, TCP là &quot;không công bằng&quot; khi RTT không đồng đều. RTT ngắn giúp cải thiện thời gian lan truyền, nhưng cũng giúp TCP tăng tốc độ nhanh hơn. Chúng ta chấp nhận điều này như một đặc điểm của TCP, và không có biện pháp xử lý trong thực tế.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="các-vấn-đề-trong-Điều-khiển-tắc-nghẽn-congestion-control"><a class="header" href="#các-vấn-đề-trong-Điều-khiển-tắc-nghẽn-congestion-control">Các vấn đề trong Điều khiển Tắc nghẽn (Congestion Control)</a></h1>
<h2 id="nhầm-lẫn-giữa-hỏng-gói-tin-corruption-và-tắc-nghẽn-congestion"><a class="header" href="#nhầm-lẫn-giữa-hỏng-gói-tin-corruption-và-tắc-nghẽn-congestion">Nhầm lẫn giữa Hỏng gói tin (Corruption) và Tắc nghẽn (Congestion)</a></h2>
<p><em>TCP</em> phát hiện tắc nghẽn bằng cách kiểm tra tình trạng mất gói tin (<em>packet loss</em>), nhưng tắc nghẽn không phải là lý do duy nhất khiến gói tin bị mất. Gói tin cũng có thể bị mất do hỏng gói tin, và <em>TCP</em> không thể phân biệt được mất gói do hỏng hay do tắc nghẽn. Nếu một gói tin bị hỏng, <em>TCP</em> vẫn sẽ giảm tốc độ truyền, ngay cả khi mạng không bị tắc nghẽn.</p>
<p>Chúng ta cũng có thể thấy điều này trong phương trình liên hệ giữa <em>throughput</em> (thông lượng) và tỷ lệ mất gói (<em>loss rate</em>). <em>Throughput</em> và <em>loss rate</em> tỉ lệ nghịch với nhau, ngay cả đối với các trường hợp mất gói không do tắc nghẽn. Phương trình này hữu ích để ước lượng tác động của một đường truyền kém ổn định (<em>lossy link</em>, ví dụ: đường truyền không dây thường xuyên làm hỏng gói tin) đối với <em>TCP</em>.</p>
<h2 id="kết-nối-ngắn-short-connections"><a class="header" href="#kết-nối-ngắn-short-connections">Kết nối ngắn (Short Connections)</a></h2>
<p>Hầu hết các kết nối <em>TCP</em> trong thực tế tồn tại rất ngắn. 50% số kết nối truyền ít hơn 1,5 KB dữ liệu, và 80% số kết nối truyền ít hơn 100 KB. Rất ít gói tin (có thể chỉ một gói) được gửi trong các kết nối này.</p>
<p>Giả sử chúng ta có một kết nối mà phía gửi chỉ có 3 gói tin cần gửi. <em>TCP congestion control</em> (điều khiển tắc nghẽn trong TCP) sẽ làm gì? Chúng ta bắt đầu với kích thước cửa sổ (<em>window size</em>) là 1 và gửi gói tin đầu tiên. Sau đó, chờ <em>ack</em> (thông báo xác nhận), tăng kích thước cửa sổ lên 2, và gửi hai gói tin còn lại. Tiếp theo, chờ thêm hai <em>ack</em> nữa, và hoàn tất.</p>
<img width="400px" src="transport/../assets/transport/3-091-short-flow.png">
<p>Kết nối này mất hai <em>RTT</em> (Round-Trip Time – thời gian khứ hồi) để gửi 3 gói tin, dẫn đến <em>throughput</em> cực thấp (1,5 gói tin mỗi <em>RTT</em>).</p>
<p>Nói chung, các kết nối ngắn này không bao giờ thoát khỏi giai đoạn <em>slow-start</em> (khởi động chậm), và không bao giờ đạt được phần <em>bandwidth</em> (băng thông) công bằng của mình. Điều này khiến các kết nối ngắn phải chịu thời gian truyền tải dài không cần thiết.</p>
<p>Một vấn đề khác với kết nối ngắn là xử lý mất gói. Hãy nhớ rằng chúng ta phát hiện mất gói khi có 3 <em>duplicate acks</em> (gói xác nhận trùng lặp), nhưng trong một kết nối ngắn, có thể không đủ gói tin để kích hoạt 3 <em>duplicate acks</em>. Ví dụ, nếu chúng ta có 4 gói tin cần gửi, và mất gói thứ hai, chúng ta sẽ không bao giờ nhận được 3 <em>duplicate acks</em>. Thay vào đó, chúng ta phải chờ <em>timeout</em> (hết thời gian chờ) để kích hoạt. Với giá trị <em>timeout</em> thực tế khoảng 500ms, điều này cũng khiến kết nối ngắn mất nhiều thời gian hơn cần thiết.</p>
<p>Làm thế nào để khắc phục cả hai vấn đề này? Một giải pháp một phần là bắt đầu với <em>initial window</em> (cửa sổ khởi tạo) lớn hơn (ví dụ: 10 gói thay vì 1). Khi đó, các kết nối có 10 gói tin hoặc ít hơn có thể gửi toàn bộ dữ liệu ngay từ đầu kết nối.</p>
<h2 id="tcp-làm-đầy-hàng-đợi-queues"><a class="header" href="#tcp-làm-đầy-hàng-đợi-queues">TCP làm đầy hàng đợi (Queues)</a></h2>
<p><em>TCP</em> phát hiện tắc nghẽn bằng cách dựa vào mất gói, và thuật toán <em>congestion control</em> cố tình tăng tốc độ truyền cho đến khi gây ra mất gói. Để gây ra mất gói, các hàng đợi (<em>queues</em>) phải đầy. Điều này có nghĩa là <em>TCP</em> tạo ra độ trễ xếp hàng (<em>queuing delay</em>) trên toàn mạng, và độ trễ này ảnh hưởng đến tất cả mọi người trong mạng.</p>
<p>Giả sử chúng ta có một kết nối tải nặng truyền một tệp 10 GB, và sau đó, chúng ta bắt đầu một kết nối nhỏ chỉ truyền một gói tin. Cả hai kết nối chia sẻ cùng một đường truyền nghẽn cổ chai (<em>bottleneck link</em>). Kết nối tải nặng sẽ tăng tốc độ cho đến khi hàng đợi tại đường truyền nghẽn cổ chai đầy. Lúc này, khi kết nối nhỏ bắt đầu, nó sẽ phải chờ trong hàng đợi, phía sau các gói tin của kết nối tải nặng.</p>
<p>Vấn đề này trở nên tồi tệ hơn nếu <em>router</em> giữ hàng đợi cực lớn. Việc <em>router</em> có bộ nhớ quá lớn cho hàng đợi dài được gọi là <strong>bufferbloat</strong>. Một ví dụ về <em>bufferbloat</em> xảy ra ở các <em>home router</em> (router gia đình), vốn có thể có hàng đợi rất lớn nhưng chỉ có rất ít kết nối (chỉ các kết nối trong nhà bạn) sử dụng hàng đợi đó. Khi đó, bất kỳ kết nối nào bạn tạo ra sẽ gây ra độ trễ xếp hàng lớn cho các kết nối khác.</p>
<p>Để tránh việc hàng đợi bị đầy, chúng ta có thể tìm cách đo lường tắc nghẽn mà không cần cố tình gây mất gói. Cụ thể, chúng ta có thể phát hiện tắc nghẽn khi <em>RTT</em> bắt đầu tăng, điều này cho thấy có độ trễ. Đây là ý tưởng đằng sau thuật toán <em>BBR</em> của Google (2016). Phía gửi sẽ học được <em>RTT</em> tối thiểu của mình, và giảm tốc độ nếu nhận thấy <em>RTT</em> vượt quá giá trị tối thiểu.</p>
<img width="600px" src="transport/../assets/transport/3-092-delay-based-taxonomy.png">
<h2 id="gian-lận-cheating"><a class="header" href="#gian-lận-cheating">Gian lận (Cheating)</a></h2>
<p>Không có gì bắt buộc phía gửi phải tuân theo thuật toán <em>TCP congestion control</em>. Phía gửi có thể gian lận để giành được phần <em>bandwidth</em> lớn hơn một cách không công bằng.</p>
<p>Ví dụ, một phía gửi có thể tăng kích thước cửa sổ nhanh hơn (ví dụ: +2 mỗi <em>RTT</em> thay vì +1). Nếu áp dụng mô hình đồ thị của chúng ta cho một phía gửi gian lận và một phía gửi trung thực, các cập nhật <em>AIMD</em> (Additive Increase Multiplicative Decrease – Tăng cộng, giảm nhân) sẽ hội tụ về một đường công bằng xấu, nơi phía gửi gian lận nhận gấp đôi <em>bandwidth</em> của phía gửi trung thực.</p>
<img width="600px" src="transport/../assets/transport/3-093-cheating-aimd.png">
<p>Có nhiều cách khác để sửa đổi giao thức, chẳng hạn như bắt đầu với <em>initial congestion window</em> rất lớn.</p>
<p>Trong thực tế, vì <em>TCP</em> được triển khai trong hệ điều hành (<em>operating system</em>), để gian lận, phía gửi sẽ phải sửa đổi mã trong hệ điều hành của mình, điều mà phần lớn người dùng Internet không làm.</p>
<p>Nếu chỉ một số ít phía gửi lạm dụng hệ thống, họ sẽ nhận được nhiều <em>bandwidth</em> hơn. Nếu một số lượng lớn phía gửi lạm dụng hệ thống (ví dụ: Microsoft phát hành một phiên bản Windows lạm dụng <em>TCP</em>), hàng triệu người dùng Windows vẫn sẽ cạnh tranh với nhau, và khó có khả năng ai đó sẽ nhận được nhiều <em>bandwidth</em> hơn.</p>
<p>Một cách khác để gian lận, mà không cần sửa đổi <em>TCP</em>, là mở nhiều kết nối. <em>TCP</em> chỉ đảm bảo rằng mỗi kết nối nhận được phần công bằng. Nếu một phía gửi gian lận mở 10 kết nối và một phía gửi trung thực mở 1 kết nối, phía gian lận sẽ nhận được gấp 10 lần <em>bandwidth</em>. Nhiều ứng dụng cố tình mở nhiều kết nối để cải thiện <em>bandwidth</em>.</p>
<p>Nếu gian lận là có thể, tại sao Internet chưa gặp lại sự cố sụp đổ tắc nghẽn (<em>congestion collapse</em>)? Hóa ra, các nhà nghiên cứu cũng không thực sự biết câu trả lời. Một khả năng là: những kẻ gian lận sửa đổi thuật toán <em>congestion control</em> có thể nhận được phần <em>bandwidth</em> không công bằng, nhưng nếu họ vẫn tuân theo các nguyên tắc của <em>congestion control</em> (ví dụ: giảm tốc độ khi mất gói), thì họ không làm quá tải mạng. Ngược lại, trong sự cố <em>congestion collapse</em> những năm 1980, phía gửi liên tục gửi lại gói tin với tốc độ cao, mà không hề điều chỉnh tốc độ.</p>
<p>Nếu gian lận là có thể, thì trên thực tế có bao nhiêu gian lận xảy ra? Một lần nữa, chúng ta không thực sự biết. Rất khó để đo lường gian lận (ví dụ: bạn không biết kích thước <em>window</em> mà mỗi phía gửi đang sử dụng).</p>
<h2 id="Điều-khiển-tắc-nghẽn-congestion-control-và-Độ-tin-cậy-reliability-gắn-chặt-với-nhau"><a class="header" href="#Điều-khiển-tắc-nghẽn-congestion-control-và-Độ-tin-cậy-reliability-gắn-chặt-với-nhau">Điều khiển tắc nghẽn (Congestion Control) và Độ tin cậy (Reliability) gắn chặt với nhau</a></h2>
<p>Các cơ chế điều khiển tắc nghẽn (<em>congestion control</em>) và độ tin cậy (<em>reliability</em>) được liên kết chặt chẽ. Như chúng ta đã thấy, <em>congestion control</em> được triển khai bằng cách lấy mã của phần đảm bảo <em>TCP reliability</em> và chỉnh sửa một vài dòng mã.</p>
<p>Chúng ta cũng có thể thấy sự phụ thuộc này ngay trong thuật toán. <em>Window</em> được cập nhật dựa trên <em>acks</em> và <em>timeouts</em> vì mã của phần <em>reliability</em> được viết để phản ứng với các sự kiện đó. Chúng ta phát hiện mất gói bằng <em>duplicate acks</em> vì phần triển khai <em>reliability</em> sử dụng <em>cumulative acks</em> (xác nhận cộng dồn).</p>
<p>Việc kết hợp <em>reliability</em> và <em>congestion control</em> là một lựa chọn thiết kế. Một lợi ích là <em>congestion control</em> chỉ cần một bản vá mã nhỏ và có thể triển khai rộng rãi để ứng phó với sự cố <em>congestion collapse</em> (sụp đổ tắc nghẽn) trong những năm 1980. Tuy nhiên, kể từ đó, việc kết hợp hai tính năng này đã làm phức tạp quá trình phát triển các thuật toán. Ví dụ, nếu chúng ta muốn thay đổi điều gì đó trong thuật toán <em>congestion control</em>, rất có thể chúng ta cũng phải thay đổi mã của phần <em>reliability</em>. Hoặc nếu muốn thay đổi phần triển khai <em>reliability</em> (ví dụ: chuyển từ <em>cumulative acks</em> sang <em>full-information acks</em>), chúng ta cũng phải cập nhật <em>congestion control</em>.</p>
<p>Từ góc độ thiết kế, đây là một thất bại về tính mô-đun (<em>modularity</em>), chứ không phải về phân lớp (<em>layering</em>). <em>Congestion control</em> và <em>reliability</em> đang hoạt động ở đúng lớp trừu tượng (<em>transport layer</em> – tầng vận chuyển). Tuy nhiên, bên trong tầng vận chuyển, chúng ta chưa tách biệt rõ ràng các chức năng khác nhau thành các phần mã riêng biệt.</p>
<p>Bởi vì <em>congestion control</em> phụ thuộc vào <em>reliability</em>, nên rất khó để đạt được <em>congestion control</em> mà không có <em>reliability</em>. Một số ứng dụng (ví dụ: <em>video streaming</em> – truyền phát video) có thể không muốn <em>reliability</em>, nhưng vẫn muốn <em>congestion control</em>. Tuy nhiên, hiện không có cách nào để tắt <em>reliability</em> và chỉ giữ lại <em>congestion control</em>.</p>
<p>Tương tự, cũng khó để đạt được <em>reliability</em> mà không có <em>congestion control</em>. Ví dụ, nếu chúng ta có một kết nối nhẹ chỉ gửi một gói tin mỗi 10 phút, có lẽ không cần <em>congestion control</em> cho kết nối này. Nhưng chúng ta cũng không thể dễ dàng tắt <em>congestion control</em> chỉ cho một số kết nối nhất định.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kiểm-soát-tắc-nghẽn-hỗ-trợ-bởi-router"><a class="header" href="#kiểm-soát-tắc-nghẽn-hỗ-trợ-bởi-router">Kiểm soát tắc nghẽn hỗ trợ bởi Router</a></h1>
<h2 id="kiểm-soát-tắc-nghẽn-với-router"><a class="header" href="#kiểm-soát-tắc-nghẽn-với-router">Kiểm soát tắc nghẽn với Router</a></h2>
<p>Trước đây, chúng ta đã thấy một số vấn đề với các thuật toán kiểm soát tắc nghẽn dựa trên host. Nhiều vấn đề này có thể được khắc phục với sự hỗ trợ từ router (bộ định tuyến)!</p>
<p>TCP (Transmission Control Protocol - Giao thức kiểm soát truyền) nhầm lẫn giữa tắc nghẽn và hỏng hóc. TCP làm đầy hàng đợi, có tốc độ không ổn định, và hoạt động kém với các dòng chảy ngắn, tất cả đều vì host cần liên tục điều chỉnh tốc độ để phát hiện tắc nghẽn. Nếu router có thể thông báo cho người gửi về tắc nghẽn, hoặc thậm chí trực tiếp chỉ cho người gửi tốc độ lý tưởng, thì nhiều vấn đề này có thể được giải quyết.</p>
<p>Ngoài ra, nếu router thực thi chia sẻ công bằng, thì sẽ khó khăn hơn nhiều để host gian lận.</p>
<p>Về mặt triết lý, đây là một lựa chọn thiết kế tự nhiên để router tham gia vào kiểm soát tắc nghẽn. Tắc nghẽn xảy ra tại router, vì vậy chúng thường có nhiều thông tin hơn về tắc nghẽn so với host.</p>
<p>Kiểm soát tắc nghẽn hỗ trợ bởi router có thể rất hiệu quả và dẫn đến hiệu suất gần như tối ưu (sử dụng liên kết cao, độ trễ thấp), nhưng việc triển khai các giao thức này có thể gặp thách thức. Router giờ đây cần hỗ trợ chức năng bổ sung, và đôi khi chức năng đó có thể khá phức tạp. Một số giao thức thậm chí có thể yêu cầu mọi router đồng ý thêm chức năng đó.</p>
<h2 id="thực-thi-fair-queuing"><a class="header" href="#thực-thi-fair-queuing">Thực thi Fair Queuing</a></h2>
<p>Làm thế nào để một router đảm bảo rằng mọi kết nối nhận được phần chia sẻ công bằng của mình?</p>
<p>Cho đến nay, một router đang nhận packet (gói tin), xếp hàng chúng nếu cần, và gửi chúng ra theo thứ tự first-in-first-out (FIFO - tiên nhập tiên xuất). Router không quan tâm packet đến từ kết nối nào.</p>
<p>Trong mô hình mới của chúng ta, router sẽ cần phân loại packet vào các kết nối. (Hiện tại, giả sử các kết nối đều là kết nối TCP.) Điều này có nghĩa là router phải nhìn vào bên trong packet để biết địa chỉ IP nguồn và đích cũng như port (cổng).</p>
<p>Để định nghĩa chính thức về tính công bằng, router có thể duy trì một hàng đợi riêng cho mỗi kết nối. Khi một packet đến, router thêm packet vào hàng đợi phù hợp. Sau đó, router chỉ cần chọn một hàng đợi mỗi lần, gửi packet từ đầu hàng đợi đó. Miễn là router chọn hàng đợi theo cách công bằng, thì router đang thực thi tính công bằng giữa các kết nối.</p>
<p>Nếu tất cả packet có kích thước giống nhau, thì router có thể chọn hàng đợi theo kiểu round-robin (luân phiên - gửi từ hàng đợi đầu tiên, sau đó hàng đợi thứ hai, v.v.). Hóa ra cách này hoạt động, ngay cả khi không phải tất cả kết nối cần cùng bandwidth (băng thông). Một số kết nối có thể xếp hàng packet chậm hơn những kết nối khác. Nếu chúng ta áp dụng dịch vụ round-robin cho các kết nối có bandwidth khác nhau, làm thế nào để tính toán bandwidth được phân bổ cho mỗi kết nối? Ví dụ, giả sử chúng ta có thể gửi 10 packet mỗi giây, và A, B, và C gửi 8, 6, và 2 packet mỗi giây, tương ứng.</p>
<img width="500px" src="transport/../assets/transport/3-094-fair-queuing-1.png">
<p>Nếu chúng ta gửi packet theo kiểu round-robin, thì sẽ có bao nhiêu packet mỗi giây của mỗi loại được gửi? Chúng ta có thể mô hình hóa điều này như một vấn đề phân bổ tài nguyên và giải quyết nó.</p>
<img width="600px" src="transport/../assets/transport/3-095-fair-queuing2.png">
<p>Ví dụ, giả sử chúng ta có dung lượng liên kết là 10. Kết nối A yêu cầu 8, B yêu cầu 6, và C yêu cầu 2. Làm thế nào để phân bổ dung lượng giữa ba kết nối? Nếu chúng ta cố gắng công bằng, mọi người sẽ nhận 3.33. Nhưng C chỉ yêu cầu 2, vì vậy hãy cho C 2 mà nó yêu cầu, không thêm thừa.</p>
<p>Bây giờ chúng ta còn dư 8, và A và B vẫn cần phân bổ. Nếu chúng ta công bằng, mỗi bên sẽ nhận 4. Điều này ít hơn những gì chúng yêu cầu, nhưng chúng ta không có cách nào để thỏa mãn yêu cầu của chúng, vì vậy chúng ta sẽ cho mỗi bên phần chia sẻ công bằng là 4.</p>
<p>Chính thức, để định nghĩa max-min fairness (tính công bằng max-min), giả sử C là tổng bandwidth có sẵn cho router. Mỗi kết nối $$r_i$$ có nhu cầu bandwidth, và chúng ta phải phân bổ bandwidth $$a_i$$ cho mỗi kết nối. Các phân bổ bandwidth max-min là $$a_i = \min(f, r_i)$$, trong đó $$f$$ là giá trị duy nhất (giá trị giống nhau cho tất cả kết nối) sao cho $$\sum a_i = C$$. Trong phương trình này, thuật ngữ min đảm bảo rằng không ai nhận nhiều hơn những gì họ yêu cầu, và ràng buộc tổng đảm bảo rằng không có bandwidth nào bị lãng phí. Trực quan, $$f$$ là phần chia sẻ công bằng mà chúng ta phân bổ đều cho mọi người (do đó một giá trị $$f$$ cho tất cả kết nối).</p>
<p>Một cách khác để đọc phương trình này là: Có một con số chia sẻ công bằng kỳ diệu mà chúng ta có thể phân bổ đều cho mọi người. Nếu bạn yêu cầu ít hơn phần chia sẻ công bằng, bạn nhận phần chia sẻ công bằng (không thêm thừa). Nếu bạn yêu cầu nhiều hơn phần chia sẻ công bằng, bạn bị giới hạn ở phần chia sẻ công bằng, nhưng không ai khác nhận nhiều hơn bạn.</p>
<p>Trong ví dụ trước, $$f$$ là 4. A và B nhận $$f$$ (chúng muốn nhiều hơn), và C nhận 2 (nó muốn ít hơn).</p>
<p>Nếu chúng ta áp dụng max-min fairness, phương trình đảm bảo rằng nếu bạn không nhận đầy đủ nhu cầu của mình, không ai khác nhận nhiều hơn bạn. Cách tiếp cận round-robin là max-min fair (giả sử kích thước packet bằng nhau).</p>
<p>Điều gì nếu chúng ta không giả sử kích thước packet bằng nhau? Trong thực tế, kích thước packet có thể khác nhau lớn (ví dụ 40 byte so với 1500 byte). Lý tưởng, chúng ta muốn thực hiện bit-by-bit round robin (luân phiên từng bit), nơi chúng ta luân phiên gửi một bit từ hàng đợi của mỗi kết nối. Điều này không thực tế (chúng ta không gửi một bit mỗi lần), nhưng nếu chúng ta áp dụng lý thuyết này, chúng ta có thể ghi lại thời điểm bit cuối cùng của một packet được gửi ra, cho mọi packet. Chúng ta sẽ gọi đây là deadline (hạn chót) cho packet đó. Sau đó, một xấp xỉ công bằng sẽ là gửi packet theo thứ tự deadline (khi bit cuối cùng của chúng sẽ được gửi lý tưởng).</p>
<p>Sự thật thú vị: Bài báo về mô phỏng fair queuing (xếp hàng công bằng) rất có ảnh hưởng, và hai trong số các tác giả là Scott Shenker (giảng viên UC Berkeley) và Srinivasan Keshav (sinh viên tiến sĩ EECS lúc đó).</p>
<p>Dưới đây là ví dụ về fair queuing bit-by-bit chính xác trên hai kết nối (khi có hòa, chúng ta chọn packet đến trước).</p>
<img width="900px" src="transport/../assets/transport/3-096-fair-queuing3.png">
<h2 id="fair-queuing-trong-thực-tế"><a class="header" href="#fair-queuing-trong-thực-tế">Fair Queuing trong Thực tế</a></h2>
<p>Fair queuing có gì tốt? Nó đảm bảo sự cô lập giữa các kết nối, và ngăn chặn các kết nối gian lận nhận nhiều bandwidth hơn. Các kết nối sẽ không cần triển khai TCP (hoặc một lựa chọn thay thế thân thiện với TCP), và có thể chọn thuật toán kiểm soát tắc nghẽn riêng của mình (có thể không thân thiện).</p>
<p>Về cơ bản, lợi ích của fair queuing là khả năng phục hồi trước các yếu tố bên ngoài như gian lận và biến đổi RTT (Round-Trip Time - thời gian khứ hồi). Dù sao đi nữa, mọi người đều nhận được phần chia sẻ công bằng của một liên kết nhất định. Nhưng, chúng ta vẫn cần các host đầu cuối phát hiện và thích ứng với phần chia sẻ công bằng của mình (ví dụ chậm lại nếu chúng yêu cầu quá nhiều).</p>
<p>Fair queuing có gì xấu? Nó phức tạp hơn nhiều so với xếp hàng FIFO. Quá trình tính toán deadline khó khăn và chúng ta chưa trình bày thuật toán để làm điều đó ở đây. Ngoài ra, router sẽ cần duy trì nhiều hàng đợi, và thực hiện công việc phân tích bổ sung trên mọi packet.</p>
<p>Trong thực tế, chúng ta không thể triển khai fair queuing hoàn hảo trong router (quá phức tạp để chạy ở tốc độ cao), nhưng các xấp xỉ tồn tại (ví dụ Deficit Round Robin). Các router hiện đại thường triển khai các xấp xỉ, mặc dù với ít hàng đợi hơn. Ít hàng đợi hơn nghĩa là thay vì một hàng đợi cho mỗi kết nối, sự cô lập thô hơn (ví dụ một hàng đợi cho mỗi khách hàng).</p>
<p>Fair queuing không thể loại bỏ tắc nghẽn. Nó chỉ là một cách thay thế để quản lý tắc nghẽn. Ví dụ, hãy xem xét liên kết nút cổ chai này: Nó có thể phân bổ 0.5 Gbps cho mỗi kết nối, điều này đánh bại gian lận. Nhưng, nếu kết nối trên cùng chạy ở 0.5 Gbps, thì 0.4 Gbps sẽ bị drop tại liên kết tiếp theo ngay lập tức. Một phân bổ tốt hơn sẽ là gửi 0.1 Gbps dọc theo kết nối trên cùng, và 0.9 Gbps dọc theo kết nối dưới cùng.</p>
<p>Về cơ bản, vấn đề là liên kết nút cổ chai này không biết điều gì sẽ xảy ra tại các liên kết tương lai (hạ lưu). Cách duy nhất để khắc phục là làm cho host người gửi chậm lại (xếp hàng router không thể giúp).</p>
<p>Fair queuing mang lại tính công bằng cho mỗi kết nối, nhưng về mặt triết lý, chúng ta vẫn phải hỏi liệu đây có phải là mô hình công bằng đúng đắn không. Như chúng ta đã thấy trước đó, tính công bằng cho mỗi kết nối nghĩa là ai đó có nhiều kết nối hơn vẫn nhận nhiều bandwidth hơn. Chúng ta có nên thực thi tính công bằng cho mỗi cặp nguồn-đích, hoặc có lẽ cho mỗi nguồn? Chúng ta có nên phạt các kết nối sử dụng nhiều liên kết tắc nghẽn hơn (chiếm nhiều tài nguyên khan hiếm hơn)?</p>
<h2 id="kiểm-soát-tắc-nghẽn-hỗ-trợ-bởi-router-1"><a class="header" href="#kiểm-soát-tắc-nghẽn-hỗ-trợ-bởi-router-1">Kiểm soát tắc nghẽn hỗ trợ bởi Router</a></h2>
<p>Fair queuing thực thi tính công bằng trên một liên kết cụ thể, nhưng nó không thông báo gì cho người gửi. Điều gì nếu router truyền thông tin ngược lại cho người gửi để giúp người gửi điều chỉnh tốc độ của mình?</p>
<p>Một giải pháp là để router trực tiếp chỉ cho người gửi tốc độ mà chúng nên sử dụng. Chúng ta có thể thêm một trường rate trong packet, và để router điền vào trường đó với phần chia sẻ công bằng của kết nối. Khi packet đến người gửi, người gửi có thể đọc header và đặt tốc độ theo những gì router nói. Bây giờ, người gửi không cần điều chỉnh động để phát hiện tốc độ tốt.</p>
<p>Một giải pháp khác là để router thông báo cho người gửi về tắc nghẽn (mà không chỉ định tốc độ chính xác). Điều này được triển khai dưới dạng bit Explicit Congestion Notification (ECN - Thông báo tắc nghẽn rõ ràng) trong IP header (tiêu đề IP). Nếu một packet đi qua một router tắc nghẽn, router đặt bit đó thành 1. Khi người nhận nhận packet với bit ECN bật, ack (xác nhận) trả lời cũng sẽ có bit ECN được đặt, vì vậy người gửi biết về tắc nghẽn.</p>
<p>Có nhiều lựa chọn cho việc khi nào router đặt bit này. Router có thể hoang tưởng và đặt bit thường xuyên, điều này giảm độ trễ nhưng có thể dẫn đến liên kết không được sử dụng đầy đủ. Hoặc, router có thể liều lĩnh hơn và hiếm khi đặt bit, điều này tăng độ trễ nhưng dẫn đến sử dụng liên kết cao.</p>
<p>Cũng có nhiều lựa chọn cho cách host phản ứng khi bit này được đặt. Ví dụ, host có thể giả vờ packet bị drop và điều chỉnh tương ứng.</p>
<p>ECN có gì tốt? Nó giải quyết vấn đề nhầm lẫn giữa hỏng hóc và tắc nghẽn. Nó cho phép router cảnh báo host về tắc nghẽn sớm hơn (ví dụ trước khi hàng đợi đầy), điều này có thể giảm độ trễ. Nó cũng nhẹ để triển khai.</p>
<p>Trong thực tế, ECN hiệu quả yêu cầu hầu hết hoặc tất cả router hỗ trợ giao thức này và bật bit khi cần thiết. Trong Internet hiện đại, bit ECN được triển khai trên một số, nhưng không phải tất cả router. Tuy nhiên, bit ECN có thể hiệu quả trong một mạng nhỏ (ví dụ bên trong mạng cục bộ của datacenter) nơi tất cả router đồng ý kích hoạt bit.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dns"><a class="header" href="#dns">DNS</a></h1>
<h2 id="dns-dùng-để-làm-gì-what-is-dns-for"><a class="header" href="#dns-dùng-để-làm-gì-what-is-dns-for">DNS dùng để làm gì? (What is DNS For?)</a></h2>
<p>Trong phần này, chúng ta sẽ xem xét một số ứng dụng phổ biến ở <strong>Layer 7</strong> (tầng ứng dụng) hoạt động trên nền tảng các tầng mà chúng ta đã xây dựng trước đó.</p>
<img width="400px" src="applications/../assets/applications/4-01-layer7.png">
<p>Ứng dụng đầu tiên chúng ta sẽ tìm hiểu là <strong>DNS (Domain Name System – Hệ thống tên miền)</strong>, đây là một giao thức hoạt động trên các tầng (1–4) để cung cấp chức năng mạng quan trọng là <strong>name resolution</strong> (phân giải tên miền).</p>
<p>Trên Internet, thông tin thường được lập chỉ mục theo hai cách khác nhau. Con người truy cập các trang web bằng các tên dễ đọc như <em>google.com</em> và <em>eecs.berkeley.edu</em>, trong khi máy tính truy cập các trang web bằng địa chỉ IP như <em>172.217.4.174</em> và <em>23.195.69.108</em>. <strong>DNS</strong> là giao thức dịch giữa hai cách biểu diễn này.</p>
<img width="700px" src="applications/../assets/applications/4-02-dns-intro.png">
<h2 id="lược-sử-dns-brief-history-of-dns"><a class="header" href="#lược-sử-dns-brief-history-of-dns">Lược sử DNS (Brief History of DNS)</a></h2>
<p>Để hiểu tại sao DNS được thiết kế như hiện nay, chúng ta cần quay lại tìm hiểu lịch sử phát triển của nó.</p>
<p>Trên Internet nguyên thủy và tiền thân của nó (<strong>ARPANET</strong>), có ba ứng dụng chính. Đây là thời kỳ trước khi có <strong>World Wide Web</strong> và trình duyệt web, khi hầu hết ứng dụng chạy trên dòng lệnh.</p>
<ul>
<li><strong>Remote terminal (telnet)</strong> cho phép người dùng kết nối từ xa tới một máy khác và chạy lệnh trên máy đó. Bạn có thể đã nghe đến <strong>SSH</strong>, phiên bản hiện đại và bảo mật hơn của giao thức này.</li>
<li><strong>File transfer</strong> cho phép người dùng truyền tệp giữa máy cục bộ và máy từ xa. Bạn có thể đã nghe đến <strong>FTP (File Transfer Protocol)</strong>, giao thức tầng ứng dụng dùng để truyền tệp.</li>
<li><strong>Email</strong> cho phép người dùng trao đổi thư điện tử. Email hiện đại thường có giao diện web trong trình duyệt, nhưng ban đầu, người dùng phải gõ lệnh trong terminal như <em>mail alice@46.0.1.2</em>, trong đó <em>46.0.1.2</em> là địa chỉ IP của người nhận và <em>alice</em> là tên người dùng trên máy đó.</li>
</ul>
<p>Trong cả ba trường hợp, để thực hiện thao tác, cần chỉ định một máy chủ từ xa. Nhưng như đã đề cập, việc ghi nhớ địa chỉ IP của các máy chủ từ xa là khó và không thân thiện với người dùng.</p>
<p>Nỗ lực đầu tiên để khắc phục vấn đề này là gán một <strong>hostname</strong> (tên máy) cho mỗi địa chỉ IP. Mỗi máy tính sẽ có một tệp <em>hosts.txt</em> ánh xạ mỗi hostname tới địa chỉ IP tương ứng. Ví dụ, chúng ta có thể ánh xạ hostname <em>ucb-arpa</em> tới <em>10.0.0.78</em>, và thay vì gõ <em>mail mosher@10.0.0.78</em>, ta có thể gõ <em>mail mosher@ucb-arpa</em>.</p>
<p>Khái niệm này thực tế vẫn tồn tại đến ngày nay. Nếu bạn từng khởi chạy một máy chủ trên máy tính của mình, nó thường có địa chỉ IP <em>127.0.0.1</em> và hostname <em>localhost</em>. Nhập một trong hai vào trình duyệt sẽ cho kết quả giống nhau.</p>
<p>Chúng ta phải đảm bảo rằng <em>hosts.txt</em> giống nhau trên các máy tính khác nhau. Nếu bạn đến một máy khác và gõ <em>mail mosher@ucb-arpa</em>, bạn vẫn phải gửi thư đến đúng người. Ban đầu, tệp hosts được duy trì bởi một người duy nhất (Elizabeth Feinler) và được chia sẻ giữa người dùng bằng cách sao chép tài liệu giấy.</p>
<p>Tệp hosts dạng giấy ban đầu có thể đọc được bởi con người. Nó ánh xạ hostname tới địa chỉ, nhưng cũng bao gồm thông tin như tên đầy đủ của người dùng, các giao thức họ sử dụng (ví dụ: TCP, FTP), và thậm chí cả số điện thoại.</p>
<img width="600px" src="applications/../assets/applications/4-03-paper-hostsfile.png">
<p>Mọi người đều đồng ý (như được đề cập trong <strong>RFC606</strong> năm 1973) rằng đây là một tình huống bất hợp lý. Nếu bạn nhận được bản sao giấy của tệp, bạn phải nhập thủ công vào máy tính. Hơn nữa, vì tệp được truyền tay dưới dạng giấy, bạn có thể nhận phải bản đã lỗi thời.</p>
<p>Cải tiến đầu tiên là làm cho danh sách này có thể đọc được bởi máy tính. Khi đó, thay vì bản giấy, chúng ta có thể dùng các giao thức như FTP để chia sẻ tệp. Nhưng cách này vẫn không thể mở rộng. Không thể yêu cầu một người duy nhất duy trì tệp này mãi mãi. Ngoài ra, khi tệp trở nên lớn, việc tải xuống có thể rất chậm, và nếu kết nối mạng bị gián đoạn, bạn có thể chỉ nhận được một phần tệp.</p>
<p><strong>DNS</strong> lần đầu được đề xuất vào năm 1983 (<strong>RFC882</strong>) như một giải pháp cho các vấn đề này. Kể từ đó có một số sửa đổi, nhưng hệ thống cơ bản vẫn được sử dụng cho đến ngày nay.</p>
<p>Một thông tin thú vị: phần mềm đầu tiên để chạy máy chủ DNS trên Unix là <strong>BIND</strong> (1984, UC Berkeley), và đến nay vẫn khá phổ biến.</p>
<h2 id="mục-tiêu-thiết-kế-của-dns-dns-design-goals"><a class="header" href="#mục-tiêu-thiết-kế-của-dns-dns-design-goals">Mục tiêu thiết kế của DNS (DNS Design Goals)</a></h2>
<p>Lược sử trên cho chúng ta thấy một số mục tiêu thiết kế của DNS cần ghi nhớ:</p>
<ul>
<li><strong>DNS phải có khả năng mở rộng</strong>: Internet có số lượng máy chủ khổng lồ, và mỗi giây có một lượng lớn truy vấn được thực hiện. Các máy chủ có thể được thêm hoặc gỡ bỏ thường xuyên.</li>
<li><strong>DNS phải luôn sẵn sàng, nhẹ và nhanh</strong>: Hầu như mọi kết nối Internet đều bắt đầu bằng một truy vấn DNS để phân giải hostname thành địa chỉ IP. Do đó, DNS phải cực kỳ nhanh, nếu không mọi kết nối sẽ bị chậm lại. Đồng thời, không được tồn tại <strong>single point of failure</strong> (điểm lỗi đơn lẻ), nếu không Internet sẽ ngừng hoạt động khi xảy ra sự cố.</li>
</ul>
<h2 id="name-servers-máy-chủ-tên-miền"><a class="header" href="#name-servers-máy-chủ-tên-miền">Name servers (Máy chủ tên miền)</a></h2>
<p>Sẽ thật tuyệt nếu có một máy chủ tập trung duy nhất lưu trữ ánh xạ từ mọi tên miền tới mọi địa chỉ IP để mọi người có thể truy vấn, nhưng thật không may, không có máy chủ nào đủ lớn để lưu trữ địa chỉ IP của mọi tên miền trên Internet và đủ nhanh để xử lý khối lượng truy vấn DNS khổng lồ từ toàn thế giới. Thay vào đó, DNS sử dụng một tập hợp nhiều <strong>name server</strong> (máy chủ tên miền), là các máy chủ chuyên dụng để trả lời các truy vấn DNS.</p>
<p>Mỗi name server chịu trách nhiệm cho một <strong>zone</strong> (vùng) tên miền cụ thể, để không máy chủ nào phải lưu trữ toàn bộ tên miền trên Internet. Ví dụ, một name server chịu trách nhiệm cho zone <em>.com</em> chỉ cần trả lời các truy vấn cho tên miền kết thúc bằng <em>.com</em>. Máy chủ này không cần lưu bất kỳ thông tin DNS nào liên quan đến <em>wikipedia.org</em>. Tương tự, một name server chịu trách nhiệm cho zone <em>berkeley.edu</em> không cần lưu thông tin DNS nào liên quan đến <em>stanford.edu</em>.</p>
<p>Mặc dù có mục đích đặc biệt (trả lời truy vấn DNS), một name server cũng giống như bất kỳ máy chủ nào khác trên Internet – mỗi máy chủ đều có một tên miền dễ đọc (ví dụ: <em>a.edu-servers.net</em>) và một địa chỉ IP mà máy tính có thể đọc được (ví dụ: <em>192.5.6.30</em>). Cần lưu ý không nhầm lẫn giữa tên miền của máy chủ và zone mà nó phục vụ. Ví dụ, name server này có <em>.net</em> trong tên miền, nhưng lại trả lời các truy vấn DNS cho các tên miền <em>.edu</em>.</p>
<h2 id="cấu-trúc-phân-cấp-của-name-server-name-server-hierarchy"><a class="header" href="#cấu-trúc-phân-cấp-của-name-server-name-server-hierarchy">Cấu trúc phân cấp của Name server (Name server hierarchy)</a></h2>
<p>Bạn có thể nhận thấy hai vấn đề với thiết kế này. Thứ nhất, zone <em>.com</em> có thể nhỏ hơn toàn bộ Internet, nhưng vẫn là bất khả thi nếu một name server phải lưu trữ tất cả các tên miền kết thúc bằng <em>.com</em>. Thứ hai, nếu có nhiều name server, làm sao máy tính của bạn biết phải liên hệ với cái nào?</p>
<p><strong>DNS (Domain Name System – Hệ thống tên miền)</strong> giải quyết cả hai vấn đề này bằng cách đưa ra một ý tưởng mới: khi bạn truy vấn một name server, thay vì luôn trả về địa chỉ IP của tên miền bạn hỏi, name server đó cũng có thể hướng bạn đến một name server khác để lấy câu trả lời. Điều này cho phép các name server có zone lớn như <em>.edu</em> chuyển hướng truy vấn của bạn đến các name server có zone nhỏ hơn như <em>berkeley.edu</em>. Khi đó, name server cho zone <em>.edu</em> không cần lưu trữ bất kỳ thông tin nào về <em>eecs.berkeley.edu</em>, <em>math.berkeley.edu</em>, v.v. Thay vào đó, name server <em>.edu</em> lưu thông tin về name server <em>berkeley.edu</em> và chuyển hướng các yêu cầu cho <em>eecs.berkeley.edu</em>, <em>math.berkeley.edu</em>, v.v. đến name server <em>berkeley.edu</em>.</p>
<p>DNS sắp xếp tất cả các name server thành một cấu trúc cây phân cấp dựa trên các zone của chúng:</p>
<img width="900px" src="applications/../assets/applications/4-04-basic-tree.png">
<p><strong>Root server</strong> (máy chủ gốc) ở cấp cao nhất của cây có tất cả các tên miền trong zone của nó (zone này thường được viết là <em>.</em>). Các name server ở cấp thấp hơn của cây có các zone nhỏ hơn và cụ thể hơn.</p>
<h2 id="tra-cứu-dns-khái-niệm--dns-lookup-conceptual"><a class="header" href="#tra-cứu-dns-khái-niệm--dns-lookup-conceptual">Tra cứu DNS (Khái niệm) – DNS Lookup (Conceptual)</a></h2>
<p>Các truy vấn DNS luôn bắt đầu từ root. Root sẽ hướng truy vấn của bạn đến một trong các name server con của nó. Sau đó, bạn gửi truy vấn đến name server con, và name server đó lại chuyển hướng bạn đến một trong các name server con của nó. Quá trình này lặp lại cho đến khi bạn truy vấn đến một name server biết câu trả lời, và nó sẽ trả về địa chỉ IP tương ứng với tên miền của bạn.</p>
<p>Để chuyển hướng bạn đến một name server con, name server cha phải cung cấp zone của name server con, tên miền dễ đọc và địa chỉ IP của nó, để bạn có thể liên hệ với name server con đó để biết thêm thông tin.</p>
<p>Ví dụ, một truy vấn DNS cho <em>eecs.berkeley.edu</em> có thể diễn ra như sau (phiên bản minh họa dạng comic có tại <a href="https://howdns.works/">howdns.works</a>):</p>
<img width="900px" src="applications/../assets/applications/4-05-basic-lookup.png">
<ol>
<li>Bạn → root name server: Vui lòng cho tôi biết địa chỉ IP của <em>eecs.berkeley.edu</em>.</li>
<li>Root server → bạn: Tôi không biết, nhưng tôi có thể chuyển bạn đến một name server khác có nhiều thông tin hơn. Name server này chịu trách nhiệm cho zone <em>.edu</em>. Nó có tên miền dễ đọc là <em>a.edu-servers.net</em> và địa chỉ IP là <em>192.5.6.30</em>.</li>
<li>Bạn → name server <em>.edu</em>: Vui lòng cho tôi biết địa chỉ IP của <em>eecs.berkeley.edu</em>.</li>
<li>Name server <em>.edu</em> → bạn: Tôi không biết, nhưng tôi có thể chuyển bạn đến một name server khác có nhiều thông tin hơn. Name server này chịu trách nhiệm cho zone <em>berkeley.edu</em>. Nó có tên miền dễ đọc là <em>adns1.berkeley.edu</em> và địa chỉ IP là <em>128.32.136.3</em>.</li>
<li>Bạn → name server <em>berkeley.edu</em>: Vui lòng cho tôi biết địa chỉ IP của <em>eecs.berkeley.edu</em>.</li>
<li>Name server <em>berkeley.edu</em> → bạn: Được, địa chỉ IP của <em>eecs.berkeley.edu</em> là <em>23.185.0.1</em>.</li>
</ol>
<p>Khi đã có câu trả lời, chúng ta có thể lưu nó vào bộ nhớ đệm (<strong>cache</strong>) để không phải hỏi lại nếu cần dùng bản ghi này sau đó.</p>
<h2 id="stub-resolvers-và-recursive-resolvers"><a class="header" href="#stub-resolvers-và-recursive-resolvers">Stub Resolvers và Recursive Resolvers</a></h2>
<p>Ban đầu, máy chủ đầu cuối (ví dụ: máy tính của bạn) sẽ tự thực hiện các truy vấn DNS, liên hệ trực tiếp với từng name server.</p>
<p>Ngày nay, máy tính của bạn thường ủy quyền nhiệm vụ tra cứu DNS cho một <strong>DNS Recursive Resolver</strong> (bộ phân giải đệ quy DNS), bộ này sẽ truy vấn các name server thay cho bạn. Khi thực hiện tra cứu, <strong>DNS Stub Resolver</strong> (bộ phân giải stub DNS) trên máy tính của bạn sẽ gửi truy vấn đến recursive resolver, để resolver thực hiện toàn bộ công việc và trả lại kết quả.</p>
<img width="900px" src="applications/../assets/applications/4-06-stub-resolver.png">
<p>Làm thế nào để biết địa chỉ IP của resolver? Khi bạn kết nối Internet lần đầu, ai đó (ví dụ: ISP hoặc Router) có thể cung cấp địa chỉ của resolver. Bạn cũng có thể nhập thủ công địa chỉ của resolver mà bạn muốn sử dụng.</p>
<p>Một số resolver nổi tiếng trên Internet gồm 1.1.1.1 (do Cloudflare vận hành) và 8.8.8.8 (do Google vận hành). Chúng thường có địa chỉ IP dễ nhớ để chúng ta không cần gọi tên. Nếu không, chúng ta sẽ phải thực hiện truy vấn DNS để tìm địa chỉ IP của chúng, và mục đích của các máy chủ này là thực hiện truy vấn DNS cho chúng ta.</p>
<p>Ngoài các công ty công nghệ, các <strong>ISP (Internet Service Provider – Nhà cung cấp dịch vụ Internet)</strong> cũng vận hành các resolver như một phần của dịch vụ Internet mà họ bán cho khách hàng. (Sẽ thật tệ nếu bạn trả tiền cho dịch vụ Internet nhưng lại phải nhập địa chỉ IP thủ công vào trình duyệt.)</p>
<p>Router trong gia đình bạn cũng có thể đóng vai trò là resolver. Truy vấn DNS có thể nhanh hơn nếu bạn sử dụng một router ở gần về mặt vật lý (độ trễ giữa bạn và router thấp hơn).</p>
<p>Một lợi ích lớn của resolver là khả năng lưu đệm tốt hơn. Resolver xử lý truy vấn từ nhiều máy chủ đầu cuối khác nhau (không chỉ riêng máy tính của bạn), nên nó xây dựng được bộ nhớ đệm lớn hơn nhiều. Nếu bạn hỏi resolver về <em>eecs.berkeley.edu</em> và trước đó có ai đó đã hỏi cùng câu này gần đây, resolver có thể trả lời ngay mà không cần liên hệ thêm bất kỳ name server nào khác.</p>
<p>Lưu ý rằng mặc dù recursive resolver lưu trữ bộ nhớ đệm lớn hơn, stub resolver vẫn có thể duy trì bộ nhớ đệm riêng của mình. Một số truy vấn có thể được trả lời ngay từ cache của stub resolver mà không cần hỏi recursive resolver.</p>
<h2 id="dự-phòng-redundancy"><a class="header" href="#dự-phòng-redundancy">Dự phòng (Redundancy)</a></h2>
<p>Cho đến giờ, chúng ta vẫn đang nói về “name server <em>berkeley.edu</em>”, nhưng thực tế, mỗi zone có nhiều name server. Tất cả các name server của một zone đều giống nhau về chức năng, và mỗi name server có thể trả lời bất kỳ truy vấn nào trong zone đó.</p>
<p>Điều này đảm bảo tính sẵn sàng cho zone, và nếu một name server gặp sự cố, các server khác vẫn có thể trả lời truy vấn cho zone đó. Theo quy ước, mỗi zone phải có ít nhất hai name server, nhưng trên thực tế, hầu hết các zone sẽ có ít nhất ba.</p>
<p>Thông thường, một trong các name server được chỉ định là <strong>primary server</strong> (máy chủ chính) thực sự quản lý zone. Các server còn lại là <strong>secondary mirror server</strong> (máy chủ bản sao phụ) chỉ lưu trữ và phục vụ bản sao thông tin từ máy chủ chính.</p>
<p>Trong quá trình tra cứu DNS, name server có thể trả lời bạn: “Tôi không biết, nhưng bạn nên hỏi zone <em>.edu</em>. Zone này có 13 name server. Đây là tên miền và địa chỉ IP của từng cái.” Sau đó, bạn có thể chọn name server nào để liên hệ tiếp theo.</p>
<h2 id="dns-apis"><a class="header" href="#dns-apis"><strong>DNS APIs</strong></a></h2>
<p>Bây giờ, khi chúng ta đã có cái nhìn khái quát về <strong>DNS (Domain Name System – Hệ thống tên miền)</strong>, hãy xem nó được triển khai thực tế như thế nào.</p>
<p>Trước hết, lập trình viên sử dụng DNS để thực hiện tra cứu (<strong>lookup</strong>) như thế nào?</p>
<p>Có những <strong>API</strong> (giao diện lập trình ứng dụng) tương đối đơn giản, phổ biến và ổn định để thực hiện tra cứu DNS. API này khá giống nhau giữa các ngôn ngữ lập trình khác nhau.</p>
<p>Trong thư viện C chuẩn, hàm <em>gethostbyname(&quot;foo.com&quot;)</em> có thể được dùng để tra cứu địa chỉ IP tương ứng với <em>foo.com</em>. Tuy nhiên, hàm này chỉ hỗ trợ <strong>IPv4</strong>, nên hiện đã bị loại bỏ (deprecated), mặc dù bạn vẫn có thể bắt gặp nó trong một số mã nguồn.</p>
<p>Phiên bản cập nhật, cũng nằm trong thư viện C chuẩn, là <em>getaddrinfo(&quot;example.com&quot;, NULL, NULL, &amp;result)</em>, dùng để tra cứu địa chỉ IP của <em>example.com</em> và lưu kết quả vào cấu trúc <em>result</em>. Bạn không cần quá lo lắng về chi tiết hoặc các tham số bổ sung (ở đây được đặt là NULL). API thay thế này hỗ trợ nhiều hơn IPv4, ví dụ như <strong>IPv6</strong>.</p>
<p>Là lập trình viên, bạn không cần quan tâm đến các phức tạp của DNS như <strong>recursive resolver</strong> (bộ phân giải đệ quy) hay các name server cụ thể. Bạn chỉ cần gọi hàm thư viện chuẩn. Các hàm này thường gửi yêu cầu đến <strong>stub resolver</strong> (bộ phân giải stub) trong hệ điều hành của bạn.</p>
<h2 id="dns-sử-dụng-udp-không-phải-tcp"><a class="header" href="#dns-sử-dụng-udp-không-phải-tcp"><strong>DNS sử dụng UDP, không phải TCP</strong></a></h2>
<p>Về bản chất, DNS là một giao thức <strong>client-server</strong> (máy khách – máy chủ). Một bên (client) gửi câu hỏi, và bên kia (server) gửi câu trả lời. Client thường là máy người dùng hoặc recursive resolver, còn server thường là name server. Vậy client và server nên định dạng thông điệp như thế nào?</p>
<p>DNS sử dụng <strong>UDP (User Datagram Protocol)</strong> – gói tin best-effort, không có bắt tay TCP – để giúp DNS nhẹ và nhanh. Chúng ta không phải chờ hoàn tất <strong>3-way TCP handshake</strong>. Chúng ta cũng không cần quan tâm đến việc gói tin đến đúng thứ tự, vì truy vấn và phản hồi thường vừa vặn trong một gói UDP duy nhất.</p>
<p>Với UDP, server không cần lưu trạng thái cho mỗi kết nối (trái ngược với TCP, nơi server phải duy trì bộ đệm). Mỗi gói tin có thể được xử lý độc lập. Điều này giúp DNS nhẹ hơn, vì name server nhận rất nhiều yêu cầu, và việc mở kết nối mới cho từng yêu cầu sẽ rất tốn kém.</p>
<p>Vậy làm sao xử lý việc UDP không đáng tin cậy và gói tin có thể bị mất? Chúng ta giải quyết bằng cơ chế thử lại đơn giản: nếu không nhận được phản hồi trong một khoảng thời gian nhất định, hãy gửi lại truy vấn. Thời gian chờ (<strong>timeout</strong>) khác nhau giữa các hệ điều hành, và đôi khi khá chậm.</p>
<p>Việc UDP không đáng tin cậy và timeout chậm là lý do tại sao cần có một resolver ở gần và có thể liên hệ đáng tin cậy. Ví dụ, một resolver trong router gia đình ở gần bạn và thường khá ổn định (ít tắc nghẽn trong mạng nội bộ). Bạn cũng có thể cải thiện độ tin cậy bằng cách có nhiều resolver dự phòng (ví dụ: router gia đình và 8.8.8.8).</p>
<p>Như đã đề cập, truy vấn và phản hồi DNS thường vừa trong một gói tin. Ngoại lệ đáng chú ý là khi chúng ta <strong>transfer zone</strong> (truyền vùng dữ liệu) giữa <strong>primary name server</strong> (máy chủ tên miền chính) và <strong>secondary name server</strong> (máy chủ tên miền phụ). Secondary name server sẽ yêu cầu: “Hãy gửi cho tôi tất cả bản ghi của bạn để tôi có thể phục vụ chúng.” Phản hồi có thể rất lớn, nên các truyền vùng này thường được thực hiện qua TCP.</p>
<p>Những cải tiến gần đây của DNS đã bổ sung các tính năng bảo mật (ví dụ: ngăn kẻ tấn công thay đổi bản ghi trong quá trình truyền), điều này đôi khi cũng yêu cầu chuyển từ UDP sang TCP.</p>
<p>Hãy nhớ rằng UDP sử dụng <strong>port</strong> để hỗ trợ nhiều ứng dụng trên cùng một server. Theo quy ước, tất cả name server lắng nghe truy vấn DNS trên <strong>UDP port 53</strong>. Số port này là cố định và được biết rộng rãi để mọi người có thể liên hệ đúng cổng trên name server.</p>
<h2 id="Định-dạng-gói-tin-dns-dns-message-format"><a class="header" href="#Định-dạng-gói-tin-dns-dns-message-format"><strong>Định dạng gói tin DNS (DNS Message Format)</strong></a></h2>
<img width="800px" src="applications/../assets/applications/dns_packet.png">
<p>Trường đầu tiên là <strong>identification field</strong> (trường định danh) dài 16 bit, được chọn ngẫu nhiên cho mỗi truy vấn và dùng để ghép yêu cầu với phản hồi. Khi gửi truy vấn DNS, trường ID được điền bằng các bit ngẫu nhiên. Vì UDP là giao thức không trạng thái, phản hồi DNS phải gửi lại đúng các bit này trong trường ID để bên gửi truy vấn biết phản hồi này thuộc về truy vấn nào.</p>
<p>16 bit tiếp theo dành cho <strong>flags</strong> (cờ). Bit <strong>QR</strong> cho biết thông điệp là truy vấn (0) hay phản hồi (1). Bit <strong>RD</strong> cho biết bạn muốn resolver thực hiện truy vấn đệ quy hay chỉ trả về những gì name server nói (kể cả khi là “Tôi không biết”).</p>
<p>Về lý thuyết, bạn có thể chỉ định loại truy vấn trong flags, nhưng loại <em>IQUERY</em> đã lỗi thời, và loại <em>STATUS</em> hầu như không được định nghĩa, nên loại <em>QUERY</em> được dùng cho hầu hết mọi trường hợp.</p>
<p>Flags cũng có thể cho biết truy vấn thành công hay không (ví dụ: cờ <em>NOERROR</em> được đặt trong phản hồi nếu truy vấn thành công, cờ <em>NXDOMAIN</em> được đặt nếu truy vấn hỏi về tên miền không tồn tại).</p>
<p>Trường tiếp theo cho biết số lượng câu hỏi được hỏi (trên thực tế, luôn là 1). Ba trường tiếp theo được dùng trong thông điệp phản hồi và cho biết số lượng <strong>resource record</strong> (RR – bản ghi tài nguyên) chứa trong thông điệp. Chúng ta sẽ mô tả chi tiết từng loại RR này sau.</p>
<p>Phần còn lại của thông điệp chứa nội dung thực tế của truy vấn/phản hồi DNS. Nội dung này luôn được cấu trúc thành tập hợp các RR, mỗi RR là một cặp khóa–giá trị kèm loại dữ liệu.</p>
<p>Cụ thể, khóa của một bản ghi DNS được định nghĩa chính thức là bộ 3 <em>&lt;Name, Class, Type&gt;</em>, trong đó <em>Name</em> là dữ liệu khóa, <em>Class</em> luôn là <em>IN</em> cho Internet (trừ các truy vấn đặc biệt để lấy thông tin về DNS), và <em>Type</em> chỉ loại bản ghi. Giá trị của bản ghi DNS chứa <em>&lt;TTL, Value&gt;</em>, trong đó <em>TTL</em> là thời gian sống (tính bằng giây – thời gian bản ghi có thể được lưu trong cache), và <em>Value</em> là dữ liệu giá trị thực tế.</p>
<p>Có ba loại bản ghi chính trong DNS:</p>
<ul>
<li><strong>A type record</strong> ánh xạ tên miền sang địa chỉ IPv4 (khóa là tên miền, giá trị là địa chỉ IP).</li>
<li><strong>AAAA type record</strong> ánh xạ tên miền sang địa chỉ IPv6.</li>
<li><strong>NS type record</strong> ánh xạ zone sang tên miền (khóa là zone, giá trị là tên miền).</li>
</ul>
<p>Bạn cũng có thể gặp bản ghi loại <strong>CNAME</strong> dùng để tạo bí danh hoặc chuyển hướng. Cả tên và giá trị đều là tên miền, và bản ghi cho biết cả hai tên miền này có cùng địa chỉ IP.</p>
<p>Điểm mấu chốt: Mỗi gói DNS có một trường ID ngẫu nhiên 16 bit, một số siêu dữ liệu, và một tập hợp các resource record. Mỗi bản ghi thuộc một trong bốn loại (question, answer, authority, additional) và chứa loại, khóa, giá trị. Có các bản ghi loại A và loại NS.</p>
<h2 id="dns-lookup-triển-khai-thực-tế"><a class="header" href="#dns-lookup-triển-khai-thực-tế"><strong>DNS Lookup (Triển khai thực tế)</strong></a></h2>
<p>Bây giờ, hãy cùng đi qua một truy vấn DNS thực tế để lấy địa chỉ IP của <em>eecs.berkeley.edu</em>. Bạn có thể thử tại nhà với tiện ích <a href="https://en.wikipedia.org/wiki/Dig_(command)"><em>dig</em></a> – nhớ đặt cờ <em>+norecurse</em> để bạn có thể tự lần theo quá trình đệ quy.</p>
<p>Mỗi truy vấn DNS bắt đầu từ <strong>root server</strong>. Tên và địa chỉ IP của các root server thường được mã hóa sẵn trong resolver, dưới dạng <strong>root hints file</strong>. Bạn có thể xem một root hints file tại: <a href="https://www.internic.net/domain/named.root">https://www.internic.net/domain/named.root</a>.</p>
<p>Root server đầu tiên có tên miền <em>a.root-servers.net</em> và địa chỉ IP <em>198.41.0.4</em>. Chúng ta có thể dùng <em>dig</em> để gửi yêu cầu DNS đến địa chỉ này, hỏi địa chỉ IP của <em>eecs.berkeley.edu</em>.</p>
<hr />
<p>$ dig +norecurse eecs.berkeley.edu @198.41.0.4</p>
<p>;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 26114
;; flags: qr; QUERY: 1, ANSWER: 0, AUTHORITY: 13, ADDITIONAL: 27</p>
<p>;; QUESTION SECTION:
;eecs.berkeley.edu.          IN   A</p>
<p>;; AUTHORITY SECTION:
edu.                172800   IN   NS   a.edu-servers.net.
edu.                172800   IN   NS   b.edu-servers.net.
edu.                172800   IN   NS   c.edu-servers.net.
...</p>
<p>;; ADDITIONAL SECTION:
a.edu-servers.net.  172800   IN   A    192.5.6.30
b.edu-servers.net.  172800   IN   A    192.33.14.30
c.edu-servers.net.  172800   IN   A    192.26.92.30
...</p>
<hr />
<p>Trong <strong>phần đầu tiên</strong> của phản hồi, chúng ta có thể thấy thông tin tiêu đề (<strong>header information</strong>), bao gồm trường <strong>ID</strong> (<em>26114</em>), các cờ phản hồi (<strong>return flags</strong>) (<em>NOERROR</em>), và số lượng bản ghi được trả về trong mỗi phần.</p>
<p><strong>Phần question</strong> (<strong>question section</strong>) chứa 1 bản ghi (bạn có thể xác minh bằng cách thấy <em>QUERY: 1</em> trong phần header). Bản ghi này có <strong>key</strong> là <em>eecs.berkeley.edu</em>, <strong>type</strong> là <em>A</em>, và giá trị (<strong>value</strong>) để trống. Điều này biểu thị tên miền mà chúng ta đã truy vấn (giá trị để trống vì chúng ta chưa biết địa chỉ IP tương ứng).</p>
<p><strong>Phần answer</strong> (<strong>answer section</strong>) để trống (<em>ANSWER: 0</em> trong header), vì root server không cung cấp câu trả lời trực tiếp cho truy vấn của chúng ta.</p>
<p><strong>Phần authority</strong> (<strong>authority section</strong>) chứa 13 bản ghi. Bản ghi đầu tiên có <strong>key</strong> là <em>.edu</em>, <strong>type</strong> là <em>NS</em>, và <strong>value</strong> là <em>a.edu-servers.net</em>. Đây là root server cung cấp cho chúng ta zone và tên miền của các name server tiếp theo mà chúng ta có thể liên hệ. Mỗi bản ghi trong phần này tương ứng với một name server tiềm năng mà chúng ta có thể hỏi tiếp.</p>
<p><strong>Ghi chú:</strong> Thông thường, máy chủ có tên đứng đầu (theo thứ tự chữ cái hoặc số) là <strong>primary server</strong> (ở đây là <em>a.edu-servers.net</em>), và các máy chủ còn lại là các <strong>mirror</strong> (bản sao). Ngoài ra, việc có nhiều bản ghi cùng tên (<em>.edu</em>) là bình thường. Điều này chỉ cho biết có nhiều name server có thể trả lời truy vấn cho zone này.</p>
<p><strong>Phần additional</strong> (<strong>additional section</strong>) chứa 27 bản ghi. Bản ghi đầu tiên có <strong>key</strong> là <em>a.edu-servers.net</em>, <strong>type</strong> là <em>A</em>, và <strong>value</strong> là <em>192.5.6.30</em>. Đây là root server cung cấp cho chúng ta địa chỉ IP của name server tiếp theo bằng cách ánh xạ một tên miền từ phần authority sang một địa chỉ IP.</p>
<p>Kết hợp lại, <strong>phần authority</strong> và <strong>phần additional</strong> cung cấp cho chúng ta zone, tên miền, và địa chỉ IP của name server tiếp theo. Thông tin này được phân tách thành hai phần để duy trì cấu trúc <strong>key–value</strong> của thông điệp DNS.</p>
<p><strong>Bổ sung:</strong> <em>172800</em> là <strong>TTL (time-to-live)</strong> cho mỗi bản ghi, được đặt ở mức 172.800 giây = 48 giờ trong trường hợp này. <em>IN</em> là lớp <strong>Internet class</strong> và về cơ bản có thể bỏ qua. Đôi khi bạn sẽ thấy các bản ghi loại <em>AAAA</em>, tương ứng với địa chỉ IPv6 (trong khi bản ghi loại <em>A</em> thông thường tương ứng với địa chỉ IPv4).</p>
<p><strong>Kiểm tra nhanh:</strong> Name server nào chúng ta sẽ truy vấn tiếp theo? Làm sao chúng ta biết vị trí của name server đó? Chúng ta sẽ truy vấn name server đó về điều gì?<br />
<sub>Trả lời: Truy vấn <em>a.edu-servers.net</em>, vị trí của nó được biết nhờ các bản ghi trong phần additional. Truy vấn địa chỉ IP của <em>eecs.berkeley.edu</em> giống như trước.</sub></p>
<hr />
<p>$ dig +norecurse eecs.berkeley.edu @192.5.6.30</p>
<p>;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 36257
;; flags: qr; QUERY: 1, ANSWER: 0, AUTHORITY: 3, ADDITIONAL: 5</p>
<p>;; QUESTION SECTION:
;eecs.berkeley.edu.           IN   A</p>
<p>;; AUTHORITY SECTION:
berkeley.edu.        172800   IN   NS   adns1.berkeley.edu.
berkeley.edu.        172800   IN   NS   adns2.berkeley.edu.
berkeley.edu.        172800   IN   NS   adns3.berkeley.edu.</p>
<p>;; ADDITIONAL SECTION:
adns1.berkeley.edu.  172800   IN   A    128.32.136.3
adns2.berkeley.edu.  172800   IN   A    128.32.136.14
adns3.berkeley.edu.  172800   IN   A    192.107.102.142
...</p>
<hr />
<p>The next query also has an empty answer section, with <em>NS</em> records in the authority section and <em>A</em> records in the additional section which give us the domains and IP addresses of name servers responsible for the <em>berkeley.edu</em> zone.</p>
<hr />
<p>$ dig +norecurse eecs.berkeley.edu @128.32.136.3</p>
<p>;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 52788
;; flags: qr aa; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1</p>
<p>;; QUESTION SECTION:
;eecs.berkeley.edu.         IN   A</p>
<p>;; ANSWER SECTION:
eecs.berkeley.edu.  86400   IN   A   23.185.0.1</p>
<hr />
<p>Cuối cùng, truy vấn cuối cùng cung cấp cho chúng ta địa chỉ IP tương ứng với <em>eecs.berkeley.edu</em> dưới dạng một bản ghi loại <strong>A</strong> duy nhất trong phần <strong>answer</strong> (phần trả lời).</p>
<p>Trên thực tế, vì <strong>recursive resolver</strong> (bộ phân giải đệ quy) lưu vào bộ nhớ đệm (<strong>cache</strong>) càng nhiều câu trả lời càng tốt, nên hầu hết các truy vấn có thể bỏ qua một vài bước đầu và sử dụng các bản ghi đã được lưu trong cache thay vì phải hỏi lại các root server và name server cấp cao như <em>.edu</em> mỗi lần. Cơ chế lưu đệm giúp tăng tốc DNS vì ít gói tin hơn phải được gửi qua mạng để phân giải tên miền thành địa chỉ IP. Lưu đệm cũng giúp giảm tải yêu cầu lên các name server cấp cao nhất.</p>
<p>Bây giờ, khi chúng ta đã biết DNS được triển khai như thế nào để hỗ trợ các truy vấn, chúng ta có thể xem DNS thực sự hoạt động ra sao trong thực tế và khám phá khía cạnh kinh doanh thực tế của DNS.</p>
<h2 id="dns-authority-hierarchy-phân-cấp-quyền-quản-lý-dns"><a class="header" href="#dns-authority-hierarchy-phân-cấp-quyền-quản-lý-dns"><strong>DNS Authority Hierarchy</strong> (Phân cấp quyền quản lý DNS)</a></h2>
<p>Cấu trúc cây mà chúng ta đã vẽ thực tế thể hiện ba cách khác nhau mà DNS mang tính phân cấp.</p>
<p>Như chúng ta đã thấy, tên miền DNS có cấu trúc phân cấp. Đây là lý do tại sao tên miền của chúng ta, như <em>eecs.berkeley.edu</em>, gồm nhiều từ được phân tách bằng dấu chấm.</p>
<img width="900px" src="applications/../assets/applications/4-07-hierarchy1.png">
<p>Chúng ta cũng đã thấy rằng hạ tầng của DNS có tính phân cấp. Chúng ta có thể tổ chức các name server thành cấu trúc cây, trong đó mỗi name server chỉ biết về phần cây mà nó quản lý.</p>
<img width="700px" src="applications/../assets/applications/4-08-hierarchy2.png">
<p>Phân cấp thứ ba mà chúng ta sẽ giới thiệu là <strong>authority</strong> (quyền quản lý). Điều này cho biết ai là người định nghĩa các tên tồn tại trong cây. Ví dụ, tổ chức vận hành name server <em>.edu</em> chịu trách nhiệm cho tất cả các tên miền trong zone <em>.edu</em>. Tổ chức <em>.edu</em> có thể ủy quyền quản lý một phần zone của mình cho các đơn vị cấp dưới trong cây.</p>
<p>Ví dụ, tổ chức <em>.edu</em> có thể nói: <em>berkeley.edu</em> (và tất cả các tên miền con) thuộc zone của tôi, và tôi sẽ chuyển quyền kiểm soát phần này của zone cho tổ chức UC Berkeley. Bây giờ, chúng ta đã tạo ra một zone mới thuộc sở hữu của UC Berkeley, và tổ chức <em>.edu</em> không cần biết về các cập nhật trong zone <em>berkeley.edu</em> mới này. UC Berkeley có quyền tạo các tên miền mới trong zone của mình, hoặc có thể ủy quyền một số phần của zone cho các đơn vị cấp dưới khác.</p>
<img width="700px" src="applications/../assets/applications/4-09-hierarchy3.png">
<p>Khi vẽ cây này với cả ba khía cạnh phân cấp, chúng ta có thể nói chính xác hơn rằng mỗi nút đại diện cho một <strong>zone</strong>. Zone được định nghĩa chính thức là một đơn vị quản trị chịu trách nhiệm cho một phần của hệ thống phân cấp.</p>
<ul>
<li><strong>Về mặt tên miền</strong>: mỗi zone chứa một hoặc nhiều ánh xạ tên–IP, trong đó các tên là tên miền con của zone đó. Zone <em>eecs.berkeley.edu</em> có thể chứa tên <em>eecs.berkeley.edu</em> hoặc <em>iris.eecs.berkeley.edu</em>, nhưng không thể chứa <em>math.berkeley.edu</em>.</li>
<li><strong>Về mặt hạ tầng</strong>: zone đó được hỗ trợ bởi một hoặc nhiều name server trả lời các truy vấn về tên miền trong zone.</li>
<li><strong>Về mặt quyền quản lý</strong>: zone được kiểm soát bởi một tổ chức, tổ chức này được cấp quyền từ zone cha để quản lý các tên miền trong zone. Ví dụ, UC Berkeley, tổ chức kiểm soát zone <em>berkeley.edu</em>, có thể ủy quyền zone <em>eecs.berkeley.edu</em> cho khoa EECS.</li>
</ul>
<h2 id="dns-zones-in-practice-các-zone-dns-trong-thực-tế"><a class="header" href="#dns-zones-in-practice-các-zone-dns-trong-thực-tế"><strong>DNS Zones in Practice</strong> (Các zone DNS trong thực tế)</a></h2>
<p>Vậy trong thực tế, những tổ chức này là ai?</p>
<img width="800px" src="applications/../assets/applications/4-10-zones.png">
<p><strong>Root zone</strong> (zone gốc) được kiểm soát bởi <strong>ICANN (Internet Corporation for Assigned Names and Numbers)</strong>. ICANN chịu trách nhiệm phân chia các phần của root zone (đại diện cho toàn bộ Internet) cho các <strong>top-level domain</strong> (TLD – tên miền cấp cao nhất) cụ thể.</p>
<p>Tất cả các zone nằm ngay dưới root trong cây là các <strong>TLD</strong>. Internet ban đầu được phát triển ở Mỹ, nên các TLD đầu tiên chia Internet thành các zone dựa trên mục đích, như <em>.com</em> (thương mại), <em>.gov</em> (chính phủ), <em>.edu</em> (giáo dục), và <em>.mil</em> (quân sự). Sau đó, các TLD cho quốc gia được tạo ra, như <em>.fr</em> (Pháp) và <em>.jp</em> (Nhật Bản).</p>
<p>Lịch sử cho thấy số lượng TLD ban đầu khá ít. Gần đây, ICANN bắt đầu bán các TLD mới với giá đăng ký 150.000 USD (chưa kể chi phí duy trì hàng năm), dẫn đến sự bùng nổ các TLD mới. Tính đến năm 2024, có hơn 1.500 TLD, bao gồm các TLD dành riêng cho công ty như <em>.google</em>, và các TLD đặc biệt như <em>.travel</em> hoặc <em>.pizza</em>.</p>
<p>Mỗi TLD được vận hành bởi một tổ chức, và tổ chức đó có thể quyết định cấu trúc chia nhỏ TLD của mình. Ví dụ, TLD <em>.uk</em> được quản lý bởi Nominet, và họ quyết định chia zone <em>.uk</em> theo mục đích, tạo ra các zone như <em>.co.uk</em> (thương mại), <em>.ac.uk</em> (học thuật).</p>
<p>Các zone sâu hơn trong cây có thể được gọi theo độ sâu của chúng. <em>example.com</em> là tên miền cấp hai (<strong>second-level domain</strong>), và <em>blog.example.com</em> là tên miền cấp ba (<strong>third-level domain</strong>). Các zone này thường được kiểm soát bởi các tổ chức hoặc công ty khác nhau, những đơn vị mua zone đó từ zone cha. Khi bạn mua một zone, bạn cũng cần thông báo cho zone cha về các name server mà bạn sử dụng. Điều này cho phép zone cha chuyển hướng người dùng đến name server của bạn.</p>
<p>Các name server ở sâu hơn trong cây thường được vận hành bởi <strong>domain name registrar</strong> (nhà đăng ký tên miền). Registrar là các công ty sở hữu các zone cụ thể và cho phép người dùng lưu trữ dịch vụ của họ trên các tên miền trong zone đó. Ví dụ, tôi có thể trả phí hàng tháng để lưu trữ trang web của mình trên <em>blog.foo.com</em>. Registrar thường sẽ cung cấp dịch vụ thêm ánh xạ tên miền–IP tương ứng vào name server của họ.</p>
<p>Ngoài các registrar, các công ty như Google cũng có thể vận hành name server riêng cho các ứng dụng của họ (ví dụ: cung cấp bản ghi cho <em>maps.google.com</em>). Amazon Web Services cũng có một name server gọi là <strong>Route 53</strong>, nơi người dùng có thể thêm các bản ghi để được phục vụ.</p>
<h2 id="root-server-availability-with-anycast-tính-sẵn-sàng-của-root-server-với-anycast"><a class="header" href="#root-server-availability-with-anycast-tính-sẵn-sàng-của-root-server-với-anycast"><strong>Root Server Availability with Anycast</strong> (Tính sẵn sàng của Root Server với Anycast)</a></h2>
<p>Sẽ rất tệ nếu các root server không khả dụng. Một người có cache trống sẽ không thể thực hiện bất kỳ truy vấn DNS nào. Cuối cùng, cache của mọi người sẽ hết hạn khi TTL (time-to-live) kết thúc, và Internet sẽ ngừng hoạt động.</p>
<p>Để dự phòng, có 13 root server được đặt tại nhiều nơi trên thế giới. Chúng ta có thể tra cứu <a href="https://www.iana.org/domains/root/servers">địa chỉ IP</a> của các root server, vốn là thông tin công khai và được biết rộng rãi.</p>
<p>Con số 13 vẫn có vẻ khá ít, xét rằng toàn bộ Internet phụ thuộc vào chúng. Để cung cấp khả năng sẵn sàng cực cao, thực tế có nhiều hơn 13 root server, nhưng danh sách chỉ chứa 13 địa chỉ IP, nhờ một kỹ thuật thông minh gọi là <strong>anycast</strong>.</p>
<p>Trong kỹ thuật <strong>anycast</strong>, chúng ta triển khai nhiều bản sao (<strong>mirror</strong>) của một root server và sử dụng cùng một địa chỉ IP cho tất cả. Nếu bạn liên hệ với tên miền <em>k.root-servers.net</em> hoặc địa chỉ IP tương ứng, bạn có thể đang kết nối tới bất kỳ bản sao nào của nó.</p>
<p>Mỗi root server trong số 13 cái thực chất bao gồm nhiều bản sao. Ví dụ, <em>f.root-servers.net</em> có hơn 3.000 instance. Các bản sao này có thể được vận hành bởi các nhà cung cấp mạng khác nhau (ví dụ: Google và Cloudflare có thể hỗ trợ vận hành các root mirror).</p>
<p>Để triển khai <strong>anycast</strong>, trong quá trình hoạt động của giao thức định tuyến (<strong>routing protocol</strong>), mỗi máy chủ bản sao (<strong>mirror</strong>) sẽ thông báo cùng một địa chỉ IP. Phần còn lại của giao thức định tuyến vẫn hoạt động như bình thường. Bạn có thể nhận được nhiều thông báo về các tuyến đường (<strong>route</strong>) tới <em>k.root-servers.net</em>, và bạn có thể chấp nhận bất kỳ tuyến nào trong số đó, kết quả là các gói tin của bạn sẽ được định tuyến tới một trong các mirror. Nếu một mirror gặp sự cố, các mirror còn lại vẫn tiếp tục gửi thông báo, và bạn có thể chấp nhận một tuyến đường khác để duy trì tính sẵn sàng.</p>
<p>Anycast cũng có nghĩa là các địa chỉ IP của root server rất hiếm khi thay đổi, ngay cả khi các mirror được thêm hoặc gỡ bỏ. Do đó, <strong>root hints file</strong> (tệp gợi ý root) chứa các bản ghi cho các root name server với giá trị <strong>TTL (time-to-live)</strong> rất dài (42 ngày).</p>
<img width="500px" src="applications/../assets/applications/4-11-anycast.png">
<p>Đây là bản đồ tất cả các mirror của <em>k.root-servers.net</em>. Tất cả chúng đều quảng bá cùng một địa chỉ IP, và router của bạn có thể sẽ chọn kết nối tới mirror gần nhất. <em>k.root-servers.net</em> được vận hành bởi <strong>RIPE</strong> (tại châu Âu), điều này có thể giải thích tại sao có nhiều mirror ở châu Âu.</p>
<p>Các <strong>public resolver</strong> (bộ phân giải công cộng) như 8.8.8.8 của Google cũng có thể sử dụng anycast để đạt độ sẵn sàng cao.</p>
<h2 id="dns-for-email-dns-cho-email"><a class="header" href="#dns-for-email-dns-cho-email"><strong>DNS for Email</strong> (DNS cho Email)</a></h2>
<p>DNS có thể được sử dụng để lưu trữ và cung cấp nhiều thông tin hơn là ánh xạ tên miền–địa chỉ IP. Ví dụ, nếu bạn muốn gửi email tới một địa chỉ như <em>evanbot@berkeley.edu</em>, máy tính của bạn vẫn cần biết phải gửi các gói tin tới đâu.</p>
<p>Để phân giải địa chỉ email thành máy chủ thư (<strong>mail server</strong>), chúng ta có thể sử dụng các bản ghi loại <strong>MX (Mail Exchange)</strong>. Các bản ghi này ánh xạ tên miền như <em>berkeley.edu</em> tới máy chủ thư như <em>aspmx.l.google.com</em>. Lưu ý rằng máy chủ thư có thể nằm ở một zone khác (ví dụ: trong trường hợp này, các máy chủ thư của UC Berkeley được Google vận hành).</p>
<p>Trước đây, một địa chỉ email tương ứng với một người dùng trên một máy cụ thể, vì vậy máy chủ thư chính là máy đó. Ngày nay, bạn có thể muốn truy cập email của mình từ bất kỳ đâu. Đó là lý do tại sao các bản ghi MX ánh xạ tới các máy chủ thư như <em>aspmx.l.google.com</em>, nơi nhận thư của bạn và cho phép bạn truy cập từ bất kỳ máy tính nào.</p>
<p>Một điểm khác biệt quan trọng của bản ghi MX là giá trị của chúng còn chứa <strong>priority</strong> (độ ưu tiên). Nếu bạn nhận được nhiều bản ghi MX, tất cả đều ánh xạ cùng một tên miền tới các máy chủ thư khác nhau, bạn nên thử kết nối tới máy chủ thư có độ ưu tiên cao nhất (số nhỏ nhất) trước.</p>
<h2 id="dns-for-load-balancing-dns-cho-cân-bằng-tải"><a class="header" href="#dns-for-load-balancing-dns-cho-cân-bằng-tải"><strong>DNS for Load Balancing</strong> (DNS cho Cân bằng tải)</a></h2>
<p>Chúng ta đã thấy trong phần demo rằng name server cuối cùng trả về một bản ghi loại <strong>A</strong>, nhưng thực tế có thể nhận được nhiều bản ghi loại A, ánh xạ một tên miền tới nhiều địa chỉ IP. Không có thứ tự cố định cho các bản ghi này, và server có thể xáo trộn thứ tự trước khi trả về. Tất cả đều hợp lệ, và client có thể chọn bất kỳ bản ghi nào (thường là bản đầu tiên). Việc cung cấp nhiều địa chỉ IP hữu ích cho <strong>load balancing</strong> (cân bằng tải) và <strong>redundancy</strong> (dự phòng).</p>
<p>Name server cũng có thể trả về các bản ghi loại A khác nhau tùy thuộc vào ai gửi truy vấn và từ đâu. Điều này hữu ích nếu chúng ta muốn cân bằng tải cho một tên miền phổ biến như <em>www.google.com</em> trên nhiều máy chủ. Ví dụ, chúng ta có thể cố gắng gửi người dùng tới máy chủ gần nhất.</p>
<p>Name server lúc này cần thêm logic bổ sung (có thể là độc quyền) để quyết định bản ghi nào sẽ được gửi trong phản hồi. Name server có thể kiểm tra recursive resolver là ai. Nó cũng có thể kiểm tra client cuối là ai, mặc dù điều này yêu cầu mở rộng DNS để truy vấn của resolver bao gồm địa chỉ của client. Thậm chí, nó có thể kiểm tra vị trí địa lý của người dùng cuối, mặc dù điều này cần ánh xạ địa chỉ IP sang vị trí vật lý. Các cơ sở dữ liệu thương mại như <strong>MaxMind</strong> tồn tại để phục vụ việc ánh xạ này.</p>
<p>Cân bằng tải dựa trên vị trí địa lý của người dùng không phải lúc nào cũng hoàn hảo. Ngay cả khi biết vị trí vật lý của máy chủ và của người dùng, chúng ta vẫn phải phỏng đoán máy chủ nào gần nhất về mặt mạng. Chúng ta cũng không biết về hiệu năng (ví dụ: <strong>network bandwidth</strong> – băng thông mạng) giữa người dùng và các máy chủ khác nhau.</p>
<img width="600px" src="applications/../assets/applications/4-12-load-balance.png">
<p>Dưới đây là một thí nghiệm để xem Google thực hiện cân bằng tải theo vị trí địa lý tốt như thế nào. Chúng tôi tra cứu <em>www.google.com</em> tại San Francisco và Oregon và nhận được hai địa chỉ IP khác nhau.</p>
<p>Sau đó, chúng tôi thực hiện <strong>reverse lookup</strong> (tra cứu ngược) để ánh xạ mỗi địa chỉ IP tới một tên máy chủ cụ thể (khác nhau cho mỗi máy chủ, không phải <em>www.google.com</em>). Kết quả là một bản ghi loại <strong>PTR (Pointer)</strong>, ánh xạ địa chỉ IP sang tên (ngược lại với bản ghi loại A). Chúng ta có thể thấy rằng địa chỉ IP mà Google cung cấp cho San Francisco được ánh xạ tới một máy chủ có tên <em>sfo03s25</em>. Giả sử <em>sfo</em> là viết tắt của San Francisco, thì điều này khá chính xác.</p>
<p>Nếu xem xét độ trễ (<strong>latency</strong>), kết nối từ máy tính ở San Francisco tới địa chỉ IP được cấp cho San Francisco mất 20 ms, trong khi kết nối từ máy tính ở San Francisco tới địa chỉ IP được cấp cho Oregon mất 35 giây. Google đã làm rất tốt khi cung cấp cho máy tính ở San Francisco một máy chủ gần hơn!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="http"><a class="header" href="#http">HTTP</a></h1>
<h2 id="lược-sử-http-brief-history-of-http"><a class="header" href="#lược-sử-http-brief-history-of-http">Lược sử HTTP (Brief History of HTTP)</a></h2>
<p>Năm 1989, <strong>Tim Berners-Lee</strong> đang làm việc tại <strong>CERN</strong> (phòng thí nghiệm nghiên cứu ở Thụy Sĩ) và cần trao đổi thông tin giữa các nhà khoa học. Thời điểm đó, đã tồn tại các giao thức như <strong>FTP (File Transfer Protocol)</strong> để truyền tệp qua Internet. Tuy nhiên, một tệp thường chứa các liên kết tới những tài nguyên khác trên Internet. Mục tiêu của ông là tạo ra một giao thức và định dạng tệp cho phép liên kết các trang với nhau và truy xuất các trang đó.</p>
<p>Phiên bản đặc tả HTTP ban đầu được đánh số <strong>HTTP/0.9</strong> và phát hành năm 1991. <strong>HTTP/1.0</strong> được tiêu chuẩn hóa năm 1996, và <strong>HTTP/1.1</strong> được tiêu chuẩn hóa năm 1997. Trừ khi có ghi chú khác, phần này đề cập đến HTTP/1.1, vì đây là phiên bản phổ biến nhất hiện nay. Các phiên bản mới hơn có tồn tại (xem ở cuối phần này), nhưng các nguyên tắc cơ bản của giao thức đã giữ nguyên trong hơn 20 năm.</p>
<h2 id="kiến-thức-cơ-bản-về-http-http-basics"><a class="header" href="#kiến-thức-cơ-bản-về-http-http-basics">Kiến thức cơ bản về HTTP (HTTP Basics)</a></h2>
<p>HTTP hoạt động trên <strong>TCP (Transmission Control Protocol)</strong>. Hai bên muốn gửi dữ liệu qua HTTP sẽ bắt đầu bằng việc thiết lập kết nối TCP. Sau đó, họ có thể sử dụng cơ chế <strong>bytestream</strong> (luồng byte) của TCP để trao đổi dữ liệu có độ dài tùy ý một cách tin cậy. Các máy chủ chạy HTTP không phải lo lắng về việc gói tin bị sắp xếp lại, mất mát, v.v.</p>
<img width="900px" src="applications/../assets/applications/4-13-http-bytestream.png">
<p>HTTP là một giao thức <strong>client-server</strong>. Một bên được chỉ định là <strong>client</strong> (ví dụ: bạn – người dùng cuối), và một bên là <strong>server</strong> (ví dụ: Google, trang web ngân hàng, v.v.). Client gần như luôn chạy HTTP trong trình duyệt web (ví dụ: Firefox hoặc Chrome), mặc dù HTTP cũng có thể chạy theo cách khác (ví dụ: trực tiếp trên terminal).</p>
<p>Khi thiết lập kết nối HTTP, server phải lắng nghe các yêu cầu kết nối trên <strong>port</strong> cố định và phổ biến là 80. (<strong>HTTPS</strong>, phiên bản bảo mật hơn, sử dụng port 443). Client có thể chọn bất kỳ <strong>ephemeral port</strong> (cổng tạm thời) ngẫu nhiên nào để bắt đầu kết nối, và server sẽ gửi phản hồi về cổng đó.</p>
<p>HTTP là một giao thức <strong>request-response</strong> (yêu cầu – phản hồi). Mỗi yêu cầu từ client sẽ nhận được đúng một phản hồi tương ứng từ server.</p>
<h2 id="http-requests-yêu-cầu-http"><a class="header" href="#http-requests-yêu-cầu-http">HTTP Requests (Yêu cầu HTTP)</a></h2>
<p>Thông điệp yêu cầu HTTP được định dạng ở dạng văn bản thuần (<strong>plaintext</strong>) dễ đọc, nghĩa là bạn có thể gõ trực tiếp yêu cầu HTTP thô vào terminal. Yêu cầu gồm ba phần: <strong>method</strong> (phương thức), <strong>URL</strong>, <strong>version</strong> (phiên bản), và nội dung tùy chọn (<strong>optional content</strong>).</p>
<p>Thông điệp kết thúc bằng một ký tự xuống dòng (thực tế là <strong>CRLF</strong> – Carriage Return Line Feed), bạn có thể hình dung như việc nhấn phím Enter sau khi gõ yêu cầu HTTP trong terminal.</p>
<ul>
<li><strong>Version</strong>: chỉ định phiên bản HTTP đang sử dụng, ví dụ: HTTP/0.9, HTTP/1.0, HTTP/1.1, v.v.</li>
<li><strong>URL</strong>: xác định tài nguyên trên server. Bạn có thể hình dung URL như đường dẫn tệp mà bạn muốn lấy từ server từ xa. Ví dụ: trong URL <em>http://cs168.io/assets/lectures/lecture1.pdf</em>, chúng ta đang yêu cầu tệp <em>lecture1.pdf</em> trong thư mục <em>assets/lectures</em> trên server <em>cs168.io</em>. (Server không bắt buộc phải hoạt động theo cách này, nhưng đây là một cách hình dung hữu ích).</li>
<li><strong>Method</strong>: xác định hành động mà người dùng muốn thực hiện. Ban đầu, HTTP chỉ có một phương thức là <strong>GET</strong>, cho phép client lấy một trang cụ thể (được chỉ định bởi URL) từ server.</li>
</ul>
<p>Sau này, HTTP được mở rộng thêm các phương thức khác. Đáng chú ý là <strong>POST</strong>, cho phép client gửi dữ liệu tới server. Ví dụ: khi người dùng điền vào một biểu mẫu và nhấn Submit, dữ liệu sẽ được gửi tới server trong một yêu cầu POST.</p>
<p>Một số phương thức ít dùng hơn gồm:</p>
<ul>
<li><strong>HEAD</strong>: chỉ lấy phần header (metadata) của phản hồi, không lấy nội dung.</li>
<li><strong>PUT, CONNECT, DELETE, OPTIONS, PATCH, TRACE</strong>: mở rộng HTTP thành giao thức cho phép người dùng tương tác và thay đổi nội dung trên server, thay vì chỉ lấy nội dung như thiết kế ban đầu.</li>
</ul>
<p>Lưu ý: Với các phương thức như POST, chúng ta vẫn phải cung cấp URL để chỉ định cách diễn giải dữ liệu gửi đi. Ví dụ: trên trang web ngân hàng, gửi tên tới <em>/send-money</em> sẽ khác với gửi cùng tên đó tới <em>/request-money</em>.</p>
<ul>
<li>Với <strong>GET request</strong>, nội dung yêu cầu thường rỗng, vì chúng ta chỉ yêu cầu một trang từ server.</li>
<li>Với <strong>POST request</strong>, nội dung yêu cầu chứa dữ liệu mà chúng ta muốn gửi tới server.</li>
</ul>
<h2 id="http-responses-phản-hồi-http"><a class="header" href="#http-responses-phản-hồi-http">HTTP Responses (Phản hồi HTTP)</a></h2>
<p>Mỗi yêu cầu HTTP tương ứng với một phản hồi HTTP. Phản hồi cũng ở dạng văn bản thuần dễ đọc, nghĩa là bạn có thể đọc phản hồi HTTP thô trong terminal. Phản hồi gồm bốn phần: <strong>version</strong> (phiên bản), <strong>status code</strong> (mã trạng thái), thông điệp tùy chọn (<strong>optional message</strong>), và <strong>content</strong> (nội dung).</p>
<ul>
<li><strong>Version</strong>: chỉ định phiên bản HTTP đang sử dụng.</li>
<li><strong>Content</strong>: chứa nội dung mà server trả về, ví dụ: trang mà người dùng yêu cầu trong GET request.</li>
<li><strong>Status code</strong>: là số cho phép server thông báo kết quả xử lý yêu cầu của client. Mỗi mã trạng thái có thông điệp dễ đọc đi kèm.</li>
</ul>
<p>Các mã trạng thái được phân loại theo giá trị số:</p>
<ul>
<li><strong>100</strong> = Thông tin (<strong>Informational responses</strong>).</li>
<li><strong>200</strong> = Thành công (<strong>Successful responses</strong>).
<ul>
<li><em>200 OK</em>: yêu cầu thành công (ý nghĩa cụ thể phụ thuộc vào phương thức và ứng dụng).</li>
<li><em>201 Created</em>: yêu cầu thành công và một tài nguyên mới đã được tạo (thường thấy trong POST hoặc PUT).</li>
</ul>
</li>
<li><strong>300</strong> = Chuyển hướng (<strong>Redirection messages</strong>).
<ul>
<li><em>301 Moved Permanently</em>: tài nguyên đã được chuyển vĩnh viễn.</li>
<li><em>302 Found</em>: tài nguyên được chuyển tạm thời.<br />
Trong các trường hợp này, phản hồi thường kèm thông tin bổ sung về vị trí mới của tài nguyên (ví dụ: URL khác).</li>
</ul>
</li>
<li><strong>400</strong> = Lỗi từ phía client (<strong>Client errors</strong>).
<ul>
<li><em>401 Unauthorized</em>: client chưa được phép truy cập nội dung, nhưng có thể truy cập nếu xác thực (login).</li>
<li><em>403 Forbidden</em>: client đã xác thực, server biết danh tính nhưng vẫn không cho phép truy cập.</li>
</ul>
</li>
<li><strong>500</strong> = Lỗi từ phía server (<strong>Server errors</strong>).
<ul>
<li><em>500 Internal Server Error</em>, <em>503 Service Unavailable</em> là phổ biến. Client hầu như không thể làm gì ngoài thử lại sau.</li>
</ul>
</li>
</ul>
<p>Một số mã lỗi rất quen thuộc như <em>404 Not Found</em> (không tìm thấy tệp) và <em>503 Service Unavailable</em> (dịch vụ không khả dụng).</p>
<p>Đôi khi, việc chọn mã trạng thái phù hợp có thể không rõ ràng. Ví dụ: nếu gửi yêu cầu HTTP phiên bản 0.9 tới Google, mã phù hợp có thể là <em>505 HTTP Version Not Supported</em>, nhưng Google lại trả về <em>400 Bad Request</em>. Thông thường, mục tiêu là trả về mã lỗi thuộc đúng nhóm (ví dụ: 400 hoặc 500) để kích hoạt hành vi xử lý phù hợp từ phía client.</p>
<h2 id="http-headers"><a class="header" href="#http-headers"><strong>HTTP Headers</strong></a></h2>
<p>Nếu <strong>client</strong> (máy khách) có thêm thông tin muốn gửi tới <strong>server</strong> (máy chủ), họ có thể bao gồm <strong>metadata</strong> (siêu dữ liệu) bổ sung gọi là <strong>header</strong>. Trong <strong>HTTP/1.1</strong>, không có header nào là bắt buộc, vì vậy việc không gửi bất kỳ header nào là hợp lệ (mặc dù server hoặc client có thể mong đợi một header nhất định và báo lỗi nếu thiếu).</p>
<p>Ví dụ: <strong>Location header</strong> có thể được sử dụng trong phản hồi HTTP mã 300 để chỉ ra vị trí mới của tài nguyên.</p>
<p>Đôi khi, thông tin trong header là tùy chọn. Ví dụ: <strong>User-Agent header</strong> trong yêu cầu cho phép client thông báo cho server biết về trình duyệt hoặc chương trình client đang sử dụng (ví dụ: Firefox hoặc Chrome). Điều này có thể cho phép server xử lý yêu cầu khác nhau tùy thuộc vào giá trị của header (ví dụ: người dùng đang dùng Chrome hay đang gửi yêu cầu từ terminal).</p>
<p>Một số trường hợp khác, thông tin trong header lại rất quan trọng. Ví dụ: <strong>Content-Type</strong> cho biết payload (dữ liệu tải) là một trang HTML, hình ảnh, video, v.v. Thông tin này giúp trình duyệt biết cách hiển thị phản hồi HTTP. Nếu một server lưu trữ nhiều website, <strong>Host header</strong> có thể được dùng trong yêu cầu để chỉ định website nào cần truy cập.</p>
<p>Một số header liên quan đến <strong>request</strong> (yêu cầu). Chúng cho phép client truyền thông tin tới server. Ví dụ:</p>
<ul>
<li><strong>Accept header</strong>: cho phép client cho server biết loại nội dung mà client mong đợi (ví dụ: HTML cho trang dễ đọc với con người, JSON cho dữ liệu máy có thể phân tích).</li>
<li><strong>User-Agent header</strong>: cho biết loại client đang được sử dụng.</li>
<li><strong>Host header</strong>: cho biết host cụ thể đang được truy cập (trong trường hợp server lưu trữ nhiều website).</li>
<li><strong>Referer header</strong>: cho biết cách client đã thực hiện yêu cầu (ví dụ: nếu họ nhấp vào một liên kết từ Facebook để thực hiện yêu cầu này).</li>
</ul>
<p>Một số header liên quan đến <strong>response</strong> (phản hồi). Hãy nhớ rằng header là metadata về nội dung, không phải bản thân nội dung. Ví dụ:</p>
<ul>
<li><strong>Content-Encoding</strong>: cho biết cách diễn giải các bit của phản hồi (ví dụ: Unicode/ASCII cho văn bản dễ đọc, hoặc gzip cho tệp nén).</li>
<li><strong>Date header</strong>: cho biết thời điểm server tạo ra phản hồi.</li>
</ul>
<p>Một số header là <strong>representation header</strong>, được sử dụng trong cả request và response để mô tả cách nội dung được biểu diễn. Ví dụ: <strong>Content-Type header</strong> chỉ định loại tài liệu (ví dụ: văn bản, hình ảnh) và có thể xuất hiện trong POST request hoặc GET response. Representation header cho phép chúng ta truyền nhiều loại nội dung khác nhau qua HTTP, giúp giao thức này tổng quát và có thể được sử dụng cho nhiều loại ứng dụng.</p>
<h2 id="http-examples-ví-dụ-về-http"><a class="header" href="#http-examples-ví-dụ-về-http"><strong>HTTP Examples</strong> (Ví dụ về HTTP)</a></h2>
<p>Trong terminal, bạn có thể gõ:</p>
<hr />
<p>telnet google.com 80</p>
<hr />
<p>để kết nối tới <strong>Port 80</strong> (HTTP) trên server của Google. Terminal sau đó sẽ cho phép bạn gõ một yêu cầu HTTP thô, kèm header, như:</p>
<hr />
<p>GET / HTTP/1.1
User-Agent: robjs</p>
<hr />
<p>Đây là một GET request cho trang gốc trên server, chạy trên HTTP phiên bản 1.1. <strong>User-Agent header</strong> cho biết loại client mà chúng ta đang sử dụng.</p>
<p>Tương tự, phản hồi cũng ở dạng văn bản dễ đọc:</p>
<hr />
<p>HTTP/1.1 200 OK
Date: Sat, 16 Mar 2024 18:33:08 GMT
Content-Type: text/html; charset=ISO-8859-1
&lt;!doctype html&gt;<html lang="en"><head><meta content="Search the world's information, including webpages, images, videos and more. Google has many special features to help you find exactly what you're looking for." name="description">...</p>
<hr />
<p>Dòng <em>HTTP/1.1 200 OK</em> cho chúng ta biết phiên bản và mã trạng thái (200) cùng thông điệp tương ứng (OK). Có hai header đi kèm: ngày tạo phản hồi và loại nội dung. Sau đó, phần nội dung chứa HTML thô của trang web. Nếu mở HTML này trong trình duyệt, nó sẽ hiển thị như một trang web thực sự.</p>
<img width="800px" src="applications/../assets/applications/4-14-httpexample1.png">
<img width="800px" src="applications/../assets/applications/4-15-httpexample2.png">
<p>Dưới đây là một số ví dụ khác. Lưu ý rằng phần nội dung trống trong GET request, nhưng chứa dữ liệu trong POST và PUT request. Ngược lại, phản hồi của POST và PUT không có nội dung, nhưng phản hồi của GET thì có.</p>
<p>Mã trạng thái và header cung cấp metadata hữu ích về yêu cầu. Ví dụ: mã trạng thái <em>201 Created</em> cho biết tệp mà chúng ta gửi đã được lưu thành công trên server. Header cho biết vị trí trên server nơi tệp được lưu (và chúng ta có thể dùng vị trí đó để tải lại tệp sau này).</p>
<h2 id="speeding-up-http-with-pipelining-tăng-tốc-http-với-pipelining"><a class="header" href="#speeding-up-http-with-pipelining-tăng-tốc-http-với-pipelining"><strong>Speeding Up HTTP with Pipelining</strong> (Tăng tốc HTTP với Pipelining)</a></h2>
<p>Tải một trang duy nhất trong trình duyệt web của bạn có thể yêu cầu nhiều HTTP request. Khi bạn yêu cầu một video YouTube, trình duyệt phải gửi các yêu cầu riêng cho:</p>
<ul>
<li>Video chính</li>
<li>HTML chứa văn bản khác trên trang (ví dụ: tiêu đề video, bình luận)</li>
<li>Ảnh thu nhỏ (thumbnail) của các video liên quan<br />
… và nhiều thành phần khác. Nhiều yêu cầu trong số này có thể tới cùng một server (ví dụ: server của YouTube).</li>
</ul>
<p>Hãy nhớ rằng HTTP chạy trên TCP. Trong trường hợp đơn giản, mỗi yêu cầu riêng biệt sẽ cần bắt đầu một kết nối TCP mới với <strong>3-way handshake</strong>. Sau khi yêu cầu hoàn tất, chúng ta đóng kết nối và lại thực hiện handshake cho yêu cầu tiếp theo.</p>
<img width="900px" src="applications/../assets/applications/4-16-no-pipeline.png">
<p><strong>HTTP/1.1</strong> đã tối ưu điều này bằng cách cho phép nhiều HTTP request và response được <strong>pipelined</strong> (xếp nối) trên cùng một kết nối. Giờ đây, chúng ta không cần một kết nối TCP riêng (với handshake riêng) cho mỗi yêu cầu nữa.</p>
<img width="900px" src="applications/../assets/applications/4-17-pipeline.png">
<p>Một nhược điểm của tối ưu hóa này là server giờ phải giữ nhiều kết nối mở đồng thời hơn. Server cần có cơ chế <strong>timeout</strong> (hết thời gian chờ) cho các kết nối. Nếu server bị quá tải với các kết nối mở, client có thể gặp lỗi như <em>503 Service Unavailable</em>. Kẻ tấn công có thể lợi dụng điều này để thực hiện <strong>denial-of-service attack</strong> (tấn công từ chối dịch vụ).</p>
<h2 id="tăng-tốc-http-với-caching-các-loại-speeding-up-http-with-caching-types"><a class="header" href="#tăng-tốc-http-với-caching-các-loại-speeding-up-http-with-caching-types"><strong>Tăng tốc HTTP với Caching: Các loại</strong> (Speeding Up HTTP with Caching: Types)</a></h2>
<p>Một chiến lược khác để tăng tốc <strong>HTTP</strong> là lưu vào bộ nhớ đệm (<strong>cache</strong>) các phản hồi, nhằm tránh việc gửi các yêu cầu trùng lặp cho cùng một dữ liệu.</p>
<p>Nếu không có caching, mọi yêu cầu đều phải đi đến server.</p>
<img width="900px" src="applications/../assets/applications/4-18-nocache.png">
<p>Có ba loại HTTP cache:</p>
<ul>
<li><strong>Private cache</strong> (bộ nhớ đệm riêng) gắn liền với một client (máy khách) cụ thể kết nối tới server (ví dụ: cache trong trình duyệt của bạn). Khi cùng một người dùng yêu cầu cùng một tài nguyên lần thứ hai, họ có thể lấy tài nguyên từ cache cục bộ. Tuy nhiên, private cache không được chia sẻ giữa các người dùng.</li>
</ul>
<img width="900px" src="applications/../assets/applications/4-19-privatecache.png">
<ul>
<li><strong>Proxy cache</strong> (bộ nhớ đệm proxy) nằm trong mạng (không nằm trên máy của người dùng cuối), và được điều khiển bởi nhà vận hành mạng, không phải nhà cung cấp ứng dụng. Các cache này có thể được chia sẻ giữa nhiều người dùng, vì vậy một người dùng yêu cầu một tài nguyên lần đầu tiên có thể nhận dữ liệu từ proxy cache thay vì từ <strong>origin server</strong> (máy chủ gốc).</li>
</ul>
<img width="900px" src="applications/../assets/applications/4-20-proxycache.png">
<p><strong>Vấn đề</strong> với proxy cache là client cần một cách nào đó để được chuyển hướng tới proxy cache. Ứng dụng không vận hành proxy cache, nên origin server không nhất thiết biết về nó. Nhà vận hành mạng cần một cách để kiểm soát client và thông báo cho họ về proxy cache.</p>
<p>Một cách phổ biến là “nói dối” trong phản hồi <strong>DNS</strong> (nếu nhà mạng kiểm soát cả proxy cache và <strong>recursive resolver</strong>). Khi client tra cứu địa chỉ IP của origin server, recursive resolver có thể trả về địa chỉ IP của proxy cache (ví dụ: 1.2.3.4). Khi đó, các yêu cầu tới origin server sẽ đi tới proxy cache, nơi có thể phục vụ dữ liệu đã được cache. Nếu tài nguyên chưa có trong proxy cache, proxy cache sẽ gửi yêu cầu tới origin server, nhận dữ liệu và trả lại cho người dùng.</p>
<p>Một vấn đề khác là ứng dụng không quản lý proxy cache, nên origin server phải tin rằng proxy cache hoạt động đúng (ví dụ: tôn trọng thời hạn cache, trả dữ liệu chính xác).</p>
<ul>
<li><strong>Managed cache</strong> (bộ nhớ đệm được quản lý) nằm trong mạng và do nhà cung cấp ứng dụng điều khiển. Các máy chủ cache này được triển khai riêng biệt, không phải là origin server tạo ra nội dung. Vì được kiểm soát bởi nhà cung cấp ứng dụng, managed cache cho phép ứng dụng có nhiều quyền kiểm soát hơn.</li>
</ul>
<img width="900px" src="applications/../assets/applications/4-21-managedcache.png">
<p>Vì ứng dụng kiểm soát cả origin server và cache, họ có thể tự chuyển hướng người dùng tới cache. Ví dụ: khi bạn yêu cầu một trang video YouTube từ origin server, phản hồi có thể chứa HTML (tiêu đề video, bình luận). HTML này có thể bao gồm các liên kết để tải video và hình ảnh từ proxy cache (ví dụ: tải từ <em>static.youtube.com</em> thay vì <em>www.youtube.com</em>).</p>
<h2 id="tăng-tốc-http-với-caching-lợi-ích-và-hạn-chế-benefits-and-drawbacks"><a class="header" href="#tăng-tốc-http-với-caching-lợi-ích-và-hạn-chế-benefits-and-drawbacks"><strong>Tăng tốc HTTP với Caching: Lợi ích và Hạn chế</strong> (Benefits and Drawbacks)</a></h2>
<p>Caching mang lại lợi ích cho tất cả mọi bên:</p>
<ul>
<li><strong>Client</strong>: tải trang nhanh hơn vì tránh được các yêu cầu trùng lặp và có thể sử dụng proxy gần hơn.</li>
<li><strong>ISP</strong> (nhà cung cấp dịch vụ Internet): giảm số lượng HTTP request/response truyền qua mạng, tiết kiệm băng thông.</li>
<li><strong>Server</strong>: nhận ít yêu cầu hơn, giảm tải xử lý.</li>
</ul>
<p>Tất cả (client, ISP, server) đều quan tâm đến việc mang lại hiệu năng tốt cho client. Client muốn xem video chất lượng cao, và ISP cùng ứng dụng sẽ thu hút nhiều khách hàng hơn nếu cung cấp hiệu năng tốt. Caching giúp đạt được điều này vì client có thể nhận dữ liệu từ cache gần hơn (cục bộ hoặc trong mạng), với độ trễ (<strong>latency</strong>) thấp hơn. Ngoài ra, hãy nhớ rằng <strong>TCP throughput</strong> và <strong>RTT</strong> (round-trip time) tỉ lệ nghịch, nên RTT ngắn hơn tới server gần hơn sẽ cho throughput cao hơn. Điều này đặc biệt hữu ích cho nội dung lớn như video.</p>
<p>Khi nghĩ về caching, cần xem xét nội dung có thay đổi ở các yêu cầu sau hay không:</p>
<ul>
<li><strong>Tài nguyên tĩnh</strong>: không thay đổi giữa các lần yêu cầu (ví dụ: logo Google).</li>
<li><strong>Tài nguyên động</strong>: thay đổi tùy người yêu cầu và thời điểm yêu cầu (ví dụ: kết quả tìm kiếm Google).</li>
</ul>
<p>Một số tài nguyên tĩnh có thể được cache và phục vụ từ proxy hoặc managed cache, trong khi tài nguyên động phải được tạo mới. Ví dụ: kết quả tìm kiếm Google (HTML) cần được tạo động từ origin server, nhưng HTML đó có thể chứa liên kết tải logo Google (tĩnh) từ managed cache.</p>
<p>Thuận lợi là các tài nguyên lớn như hình ảnh và video thường là tĩnh và có thể cache mạnh tay. Nội dung động như HTML tùy biến thường nhỏ hơn. Client có thể lấy nội dung động từ origin server (xa) và dùng cache/proxy (gần) cho nội dung tĩnh.</p>
<h2 id="tăng-tốc-http-với-caching-triển-khai-implementation"><a class="header" href="#tăng-tốc-http-với-caching-triển-khai-implementation"><strong>Tăng tốc HTTP với Caching: Triển khai</strong> (Implementation)</a></h2>
<p>Để triển khai caching, chúng ta cần dùng <strong>HTTP header</strong> để mang metadata về caching (ví dụ: thời gian lưu cache). Đây là một ví dụ khác cho thấy header giúp mở rộng giao thức gốc (vốn không hỗ trợ caching).</p>
<ul>
<li>Trong <strong>HTTP/1.0</strong>, caching dùng <strong>Expires header</strong>, chỉ định thời gian dữ liệu có thể được cache.</li>
<li>Trong <strong>HTTP/1.1</strong>, giới thiệu <strong>Cache-Control header</strong> phức tạp hơn. Để tương thích, một số web server trả về cả hai header. Client HTTP/1.0 sẽ bỏ qua Cache-Control, còn client HTTP/1.1 sẽ ưu tiên Cache-Control hơn Expires.</li>
</ul>
<p><strong>Cache-Control header</strong> chỉ định loại cache nào được phép lưu dữ liệu và thời gian lưu. Ví dụ: nếu tài nguyên là động và thay đổi theo từng người dùng nhưng giữ nguyên theo thời gian cho một người dùng cụ thể, server có thể trả về:</p>
<hr />
<p>Cache-Control: private, max-age=86400</p>
<hr />
<p>Điều này nghĩa là nội dung chỉ được lưu trong cache cục bộ của người dùng (không lưu trong proxy/managed cache chia sẻ) và có thể lưu trong 1 ngày (86400 giây).</p>
<p>Một số dữ liệu không thể cache (ví dụ: nội dung động thay đổi thường xuyên). Khi đó, server có thể đặt:</p>
<hr />
<p>Cache-Control: no-store</p>
<hr />
<p>để báo rằng client và proxy không được cache nội dung.</p>
<p>Cache-Control là tùy chọn, nên không đảm bảo client sẽ đọc hoặc tuân thủ. Bạn có thể coi đây là “yêu cầu” từ server để cache dữ liệu. Điều này đặc biệt đáng lo với proxy cache (không do nhà cung cấp ứng dụng vận hành). Ngược lại, private cache do client (trình duyệt) vận hành, vi phạm chỉ ảnh hưởng tới chính họ. Managed cache do cùng nhà cung cấp ứng dụng vận hành, nên họ có thể đảm bảo tuân thủ quy tắc từ origin server.</p>
<p>Header này cũng có thể dùng cho chính sách phức tạp hơn. Ví dụ: server có thể cho phép cache dữ liệu, nhưng yêu cầu trước khi dùng dữ liệu cache, client phải gửi <strong>HTTP HEAD request</strong> để lấy lại header và xác thực dữ liệu. Nếu header cho thấy dữ liệu đã thay đổi, hãy xóa cache.</p>
<h2 id="content-delivery-networks-cdns--mạng-phân-phối-nội-dung"><a class="header" href="#content-delivery-networks-cdns--mạng-phân-phối-nội-dung"><strong>Content Delivery Networks (CDNs)</strong> – Mạng phân phối nội dung</a></h2>
<p>Trước đây, chúng ta đã thấy rằng <strong>managed cache</strong> (bộ nhớ đệm được quản lý) là một chiến lược tốt để lưu đệm và cải thiện hiệu năng cho người dùng. Không giống như <strong>private cache</strong> (bộ nhớ đệm riêng), chúng được chia sẻ giữa nhiều người dùng (ví dụ: một người dùng yêu cầu một nội dung lần đầu tiên vẫn có thể được phục vụ từ cache). Đồng thời, khác với <strong>proxy cache</strong> (bộ nhớ đệm proxy), chúng được kiểm soát bởi nhà cung cấp ứng dụng (<strong>application provider</strong>), điều này giúp ứng dụng có nhiều quyền kiểm soát hơn. Ứng dụng có thể đảm bảo rằng cache tuân thủ các quy tắc do <strong>origin server</strong> (máy chủ gốc) đặt ra, và origin server có thể kiểm soát việc người dùng được chuyển hướng tới cache nào.</p>
<p>Triển khai managed cache trên toàn mạng dẫn đến ý tưởng về <strong>Content Delivery Network (CDN)</strong> – tập hợp các máy chủ trong mạng phục vụ nội dung (ví dụ: các tài nguyên HTTP).</p>
<p>Để đạt hiệu năng tốt, chúng ta cố gắng đặt CDN gần người dùng cuối. Ở đây, “gần” có nghĩa là gần về mặt địa lý, nhưng cũng gần về mặt mạng (ít số bước nhảy hơn).</p>
<p>CDN mang lại tất cả lợi ích của caching. Người dùng nhận được nội dung với hiệu năng cao hơn vì máy chủ gần hơn. Chúng ta có thể giảm lượng <strong>network bandwidth</strong> (băng thông mạng) và hạ tầng cần thiết, vì người dùng chủ yếu gửi yêu cầu tới các máy chủ gần thay vì một origin server duy nhất (có thể ở rất xa).</p>
<p>CDN cho phép nhà cung cấp mở rộng hạ tầng máy chủ dễ dàng hơn. Với một origin server duy nhất, chúng ta phải nâng cấp máy chủ đó trở nên cực kỳ mạnh và có băng thông cực lớn. Ngược lại, với CDN, chúng ta chỉ cần bổ sung thêm nhiều máy chủ nhỏ trên khắp Internet.</p>
<p>CDN cũng cung cấp khả năng <strong>redundancy</strong> (dự phòng) tốt hơn cho nhà cung cấp. Nếu một origin server gặp sự cố, dịch vụ có thể bị gián đoạn. Ngược lại, với CDN, nếu một máy chủ gặp sự cố, người dùng vẫn có thể được chuyển hướng tới các máy chủ khác.</p>
<h2 id="triển-khai-cdn-cdn-deployment"><a class="header" href="#triển-khai-cdn-cdn-deployment"><strong>Triển khai CDN</strong> (CDN Deployment)</a></h2>
<p>Hãy nhớ lại mô hình Internet: Yêu cầu của client được chuyển tiếp qua các <strong>WAN router</strong> (do ISP sở hữu) cho đến khi đến một <strong>peering location</strong> (điểm kết nối ngang hàng). Sau đó, yêu cầu đi tới peering location trong mạng của nhà cung cấp ứng dụng. Yêu cầu tiếp tục đi qua mạng WAN của ứng dụng cho đến khi đến <strong>datacenter network</strong> (mạng trung tâm dữ liệu), nơi đặt origin server.</p>
<p>Nếu không triển khai CDN, mọi yêu cầu đều phải đến origin server. Điều này dẫn đến <strong>latency</strong> (độ trễ) cao nhất (so với các phương án có CDN), hiệu năng thấp nhất, yêu cầu nhiều băng thông nhất, và buộc origin server phải mở rộng để xử lý mọi yêu cầu.</p>
<img width="900px" src="applications/../assets/applications/4-21-cdn1.png">
<p>Một lựa chọn tốt hơn là triển khai một số máy chủ CDN ở rìa mạng của nhà cung cấp ứng dụng. Ví dụ: nếu mạng của Google kết nối ngang hàng với mạng ISP ở New York, chúng ta có thể đặt một số CDN tại đó.</p>
<p>Khi đó, lượng băng thông truyền qua mạng của nhà cung cấp ứng dụng giảm đáng kể. Origin server chỉ cần gửi video tới CDN một lần, và CDN có thể phục vụ video đó cho nhiều người dùng. Mạng ứng dụng không còn cần mở rộng mạng WAN của mình.</p>
<p>Ngoài ra, như đã thấy, chúng ta có thể mở rộng bằng cách thêm nhiều CDN thay vì nâng cấp một origin server duy nhất. Chúng ta cũng có thêm khả năng dự phòng.</p>
<img width="900px" src="applications/../assets/applications/4-22-cdn2.png">
<p>Chúng ta có thể làm tốt hơn nữa bằng cách đẩy caching sâu hơn vào trong mạng. Lúc này, ứng dụng triển khai máy chủ ngay bên trong mạng của ISP.</p>
<img width="900px" src="applications/../assets/applications/4-23-cdn3.png">
<p>Tại sao ISP lại đồng ý cho ứng dụng triển khai CDN trong mạng của họ? Thực tế, điều này mang lại lợi ích cho cả hai bên. Khách hàng của ISP sẽ có hiệu năng tốt hơn vì họ có thể sử dụng CDN gần hơn. Ngoài ra, lưu lượng lớn giữa người dùng và CDN giờ đây được giữ hoàn toàn trong mạng của ISP. Điều này có nghĩa là ISP cần ít băng thông hơn ở kết nối peering giữa ISP và ứng dụng (vì nội dung chỉ được gửi một lần qua kết nối đó).</p>
<p>Trên thực tế, ISP và CDN thường hợp tác để triển khai máy chủ. Ví dụ: ứng dụng cung cấp máy chủ miễn phí, và ISP kết nối máy chủ vào mạng miễn phí. Trong một số trường hợp, ISP và CDN cần đàm phán về khoản thanh toán (CDN trả cho ISP hoặc ISP trả cho CDN), tùy thuộc vào vị trí triển khai máy chủ trong mạng và chi phí máy chủ cũng như kết nối. Tuy nhiên, cả hai bên đều có lợi ích trong việc triển khai các máy chủ này.</p>
<p>Chúng ta có thể tiến xa hơn nữa, nhưng cuối cùng sẽ gặp giới hạn chi phí – lợi ích. Trong trường hợp cực đoan, chúng ta có thể triển khai CDN tại từng hộ gia đình, nhưng chi phí có thể vượt quá lợi ích. Đặc biệt, CDN hoạt động tốt nhất khi có nhiều người dùng sử dụng nó. Cache tập thể sẽ lớn hơn, và một điểm triển khai có thể phục vụ nhiều người dùng.</p>
<img width="900px" src="applications/../assets/applications/4-24-cdn4.png">
<p>Nói chung, luôn tồn tại sự đánh đổi giữa chi phí bổ sung CDN mới và số tiền tiết kiệm được từ việc giảm xây dựng băng thông. Trên thực tế, CDN tồn tại trong mạng ISP vì chúng vẫn mang lại lợi nhuận khi lắp đặt.</p>
<p>Báo cáo năm 2023 của <strong>Sandvine</strong> (công ty giám sát gói tin) cho thấy 15% tổng lưu lượng Internet đến từ Netflix, 11,4% từ YouTube, và 4,5% từ Disney+. Nếu một ISP cài đặt máy chủ cho chỉ ba ứng dụng này trong mạng của họ, họ có thể giảm tới 25% dung lượng mạng cần xây dựng.</p>
<p>Các nhà cung cấp ứng dụng lớn như Google, Netflix, Amazon và Facebook triển khai CDN cả trong mạng của họ và trong mạng ISP.</p>
<p>Nếu bạn là nhà cung cấp ứng dụng, có thể bạn không phải là “ông lớn” công nghệ như Google hay Amazon, nhưng bạn vẫn muốn nội dung của mình được phân phối qua CDN để đạt hiệu năng tốt. Các ứng dụng nhỏ hơn có thể không đủ khả năng tự triển khai CDN. Tuy nhiên, các công ty như Cloudflare, Akamai và Edgio đã triển khai CDN, và bạn có thể trả phí để họ phân phối nội dung của bạn trên CDN sẵn có của họ. Các nhà cung cấp CDN này cũng triển khai hạ tầng cả trong mạng của họ và trong mạng ISP.</p>
<p>CDN cũng có thể được ISP sử dụng, vì bản thân ISP cũng có thể có ứng dụng phục vụ nội dung. Khi bạn trả tiền cho dịch vụ Internet, ISP có thể cung cấp thêm dịch vụ TV (truyền hình trực tiếp hoặc video theo yêu cầu). Các ISP này triển khai CDN riêng để phục vụ nội dung TV đó một cách hiệu quả.</p>
<p>Về cơ bản, các máy chủ trong CDN giống như bất kỳ máy chủ nào khác trên Internet cung cấp nội dung, mặc dù chúng thường được tối ưu hóa cao để lưu trữ và phân phối lượng lớn nội dung. Một số máy chủ có thể được tối ưu để lưu trữ và phục vụ lượng lớn dữ liệu, trong khi một số khác được tối ưu để phục vụ nhanh các phần nội dung nhỏ cho số lượng lớn khách hàng.</p>
<h2 id="directing-clients-to-caches-chuyển-hướng-client-tới-các-bộ-nhớ-đệm"><a class="header" href="#directing-clients-to-caches-chuyển-hướng-client-tới-các-bộ-nhớ-đệm"><strong>Directing Clients to Caches</strong> (Chuyển hướng client tới các bộ nhớ đệm)</a></h2>
<p>Trong một <strong>CDN (Content Delivery Network – Mạng phân phối nội dung)</strong>, có nhiều máy chủ khác nhau trên khắp Internet cùng cung cấp một nội dung giống nhau. Vậy làm thế nào để client (máy khách) biết nên kết nối tới máy chủ nào?</p>
<p>Một số kỹ thuật từ <strong>DNS (Domain Name System)</strong> cũng có thể áp dụng cho CDN. Chúng ta có thể sử dụng <strong>anycast</strong>, trong đó nhiều máy chủ quảng bá cùng một tiền tố địa chỉ IP (<strong>IP prefix</strong>). Điều này cho phép thuật toán định tuyến tìm đường tốt nhất tới bất kỳ máy chủ nào trong số đó.</p>
<img width="800px" src="applications/../assets/applications/4-25-anycast1.png">
<p>Một vấn đề của anycast là với các kết nối dài hạn. Giả sử client đang có một kết nối <strong>TCP</strong> đang hoạt động với một trong các máy chủ. Trong quá trình kết nối, một liên kết trung gian trong mạng bị lỗi. Vì tất cả các máy chủ đều có cùng địa chỉ IP, nên từ góc nhìn của router trung gian, việc chuyển tiếp tới bất kỳ máy chủ nào cũng hợp lệ. Router trung gian có thể bắt đầu chuyển tiếp gói tin tới một máy chủ khác (có cùng địa chỉ IP). Tuy nhiên, kết nối TCP ban đầu là với máy chủ cũ, và máy chủ mới này không thể tiếp tục kết nối đó.</p>
<p>Lưu ý rằng vấn đề này không xảy ra khi chúng ta dùng anycast trong DNS, vì các kết nối DNS rất ngắn (thường chỉ là một gói UDP duy nhất).</p>
<img width="800px" src="applications/../assets/applications/4-26-anycast2.png">
<p>Chúng ta cũng có thể dùng DNS để <strong>load-balance</strong> (cân bằng tải). Khác với anycast, các máy chủ lúc này có địa chỉ IP khác nhau, nhưng vẫn cùng một tên miền. Khi client truy vấn ánh xạ tên miền–IP, <strong>DNS name server</strong> có thể trả về địa chỉ IP khác nhau tùy theo vị trí của client.</p>
<p>Cách tiếp cận dựa trên DNS này không gặp vấn đề với kết nối dài hạn như anycast, vì các máy chủ có địa chỉ khác nhau. Router sẽ không đột ngột chuyển gói tin sang máy chủ khác.</p>
<p>Một vấn đề của cách tiếp cận dựa trên DNS là thiếu tính chi tiết (<strong>granularity</strong>). Ví dụ cực đoan: giả sử tất cả người dùng trong ISP Comcast dùng chung một <strong>recursive resolver</strong>. Điều này có nghĩa là tất cả gửi truy vấn DNS tới resolver này, và resolver sẽ gửi truy vấn tới <strong>application name server</strong>. Application name server chỉ thấy rằng truy vấn đến từ Comcast, và phải trả về một địa chỉ IP duy nhất cho Comcast. Kết quả là mọi người dùng trong mạng Comcast sẽ dùng cùng một máy chủ, ngay cả khi họ ở khắp nơi trên thế giới.</p>
<img width="800px" src="applications/../assets/applications/4-27-dns-loadbalance.png">
<p>Một cách tiếp cận mạnh mẽ hơn anycast hoặc DNS là <strong>application-level mapping</strong> (ánh xạ ở tầng ứng dụng). Khi origin server nhận một yêu cầu HTTP, các liên kết trong phản hồi có thể trỏ tới các máy chủ khác nhau (ví dụ: <em>static1.google.com</em> hoặc <em>static2.google.com</em>, hai máy chủ ở các vị trí khác nhau), tùy thuộc vào nơi yêu cầu xuất phát. Hoặc, origin server có thể trả về mã trạng thái HTTP 300-level để chuyển hướng người dùng tới máy chủ phù hợp.</p>
<p>Cách tiếp cận ở tầng ứng dụng này không gặp vấn đề về granularity như DNS, vì ứng dụng có thể thấy địa chỉ của client trong yêu cầu HTTP. Nó cũng không gặp vấn đề của anycast, vì các máy chủ có thể có địa chỉ IP khác nhau.</p>
<p>Tuy nhiên, giống như trong cân bằng tải dựa trên DNS, ứng dụng vẫn cần một cách để ước lượng máy chủ gần nhất với client (gần có thể là về mặt địa lý hoặc dựa trên cấu trúc mạng).</p>
<p>Một lợi ích của application-level mapping là có thể tinh chỉnh tùy theo nội dung. Ví dụ: các video phổ biến có thể được triển khai trên nhiều máy chủ, cho phép mọi client lấy video từ máy chủ gần nhất. Ngược lại, các video ít phổ biến hơn có thể chỉ được triển khai trên ít máy chủ, buộc người dùng phải kết nối xa hơn để lấy nội dung.</p>
<h2 id="newer-http-versions-các-phiên-bản-http-mới-hơn"><a class="header" href="#newer-http-versions-các-phiên-bản-http-mới-hơn"><strong>Newer HTTP Versions</strong> (Các phiên bản HTTP mới hơn)</a></h2>
<p>Khi Internet phát triển, <strong>HTTP</strong> bắt đầu được sử dụng bởi ngày càng nhiều ứng dụng, vì đây là một giao thức rất dễ tổng quát hóa.</p>
<p>Cuối cùng, vấn đề bảo mật của HTTP trở nên đáng lo ngại hơn. Một máy chủ ngân hàng chạy HTTP có lẽ không muốn thông tin được gửi dưới dạng văn bản thuần (<strong>plaintext</strong>) qua mạng, nơi các router trung gian hoặc kẻ tấn công có thể đọc được.</p>
<p><strong>HTTPS</strong> là một phần mở rộng của HTTP bổ sung bảo mật. Một giao thức gọi là <strong>TLS (Transport Layer Security)</strong> được xây dựng trên TCP, nơi người dùng trao đổi khóa bí mật và mã hóa thông điệp trước khi gửi qua bytestream. HTTPS có cùng giao thức cơ bản, nhưng chạy trên TLS (TLS chạy trên TCP), thay vì trực tiếp trên TCP không bảo mật. Trong những năm gần đây, đã có xu hướng nâng cấp website lên HTTPS, và tính đến năm 2024, hơn 85% website mặc định sử dụng HTTPS.</p>
<p><strong>HTTP/2.0</strong> được giới thiệu năm 2015, là bản sửa đổi lớn đầu tiên của giao thức kể từ năm 1997. Mục tiêu chính là cải thiện hiệu năng bằng cách giảm độ trễ và tăng tốc độ tải trang.</p>
<p>HTTP/2.0 giới thiệu <strong>server push</strong> (đẩy từ phía máy chủ), cho phép server gửi phản hồi ngay cả khi client chưa gửi yêu cầu. Điều này cho phép server dự đoán và chủ động gửi nội dung mà người dùng có thể cần, mà không phải chờ yêu cầu. Ví dụ: khi tìm kiếm Google, HTML kết quả được trả về. Sau đó, trình duyệt phân tích HTML, nhận ra cần logo Google và gửi yêu cầu HTTP khác. Với HTTP/2.0, server có thể gửi logo Google ngay lập tức, không cần chờ yêu cầu.</p>
<p>HTTP/2.0 còn có các cải tiến hiệu năng khác:</p>
<ul>
<li><strong>Header compression</strong> (nén header) để tiết kiệm dung lượng.</li>
<li><strong>Request/response prioritization</strong> (ưu tiên yêu cầu/phản hồi) để nội dung quan trọng (ví dụ: văn bản kết quả tìm kiếm) được gửi trước nội dung ít quan trọng (ví dụ: logo Google).</li>
<li><strong>Multiplexing</strong> hiệu quả hơn: nhiều yêu cầu đồng thời được xử lý thông minh, tránh việc phản hồi nhỏ bị chặn bởi phản hồi lớn.</li>
</ul>
<p>HTTP/2.0 được hỗ trợ rộng rãi bởi cả client (trình duyệt hiện đại) và server (ví dụ: CDN).</p>
<p><strong>HTTP/3.0</strong> được giới thiệu năm 2022 (không lâu sau HTTP/2.0, so với khoảng cách giữa 1.1 và 2.0). Ngữ nghĩa giống HTTP/2.0, nhưng thay đổi giao thức tầng vận chuyển (<strong>transport layer protocol</strong>). Thay vì chạy trên bytestream của TCP, HTTP/3.0 chạy trên một giao thức vận chuyển mới gọi là <strong>QUIC (Quick UDP Connections)</strong>, được thiết kế riêng để hoạt động tốt với HTTP/3.0. QUIC được Google phát triển và chuẩn hóa tại <strong>IETF</strong>.</p>
<p>HTTP/3.0 là một ví dụ về việc cố ý từ bỏ một trong những nguyên tắc cốt lõi của mạng máy tính (<strong>layering</strong>) để đổi lấy hiệu quả cao hơn. Bằng cách cho phép thiết kế tùy chỉnh cả giao thức tầng vận chuyển (QUIC) và tầng ứng dụng (HTTP/3.0), chúng ta có thể tối ưu để cả hai hoạt động tốt cùng nhau.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ethernet"><a class="header" href="#ethernet">Ethernet</a></h1>
<h2 id="mạng-cục-bộ"><a class="header" href="#mạng-cục-bộ">Mạng Cục bộ</a></h2>
<p>Trong phần này, chúng ta sẽ tập trung vào những gì xảy ra bên trong một <em>local area network (mạng cục bộ)</em>, chẳng hạn như mạng trong nhà bạn với máy tính và <em>router (bộ định tuyến)</em> của bạn. Điều này trái ngược với các <em>wide-area networks (mạng diện rộng)</em> mà chúng ta đã tìm hiểu cho đến nay, vốn trải dài trên những khoảng cách lớn hơn.</p>
<p>Cụ thể, chúng ta sẽ xem xét việc <em>forwarding (chuyển tiếp)</em> và <em>addressing (đánh địa chỉ)</em> ở <em>Layer 2 (Lớp 2)</em>. Chúng ta sẽ phải định nghĩa cách các <em>packet (gói tin)</em> được chuyển tiếp từ một <em>host (máy trạm)</em> cục bộ đến một <em>router</em>. Chúng ta cũng sẽ thấy cách các <em>host</em> trong cùng một mạng cục bộ có thể trao đổi thông điệp ở <em>Layer 2</em>, mà không cần liên hệ với <em>router</em> ở các lớp cao hơn. Giao thức chiếm ưu thế ở <em>Layer 2</em> là <em>Ethernet</em>.</p>
<img width="400px" src="end-to-end/../assets/end-to-end/5-001-layer2.png">
<h2 id="kết-nối-các-host-cục-bộ"><a class="header" href="#kết-nối-các-host-cục-bộ">Kết nối các Host Cục bộ</a></h2>
<p>Cho đến nay, chúng ta đã vẽ các liên kết kết nối chính xác hai máy. Trong mạng cục bộ, chúng ta đã vẽ một đường nối mỗi <em>host</em> với <em>router</em>.</p>
<p>Thực tế, một sợi dây duy nhất có thể được sử dụng để kết nối nhiều máy. Trong mạng cục bộ, các <em>host</em> và <em>router</em> đều có thể nằm trên cùng một dây. Chúng ta có thể trừu tượng hóa hơn nữa và lưu ý rằng ở <em>Layer 2</em>, <em>router</em> thực sự chỉ là một máy như bất kỳ máy nào khác (chỉ là nó chạy các giao thức định tuyến ở các lớp cao hơn). Cuối cùng, sợi dây không thực sự quan tâm các máy được kết nối đang làm gì với dữ liệu chúng trao đổi.</p>
<img width="700px" src="end-to-end/../assets/end-to-end/5-002-linking-machines.png">
<p>Cách tốt nhất để nối dây các máy tính trong một mạng cục bộ là gì? Trước đây, khi lần đầu giới thiệu về định tuyến, chúng ta đã nghĩ đến việc sử dụng <em>mesh topology (cấu trúc liên kết lưới)</em> để kết nối tất cả các cặp máy tính trên thế giới. Chúng ta cũng đã xem xét việc sử dụng một sợi dây duy nhất để kết nối tất cả các máy tính. Cuối cùng, chúng ta quyết định rằng đối với một mạng toàn cầu, cả hai cách tiếp cận đều không thực tế, và chúng ta cần giới thiệu các <em>router</em>.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-003-mesh-bus.png">
<p>Chúng ta có thể xem xét lại các cấu trúc liên kết này trong mạng cục bộ. Một <em>mesh topology</em> vẫn khá không thực tế. Nếu một <em>host</em> mới tham gia, chúng ta sẽ phải thêm một dây nối nó với mọi <em>host</em> khác. Tuy nhiên, một <em>bus topology (cấu trúc liên kết bus)</em>, nơi chúng ta kết nối tất cả các máy tính dọc theo một sợi dây duy nhất, lại khá phổ biến và thực tế trong một mạng cục bộ.</p>
<p><em>Bus topology</em> một dây giới thiệu khái niệm về <em>shared media (môi trường truyền dẫn chia sẻ)</em>. Khi chúng ta vẽ các liên kết nối hai máy, chỉ có hai máy tính đó sử dụng liên kết đó để giao tiếp. Bây giờ, một <em>packet</em> từ A đến C, và một <em>packet</em> từ B đến D, có thể ở trên dây cùng một lúc, và tín hiệu điện trên dây đó không thể chứa cả hai <em>packet</em> đồng thời.</p>
<img width="600px" src="end-to-end/../assets/end-to-end/5-004-collision.png">
<p>Để tương tự, hãy xem xét nhiều người trong một cuộc gọi nhóm, chia sẻ một đường dây điện thoại duy nhất: Bất kỳ hai người nào cũng có thể nói chuyện với nhau, nhưng bạn không thể có hai cuộc trò chuyện đồng thời, nếu không không ai hiểu được điều gì đang được nói.</p>
<p>Chúng ta đã vẽ các liên kết như những sợi dây có tín hiệu điện trên đó cho đơn giản, nhưng thực tế, công nghệ liên kết có thể sử dụng các <em>shared media</em> khác. Ví dụ, trong một công nghệ liên kết không dây, tất cả các <em>host</em> được kết nối bởi liên kết đều chia sẻ cùng một phần của phổ điện từ.</p>
<h2 id="giao-tiếp-qua-môi-trường-truyền-dẫn-chia-sẻ-các-phương-pháp-phối-hợp"><a class="header" href="#giao-tiếp-qua-môi-trường-truyền-dẫn-chia-sẻ-các-phương-pháp-phối-hợp">Giao tiếp qua Môi trường Truyền dẫn Chia sẻ: Các phương pháp Phối hợp</a></h2>
<p>Trong một mạng có môi trường truyền dẫn chia sẻ, có nguy cơ các lần truyền từ các nút khác nhau có thể gây nhiễu hoặc <em>collision (xung đột)</em> với nhau. Nếu hai máy tính cố gắng truyền dữ liệu đồng thời, tín hiệu của chúng sẽ chồng chéo và gây nhiễu. Bên nhận có thể không giải mã được tín hiệu, và họ không thể biết ai đã gửi tín hiệu. Để giải quyết vấn đề này, chúng ta cần một <em>multiple access protocol (giao thức đa truy cập)</em> để đảm bảo rằng nhiều máy tính có thể chia sẻ liên kết và truyền qua nó.</p>
<img width="700px" src="end-to-end/../assets/end-to-end/5-005-multiple-access-taxonomy.png">
<p>Một loại phương pháp khả thi là phân bổ một phần tài nguyên cố định cho mỗi nút trên liên kết. Có hai cách chúng ta có thể xem xét để phân chia tài nguyên. Trong <em>frequency-division multiplexing (ghép kênh phân chia theo tần số)</em>, chúng ta phân bổ một dải tần số khác nhau cho mỗi máy tính. (Hãy xem xét đài AM/FM hoặc truyền hình quảng bá, chúng chia tần số thành các kênh.) Trong <em>time-division multiplexing (ghép kênh phân chia theo thời gian)</em>, chúng ta chia thời gian thành các khe cố định và phân bổ một khe cho mỗi nút được kết nối.</p>
<p>Việc phân bổ tài nguyên cố định có một số nhược điểm. Chỉ có một lượng tần số/thời gian hạn chế để phân phối. Ngoài ra, không phải ai cũng có điều gì đó để nói mọi lúc, vì vậy tần số/thời gian chúng ta phân bổ có thể không được sử dụng trong phần lớn thời gian. Cách tiếp cận này lãng phí, bởi vì nó giới hạn các máy tính vào dải được phân bổ cụ thể của chúng, ngay cả khi các dải khác có thể không được sử dụng.</p>
<p>Thay vì phân bổ cố định, một loại phương pháp khác dựa trên việc các nút thay phiên nhau, không có bất kỳ sự phân bổ cố định nào. Trong loại này, chúng ta đang phân vùng động theo thời gian, để các nút chỉ sử dụng thời gian chúng cần trong lượt của mình, không có thời gian lãng phí. Có hai cách chúng ta có thể xem xét để các nút thay phiên nhau.</p>
<p>Trong một <em>polling protocol (giao thức thăm dò)</em>, một điều phối viên tập trung quyết định khi nào mỗi nút được kết nối được phép nói. Điều phối viên đi đến từng nút một và hỏi xem nút đó có điều gì muốn nói không. Nếu nút nói có, điều phối viên cho phép nút nói trong một khoảng thời gian. Nếu nút nói không, điều phối viên ngay lập tức chuyển sang nút tiếp theo, và nút đó không lãng phí bất kỳ tài nguyên nào. Bluetooth là một giao thức trong thế giới thực sử dụng ý tưởng này.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-006-polling.png">
<p>Cách khác để cho các nút thay phiên là <em>token passing</em>. Thay vì có một điều phối viên tập trung, chúng ta có một thẻ bài ảo có thể được truyền giữa các nút, và chỉ nút có thẻ bài mới được phép nói. Nếu một nút có điều gì muốn nói, nó sẽ giữ thẻ bài trong khi truyền, sau đó chuyển nó cho nút tiếp theo. Nếu một nút không có gì để nói vào lúc đó, nó ngay lập tức chuyển thẻ bài cho nút tiếp theo. IBM Token Ring và FDDI là những ví dụ thực tế về các giao thức sử dụng ý tưởng này.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-007-token.png">
<p>Một nhược điểm của các phương pháp dựa trên lượt này là sự phức tạp. Chúng ta phải triển khai một số hình thức giao tiếp giữa các nút, điều này có thể trở nên phức tạp. Trong <em>token passing</em>, chúng ta có thể cần một kênh tần số chuyên dụng để các nút có thể truyền thẻ bài một cách đáng tin cậy cho nhau. Chúng ta cũng có thể phải đối phó với các phức tạp như hai nút cùng nghĩ rằng chúng có thẻ bài và gây ra một <em>collision</em>. Trong một <em>polling protocol</em>, chúng ta cần chỉ định một điều phối viên trung tâm để giao tiếp với các nút, và triển khai một cách để điều phối viên nói chuyện với các nút. Trong Bluetooth, điện thoại thông minh của bạn có thể là điều phối viên trung tâm nói chuyện với các thiết bị phụ, nhưng trong các mạng khác, có thể không rõ ai là điều phối viên.</p>
<h2 id="giao-tiếp-qua-môi-trường-truyền-dẫn-chia-sẻ-các-phương-pháp-truy-cập-ngẫu-nhiên"><a class="header" href="#giao-tiếp-qua-môi-trường-truyền-dẫn-chia-sẻ-các-phương-pháp-truy-cập-ngẫu-nhiên">Giao tiếp qua Môi trường Truyền dẫn Chia sẻ: Các phương pháp Truy cập Ngẫu nhiên</a></h2>
<p>Một loại phương pháp thứ ba, bên cạnh phân bổ cố định hoặc thay phiên nhau, là <em>random access (truy cập ngẫu nhiên)</em>. Trong phương pháp này, chúng ta chỉ cho phép các nút nói bất cứ khi nào chúng có điều gì muốn nói, và giải quyết các <em>collision</em> khi chúng xảy ra. Các nút không phối hợp với nhau, và chỉ gửi dữ liệu bất cứ khi nào chúng có gì đó để gửi.</p>
<p>Một lợi ích lớn của các giao thức <em>random access</em> là sự đơn giản. Không giống như các phương pháp dựa trên lượt, chúng ta không cần triển khai giao tiếp giữa các nút.</p>
<p>Khi bên nhận nhận được một <em>packet</em>, nó sẽ trả lời bằng một <em>ack (gói tin xác nhận)</em>. Nếu hai nút gửi dữ liệu đồng thời, <em>collision</em> sẽ làm hỏng các <em>packet</em> của chúng, vì vậy không có <em>ack</em> nào được gửi. Nếu bên gửi không thấy <em>ack</em>, nó sẽ đợi một khoảng thời gian ngẫu nhiên và gửi lại. Việc đợi một khoảng thời gian ngẫu nhiên, thay vì gửi lại ngay lập tức, giúp chúng ta tránh được các <em>collision</em> khi các <em>packet</em> được gửi lại.</p>
<p>Giao thức <em>random access</em> ngây thơ là &quot;thô lỗ&quot; vì các nút bắt đầu nói bất cứ khi nào chúng muốn, và giải quyết <em>collision</em> sau đó. Một biến thể &quot;lịch sự&quot; hơn của giao thức này được gọi là <em>Carrier Sense Multiple Access (CSMA) (Đa truy cập nhận biết sóng mang)</em>. Các nút lắng nghe <em>shared media</em> trước để xem có ai đang nói không, và chỉ bắt đầu nói khi nó yên tĩnh. Ở đây, &quot;lắng nghe&quot; đề cập đến việc cảm nhận một tín hiệu trên dây.</p>
<p>Lưu ý rằng <em>CSMA</em> không giúp chúng ta tránh được tất cả các <em>collision</em>. Nếu tín hiệu lan truyền tức thời dọc theo toàn bộ chiều dài của dây, sẽ không có <em>collision</em> trong <em>CSMA</em>. Tuy nhiên, <em>propagation delay (độ trễ lan truyền)</em> có thể gây ra các vấn đề. Giả sử nút A ở một đầu của dây nghe thấy sự im lặng và bắt đầu truyền. Tín hiệu có thể chưa lan truyền đến nút B, ở đầu kia của dây. Nút B nghe thấy sự im lặng và cũng bắt đầu truyền, gây ra một <em>collision</em>.</p>
<img width="500px" src="end-to-end/../assets/end-to-end/5-008-propagation.png">
<p>Sơ đồ 2D này minh họa cách <em>propagation delay</em> có thể gây ra xung đột. Một mặt cắt ngang cho thấy sợi dây tại một thời điểm, và cho chúng ta thấy tín hiệu đã lan truyền được bao xa trên dây tại thời điểm đó. Một mặt cắt dọc cho thấy một vị trí duy nhất trên dây theo thời gian, và cho chúng ta thấy khi nào vị trí đó nhìn thấy các bit đầu tiên và cuối cùng của việc truyền. Cả H2 và H4 đều nghe thấy sự im lặng trước khi chúng bắt đầu truyền, nhưng tín hiệu của chúng vẫn xung đột.</p>
<p>Để giảm thiểu vấn đề này, chúng ta có thể sử dụng <em>CSMA/CD</em> (Carrier Sense Multiple Access with <em>Collision Detection (Phát hiện xung đột)</em>), mở rộng ý tưởng của <em>CSMA</em>. Ngoài việc lắng nghe trước khi nói, chúng ta cũng lắng nghe trong khi nói. Nếu bạn bắt đầu nghe thấy điều gì đó trong khi bạn đang truyền, bạn dừng lại ngay lập tức. Lưu ý rằng <em>CSMA/CD</em> vẫn không khắc phục được vấn đề <em>collision</em>, nhưng nó cho phép chúng ta phát hiện <em>collision</em> sớm hơn.</p>
<p>Nếu chỉ có một người nói, sẽ không có bất kỳ <em>collision</em> nào, và tất cả các lược đồ <em>random access</em> của chúng ta đều hoạt động tốt. Nếu chỉ có một vài người nói, có thể có những <em>collision</em> không thường xuyên, nhưng tất cả các lược đồ của chúng ta đều có thể giải quyết chúng. Tuy nhiên, nếu nhiều người gửi muốn nói đồng thời, chúng ta có thể gặp vấn đề với các <em>collision</em> lặp đi lặp lại, và việc đợi một khoảng thời gian ngẫu nhiên để gửi lại sẽ không giúp ích.</p>
<p>Để đối phó với các <em>collision</em> lặp đi lặp lại, <em>CSMA/CD</em> sử dụng <em>binary exponential backoff (lùi số mũ nhị phân)</em>. Mỗi lần chúng ta phát hiện một <em>collision</em> trong một lần thử gửi lại, chúng ta đợi một khoảng thời gian dài gấp đôi trước lần gửi lại tiếp theo. Lưu ý rằng chúng ta vẫn chọn ngẫu nhiên thời gian gửi lại, nhưng mỗi lần chúng ta phát hiện một <em>collision</em>, chúng ta chọn số ngẫu nhiên từ một phạm vi có giới hạn cao gấp đôi. Ví dụ, nếu chúng ta chọn một thời gian ngẫu nhiên trong khoảng [0, 4] và phát hiện một <em>collision</em>, thời gian ngẫu nhiên tiếp theo chúng ta chọn là trong khoảng [0, 8].</p>
<p><em>Binary exponential backoff</em> hoạt động tốt trong cả hai kịch bản. Khi có ít nút nói, các <em>collision</em> lặp lại không phổ biến, vì vậy chúng ta có thể gửi lại sau một thời gian chờ ngắn. Khi có nhiều nút nói, có nhiều <em>collision</em> lặp lại, vì vậy độ trễ tăng theo cấp số nhân cho đến khi không có <em>collision</em> nào (ví dụ: đủ số nút đã bị trì hoãn rất xa trong tương lai, và có ít nút cạnh tranh hơn ngay bây giờ). Cách tiếp cận này đảm bảo chúng ta chỉ giảm tốc độ khi nhiều nút muốn nói, và duy trì tốc độ truyền nhanh khi ít nút muốn nói.</p>
<h2 id="lược-sử-layer-2-alohanet"><a class="header" href="#lược-sử-layer-2-alohanet">Lược sử Layer 2: ALOHANet</a></h2>
<p>Năm 1968, Norman Abramson gặp một vấn đề tại Đại học Hawaii. Có một máy tính trung tâm tại Đại học Hawaii, và ông cần một cách để các máy tính trên các hòn đảo khác có thể truy cập vào máy tính trung tâm này. Thiết kế kết quả đã có ảnh hưởng rất lớn đến các thiết kế giao thức <em>Layer 2</em> hiện đại.</p>
<p>Giao thức kết quả được gọi là <em>ALOHANet</em> (Additive Links On-line Hawaii Area), cho phép giao tiếp không dây từ các hòn đảo khác đến máy tính trung tâm. <em>ALOHANet</em> là không dây và sử dụng một <em>shared media</em>, nơi mọi người đều gửi dữ liệu qua cùng một liên kết.</p>
<p><em>ALOHANet</em> đã sử dụng một sự kết hợp của phân bổ cố định và <em>random access</em>, do thiết lập bất đối xứng của nó. Máy tính trung tâm (hub) sử dụng tần số chuyên dụng của riêng mình để truyền các thông điệp đi, và tất cả các nút từ xa đều lắng nghe trên tần số này để nhận thông điệp. Với chỉ một người gửi trên một tần số chuyên dụng, không có nguy cơ <em>collision</em>.</p>
<p>Ngược lại, tất cả các nút từ xa đều truyền trên một tần số chia sẻ riêng biệt, và hub lắng nghe trên tần số này. Hub sẽ không xung đột với các nút từ xa, vì chúng sử dụng các tần số khác nhau, nhưng các nút từ xa có thể xung đột với nhau.</p>
<p>Thiết kế bất đối xứng này hoạt động tốt cho <em>ALOHANet</em> vì hub có lẽ có nhiều thứ để gửi hơn các nút từ xa.</p>
<img width="200px" src="end-to-end/../assets/end-to-end/5-009-alohanet.png">
<p><em>ALOHANet</em> là một trong những hệ thống đầu tiên sử dụng một <em>random access protocol</em> để xử lý các <em>collision</em>, và cách tiếp cận này sau này sẽ được sử dụng trong <em>Ethernet</em>. <em>ALOHANet</em> đã sử dụng cách tiếp cận <em>random access</em> ngây thơ và thô lỗ. Các giao thức sau này như <em>Ethernet</em> đã sử dụng cách tiếp cận lịch sự hơn của <em>CSMA/CD</em>, nơi chúng ta lắng nghe các <em>collision</em> trước và trong khi truyền, và chúng ta lùi theo cấp số nhân khi có <em>collision</em>.</p>
<h2 id="giao-tiếp-lan-Địa-chỉ-mac"><a class="header" href="#giao-tiếp-lan-Địa-chỉ-mac">Giao tiếp LAN: Địa chỉ MAC</a></h2>
<p>Bởi vì nhiều máy tính có thể được kết nối dọc theo cùng một liên kết <em>Ethernet</em>, chúng ta thực sự có thể sử dụng các giao thức <em>Layer 2</em> để gửi thông điệp giữa các máy tính cục bộ trên cùng một liên kết, mà không cần sử dụng bất kỳ giao thức <em>Layer 3 (Lớp 3)</em> nào cả (ví dụ: không có <em>router</em> chuyển tiếp <em>packet</em>). Trong phép tương tự về hệ thống bưu chính, hai người trong cùng một phòng có thể chuyền thư cho nhau, mà không cần gửi thư đến bưu điện.</p>
<p>Một vấn đề khi gửi thông điệp qua <em>shared media</em> là: Khi chúng ta truyền thông điệp, mọi người trên liên kết đều nhận được thông điệp, không chỉ người nhận dự định. Để gửi một thông điệp chỉ cho một người, chúng ta cần một hệ thống <em>addressing</em> ở <em>Layer 2</em> để có thể xác định máy nào là đích của thông điệp. Trong phép tương tự về hệ thống bưu chính, nếu tôi nói trong một căn phòng, mọi người đều nhận được thông điệp. Để nói chuyện với một người cụ thể, tôi cần gọi tên họ.</p>
<p>Ở <em>Layer 2</em>, mỗi máy tính có một <em>MAC address (Địa chỉ Kiểm soát Truy cập Phương tiện)</em>. <em>MAC address</em> dài 48 bit, và thường được viết dưới dạng thập lục phân với dấu hai chấm ngăn cách mỗi 2 chữ số hex (8 bit), ví dụ: <em>f8:ff:c2:2b:36:16</em>. <em>MAC address</em> đôi khi được gọi là địa chỉ ether hoặc địa chỉ liên kết.</p>
<p><em>MAC address</em> thường được mã hóa cứng vĩnh viễn (&quot;burned in&quot;) trên một thiết bị (ví dụ: NIC trong máy tính của bạn). Hầu hết các hệ điều hành sẽ cho phép bạn ghi đè <em>MAC address</em> bằng phần mềm, nhưng mỗi thiết bị đã đi kèm với một <em>MAC address</em> được cài đặt sẵn. <em>MAC address</em> được phân bổ theo nhà sản xuất tạo ra phần cứng. Hai bit đầu tiên là cờ, sau đó 22 bit tiếp theo xác định nhà sản xuất, rồi 24 bit cuối cùng xác định máy cụ thể trong không gian địa chỉ của nhà sản xuất đó.</p>
<p>Tại sao không chỉ sử dụng <em>IP addressing (việc đánh địa chỉ IP)</em>? Các <em>host</em> trên một liên kết có thể muốn trao đổi thông điệp, mà không cần kết nối với Internet (tức là chúng hoàn toàn không có địa chỉ IP).</p>
<p>Lược đồ <em>addressing</em> vĩnh viễn này khác với IP, nơi bạn nhận được một địa chỉ khi lần đầu tham gia mạng, và địa chỉ đó phụ thuộc vào vị trí địa lý của bạn. <em>MAC address</em> thường được cho là duy nhất trên toàn cầu, bởi vì bạn có thể cắm máy tính của mình vào bất kỳ mạng cục bộ nào, và sẽ rất tệ nếu hai máy tính trên một liên kết có cùng một <em>MAC address</em>.</p>
<h2 id="các-loại-giao-tiếp-lan-cấu-trúc-gói-tin-ethernet"><a class="header" href="#các-loại-giao-tiếp-lan-cấu-trúc-gói-tin-ethernet">Các loại Giao tiếp LAN, Cấu trúc Gói tin Ethernet</a></h2>
<p>Có các loại đích đến khác nhau trong một <em>packet</em> <em>Layer 2</em>. Trong <em>unicast (truyền tin đơn hướng)</em>, <em>packet</em> được dành cho một người nhận duy nhất. Trong <em>broadcast (truyền tin quảng bá)</em>, <em>packet</em> được dành cho tất cả các máy trên mạng cục bộ. Trong <em>multicast (truyền tin đa hướng)</em>, <em>packet</em> được dành cho tất cả các máy trong mạng cục bộ thuộc về một nhóm cụ thể. Các máy có thể chọn tham gia các nhóm nhất định để nhận các <em>packet</em> dành cho nhóm đó. <em>Ethernet</em> hỗ trợ <em>unicast</em>, <em>multicast</em>, và <em>broadcast</em>.</p>
<p>Lưu ý rằng <em>broadcast</em> đôi khi được coi là một trường hợp đặc biệt của <em>multicast</em>, nơi mọi người tự động là một phần của nhóm quảng bá.</p>
<p>Mô hình <em>unicast/broadcast/multicast</em> này cũng mở rộng đến các lớp khác. Ví dụ, chúng ta đã thấy <em>anycast (truyền tin tới một trong nhóm)</em> ở <em>Layer 3</em>, với mục tiêu là gửi đến bất kỳ một thành viên nào của một nhóm (bất kỳ máy chủ nào có cùng địa chỉ IP).</p>
<h2 id="cấu-trúc-gói-tin-ethernet"><a class="header" href="#cấu-trúc-gói-tin-ethernet">Cấu trúc Gói tin Ethernet</a></h2>
<p>Một <em>packet</em> dữ liệu trong <em>Ethernet</em> được gọi là một <em>frame (khung dữ liệu)</em>. Nhiều trường trông tương tự như các trường tiêu đề IP, mặc dù có một số khác biệt.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-010-ethernet-packet.png">
<p><em>Packet</em> <em>Ethernet</em> bắt đầu bằng một <em>preamble (phần mở đầu)</em> 7 byte, chỉ ra sự bắt đầu của một <em>packet</em>. Điều này giúp tách biệt các <em>packet</em> khi chúng được truyền tín hiệu qua dây.</p>
<p>Sau đó, chúng ta có địa chỉ MAC đích và nguồn, tương tự như các trường đích và nguồn trong tiêu đề IP. Chúng ta có một trường loại 2 byte, cho phép chúng ta phân kênh giữa IPv4 hoặc IPv6, và chuyển tải trọng <em>packet</em> đến giao thức tiếp theo chính xác. Điều này tương tự như trường giao thức trong tiêu đề IP, hoặc trường cổng trong tiêu đề TCP/UDP. Chúng ta cũng có một <em>checksum (tổng kiểm)</em>, mặc dù không giống như IP, <em>checksum</em> là trên toàn bộ <em>packet</em>, để chúng ta không phải dựa vào các lớp cao hơn (ví dụ: <em>packet</em> có thể hoàn toàn không phải là TCP/IP).</p>
<p>Để <em>unicast</em> một thông điệp, chúng ta đặt địa chỉ MAC đích thành <em>MAC address</em> của một máy cụ thể. Mọi người trên <em>shared media</em> đều nhận được <em>packet</em>, vì vậy mọi người cần kiểm tra MAC đích để xem <em>packet</em> có dành cho mình không. Nếu địa chỉ MAC đích không khớp với địa chỉ của bạn, bạn nên bỏ qua <em>packet</em>.</p>
<p>Để <em>broadcast</em> một thông điệp, chúng ta đặt MAC đích thành địa chỉ đặc biệt <em>FF:FF:FF:FF:FF:FF</em> (toàn bit 1). Giống như trong <em>unicast</em>, mọi người trên <em>shared media</em> đều nhận được <em>packet</em>, nhưng lần này, vì địa chỉ MAC đích là địa chỉ <em>broadcast</em>, mọi người đều biết để đọc <em>packet</em>. Lưu ý rằng địa chỉ <em>broadcast</em> toàn bit 1 này là giống nhau trong mọi mạng <em>Ethernet</em>.</p>
<p>Để <em>multicast</em> một thông điệp, chúng ta đặt MAC đích thành địa chỉ của nhóm đó. Nhớ lại rằng hai bit đầu tiên của <em>MAC address</em> là cờ. Các địa chỉ bình thường được phân bổ cho các máy luôn đặt bit đầu tiên thành 0, và các địa chỉ cho các nhóm luôn đặt bit đầu tiên thành 1. Giống như trong <em>unicast</em> và <em>broadcast</em>, mọi người vẫn nhận được thông điệp. Bất kỳ ai là thành viên của một nhóm cần đảm bảo rằng họ đang lắng nghe trên địa chỉ của nhóm đó để nhận các <em>packet</em> <em>multicast</em> đến nhóm đó. Các giao thức bổ sung là cần thiết để kiểm soát ai thuộc về nhóm nào, và chúng ta sẽ không thảo luận thêm về chúng.</p>
<h2 id="mạng-layer-2-với-ethernet"><a class="header" href="#mạng-layer-2-với-ethernet">Mạng Layer 2 với Ethernet</a></h2>
<p>Cho đến nay, chúng ta đã trình bày các giao thức <em>Layer 2</em> hoạt động trên một liên kết duy nhất với nhiều máy tính được gắn vào nó, nhưng chúng ta có thể giới thiệu nhiều liên kết và xây dựng một mạng hoàn toàn bằng <em>Layer 2</em>. Các <em>packet</em> có thể được chuyển tiếp, và các máy thậm chí có thể chạy các giao thức định tuyến, tất cả đều sử dụng độc quyền các <em>MAC address</em> <em>Layer 2</em>.</p>
<p>Các giao thức định tuyến chúng ta chạy ở lớp IP cũng có thể hoạt động ở <em>Layer 2</em>, mặc dù một nhược điểm là chúng ta không thể tổng hợp các <em>MAC address</em>. Địa chỉ IP được phân bổ dựa trên địa lý, nhưng <em>MAC address</em> được phân bổ dựa trên nhà sản xuất, vì vậy không có cách nào rõ ràng để tổng hợp chúng. Nhược điểm này là lý do tại sao chúng ta không thể xây dựng Internet toàn cầu chỉ bằng <em>Layer 2</em>.</p>
<p>Nếu có nhiều liên kết trong một mạng cục bộ duy nhất, chúng ta sẽ phải đảm bảo rằng nếu ai đó <em>broadcast</em> một thông điệp, bất kỳ <em>switch (thiết bị chuyển mạch)</em> nào ở <em>Layer 2</em> cũng sẽ chuyển tiếp <em>packet</em> ra khỏi tất cả các cổng đi.</p>
<p><em>Multicast</em> trở nên phức tạp hơn trong một mạng <em>Layer 2</em> với nhiều liên kết. Cần có các giao thức bổ sung, mặc dù chúng ta sẽ không thảo luận thêm.</p>
<p>Một ví dụ về <em>multicast</em> hữu ích trên mạng LAN là <em>Bonjour/mDNS</em>, một giao thức do Apple phát triển. Trong giao thức này, tất cả các thiết bị của Apple (ví dụ: iPhone, iPad, Apple TV) được mã hóa cứng để tham gia một nhóm đặc biệt trên mạng cục bộ. Nếu iPhone của bạn muốn tìm các thiết bị gần đó để phát nhạc (ví dụ: Apple TV, loa Apple hoặc HomePod hay bất cứ tên gọi nào của chúng), iPhone có thể <em>multicast</em> một thông điệp đến nhóm, hỏi xem có ai có thể phát nhạc không. Các thiết bị trong nhóm cũng có thể <em>multicast</em> phản hồi, nói rằng &quot;Tôi là một Apple TV và tôi có thể phát nhạc.&quot; Điều thú vị là giao thức này thực sự cũng sử dụng DNS trong nhóm <em>multicast</em> để gửi <em>SRV records (bản ghi SRV)</em>, ánh xạ mỗi máy với các khả năng của nó.</p>
<p>Lưu ý lịch sử: Trong Internet hiện đại, chúng ta đã nói rằng các thuật ngữ &quot;router&quot; và &quot;switch&quot; có thể thay thế cho nhau. Bây giờ chúng ta đã có khái niệm về mạng <em>Layer 2</em>, chúng ta có thể nói rằng một <em>switch</em> chỉ hoạt động ở Lớp 1 và 2, trong khi một <em>router</em> hoạt động ở Lớp 1, 2 và 3.</p>
<p>Nếu bạn quay lại hình ảnh của chúng ta về việc đóng gói và mở gói các tiêu đề, chúng ta đã giả định rằng mọi <em>router</em> đều phân tích <em>packet</em> lên đến <em>Layer 3</em>, và chuyển tiếp <em>packet</em> đến <em>router</em> tiếp theo qua IP. Tuy nhiên, nếu chúng ta có một mạng <em>Layer 2</em> với nhiều liên kết, một <em>switch</em> chỉ cần chuyển <em>packet</em> lên đến <em>Layer 2</em> và chuyển tiếp <em>packet</em> đến <em>switch</em> tiếp theo qua <em>Ethernet</em>.</p>
<p>Ngày nay, hầu như tất cả các <em>switch</em> cũng triển khai <em>Layer 3</em>, đó là lý do tại sao chúng ta sử dụng các thuật ngữ này thay thế cho nhau. Về mặt lịch sử, <em>Ethernet</em> có trước Internet, đó là lý do tại sao có sự phân biệt giữa <em>switch</em> và <em>router</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Định-tuyến-layer-2-stp"><a class="header" href="#Định-tuyến-layer-2-stp">Định tuyến Layer 2 (STP)</a></h1>
<h2 id="mạng-layer-2-với-ethernet-1"><a class="header" href="#mạng-layer-2-với-ethernet-1">Mạng Layer 2 với Ethernet</a></h2>
<p>Cho đến nay, chúng ta đã trình bày các giao thức <em>Layer 2</em> hoạt động trên một liên kết duy nhất với nhiều máy tính được gắn vào nó, nhưng chúng ta có thể giới thiệu nhiều liên kết và xây dựng một mạng hoàn toàn bằng <em>Layer 2</em>. Các <em>packet</em> có thể được <em>forwarding</em>, và các máy thậm chí có thể chạy các giao thức định tuyến, tất cả đều sử dụng độc quyền các <em>MAC address</em> <em>Layer 2</em>.</p>
<p>Các giao thức định tuyến chúng ta chạy ở lớp IP cũng có thể hoạt động ở <em>Layer 2</em>, mặc dù một nhược điểm là chúng ta không thể tổng hợp các <em>MAC address</em>. Địa chỉ IP được phân bổ dựa trên địa lý, nhưng <em>MAC address</em> được phân bổ dựa trên nhà sản xuất, vì vậy không có cách nào rõ ràng để tổng hợp chúng. Nhược điểm này là lý do tại sao chúng ta không thể xây dựng Internet toàn cầu chỉ bằng <em>Layer 2</em>.</p>
<p>Nếu có nhiều liên kết trong một mạng cục bộ duy nhất, chúng ta sẽ phải đảm bảo rằng nếu ai đó <em>broadcast</em> một thông điệp, bất kỳ <em>switch</em> nào ở <em>Layer 2</em> cũng sẽ chuyển tiếp <em>packet</em> ra khỏi tất cả các <em>port (cổng)</em> đi.</p>
<p><em>Multicast</em> trở nên phức tạp hơn trong một mạng <em>Layer 2</em> với nhiều liên kết. Cần có các giao thức bổ sung, sẽ được thảo luận sau (trong phần Chủ đề Đặc biệt).</p>
<p>Một ví dụ về <em>multicast</em> hữu ích trên mạng <em>LAN</em> là <em>Bonjour/mDNS</em>, một giao thức do Apple phát triển. Trong giao thức này, tất cả các thiết bị của Apple (ví dụ: iPhone, iPad, Apple TV) được mã hóa cứng để tham gia một nhóm đặc biệt trên mạng cục bộ. Nếu iPhone của bạn muốn tìm các thiết bị gần đó để phát nhạc (ví dụ: Apple TV, loa Apple hoặc HomePod hay bất cứ tên gọi nào của chúng), iPhone có thể <em>multicast</em> một thông điệp đến nhóm, hỏi xem có ai có thể phát nhạc không. Các thiết bị trong nhóm cũng có thể <em>multicast</em> phản hồi, nói rằng &quot;Tôi là một Apple TV và tôi có thể phát nhạc.&quot; Điều thú vị là giao thức này thực sự cũng sử dụng DNS trong nhóm <em>multicast</em> để gửi <em>SRV records</em>, ánh xạ mỗi máy với các khả năng của nó.</p>
<p>Lưu ý lịch sử: Trong Internet hiện đại, chúng ta đã nói rằng các thuật ngữ &quot;router&quot; và &quot;switch&quot; có thể thay thế cho nhau. Bây giờ chúng ta đã có khái niệm về mạng <em>Layer 2</em>, chúng ta có thể nói rằng một <em>switch</em> chỉ hoạt động ở Lớp 1 và 2, trong khi một <em>router</em> hoạt động ở Lớp 1, 2 và 3.</p>
<p>Nếu bạn quay lại hình ảnh của chúng ta về việc đóng gói và mở gói các tiêu đề, chúng ta đã giả định rằng mọi <em>router</em> đều phân tích <em>packet</em> lên đến <em>Layer 3</em>, và chuyển tiếp <em>packet</em> đến <em>router</em> tiếp theo qua IP. Tuy nhiên, nếu chúng ta có một mạng <em>Layer 2</em> với nhiều liên kết, một <em>switch</em> chỉ cần chuyển <em>packet</em> lên đến <em>Layer 2</em> và chuyển tiếp <em>packet</em> đến <em>switch</em> tiếp theo qua <em>Ethernet</em>.</p>
<p>Ngày nay, hầu như tất cả các <em>switch</em> cũng triển khai <em>Layer 3</em>, đó là lý do tại sao chúng ta sử dụng các thuật ngữ này thay thế cho nhau. Về mặt lịch sử, <em>Ethernet</em> có trước Internet, đó là lý do tại sao có sự phân biệt giữa <em>switch</em> và <em>router</em>.</p>
<h2 id="cấu-trúc-liên-kết-mạng-layer-2"><a class="header" href="#cấu-trúc-liên-kết-mạng-layer-2">Cấu trúc liên kết Mạng Layer 2</a></h2>
<p>Giống như chúng ta đã thấy trong đơn vị về định tuyến, có nhiều <em>topology (cấu trúc liên kết)</em> khác nhau mà chúng ta có thể sử dụng để kết nối các máy tính trong một mạng cục bộ.</p>
<p>Chúng ta có thể sử dụng một liên kết duy nhất để kết nối tất cả các máy tính, nhưng điều này không hiệu quả. Chúng ta chỉ có <em>bandwidth (băng thông)</em> của một liên kết duy nhất để sử dụng. Ngoài ra, mọi người cần phải đợi đến lượt mình để gửi tin nhắn, và nếu hai máy tính gửi tin nhắn đồng thời, có thể xảy ra <em>collision</em>.</p>
<p>Chúng ta cũng có thể sử dụng một <em>full mesh (lưới đầy đủ)</em>, cung cấp cho mỗi cặp <em>host</em> một liên kết chuyên dụng, nhưng lại khó mở rộng.</p>
<p>Giống như ở <em>Layer 3</em>, chúng ta có thể giới thiệu các <em>switch</em> chuyển tiếp các <em>packet</em> qua một <em>topology</em>, hướng tới đích cuối cùng của chúng. Nhưng, cũng giống như ở <em>Layer 3</em>, điều này giới thiệu vấn đề định tuyến, nơi các <em>switch</em> cần phải quyết định nơi để chuyển tiếp các <em>packet</em>.</p>
<p>Trong phần này, chúng ta sẽ khám phá một số giao thức định tuyến được thiết kế đặc biệt cho các mạng <em>Layer 2</em> cục bộ. Chúng ta cũng sẽ thấy một số thách thức ngăn cản các giao thức này được mở rộng và sử dụng cho mạng <em>Layer 3</em> toàn cầu.</p>
<h2 id="chuyển-tiếp-bằng-flooding"><a class="header" href="#chuyển-tiếp-bằng-flooding">Chuyển tiếp bằng Flooding</a></h2>
<p>Cách tiếp cận <em>ngây thơ</em> (naive approach) nhất để <em>forwarding</em> là <em>flooding (gửi tràn lan)</em> mọi <em>packet</em> bạn nhận được. Khi một <em>switch</em> nhận được một <em>packet</em>, nó sẽ gửi <em>packet</em> đó ra khỏi mọi <em>port</em>.</p>
<p>Như một tối ưu hóa nhỏ, chúng ta không cần gửi <em>packet</em> trở lại <em>port</em> mà chúng ta đã nhận <em>packet</em> từ đó.</p>
<img width="500px" src="end-to-end/../assets/end-to-end/5-011-flooding.png">
<p>Cách tiếp cận ngây thơ này có hai vấn đề lớn:</p>
<ol>
<li>
<p>Nó lãng phí <em>bandwidth</em>. Các bản sao của <em>packet</em> được gửi một cách không cần thiết đến các <em>switch</em> và <em>host</em> không cần <em>packet</em> đó.</p>
</li>
<li>
<p><em>Flooding</em> có thể khiến các <em>packet</em> bị lặp lại và làm quá tải mạng.</p>
</li>
</ol>
<h2 id="learning-switches"><a class="header" href="#learning-switches">Learning Switches</a></h2>
<p>Hãy bắt đầu với vấn đề đầu tiên: <em>Flooding</em> các <em>packet</em> làm lãng phí <em>bandwidth</em>.</p>
<p>Để giải quyết vấn đề này, chúng ta muốn điền vào các <em>forwarding table (bảng chuyển tiếp)</em> cho các <em>switch</em>, để chúng có thể chuyển tiếp các <em>packet</em> trực tiếp đến đích của chúng, thay vì <em>flooding</em> các bản sao của <em>packet</em> ra mọi hướng.</p>
<p>Chúng ta có thể chạy một thuật toán định tuyến để điền vào các <em>forwarding table</em>, nhưng một cách tiếp cận thậm chí còn đơn giản hơn là sử dụng <strong><em>learning switches</em> (switch học)</strong>.</p>
<p>Giả sử bạn là <em>router</em> R2. Bạn không có thông tin gì về <em>topology</em> mạng đầy đủ, và <em>forwarding table</em> của bạn trống rỗng. Bạn có các <em>port</em> ở phía bắc, nam, đông và tây.</p>
<p>Bạn thấy một <em>packet</em> đến từ <em>port</em> phía tây của bạn. <em>Packet</em> đó ghi: &quot;Từ A, Đến B.&quot; Từ <em>packet</em> này, bạn có thể suy ra rằng A phải ở phía tây của bạn.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-012-learning-1.png">
<p>Bây giờ bạn có thể thêm một mục vào <em>forwarding table</em> của mình: Các <em>packet</em> cho A nên được chuyển tiếp về phía tây.</p>
<p>Đây là ý tưởng chính đằng sau <em>learning switches</em>. Khi bạn nhận được một <em>packet</em> đến, bạn có một manh mối về vị trí của <em>người gửi</em>. Bạn có thể sử dụng thông tin đó để điền vào mục chuyển tiếp cho <em>người gửi</em>.</p>
<p>Lưu ý rằng <em>packet</em> đến không cho bạn biết bất cứ điều gì về vị trí của người nhận. Trong ví dụ trên, khi bạn nhận được &quot;Từ A, Đến B&quot; từ <em>port</em> phía tây, điều đó không cho bạn biết gì về vị trí của B (người nhận). Thay vào đó, bạn điền vào <em>forwarding table</em> cho A, để các <em>packet</em> trong tương lai cho A có thể được chuyển tiếp về phía tây.</p>
<p>Khi bạn nhận được nhiều <em>packet</em> đến hơn, bạn có thể bắt đầu điền vào <em>forwarding table</em> của mình với nhiều mục hơn. Nếu bạn nhận được một <em>packet</em> có đích không có trong <em>forwarding table</em> của bạn, bạn vẫn có thể chuyển tiếp <em>packet</em> bằng cách <em>flooding</em> nó ra tất cả các <em>port</em> (trừ <em>port</em> đến).</p>
<p>Ví dụ, khi bạn nhận &quot;Từ A, Đến B&quot; từ <em>port</em> phía tây, bạn chưa có <em>forwarding table</em> cho B. Do đó, bạn nên chuyển tiếp <em>packet</em> này ra tất cả các <em>port</em> (trừ <em>port</em> phía tây).</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-013-learning-2.png">
<p>Lưu ý: Không cần phải gửi <em>packet</em> trở lại <em>port</em> đến (ví dụ: phía tây), vì <em>switch/host</em> trước đó (ví dụ: ở phía tây của bạn) đã có một bản sao của <em>packet</em> và đã chuyển tiếp nó (đó là cách nó đến được bạn). Nếu bạn gửi <em>packet</em> trở lại, <em>switch/host</em> trước đó sẽ chỉ đưa ra quyết định chuyển tiếp tương tự một lần nữa (hoặc <em>flooding</em> lại, hoặc chuyển tiếp lại cho bạn), và việc chuyển tiếp lặp đi lặp lại này không giúp <em>packet</em> đến được đích của nó.</p>
<p>Tóm lại, <em>learning switches</em> có hai quy tắc để tuân theo:</p>
<ol>
<li>
<p>Khi bạn nhận được một <em>packet</em> đến, hãy cập nhật <em>forwarding table</em> để liên kết người gửi với <em>port</em> đến.</p>
</li>
<li>
<p>Nếu đích có trong <em>forwarding table</em> của bạn, thì hãy chuyển tiếp <em>packet</em> đến chặng tiếp theo chính xác. Nếu không, hãy <em>flooding</em> <em>packet</em> ra tất cả các <em>port</em> trừ <em>port</em> đến.</p>
</li>
</ol>
<p>Đây là một ví dụ về <em>learning switches</em> đang hoạt động. Hãy xem xét <em>topology</em> mạng này. Tất cả các <em>switch</em> đều là <em>learning switches</em>, và <em>forwarding table</em> của chúng bắt đầu trống.</p>
<p>A gửi một <em>packet</em> đến B. A chuyển tiếp <em>packet</em> đến R1.</p>
<p>R1 thấy <em>packet</em> &quot;Từ A, Đến B&quot; đến từ Port 1. Do đó, A phải ở hướng Port 1. R1 thêm ánh xạ này vào <em>forwarding table</em> của nó.</p>
<p>R1 không biết B ở đâu, vì vậy R1 <em>flooding</em> <em>packet</em> này ra tất cả các <em>port</em> (trừ <em>port</em> đến).</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-014-learning-3.png">
<p>R2 và R4 đều nhận được <em>packet</em> &quot;Từ A, đến B&quot;. Cả hai bây giờ đều có manh mối về vị trí của A, và thêm một ánh xạ cho A vào <em>forwarding table</em> của chúng. Cả hai đều không biết B ở đâu, vì vậy chúng <em>flooding</em> <em>packet</em> ra tất cả các <em>port</em> (trừ <em>port</em> đến).</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-015-learning-4.png">
<p>R3 và R5 đều nhận được <em>packet</em> &quot;Từ A, đến B&quot;. Cả hai bây giờ đều có manh mối về vị trí của A, và thêm một ánh xạ cho A vào <em>forwarding table</em> của chúng. Cả hai đều không biết B ở đâu, vì vậy chúng <em>flooding</em> <em>packet</em> ra tất cả các <em>port</em> (trừ <em>port</em> đến).</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-016-learning-5.png">
<p>C nhận được <em>packet</em> &quot;Từ A, đến B&quot;. C kiểm tra tiêu đề và nhận ra rằng nó không phải là người nhận dự định của <em>packet</em> này, vì vậy C loại bỏ <em>packet</em>.</p>
<p>B nhận được <em>packet</em> &quot;Từ A, đến B&quot;. B kiểm tra tiêu đề và nhận ra rằng nó là người nhận, vì vậy B nhận và xử lý thành công <em>packet</em> này.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-017-learning-6.png">
<p>Tiếp theo, giả sử B gửi một <em>packet</em> đến A. Đầu tiên, B chuyển tiếp <em>packet</em> đến R3.</p>
<p>R3 nhận được <em>packet</em> &quot;Từ B, đến A&quot;. Điều này cho R3 một manh mối về vị trí của B, vì vậy R3 thêm một ánh xạ cho B vào <em>forwarding table</em> của nó. Ngoài ra, R3 nhận thấy rằng A có trong <em>forwarding table</em> của nó, vì vậy R3 có thể chuyển tiếp <em>packet</em> dọc theo chặng tiếp theo đến A (thay vì <em>flooding</em> <em>packet</em>).</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-018-learning-7.png">
<p>R2 nhận được <em>packet</em> &quot;Từ B, đến A&quot;. Điều này cho phép R2 thêm một ánh xạ cho B vào <em>forwarding table</em> của nó. R2 nhìn vào <em>forwarding table</em> của nó và thấy một mục cho A, vì vậy nó chuyển tiếp <em>packet</em> dọc theo chặng tiếp theo đến A.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-019-learning-8.png">
<p>R1 nhận được <em>packet</em> &quot;Từ B, đến A&quot;. Điều này cho phép R1 thêm một ánh xạ cho B vào <em>forwarding table</em> của nó. R1 nhìn vào <em>forwarding table</em> của nó và thấy một mục cho A, vì vậy nó chuyển tiếp <em>packet</em> dọc theo chặng tiếp theo đến A.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-020-learning-9.png">
<p>Khi nhiều <em>packet</em> được gửi đi, nhiều mục hơn được thêm vào các <em>forwarding table</em>, và ít <em>flooding</em> hơn diễn ra.</p>
<p>Một tính năng cuối cùng chúng ta cần thêm vào: Khi một mục trong <em>forwarding table</em> được cài đặt, chúng ta gán cho nó một <em>TTL (Time-to-Live - Thời gian sống)</em>. Nếu <em>TTL</em> hết hạn, mục đó sẽ bị xóa. Điều này cho phép các tuyến đường bị hỏng (ví dụ: do một liên kết, <em>host</em>, hoặc <em>switch</em> bị sập) hết hạn. Ví dụ, nếu B rời khỏi mạng trong ví dụ trên, <em>TTL</em> sẽ đảm bảo rằng tất cả các <em>forwarding table</em> cho B cuối cùng sẽ hết hạn.</p>
<h2 id="Động-lực-của-stp-các-vòng-lặp"><a class="header" href="#Động-lực-của-stp-các-vòng-lặp">Động lực của STP: Các Vòng lặp</a></h2>
<p>Nhớ lại rằng <em>flooding</em> có hai vấn đề: Nó lãng phí <em>bandwidth</em>, và các <em>loop (vòng lặp)</em> có thể làm quá tải mạng. <em>Learning switches</em> đã giải quyết vấn đề đầu tiên, nhưng chúng không giải quyết được vấn đề <em>loop</em>.</p>
<p>Để thấy tại sao, hãy xem xét <em>topology</em> này với các <em>loop</em>. Giả sử tất cả các <em>switch</em> là <em>learning switches</em>, và tất cả các <em>forwarding table</em> bắt đầu trống. A cố gắng gửi một <em>packet</em> đến B, và chuyển tiếp <em>packet</em> đến R1.</p>
<img width="700px" src="end-to-end/../assets/end-to-end/5-021-loop.png">
<p>R1 không có mục nào cho B, vì vậy nó <em>flooding</em> <em>packet</em> đến R2 (và R3).</p>
<p>R2 không có mục nào cho B, vì vậy nó <em>flooding</em> <em>packet</em> đến R4.</p>
<p>R4 không có mục nào cho B, vì vậy nó <em>flooding</em> <em>packet</em> đến R3.</p>
<p>R3 không có mục nào cho B, vì vậy nó <em>flooding</em> <em>packet</em> đến R1.</p>
<p>R1 không có mục nào cho B, vì vậy nó <em>flooding</em> <em>packet</em> đến R2, và chu kỳ tiếp tục.</p>
<p>Đồng thời, một bản sao của <em>packet</em> cũng đang di chuyển trong một <em>loop</em> theo hướng ngược lại: R1 ban đầu <em>flooding</em> đến R3, sau đó <em>flooding</em> đến R4, sau đó <em>flooding</em> đến R2, sau đó <em>flooding</em> đến R1, rồi <em>flooding</em> đến R3, tiếp tục chu kỳ.</p>
<p>Trong suốt quá trình này, các <em>switch</em> cài đặt các mục chuyển tiếp cho A, nhưng chúng không bao giờ nhận được bất kỳ mục nào cho B, vì vậy <em>loop</em> vô hạn không bao giờ được giải quyết. Không ai có mục chuyển tiếp cho B, vì vậy mọi người đều <em>flooding</em> <em>packet</em> khi họ nhận được nó.</p>
<p>Vấn đề này đôi khi được gọi là <em>broadcast storm (bão quảng bá)</em>, vì mạng đang bị quá tải với lưu lượng <em>broadcast</em>.</p>
<p>Làm thế nào để chúng ta giải quyết vấn đề này? Lý tưởng nhất, chúng ta muốn &quot;xóa&quot; các liên kết dự phòng, để <em>topology</em> không có <em>loop</em>. Sau đó, cách tiếp cận <em>learning switch</em> sẽ hoạt động tốt, không có <em>broadcast storm</em>.</p>
<img width="700px" src="end-to-end/../assets/end-to-end/5-022-loop-fixed.png">
<p>Lưu ý: Một giải pháp khác có thể là thêm một trường <em>TTL</em> vào mỗi <em>packet</em>, để <em>packet</em> hết hạn sau khi được chuyển tiếp quá nhiều lần. Thật không may, tiêu đề <em>Ethernet</em> không có trường <em>TTL</em>, vì vậy giải pháp này không thể được triển khai.</p>
<p>Lưu ý: Một giải pháp khác có thể là loại bỏ các <em>packet</em> nếu bạn đã thấy chúng trước đây. Điều này sẽ yêu cầu đính kèm một loại dấu thời gian hoặc ID duy nhất cho mỗi <em>packet</em>. Một lần nữa, tiêu đề <em>Ethernet</em> không có trường tiêu đề cho việc này, vì vậy giải pháp này cũng không thể được triển khai.</p>
<h2 id="stp-bầu-chọn-một-root"><a class="header" href="#stp-bầu-chọn-một-root">STP: Bầu chọn một Root</a></h2>
<p><em><strong>Spanning Tree Protocol (STP) (Giao thức Cây bao trùm)</strong></em> giúp chúng ta vô hiệu hóa các liên kết, để <em>topology</em> kết quả không có <em>loop</em>. Điều này sẽ giúp chúng ta tránh được các <em>broadcast storm</em>.</p>
<p>Lưu ý rằng các <em>host</em> không tham gia vào giao thức này. Các <em>router</em> sẽ làm việc cùng nhau để vô hiệu hóa các liên kết và loại bỏ các <em>loop</em> khỏi <em>topology</em>. Do đó, chúng ta sẽ bỏ qua các <em>host</em> khi mô tả giao thức này.</p>
<img width="200px5" src="end-to-end/../assets/end-to-end/5-023-stp-no-hosts.png">
<p><em>STP</em> quyết định vô hiệu hóa các liên kết nào bằng cách nào? Hãy bắt đầu bằng cách giải quyết vấn đề này với một cái nhìn toàn cục về mạng. Sau đó, chúng ta sẽ nghĩ về cách các <em>switch</em> trao đổi thông điệp để đạt được điều này, mà không cần một cái nhìn toàn cục về mạng.</p>
<p>Bước đầu tiên trong <em>STP</em> là bầu chọn một <strong><em>root switch</em> (switch gốc)</strong>, như sau:</p>
<p>Mỗi <em>switch</em> được gán một ID, bao gồm một giá trị ưu tiên (do người vận hành mạng đặt thủ công), và <em>MAC address</em> của <em>switch</em>.</p>
<p>Khi so sánh hai <em>switch</em>, <em>switch</em> có độ ưu tiên thấp hơn sẽ có ID thấp hơn. Nếu độ ưu tiên bằng nhau, thì <em>switch</em> có <em>MAC address</em> thấp hơn sẽ có ID thấp hơn.</p>
<p><em>Root switch</em> là <em>switch</em> có ID thấp nhất.</p>
<img width="300px" src="end-to-end/../assets/end-to-end/5-024-stp-root-election.png">
<p>Nếu người vận hành mạng muốn chọn một <em>root</em> cụ thể, họ có thể làm như vậy bằng cách đặt thủ công độ ưu tiên của các <em>switch</em> khác nhau. Hoặc, người vận hành có thể để tất cả các độ ưu tiên của <em>switch</em> ở giá trị mặc định, điều này sẽ khiến <em>switch</em> có <em>MAC address</em> thấp nhất được bầu làm <em>root</em>. Trong các ghi chú này, chúng ta sẽ không thảo luận về <em>root</em> nào là tốt nhất; điều quan trọng chỉ là một trong các <em>router</em> được chọn một cách rõ ràng làm <em>root</em>.</p>
<h2 id="stp-các-trạng-thái-cổng"><a class="header" href="#stp-các-trạng-thái-cổng">STP: Các Trạng thái Cổng</a></h2>
<p>Bây giờ chúng ta đã có một <em>root switch</em>, chúng ta sẽ phân loại mọi <em>port</em> trên mọi <em>switch</em> thành một trong ba trạng thái:</p>
<ol>
<li>
<p><strong><em>Designated Port</em> (Cổng chỉ định):</strong> Đây là các <em>port</em> hướng ra xa <em>root</em> (tức là chúng dẫn đến một nơi nào đó xa <em>root</em> hơn).</p>
</li>
<li>
<p><strong><em>Root Port</em> (Cổng gốc):</strong> Có một hoặc nhiều <em>port</em> hướng về phía <em>root</em> (tức là chúng dẫn đến một nơi nào đó gần <em>root</em> hơn). Trong số các <em>port</em> này, <em>port</em> nằm trên đường đi có chi phí thấp nhất đến <em>root</em> là <em>root port</em>.</p>
</li>
<li>
<p><strong><em>Blocked Port</em> (Cổng bị chặn):</strong> Tất cả các <em>port</em> hướng về phía <em>root</em>, không phải là <em>root port</em> (cách tốt nhất để đến <em>root</em>), là các <em>blocked port</em>.</p>
</li>
</ol>
<img width="800px" src="end-to-end/../assets/end-to-end/5-025-stp-port-types.png">
<p>Dưới đây là một số ví dụ về các trạng thái <em>port</em> đang hoạt động. Giả sử rằng các ID được sắp xếp theo nhãn của <em>router</em>. Điều này có nghĩa là R1 có ID thấp nhất, vì vậy nó được bầu làm <em>root switch</em>.</p>
<img width="200px5" src="end-to-end/../assets/end-to-end/5-026-stp-port-types-example.png">
<p>Tất cả các <em>port</em> trên <em>root switch</em> (R1) đều hướng ra xa <em>root</em>, vì vậy chúng đều là các <em>designated port</em>.</p>
<p>R2 có hai <em>port</em>. Chỉ có một trong số chúng hướng về phía <em>root</em>, vì vậy đó phải là con đường tốt nhất đến <em>root</em>. Do đó, <em>port</em> hướng lên của R2 được dán nhãn là một <em>root port</em>.</p>
<p><em>Port</em> còn lại tại R2 hướng ra xa <em>root</em>, vì vậy <em>port</em> hướng xuống của R2 được dán nhãn là một <em>designated port</em>.</p>
<p>R6 có ba <em>port</em>. <em>Port</em> hướng xuống hướng ra xa <em>root</em>, vì vậy nó là một <em>designated port</em>.</p>
<p>Tại R6, các <em>port</em> đến R4 và R3 đều hướng về phía <em>root</em>. Tuy nhiên, <em>port</em> đến R3 cung cấp đường đi có chi phí thấp nhất đến <em>root</em> (chi phí 2), trong khi <em>port</em> đến R4 cung cấp một đường đi tệ hơn đến <em>root</em> (chi phí 3). Do đó, chúng ta dán nhãn <em>port</em> đến R3 là <em>root port</em> (cách tốt nhất để đến <em>root</em>), và <em>port</em> đến R4 là một <em>blocked port</em> (hướng về <em>root</em>, nhưng không phải là đường đi tốt nhất).</p>
<p>Đôi khi, chúng ta có một sự hòa, và có hai cách tốt nhất để đến <em>root</em>.</p>
<img width="400px" src="end-to-end/../assets/end-to-end/5-027-stp-tie-1.png">
<p>Ví dụ, tại R4, cả <em>port</em> đến R2 và <em>port</em> đến R3 đều hướng về phía <em>root</em>, và cả hai đều cung cấp một đường đi chi phí 2 đến <em>root</em>. Trong trường hợp hòa, chúng ta sẽ nói rằng chặng tiếp theo có ID thấp hơn là đường đi tốt hơn đến <em>root</em>. Điều này làm cho <em>port</em> đến R2 trở thành <em>root port</em>, và <em>port</em> đến R3 trở thành một <em>blocked port</em>.</p>
<p>Đôi khi, chúng ta sẽ có một liên kết dẫn đến một nơi nào đó cách <em>root</em> một khoảng bằng nhau.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-028-stp-tie-2.png">
<p>Ví dụ, R4 cách <em>root</em> một khoảng cách 2, và nó có một liên kết đến R5, cũng cách <em>root</em> một khoảng cách 2. Một lần nữa, chúng ta sẽ sử dụng ID của <em>router</em> làm yếu tố phá vỡ thế hòa. Nếu liên kết dẫn đến một <em>router</em> có ID cao hơn, chúng ta sẽ nói rằng liên kết đó hướng ra xa <em>root</em>. Nếu liên kết dẫn đến một <em>router</em> có ID thấp hơn, chúng ta sẽ nói rằng liên kết đó hướng về phía <em>root</em>. Trong ví dụ này, <em>port</em> hướng sang phải của R4 hướng ra xa <em>root</em> (dẫn đến một nơi nào đó cùng khoảng cách, nhưng ID cao hơn), vì vậy nó là một <em>designated port</em>. Mặt khác, <em>port</em> hướng sang trái của R5 hướng về phía <em>root</em> (dẫn đến một nơi nào đó cùng khoảng cách, nhưng ID thấp hơn), vì vậy nó là một <em>root port</em> hoặc một <em>blocked port</em>.</p>
<h2 id="stp-vô-hiệu-hóa-các-liên-kết"><a class="header" href="#stp-vô-hiệu-hóa-các-liên-kết">STP: Vô hiệu hóa các Liên kết</a></h2>
<p>Bây giờ mỗi <em>port</em> đã được gán một trạng thái (<em>designated port</em>, <em>root port</em>, hoặc <em>blocked port</em>), chúng ta sẵn sàng loại bỏ các <em>loop</em> khỏi <em>topology</em> mạng.</p>
<p>Để loại bỏ các <em>loop</em>, mỗi <em>switch</em> chỉ cần giả vờ như các <em>blocked port</em> của nó không tồn tại. Nói cách khác, không gửi bất kỳ dữ liệu người dùng nào ra khỏi <em>port</em> đó, và không nhận bất kỳ dữ liệu người dùng nào từ <em>port</em> đó.</p>
<img width="200px5" src="end-to-end/../assets/end-to-end/5-029-stp-disabling-ports.png">
<p>(Lưu ý: Chúng ta chỉ định dữ liệu người dùng ở đây vì các <em>packet</em> <em>STP</em> vẫn có thể được gửi và nhận từ <em>blocked port</em>. Điều này sẽ cho phép <em>STP</em> kích hoạt lại <em>blocked port</em> nếu <em>topology</em> thay đổi.)</p>
<p>Nếu chúng ta ngừng gửi dữ liệu người dùng dọc theo các <em>blocked port</em>, thì bất kỳ liên kết nào có <em>blocked port</em> cuối cùng sẽ bị vô hiệu hóa.</p>
<p>Tại sao điều này lại hoạt động? Hãy nghĩ về nó từ góc độ của một <em>switch</em> cụ thể. <em>Root port</em> của bạn là cách tốt nhất để bạn đến <em>root</em>. Các <em>blocked port</em> của bạn cũng hướng về phía <em>root</em>, nhưng chúng không phải là con đường tốt nhất đến <em>root</em>. Điều này có nghĩa là <em>blocked port</em> thực sự tạo ra một con đường dự phòng (nhưng tệ hơn) đến <em>root</em>, vì vậy chúng ta nên vô hiệu hóa liên kết đó.</p>
<p>Một mối lo ngại bạn có thể có là: Điều gì sẽ xảy ra nếu bạn chặn một <em>port</em>, nhưng ai đó khác cần sử dụng liên kết bị vô hiệu hóa đó để chuyển tiếp các <em>packet</em> đến bạn, trên đường đến <em>root</em> của họ? May mắn thay, điều này sẽ không bao giờ xảy ra. Hãy nhớ rằng <em>blocked port</em> của bạn hướng về phía <em>root</em> (tức là bạn ở xa hơn, và phía bên kia gần <em>root</em> hơn bạn). Do đó, nếu <em>switch</em> ở phía bên kia (gần hơn) chuyển tiếp các <em>packet</em> đến bạn (xa hơn), chúng sẽ chuyển tiếp các <em>packet</em> ra xa <em>root</em>. Điều này có nghĩa là chúng ta có thể chặn <em>port</em> này một cách an toàn và vô hiệu hóa liên kết này mà không cần lo lắng về việc các <em>switch</em> khác cố gắng sử dụng liên kết đó như một phần của con đường đến <em>root</em> của họ.</p>
<p>Ngược lại, các liên kết chỉ định không thể bị vô hiệu hóa một cách an toàn, bởi vì chúng dẫn ra xa <em>root</em> (tức là <em>switch</em> ở phía bên kia ở xa <em>root</em> hơn bạn). <em>Switch</em> ở phía bên kia có thể thực sự muốn chuyển tiếp các <em>packet</em> đến bạn, bởi vì bạn đang nằm trên con đường tốt nhất của họ đến <em>root</em>. May mắn thay, đây cũng không phải là vấn đề. Mặc dù bạn không thể vô hiệu hóa liên kết này một cách an toàn, bạn có thể dựa vào <em>switch</em> ở phía bên kia để vô hiệu hóa liên kết nếu họ không cần nó. <em>Switch</em> ở phía bên kia ở xa hơn bạn, vì vậy họ sẽ hoặc giữ liên kết này nếu đó là con đường tốt nhất của họ đến <em>root</em> (tức là <em>root port</em>), hoặc họ sẽ vô hiệu hóa liên kết này nếu đó không phải là con đường tốt nhất của họ đến <em>root</em> (tức là <em>blocked port</em>).</p>
<p>Với chiến lược này, mỗi liên kết chỉ bị vô hiệu hóa bởi một bên. Bên ở xa hơn đặt câu hỏi: Tôi có đang sử dụng liên kết này làm con đường tốt nhất của mình đến <em>root</em> không? Nếu có, <em>port</em> của liên kết này là một <em>root port</em>. Nếu không, <em>port</em> của liên kết này là một <em>blocked port</em>.</p>
<p>Bên ở gần hơn luôn làm cho <em>port</em> của liên kết này trở thành một <em>designated port</em>. Điều này có tác dụng để lại quyết định vô hiệu hóa cho bên ở xa hơn. Điều này tốt, bởi vì bên ở gần hơn không biết liệu bên ở xa hơn có đang sử dụng liên kết này làm con đường tốt nhất của họ đến <em>root</em> hay không.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-030-stp-why-it-works.png">
<h2 id="stp-các-cổng-chỉ-định"><a class="header" href="#stp-các-cổng-chỉ-định">STP: Các Cổng Chỉ định</a></h2>
<p>Lưu ý bên lề: Tại sao chúng ta gọi chúng là các <em>designated port</em>? Cho đến nay, chúng ta đã vẽ các mạng nơi mỗi liên kết kết nối hai máy, nhưng hãy nhớ rằng đôi khi chúng ta có thể có các liên kết kết nối nhiều máy tính.</p>
<p>Giả sử rằng một liên kết kết nối hai <em>switch</em> cũng có rất nhiều <em>host</em> được kết nối với nó. Nếu các <em>host</em> này muốn gửi hoặc nhận dữ liệu, họ sẽ gửi dữ liệu đến <em>designated port</em>, chứ không phải <em>blocked port</em>. (<em>Blocked port</em> sẽ không nhận bất kỳ dữ liệu người dùng nào.) Điều này đảm bảo rằng dữ liệu của họ chỉ đi một con đường duy nhất đến đích. Nếu dữ liệu được gửi đến cả <em>designated port</em> và <em>blocked port</em>, dữ liệu có thể đi hai con đường đến đích, tạo ra một <em>loop</em>.</p>
<img width="400px" src="end-to-end/../assets/end-to-end/5-031-stp-designated-ports.png">
<p>Với điều này trong tâm trí, một cách diễn giải tương đương khác của một <em>designated port</em> là: Các <em>host</em> trên một liên kết nên gửi dữ liệu về phía <em>designated port</em> để đến <em>root</em> (hoặc bất cứ nơi nào khác trên cây bao trùm). Từ góc độ của <em>switch</em>, <em>designated port</em> hướng ra xa <em>root</em>. Từ góc độ của các <em>host</em>, việc gửi đến <em>designated port</em> đưa họ đến gần <em>root</em> hơn (hoặc bất cứ nơi nào khác trên cây bao trùm).</p>
<h2 id="stp-trao-đổi-bpdu"><a class="header" href="#stp-trao-đổi-bpdu">STP: Trao đổi BPDU</a></h2>
<p>Bây giờ chúng ta đã biết cách sử dụng <em>STP</em> để vô hiệu hóa các liên kết và loại bỏ các <em>loop</em> khỏi một <em>topology</em> mạng. Tuy nhiên, giao thức của chúng ta cho đến nay giả định kiến thức toàn cục về mạng. Bạn sẽ cần một cái nhìn toàn cục để xác định <em>root</em>, và để quyết định xem các <em>port</em> hướng về phía hay ra xa <em>root</em>.</p>
<p>Để các <em>switch</em> có thể học được thông tin cần thiết để dán nhãn cho các <em>port</em> của mình, các <em>switch</em> trao đổi các thông điệp được gọi là <strong><em>Bridge Protocol Data Units (BPDUs)</em> (Các đơn vị dữ liệu giao thức cầu nối)</strong>. Chúng khá giống với các thông điệp định tuyến mặt phẳng điều khiển mà chúng ta đã trao đổi trong các giao thức định tuyến khác, nhưng với một cái tên hoa mỹ. Lưu ý rằng các thông điệp mặt phẳng điều khiển này khác biệt với các <em>packet</em> người dùng mặt phẳng dữ liệu (dữ liệu thực tế mà chúng ta đang chuyển tiếp).</p>
<p>Khi giao thức bắt đầu, mỗi <em>switch</em> đều nghĩ rằng <em>root</em> là chính nó, và chi phí đến <em>root</em> (chính nó) là 0.</p>
<p>Khi giao thức chạy, mỗi <em>switch</em> theo dõi những gì nó nghĩ là <em>root</em>, và con đường tốt nhất đã biết đến <em>root</em> đó (và chi phí của con đường đó).</p>
<img width="600px" src="end-to-end/../assets/end-to-end/5-032-bpdu-start.png">
<p>Khi bạn gửi một <em>BPDU</em>, bạn bao gồm hai mẩu thông tin: Bạn nghĩ <em>root</em> là ai, và bạn cách <em>root</em> bao xa. Ví dụ, một <em>BPDU</em> có thể nói: &quot;Root là R2, và tôi có thể đến R2 với chi phí 7.&quot;</p>
<p>Khi bạn nhận được một <em>BPDU</em>, bạn kiểm tra xem nó có thông tin nào &quot;tốt hơn&quot; không. <em>BPDU</em> có thể tốt hơn vì hai lý do:</p>
<ol>
<li>
<p><em>Root</em> trong <em>BPDU</em> có ID thấp hơn. Điều này có nghĩa là bạn đã khám phá ra một <em>root</em> tốt hơn. Bạn nên từ bỏ <em>root</em> và chi phí hiện tại của mình, và thay vào đó chấp nhận <em>root</em> mới và con đường đến <em>root</em> mới.</p>
</li>
<li>
<p><em>Root</em> trong <em>BPDU</em> là như nhau, nhưng <em>BPDU</em> đang cung cấp một con đường tốt hơn đến <em>root</em>. Bạn nên chấp nhận con đường mới đến <em>root</em>.</p>
</li>
</ol>
<img width="900px" src="end-to-end/../assets/end-to-end/5-033-bpdu-advertisements.png">
<p>Chi phí đến <em>root</em> được tính toán giống như chúng ta đã làm trong <em>distance-vector protocol (giao thức vector khoảng cách)</em>. Ví dụ, giả sử neighbour của bạn nói với bạn &quot;Root là R2, và tôi có thể đến R2 với chi phí 7.&quot; Thì chi phí của bạn đến <em>root</em> là chi phí liên kết trực tiếp của bạn đến neighbour, cộng với chi phí của neighbour đến <em>root</em> (như được chỉ định trong advertise).</p>
<p>Khi bạn cập nhật trạng thái của mình (bạn nghĩ <em>root</em> là ai, hoặc chi phí tốt nhất đã biết của bạn đến <em>root</em>), bạn nên gửi một <em>BPDU</em> đến các neighbour của mình để thông báo cho họ về trạng thái mới của bạn.</p>
<p>Một khi giao thức hội tụ, trạng thái sẽ cung cấp cho mỗi <em>switch</em> đủ thông tin để dán nhãn cho tất cả các <em>port</em> của nó. Bạn biết con đường tốt nhất đến <em>root</em>, vì vậy bạn có thể dán nhãn cho <em>port</em> tương ứng là <em>root port</em>.</p>
<p>Các neighbour của bạn cũng đã nói cho bạn biết họ cách <em>root</em> bao xa. Nếu một neighbour nói rằng họ ở xa hơn, thì bạn có thể dán nhãn cho <em>port</em> tương ứng là một <em>designated port</em>. Nếu một neighbour nói rằng họ ở gần hơn (nhưng họ không nằm trên con đường tốt nhất của bạn đến <em>root</em>), thì bạn có thể dán nhãn cho <em>port</em> tương ứng là một <em>blocked port</em>.</p>
<p>Các <em>BPDU</em> được trao đổi thường xuyên, để nếu <em>topology</em> mạng thay đổi, giao thức có thể thích ứng và tìm ra một cây bao trùm (tức là vô hiệu hóa các liên kết) cho <em>topology</em> mới.</p>
<h2 id="stp-ví-dụ-về-trao-đổi-bpdu"><a class="header" href="#stp-ví-dụ-về-trao-đổi-bpdu">STP: Ví dụ về Trao đổi BPDU</a></h2>
<p>Các <em>router</em> gửi và nhận các trao đổi <em>BPDU</em> song song, vì vậy không có một <em>router</em> cụ thể nào gửi <em>BPDU</em> đầu tiên. Trong ví dụ này, chúng ta sẽ hiển thị một tập hợp con của các <em>BPDU</em> được gửi đi.</p>
<p>Trạng thái ban đầu của R3 nói: Root R3 cách 0. Quảng cáo đầu tiên của R3 gửi trạng thái này đến các neighbour của nó.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-034-bpdu-exchanges-1.png">
<p>R1 nghe thấy advertise này. R1 hiện đang nghĩ <em>root</em> là R1, và advertise cung cấp một <em>root</em> là R3. <em>Root</em> được advertise tệ hơn (ID cao hơn), vì vậy R1 từ chối advertise này.</p>
<p>R6 nghe thấy advertise này. R6 hiện đang nghĩ <em>root</em> là R6, và advertise này cung cấp một <em>root</em> là R3. <em>Root</em> được advertise tốt hơn, vì vậy R6 chấp nhận advertise này. Trạng thái cập nhật của R6 nói: Root R3 cách 1. Lưu ý: Chi phí được tính từ 0, chi phí trong advertise từ R3, cộng với 1, chi phí của liên kết đến R3.</p>
<p>Tại thời điểm này, R6 đã cập nhật trạng thái của mình, vì vậy nó sẽ gửi một advertise đến các neighbour của mình (không được hiển thị trong bản demo này).</p>
<p>Một thời gian sau, R1 gửi một advertise đến các neighbour của nó với trạng thái của nó: Root R1 cách 0.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-035-bpdu-exchanges-2.png">
<p>R2 nghe thấy advertise này. <em>Root</em> được advertise (R1) tốt hơn <em>root</em> hiện đang được biết đến tốt nhất (R2), vì vậy R2 chấp nhận advertise này. Trạng thái cập nhật của R2 nói: Root R1 cách 1.</p>
<p>Tương tự, R3 nghe thấy advertise này, và chấp nhận nó vì <em>root</em> được advertise (R1) tốt hơn <em>root</em> hiện đang được biết đến tốt nhất (R3). Trạng thái cập nhật của R3 nói: Root R1 cách 1.</p>
<p>R2 và R3 đã cập nhật trạng thái của chúng, vì vậy mỗi cái sẽ gửi một advertise đến các neighbour của chúng.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-036-bpdu-exchanges-3.png">
<p>R4 nghe thấy advertise từ R2. <em>Root</em> được advertise (R1) tốt hơn <em>root</em> hiện đang được biết đến tốt nhất (R4), vì vậy R4 chấp nhận advertise này. Trạng thái cập nhật của R4 nói: Root R1 cách 2. Lưu ý: Chi phí này được tính bằng cách cộng 1 (chi phí trong advertise từ R2), cộng với 1 (chi phí liên kết đến R2).</p>
<p>R6 nghe thấy advertise từ R3. <em>Root</em> được advertise (R1) tốt hơn <em>root</em> hiện đang được biết đến tốt nhất (R3), vì vậy R6 chấp nhận advertise này. Trạng thái cập nhật của R6 nói: Root R1 cách 2. Lưu ý: Trạng thái cũ của R6 nói R3 cách 1, và trạng thái mới nói R1 cách 2. Mặc dù trạng thái mới có khoảng cách cao hơn, nó vẫn tốt hơn vì trạng thái mới có một <em>root</em> tốt hơn.</p>
<p>R4 và R6 đã cập nhật trạng thái của mình, vì vậy chúng sẽ gửi advertise đến các neighbour của mình với trạng thái cập nhật của mình. Chúng ta sẽ xem advertise của R4 trước, sau đó quay lại R6 sau (một lần nữa, hãy nhớ rằng tất cả những điều này đang diễn ra song song trong thực tế).</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-037-bpdu-exchanges-4.png">
<p>R5 nghe thấy advertise từ R4. <em>Root</em> được advertise (R1) tốt hơn <em>root</em> hiện đang được biết đến tốt nhất (R5), vì vậy R5 chấp nhận advertise này. Trạng thái cập nhật của R5 nói: Root R1 cách 3 (2 từ advertise, cộng 1 từ chi phí liên kết đến R4).</p>
<p>R6 cũng nghe thấy advertise từ R4. <em>Root</em> được advertise (R1) giống như <em>root</em> hiện đang được biết đến tốt nhất (R1), vì vậy chúng ta cần kiểm tra chi phí. Chấp nhận advertise sẽ cho chi phí là 2 (từ advertise), cộng với 1 (từ chi phí liên kết đến R4), tổng cộng là 3. Chi phí tốt nhất hiện đang được biết đến là 2. Do đó, R6 từ chối advertise (3 tệ hơn 2).</p>
<p>R5 đã cập nhật trạng thái của mình, vì vậy nó sẽ gửi một advertise đến các neighbour của mình với trạng thái cập nhật của mình.</p>
<img width="700px" src="end-to-end/../assets/end-to-end/5-038-bpdu-exchanges-5.png">
<p>R7 nghe thấy advertise từ R5. <em>Root</em> được advertise (R1) tốt hơn <em>root</em> hiện đang được biết đến tốt nhất (R7), vì vậy R7 chấp nhận advertise này.</p>
<p>R7 đã cập nhật trạng thái của mình, và sẽ gửi một advertise đến các neighbour của mình, mặc dù advertise đó không được hiển thị ở đây (R6 sẽ từ chối nó vì có chi phí đến <em>root</em> tệ hơn).</p>
<img width="700px" src="end-to-end/../assets/end-to-end/5-039-bpdu-exchanges-6.png">
<p>Tiếp nối từ trước đó, R6 gửi một advertise đến các neighbour của nó, và R7 nhận được advertise này. <em>Root</em> được advertise (R1) giống như <em>root</em> hiện đang được biết đến tốt nhất (R1), vì vậy chúng ta cần kiểm tra chi phí. Chấp nhận advertise sẽ cho chi phí là 2 (từ advertise), cộng với 1 (từ chi phí liên kết đến R6), tổng cộng là 3. Chi phí tốt nhất hiện đang được biết đến là 4. Do đó, R7 chấp nhận advertise (3 tốt hơn 4), và cập nhật trạng thái của mình để có chi phí đến <em>root</em> là 3 (thay vì 4).</p>
<p>Các <em>router</em> tiếp tục trao đổi advertise định kỳ với nhau. Không phải tất cả các advertise đều được hiển thị trong bản demo này, nhưng cuối cùng, giao thức sẽ hội tụ, và tất cả các <em>router</em> sẽ biết rằng <em>root</em> là R1. Ngoài ra, tất cả các <em>router</em> sẽ biết về chi phí của chúng đến <em>root</em>.</p>
<p>Các <em>router</em> tiếp tục trao đổi advertise định kỳ với nhau. Không phải tất cả các advertise đều được hiển thị trong bản demo này, nhưng cuối cùng, giao thức sẽ hội tụ, và tất cả các <em>router</em> sẽ biết rằng <em>root</em> là R1. Ngoài ra, tất cả các <em>router</em> sẽ biết về chi phí của chúng đến <em>root</em>.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-040-bpdu-exchanges-7.png">
<p>Một khi tất cả các <em>router</em> biết chi phí của chúng đến <em>root</em> đã được thống nhất, chúng có thể trao đổi các advertise định kỳ. Điều này cho phép các <em>router</em> tìm hiểu về giá trị chi phí đến <em>root</em> của các neighbour, điều này lần lượt cho phép các <em>router</em> gán các <em>port</em> là DP, RP, hoặc BP.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="arp-kết-nối-lớp-2-và-lớp-3"><a class="header" href="#arp-kết-nối-lớp-2-và-lớp-3">ARP: Kết nối Lớp 2 và Lớp 3</a></h1>
<h2 id="kết-nối-lớp-2-và-lớp-3"><a class="header" href="#kết-nối-lớp-2-và-lớp-3">Kết nối Lớp 2 và Lớp 3</a></h2>
<p>Hãy nhớ lại rằng các <em>packets</em> (gói tin) được bọc thêm các <em>headers</em> (phần đầu) khi chúng di chuyển xuống chồng giao thức, đến các lớp thấp hơn. Để gửi một <em>IP packet</em> (gói tin IP), trước tiên chúng ta điền địa chỉ IP đích của nó ở <em>Layer 3</em> (Lớp 3). Sau đó, chúng ta chuyển <em>packet</em> đó xuống <em>Layer 2</em> (Lớp 2), nơi chúng ta phải thêm một <em>MAC address</em> (địa chỉ MAC) để gửi <em>packet</em> đi dọc theo <em>link</em>. Chúng ta sẽ thêm <em>MAC address</em> nào?</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-041-arp-blank-mac.png">
<p>Đầu tiên, chúng ta cần kiểm tra xem IP đích có phải là một ai đó trong <em>local network</em> của chúng ta, hay là một ai đó trong một <em>local network</em> khác. Để xác định điều này, <em>forwarding table</em> (bảng chuyển tiếp) của người gửi sẽ có một mục nhập chỉ ra dải địa chỉ IP cục bộ, đôi khi được gọi là <em>subnet</em> (mạng con) của chúng ta. Ví dụ, mục nhập có thể nói rằng 192.0.2.0/24 là <em>direct</em> (trực tiếp), có nghĩa là tất cả các địa chỉ từ 192.0.2.0 đến 192.0.2.255 đều nằm trên cùng một <em>local network</em>. Bảng này cũng có một <em>default route</em> (tuyến mặc định), cho biết rằng tất cả các đích khác không thuộc mạng cục bộ sẽ được chuyển tiếp đến <em>router</em>.</p>
<p>Nếu IP đích nằm trong <em>subnet</em> của chúng ta, chúng ta cần một cách nào đó để dịch giữa địa chỉ IP đích và <em>MAC address</em> tương ứng của máy đó. Nếu đích nằm ngoài <em>subnet</em> của chúng ta, chúng ta cần một cách nào đó để dịch địa chỉ IP của <em>router</em> (từ <em>forwarding table</em>) sang <em>MAC address</em> tương ứng của nó, để chúng ta có thể gửi <em>packet</em> đến <em>router</em>.</p>
<p>Một giải pháp ngây thơ là <em>broadcast</em> (quảng bá) mọi <em>packet</em>, để đích hoặc <em>router</em> chắc chắn sẽ nhận và xử lý nó. Tuy nhiên, điều này không hiệu quả. Nó buộc mọi người phải phân tích cú pháp mọi <em>packet</em> (ví dụ: đọc các <em>headers</em> <em>Layer 3</em>) để kiểm tra xem <em>packet</em> có dành cho họ hay không. Ngoài ra, nếu mạng <em>Layer 2</em> có nhiều hơn một <em>link</em>, các <em>switches</em> ở <em>Layer 2</em> phải <em>flood</em> (tràn ngập) <em>packet</em> trên tất cả các <em>links</em>.</p>
<p>Một cách tiếp cận tốt hơn là dịch địa chỉ IP đích sang <em>MAC address</em> tương ứng của nó (nếu là cục bộ) hoặc <em>MAC address</em> của <em>router</em> (nếu không phải cục bộ), và <em>unicast</em> (truyền đơn hướng) <em>packet</em> ở <em>Layer 2</em>.</p>
<h2 id="arp-address-resolution-protocol"><a class="header" href="#arp-address-resolution-protocol">ARP: Address Resolution Protocol</a></h2>
<p><strong>ARP (Address Resolution Protocol - Giao thức phân giải địa chỉ)</strong> cho phép các máy dịch một địa chỉ IP thành <em>MAC address</em> tương ứng của nó.</p>
<p>Để yêu cầu một bản dịch, một máy có thể <em>broadcast</em> một thông điệp yêu cầu: &quot;Tôi có <em>MAC address</em> <em>f8:ff:c2:2b:36:16</em>. <em>MAC address</em> của máy có IP 192.0.2.1 là gì?&quot;</p>
<p>Tất cả các máy không có địa chỉ IP này sẽ bỏ qua thông điệp. Người dùng có địa chỉ IP này sẽ <em>unicast</em> một phản hồi đến <em>MAC address</em> của người gửi, nói rằng &quot;Tôi là 192.0.2.1, và <em>MAC address</em> của tôi là <em>a2:ff:28:02:f2:10</em>.&quot;</p>
<p>Các máy cũng có thể <em>broadcast</em> ánh xạ IP-tới-MAC của chính chúng cho mọi người, ngay cả khi không ai hỏi.</p>
<p>Khi bạn nhận được một ánh xạ IP-tới-MAC, bạn có thể thêm nó vào <em>ARP Table</em> (Bảng ARP) cục bộ của mình, bảng này lưu trữ các ánh xạ này để sử dụng trong tương lai. Bảng này cũng bao gồm ngày hết hạn cho mỗi mục nhập, vì địa chỉ IP không được gán vĩnh viễn cho một máy tính. Một máy tính khác có thể được gán cùng một địa chỉ IP, hoặc cùng một máy tính có thể thay đổi địa chỉ IP. (TODO: interfaces?)</p>
<p>Bước 1:</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-042-arp1.png">
<p>Bước 2:</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-043-arp2.png">
<p>Bước 3:</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-044-arp3.png">
<p>Bước 4:</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-045-arp4.png">
<p>Lưu ý rằng <em>ARP</em> chạy trực tiếp trên <em>Layer 2</em>, vì vậy tất cả các <em>packets</em> được gửi và nhận qua <em>Ethernet</em>, không phải <em>IP</em>.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-046-arp5.png">
<h2 id="kết-nối-bảng-arp-và-bảng-chuyển-tiếp"><a class="header" href="#kết-nối-bảng-arp-và-bảng-chuyển-tiếp">Kết nối Bảng ARP và Bảng Chuyển tiếp</a></h2>
<p>Hãy nhớ lại rằng trong <em>forwarding table</em> của một <em>router</em>, đôi khi chúng ta sẽ bao gồm một mục nhập chỉ ra rằng một <em>host</em> được kết nối trực tiếp với <em>router</em>.</p>
<p>Trong thực tế, <em>forwarding table</em> của <em>router</em> chứa một mục nhập duy nhất, ánh xạ toàn bộ dải địa chỉ IP của <em>subnet</em> là <em>direct</em>. Nếu <em>router</em> nhận được một <em>packet</em> có đích nằm trong dải cục bộ này, <em>router</em> sẽ chạy <em>ARP</em> để tìm <em>MAC address</em> tương ứng, và sử dụng <em>Layer 2</em> để gửi <em>packet</em> đến đúng <em>host</em> trên <em>link</em>.</p>
<img width="600px" src="end-to-end/../assets/end-to-end/5-047-direct-route.png">
<p>Điều này cũng giúp chúng ta trong trường hợp nhiều <em>hosts</em> được kết nối trên cùng một <em>link</em>. Trong hình ảnh khái niệm của chúng ta, chúng ta sẽ nói rằng <em>Host</em> A được kết nối trực tiếp trên Cổng 1. Nhiều <em>hosts</em> có thể nằm trên <em>link</em> đó, vì vậy bằng cách sử dụng <em>ARP</em>, chúng ta có thể tạo ra một <em>packet</em> <em>Layer 2</em> được <em>unicast</em> chỉ đến <em>Host</em> A, chứ không phải các máy tính khác trên <em>link</em>.</p>
<p>Với một mục nhập chuyển tiếp ánh xạ một <em>subnet</em> như 192.0.2.0/24 là <em>direct</em>, làm thế nào chúng ta có thể xác định xem một địa chỉ IP đã cho có nằm trong dải đó hay không? Đây là lúc việc viết các dải địa chỉ bằng <em>netmask</em> (mặt nạ mạng) thay vì <em>slash notation</em> (ký hiệu gạch chéo) trở nên hữu ích. Hãy nhớ lại rằng để viết dải này dưới dạng <em>netmask</em>, chúng ta đặt tất cả các bit cố định thành 1 và tất cả các bit không cố định thành 0, để có được 255.255.255.0. Sau đó, dải được biểu thị là 192.0.2.0 với <em>netmask</em> 255.255.255.0.</p>
<p>Bây giờ, để kiểm tra xem một địa chỉ có nằm trong dải hay không, chúng ta thực hiện phép toán AND bit của địa chỉ và <em>netmask</em>. Điều này làm cho tất cả các bit thấp không cố định bị đưa về 0, chỉ giữ lại các bit cao cố định. Sau đó, chúng ta kiểm tra xem kết quả có khớp với 192.0.2.0 (địa chỉ đầu tiên trong dải, nơi tất cả các bit không cố định là 0) hay không.</p>
<p>Lưu ý rằng khi các <em>packets</em> được chuyển tiếp qua các <em>hops</em> (chặng), đích <em>Layer 2</em> sẽ thay đổi thành <em>MAC address</em> của <em>hop</em> tiếp theo, để các <em>packets</em> có thể di chuyển qua các <em>links</em>. Tuy nhiên, đích <em>Layer 3</em> vẫn giữ nguyên qua mỗi <em>hop</em>.</p>
<img width="700px" src="end-to-end/../assets/end-to-end/5-048-arp-filled-in-mac.png">
<h2 id="neighbor-discovery-trong-ipv6"><a class="header" href="#neighbor-discovery-trong-ipv6">Neighbor Discovery trong IPv6</a></h2>
<p><em>ARP</em> dịch địa chỉ IPv4 sang <em>MAC addresses</em>. Để dịch địa chỉ IPv6 sang <em>MAC addresses</em>, chúng ta sử dụng một giao thức tương tự gọi là <strong>neighbor discovery</strong> (khám phá lân cận).</p>
<p>Thay vì <em>broadcast</em> yêu cầu dịch IP-tới-MAC, <em>neighbor discovery</em> thay vào đó <em>multicasts</em> (truyền đa hướng) yêu cầu đến một nhóm cụ thể, và mỗi máy tính lắng nghe trên một nhóm cụ thể dựa trên địa chỉ IP của nó. Ví dụ, tất cả mọi người có địa chỉ IP kết thúc bằng 12:3456 có thể lắng nghe trên nhóm <em>MAC address</em> 33:33:FF:12:34:56, trong khi tất cả mọi người có địa chỉ IP kết thúc bằng 78:90AB có thể lắng nghe trên nhóm <em>MAC address</em> 33:33:FF:78:90:AB.</p>
<p>Nếu tôi muốn <em>MAC address</em> tương ứng với người dùng có địa chỉ IPv6 kết thúc bằng 12:3456, tôi có thể cắm các bit IPv6 đó vào <em>MAC address</em> nhóm để có được 33:33:FF:12:34:56, và tôi biết rằng người dùng có địa chỉ IP đó phải đang lắng nghe <em>MAC address</em> nhóm này.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-049-neighbor-discovery.png">
<p>Một số thuật ngữ: Trong giao thức <em>neighbor discovery</em>, yêu cầu ánh xạ được gọi là <em>Neighbor Solicitation</em> (Yêu cầu thông tin lân cận), và phản hồi chứa ánh xạ được gọi là <em>Neighbor Advertisement</em> (Quảng cáo thông tin lân cận).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dhcp-gia-nhập-mạng"><a class="header" href="#dhcp-gia-nhập-mạng">DHCP: Gia nhập Mạng</a></h1>
<h2 id="gia-nhập-mạng"><a class="header" href="#gia-nhập-mạng">Gia nhập Mạng</a></h2>
<p>Khi một máy tính lần đầu tiên gia nhập mạng, nó cần những thông tin gì để kết nối với Internet?</p>
<p>Chúng ta luôn biết <em>MAC address</em> (địa chỉ MAC) của chính mình, vì nó được ghi cứng vào phần cứng.</p>
<p>Chúng ta cần được cấp phát một <em>IP address</em> để có thể gửi và nhận các <em>packets</em>. Nhớ lại rằng, các <em>IP addresses</em> được phân bổ theo vị trí địa lý, vì vậy khi chúng ta kết nối với một mạng mới, ai đó phải cấp cho chúng ta một <em>IP address</em> để sử dụng.</p>
<p>Chúng ta cần biết <em>subnet mask</em> (mặt nạ mạng con) để có thể biết được dải địa chỉ IP cục bộ. Với <em>subnet mask</em> (các bit cố định đều là một, các bit không cố định đều là không), chúng ta có thể thực hiện phép toán AND bit với <em>IP address</em> của chính mình để biết được <em>IP prefix</em> cục bộ.</p>
<p>Chúng ta cần biết <em>router</em> trên mạng cục bộ là ai, để có thể gửi bất kỳ <em>packets</em> nào không thuộc mạng cục bộ đến <em>router</em>. Đôi khi chúng ta gọi <em>router</em> này là <strong><em>default gateway</em> (cổng vào mặc định)</strong>.</p>
<p>Chúng ta cũng có thể cần biết <em>DNS recursive resolver</em> (bộ phân giải đệ quy DNS) của mạng này nằm ở đâu.</p>
<p>Người dùng có thể cấu hình thủ công các giá trị này khi họ lần đầu tiên tham gia mạng. Việc này tốn thời gian, đặc biệt là vì chúng ta phải cấu hình lại các giá trị này mỗi khi tham gia một mạng khác. Ngoài ra, người dùng Internet trung bình có lẽ không biết cách cấu hình các giá trị này theo cách thủ công. Tuy nhiên, việc cấu hình thủ công đôi khi vẫn có hiệu quả đối với các máy như <em>routers</em>, vốn không thường xuyên di chuyển.</p>
<p>Chúng ta cần một giao thức cho phép các <em>hosts</em> mới tự động tìm hiểu các giá trị này (và có thể cả các thông tin hữu ích khác).</p>
<h2 id="dhcp-dynamic-host-configuration-protocol-giao-thức-cấu-hình-máy-chủ-Động"><a class="header" href="#dhcp-dynamic-host-configuration-protocol-giao-thức-cấu-hình-máy-chủ-Động">DHCP: Dynamic Host Configuration Protocol (Giao thức Cấu hình Máy chủ Động)</a></h2>
<p><em>DHCP</em> có bốn bước:</p>
<ol>
<li>
<p>Client mới <em>broadcasts</em> (quảng bá) một <strong><em>Discover message</em> (thông điệp Khám phá)</strong>, yêu cầu thông tin cấu hình.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-050-dhcp1.png">
</li>
<li>
<p>Bất kỳ <strong><em>DHCP server</em> (máy chủ DHCP)</strong> nào có thể giúp đỡ sẽ <em>unicast</em> (truyền đơn hướng) một <strong><em>Offer</em> (Chào giá)</strong> đến client, với một cấu hình mà client có thể sử dụng (ví dụ: <em>IP address</em>, địa chỉ <em>gateway</em>, địa chỉ <em>DNS</em>).</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-051-dhcp2.png">
</li>
<li>
<p>Client sẽ <em>broadcast</em> một <strong><em>Request message</em> (thông điệp Yêu cầu)</strong>, cho biết họ đã chấp nhận <em>offer</em> nào. Thông điệp này được <em>broadcast</em> vì client có thể nhận được nhiều <em>offers</em>. Bằng cách thông báo cho mọi người biết mình chấp nhận <em>offer</em> nào, client cho phép các <em>offers</em> bị từ chối được giải phóng cho các client trong tương lai.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-052-dhcp3.png">
</li>
<li>
<p><em>Server</em> gửi một <strong><em>acknowledgement</em> (thông điệp xác nhận)</strong> để xác nhận rằng yêu cầu đã được chấp thuận.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-053-dhcp4.png">
</li>
</ol>
<h2 id="các-dhcp-server"><a class="header" href="#các-dhcp-server">Các DHCP Server</a></h2>
<p>Ở bước 2, ai có thể cung cấp cấu hình? Các <em>DHCP servers</em> được thêm vào mạng, và mục tiêu của chúng là cung cấp thông tin này cho các <em>hosts</em> mới. Trên các mạng nhỏ hơn như mạng gia đình của bạn, chính <em>home router</em> (router gia đình) thường đóng vai trò là <em>DHCP server</em>. Trong các mạng lớn hơn, có thể có một máy riêng biệt đóng vai trò là <em>DHCP server</em>.</p>
<p>Các <em>DHCP servers</em> cần phải ở trong cùng một mạng cục bộ với client, vì giao thức hoạt động bên trong mạng cục bộ. Trong các mạng lớn hơn, chúng ta có thể không muốn chạy mã <em>DHCP server</em> bên trong mọi <em>router</em>, vì vậy các <em>routers</em> cục bộ có thể chuyển tiếp các yêu cầu đến một <em>DHCP server</em> trung tâm từ xa, nơi thực sự chạy giao thức.</p>
<p>Các <em>DHCP servers</em> lắng nghe trên một cổng cố định, cổng <em>UDP</em> 67, để nhận các yêu cầu từ các máy mới. Các <em>servers</em> được cấu hình với tất cả các thông tin cần thiết: Chúng biết về <em>gateway</em> và các <em>DNS servers</em>, và chúng có một nhóm các <em>IP addresses</em> có thể sử dụng mà chúng có thể phân bổ cho người dùng mới.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-054-dhcp-over-ip.png">
<p>Lưu ý rằng các <em>IP addresses</em> chỉ được <em>lease</em> (thuê) tạm thời cho các <em>hosts</em>. Việc <em>lease</em> chỉ có hiệu lực trong một khoảng thời gian giới hạn (ví dụ: cỡ giờ hoặc ngày). Nếu <em>host</em> muốn tiếp tục sử dụng địa chỉ, nó phải gia hạn <em>lease</em>. Nếu một <em>IP address</em> hiện đang được <em>lease</em> cho một <em>host</em>, <em>DHCP server</em> không thể cung cấp cùng một địa chỉ cho các client khác.</p>
<h2 id="triển-khai-dhcp"><a class="header" href="#triển-khai-dhcp">Triển khai DHCP</a></h2>
<p>Lưu ý rằng <em>DHCP</em> là một giao thức ứng dụng <em>Layer 7</em> (Lớp 7), và nó chạy trên <em>UDP</em>, bản thân <em>UDP</em> lại chạy trên IP.</p>
<p>Ở bước 1, làm thế nào client <em>broadcast</em> một thông điệp qua IP? Nó gửi một <em>packet</em> với IP đích là 255.255.255.255 (toàn bit một), đây là <em>IPv4 broadcast address</em> (địa chỉ quảng bá IPv4). Khi <em>packet</em> này được chuyển xuống <em>Layer 2</em> (Lớp 2), thay vì dịch <em>IP address</em> này bằng <em>ARP</em>, <em>IPv4 broadcast address</em> được ánh xạ tới <em>Ethernet broadcast address</em> (địa chỉ quảng bá Ethernet) là FF:FF:FF:FF:FF:FF (toàn bit một). Sau đó, <em>packet</em> có thể được <em>broadcast</em> trên toàn mạng ở <em>Layer 2</em>.</p>
<p>Còn IP nguồn thì sao? Client không có IP nguồn khi bắt đầu giao thức, vì vậy nó đặt IP nguồn là 0.0.0.0.</p>
<p>Với IP nguồn được mã hóa cứng là 0.0.0.0 và IP đích là 255.255.255.255, client không cần biết bất cứ điều gì về mạng cục bộ để bắt đầu chạy giao thức này.</p>
<p>Nếu không có IP nguồn, làm thế nào các <em>DHCP servers</em> biết cách <em>unicast</em> các <em>offers</em>? Các <em>DHCP servers</em> có thể <em>broadcast</em> các <em>offers</em>, hoặc sử dụng <em>MAC address</em> của client để <em>unicast</em> các <em>offers</em>.</p>
<h2 id="tự-động-cấu-hình-trong-ipv6"><a class="header" href="#tự-động-cấu-hình-trong-ipv6">Tự động cấu hình trong IPv6</a></h2>
<p><em>DHCP</em> cũng tồn tại trong các mạng <em>IPv6</em>. Tuy nhiên, vì các địa chỉ <em>IPv6</em> dài hơn, hóa ra chúng ta có thể tự cấp cho mình một địa chỉ <em>IPv6</em> duy nhất được đảm bảo mà không cần ai khác quản lý một nhóm địa chỉ và cho thuê chúng. Giao thức này được gọi là <strong><em>Stateless Address Autoconfiguration (SLAAC)</em> (Tự động cấu hình địa chỉ không trạng thái)</strong>.</p>
<p>Thủ thuật ở đây là sử dụng <em>MAC address</em>, mà chúng ta biết là duy nhất cho mỗi máy. Như trước đây, chúng ta yêu cầu thông tin mạng cục bộ, bao gồm địa chỉ <em>gateway</em>, địa chỉ <em>DNS</em>, và đáng chú ý là <em>prefix</em> cho mạng cục bộ. <em>Prefix</em> này thường dài 64 bit. Sau đó, chúng ta sao chép các bit <em>MAC address</em> của chính mình vào các bit <em>host</em> của địa chỉ <em>IPv6</em>. Chúng ta có thể tự tin rằng không ai khác có địa chỉ <em>IPv6</em> này: người dùng trong các mạng khác sẽ có một <em>prefix</em> khác, và không ai khác trong mạng (hoặc bất kỳ nơi nào khác) sẽ có cùng các bit <em>MAC address</em>.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-055-slaac.png">
<p>Để có được thông tin mạng cục bộ, chúng ta có thể mở rộng <em>Neighbor Discovery protocol</em> (giao thức Khám phá Láng giềng) (phiên bản <em>IPv6</em> của <em>ARP</em>). <em>Router Solicitation message</em> (thông điệp Yêu cầu Router) cho phép người dùng <em>broadcast</em> một yêu cầu thông tin mạng cục bộ, và <em>Router Advertisement message</em> (thông điệp Quảng bá Router) cho phép các <em>routers</em> trả lời bằng thông tin đó.</p>
<p><em>SLAAC</em> có thêm các cơ chế để phát hiện các địa chỉ trùng lặp, phòng trường hợp cần thiết.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nat-network-address-translation-chuyển-đổi-địa-chỉ-mạng"><a class="header" href="#nat-network-address-translation-chuyển-đổi-địa-chỉ-mạng">NAT: <em>Network Address Translation</em> (Chuyển đổi địa chỉ mạng)</a></h1>
<h2 id="Động-cơ-cạn-kiệt-địa-chỉ-ipv4"><a class="header" href="#Động-cơ-cạn-kiệt-địa-chỉ-ipv4">Động cơ: Cạn kiệt địa chỉ <em>IPv4</em></a></h2>
<p>Hãy nhớ rằng chúng ta chỉ có $$2^{32}$$ địa chỉ <em>IPv4</em> khác nhau, con số này không đủ để gán cho mọi <em>host</em> (máy chủ/máy trạm) trên Internet. Chúng ta đã thấy rằng <em>IPv6</em> là một giải pháp mạnh mẽ cho vấn đề cạn kiệt địa chỉ <em>IPv4</em>, nhưng việc triển khai <em>IPv6</em> diễn ra khá chậm.</p>
<p>Trong thời gian chờ đợi, để tiết kiệm địa chỉ, <em>IANA</em> đã phân bổ các dải địa chỉ IP riêng (<em>private IP addresses</em>) theo chuẩn RFC 1918, có thể được sử dụng bởi bất kỳ mạng nào không yêu cầu địa chỉ Internet công cộng: 192.168.0.0/16, 10.0.0.0/8 và 172.16.0.0/12. Thực tế, các địa chỉ này thường được dùng trong mạng gia đình, giúp thiết bị cá nhân của bạn không cần một địa chỉ IP công cộng duy nhất. Tuy nhiên, bạn vẫn cần truy cập Internet, vậy làm thế nào để sử dụng địa chỉ IP riêng?</p>
<h2 id="nat-khái-niệm"><a class="header" href="#nat-khái-niệm">NAT: Khái niệm</a></h2>
<p>Trong <em>NAT</em>, mục tiêu là sử dụng một địa chỉ IP công cộng duy nhất để đại diện cho nhiều <em>host</em> trong mạng nội bộ. Mấu chốt là <em>gateway router</em> (bộ định tuyến cổng) sẽ chuyển đổi địa chỉ IP riêng thành địa chỉ công cộng trước khi gửi gói tin ra ngoài. Sau đó, <em>router</em> sẽ chuyển đổi địa chỉ công cộng trở lại thành địa chỉ riêng cho các gói tin phản hồi đi vào.</p>
<p>Alice, Bob và Chuck cùng làm việc tại tiệm lốp xe của Joe. Họ có các địa chỉ IP riêng A, B và C, vốn không thể sử dụng trực tiếp trên Internet vì không duy nhất. Thay vào đó, tất cả mọi người trong tiệm phải chia sẻ một địa chỉ IP công cộng duy nhất – đây là địa chỉ duy nhất và hợp lệ trên Internet mà họ có.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-056-nat1.png">
<p>Alice muốn gửi một thông điệp đến máy chủ công cộng bên ngoài có địa chỉ IP công cộng S. Cô gửi một <em>packet</em> (gói tin) với thông tin: &quot;From: A, To: S&quot;. Nếu gửi gói tin này trực tiếp, S sẽ không thể phản hồi vì A là địa chỉ IP riêng.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-057-nat2.png">
<p>Thay vào đó, khi gói tin đến <em>gateway router</em>, nó sẽ ghi lại tiêu đề thành &quot;From: R1, To: S&quot;. <em>Router</em> cũng ghi chú: Nếu nhận được phản hồi từ S, hãy gửi cho A.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-058-nat3.png">
<p>Khi S nhận được gói tin, nó sẽ phản hồi đến địa chỉ công cộng R1: &quot;From: S, To: R1&quot;. Khi R1 nhận được phản hồi, nó kiểm tra ghi chú và sửa tiêu đề thành &quot;From: S, To: A&quot;, rồi gửi gói tin về cho A.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-059-nat4.png">
<p>Nhờ vậy, Alice, Bob và Chuck đều có thể gửi gói tin ra ngoài. Khi <em>router</em> nhận gói tin, nó phải ghi nhớ ánh xạ giữa đích bên ngoài và nguồn bên trong (&quot;B vừa gửi gói tin đến N, nên mọi phản hồi từ N phải gửi lại cho B&quot;).</p>
<p>Vấn đề phát sinh nếu Alice và Bob cùng muốn giao tiếp với S.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-060-nat5.png">
<p>Khi phản hồi từ S đến, <em>router</em> sẽ không biết nên gửi cho A hay B.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-061-nat6.png">
<p>Chúng ta có thể giải quyết bằng cách sử dụng <em>logical ports</em> (cổng logic) từ <em>Layer 4</em>. Kết nối của Alice: &quot;From: A, Port 50000, To: S, Port 80&quot;. <em>Router</em> chuyển thành &quot;From: R1, Port 50000, To: S, Port 80&quot; và ghi chú: nếu nhận phản hồi từ S, Port 80, đến R1, Port 50000 thì gửi cho A.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-062-nat7.png">
<p>Bob có thể tạo kết nối riêng: &quot;From: B, Port 60000, To: S, Port 80&quot;. <em>Router</em> chuyển thành &quot;From: R1, Port 60000, To: S, Port 80&quot; và ghi chú: nếu nhận phản hồi từ S, Port 80, đến R1, Port 60000 thì gửi cho B.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-063-nat8.png">
<p>Nói chung, <em>router</em> sẽ theo dõi kết nối bằng bộ 5 thông tin (<em>5-tuple</em>): địa chỉ IP nguồn, địa chỉ IP đích, giao thức, <em>source port</em> (cổng nguồn) và <em>destination port</em> (cổng đích). Khi nhận gói tin đi ra, <em>router</em> đổi IP nguồn riêng thành IP nguồn công cộng và lưu bộ 5-tuple. Khi nhận gói tin đi vào, <em>router</em> tra bảng để tìm kết nối tương ứng và gửi đến <em>client</em> phù hợp (với IP riêng của họ).</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-064-nat9.png">
<h2 id="thay-đổi-số-cổng-của-client"><a class="header" href="#thay-đổi-số-cổng-của-client">Thay đổi số cổng của <em>Client</em></a></h2>
<p>Vấn đề cuối cùng: nếu Alice và Bob cùng chọn cùng một số cổng (ví dụ Port 50000)?</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-065-nat10.png">
<p>Khi đó, <em>router</em> sẽ lưu hai kết nối: (A Port 50000 → S Port 80) và (B Port 50000 → S Port 80). Nếu nhận gói tin &quot;From: S, Port 80, To: R1, Port 50000&quot;, sẽ không rõ gói tin thuộc kết nối của A hay B.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-066-nat11.png">
<p>Giải pháp là cho phép <em>router</em> thay đổi cả số cổng. Khi Bob gửi &quot;From: B, Port 50000, To: S, Port 80&quot;, <em>router</em> nhận thấy Port 50000 đã được dùng cho kết nối đến S Port 80, nên tạo một <em>fake port</em> (cổng giả) cho Bob, ví dụ 60000, và chuyển thành &quot;From: R1, Port 60000, To: S, Port 80&quot;.</p>
<p><em>Router</em> lưu: (B Port 50000, giả thành 60000, → S Port 80).</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-067-nat12.png">
<p>Khi nhận gói tin &quot;From: S, Port 80, To: R1, Port 50000&quot; → của Alice; còn &quot;From: S, Port 80, To: R1, Port 60000&quot; → của Bob.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-068-nat13.png">
<p>Bob không hề biết <em>router</em> đã đổi số cổng. Khi <em>router</em> gửi lại gói tin cho Bob, nó đổi cổng giả về cổng gốc.</p>
<h2 id="nat-triển-khai"><a class="header" href="#nat-triển-khai">NAT: Triển khai</a></h2>
<p>Khi <em>home router</em> (router gia đình) kết nối <em>ISP</em> lần đầu, nó có thể chạy <em>DHCP</em> để nhận địa chỉ IP công cộng. <em>ISP</em> cấp một địa chỉ IP duy nhất cho <em>home router</em>, và tất cả thiết bị trong mạng gia đình sẽ chia sẻ địa chỉ này.</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-069-nat-dhcp.png">
<p>Chế độ NAT vừa mô tả gọi là <strong>Port Address Translation (PAT)</strong> – cho phép tạo <em>fake port</em>. PAT yêu cầu <em>router</em> hiểu <em>Layer 4</em> để phân tích gói tin, theo dõi kết nối và sửa tiêu đề.</p>
<p>PAT là chế độ NAT phức tạp và phổ biến nhất, nhưng cũng có chế độ NAT đơn giản hơn cho ánh xạ một-một. Ví dụ: 10.0.0.1 (riêng) ↔ 42.0.2.1 (công cộng).</p>
<img width="400px" src="end-to-end/../assets/end-to-end/5-070-simpler-nat.png">
<h2 id="nat-được-dùng-ở-đâu"><a class="header" href="#nat-được-dùng-ở-đâu">NAT được dùng ở đâu?</a></h2>
<p>NAT làm tăng độ phức tạp của <em>packet forwarding</em> (chuyển tiếp gói tin) vì <em>router</em> phải phân tích cả tiêu đề <em>Layer 4</em>, sửa tiêu đề <em>Layer 3</em> và <em>Layer 4</em>, và duy trì bảng trạng thái kết nối. Điều này tiêu tốn CPU và bộ nhớ.</p>
<p>Vì vậy, NAT thường được triển khai ở rìa mạng (<em>edge</em>), ví dụ trên <em>home router</em> (router gia đình), để giới hạn số lượng luồng (<em>flow</em>) đi qua router. Chạy NAT trên router gia đình là hợp lý vì thường không có quá nhiều thiết bị trong nhà gửi kết nối ra ngoài. Ngược lại, chạy NAT trên các <em>datacenter router</em> (router trung tâm dữ liệu) hiệu năng cao sẽ là ý tưởng tồi.</p>
<p>Trong thực tế, NAT quy mô nhỏ được sử dụng trong hầu hết các mạng cá nhân (gia đình/văn phòng) cho <em>IPv4</em>, ngay cả ngày nay. Khi địa chỉ <em>IPv4</em> cạn kiệt, các <em>ISP</em> (nhà cung cấp dịch vụ Internet) không thể cấp một địa chỉ công cộng cho mỗi khách hàng (tức mỗi router gia đình). Kết quả là, chính mạng của ISP cũng phải chạy một phiên bản NAT phức tạp hơn gọi là <strong>Carrier Grade NAT (CGNAT)</strong>. Phiên bản này được triển khai sâu hơn trong mạng và yêu cầu router theo dõi nhiều kết nối hơn rất nhiều.</p>
<p>Lưu ý rằng chúng ta thường không dùng NAT cho <em>IPv6</em>, vì <em>IPv6</em> có đủ địa chỉ để gán một địa chỉ công cộng duy nhất cho mọi máy tính trên thế giới.</p>
<h2 id="kết-nối-đến-inbound-connections"><a class="header" href="#kết-nối-đến-inbound-connections">Kết nối đến (<em>Inbound Connections</em>)</a></h2>
<p>Cho đến giờ, chúng ta giả định rằng các kết nối luôn được khởi tạo từ phía <em>client</em> (máy khách) có địa chỉ IP riêng. Nói cách khác, gói tin đầu tiên luôn đi ra ngoài, từ <em>client</em> đến <em>server</em>. Điều này phù hợp với cách hầu hết các mạng gia đình hoạt động: khi bạn tải một trang web, bạn là bên khởi tạo kết nối. Thông thường, không ai từ bên ngoài cố gắng kết nối đến bạn.</p>
<p>Nhưng nếu bạn đang chạy một <em>server</em> và muốn người bên ngoài có thể khởi tạo kết nối đến <em>server</em> này thì sao? Người dùng bên ngoài không thể gửi gói tin trực tiếp đến địa chỉ IP riêng. Họ có thể gửi đến địa chỉ IP công cộng của router, nhưng nếu router nhận được gói tin như &quot;From: outside user, To: R1, Port 28&quot;, router sẽ không biết phải chuyển tiếp đến <em>client</em> riêng nào. Đây là gói tin đầu tiên của một kết nối mới, nên bảng NAT của router chưa có thông tin về kết nối này.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-071-inbound-nat.png">
<p>Để cho phép kết nối đến, router chạy NAT cần có <strong>port mapping table</strong> (bảng ánh xạ cổng). Ví dụ, Alice (bên trong mạng, chỉ có IP riêng) thông báo cho router: &quot;Tôi sẽ chạy một <em>server</em> mới và lắng nghe trên Port 28&quot;. Khi đó, nếu router thấy gói tin từ bên ngoài gửi đến R1, Port 28, nó sẽ biết cần chuyển tiếp gói tin này cho Alice.</p>
<p>Các mục trong bảng ánh xạ cổng có thể cần cấu hình thủ công (ví dụ: Alice cấu hình router bằng tay). Các giao thức động như <em>UPnP</em> (<em>Universal Plug-n-Play</em>) và <em>NAT-PMP</em> (<em>NAT Port Mapping Protocol</em>) cho phép cấu hình cổng mở một cách tự động. Các giao thức này đôi khi được dùng bởi ứng dụng như trò chơi trực tuyến, nơi cần kết nối đến từ bên ngoài.</p>
<h2 id="tác-động-bảo-mật-của-nat-security-implications-of-nat"><a class="header" href="#tác-động-bảo-mật-của-nat-security-implications-of-nat">Tác động bảo mật của NAT (<em>Security Implications of NAT</em>)</a></h2>
<p>NAT phá vỡ <em>End-to-end Principle</em> (nguyên tắc đầu-cuối). Trước đây, với <em>Layer 3</em>, bất kỳ ai trên Internet cũng có thể kết nối đến bất kỳ ai khác. Tuy nhiên, vì NAT không cho phép kết nối đến theo mặc định, người dùng trong mạng gia đình (chỉ có IP riêng và chia sẻ IP công cộng) sẽ không thể được truy cập trực tiếp. Họ phải cấu hình router trước khi có thể nhận gói tin đến.</p>
<p>NAT có đặc điểm là chặn kết nối đến theo mặc định. Điều này có thể được xem như một tính năng bảo mật, dù thực chất chỉ là hệ quả phụ chứ không phải mục tiêu thiết kế. NAT khiến các kết nối đến bị chặn, điều này có thể hữu ích để ngăn kẻ tấn công kết nối vào các <em>host</em> bên trong mạng. Hành vi này khá giống với <em>firewall</em> (tường lửa), vốn cũng thường chặn kết nối đến theo mặc định. Tuy nhiên, đây chỉ là sự trùng hợp, nên NAT không thực sự thực thi một chính sách bảo mật có nguyên tắc, và không nên được coi là một biện pháp phòng thủ tuyệt đối.</p>
<p>NAT cũng có tác dụng phụ là giúp bảo vệ quyền riêng tư của <em>client</em>. Một lần nữa, đây không phải là tính năng bảo mật được thiết kế chủ đích. Vì router thay đổi địa chỉ IP của <em>client</em>, khi <em>server</em> nhận gói tin, nó không biết chính xác ai là người gửi ban đầu (có thể là Alice, Bob hoặc Chuck).</p>
<p>Ngược lại, nếu không dùng NAT, <em>server</em> có thể biết chính xác danh tính của người gửi. Ngoài ra, nếu không dùng NAT và dùng <em>IPv6</em>, <em>server</em> thậm chí có thể biết chính xác máy tính mà người gửi đang dùng, vì địa chỉ <em>IPv6</em> đôi khi được tự động cấu hình dựa trên địa chỉ MAC (chép một phần địa chỉ MAC vào địa chỉ IP). Nếu dùng <em>IPv6</em> và vẫn muốn bảo vệ quyền riêng tư của <em>client</em>, có thể dùng các giải pháp khác như <em>IPv6 temporary/privacy addresses</em> (địa chỉ tạm thời/riêng tư).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tls-luồng-byte-an-toàn-secure-bytestreams"><a class="header" href="#tls-luồng-byte-an-toàn-secure-bytestreams">TLS: Luồng byte an toàn (<em>Secure Bytestreams</em>)</a></h1>
<h2 id="luồng-byte-an-toàn-secure-bytestreams"><a class="header" href="#luồng-byte-an-toàn-secure-bytestreams">Luồng byte an toàn (<em>Secure Bytestreams</em>)</a></h2>
<p><em>TCP</em> (<em>Transmission Control Protocol</em> – Giao thức điều khiển truyền) tự thân nó không an toàn trước các kẻ tấn công trên mạng. Một ai đó trong mạng (ví dụ: một <em>router</em> độc hại, hoặc kẻ tấn công nghe lén gói tin trên đường truyền) có thể đọc hoặc thậm chí sửa đổi các gói tin <em>TCP</em> của bạn khi chúng đang được truyền.</p>
<p>Ngoài ra, với <em>TCP</em>, bạn có thể kết nối tới kẻ tấn công thay vì máy chủ thật. Giả sử bạn muốn kết nối tới trang web ngân hàng, và bạn thực hiện tra cứu <em>DNS</em> (<em>Domain Name System</em> – Hệ thống tên miền) cho <em>www.bank.com</em>. Kẻ tấn công (ví dụ: ai đó đã xâm nhập vào bộ phân giải <em>DNS resolver</em> hoặc một <em>router</em>) thay đổi phản hồi <em>DNS</em> để ánh xạ <em>www.bank.com</em> tới địa chỉ IP của kẻ tấn công, 6.6.6.6. Bây giờ, khi bạn thiết lập kết nối <em>TCP</em> tới trang web ngân hàng, bạn thực chất đang nói chuyện với kẻ tấn công. Bạn có thể sẽ gửi mật khẩu ngân hàng của mình cho hắn!</p>
<p>Để giải quyết các vấn đề bảo mật này, chúng ta thêm một giao thức mới, <strong>Transport Layer Security (TLS)</strong> (Bảo mật tầng vận chuyển), chạy trên <em>TCP</em>.</p>
<p><em>TLS</em> có thể được xem như một giao thức tầng 4.5, nằm giữa <em>TCP</em> và các giao thức ứng dụng như <em>HTTP</em>. (Chúng ta dùng số “lạ” 4.5 vì các tầng 5 và 6 đã lỗi thời và không liên quan đến bảo mật.) <em>TLS</em> dựa trên trừu tượng hóa luồng byte (<em>bytestream abstraction</em>) của <em>TCP</em>, nên nó không quan tâm đến từng gói tin riêng lẻ hoặc việc mất/sắp xếp lại gói tin. <em>TLS</em> cung cấp cho ứng dụng cùng một trừu tượng hóa luồng byte như <em>TCP</em>, nhưng luồng byte này giờ đã an toàn trước các kẻ tấn công mạng. Đây là lý do tại sao <em>HTTP</em> và <em>HTTPS</em> về mặt ngữ nghĩa là các giao thức giống hệt nhau. Điểm khác biệt duy nhất là <em>HTTPS</em> chạy trên luồng byte an toàn của <em>TLS-over-TCP</em>, trong khi <em>HTTP</em> chạy trên <em>TCP</em> thuần túy không có <em>TLS</em>.</p>
<img width="400px" src="end-to-end/../assets/end-to-end/5-072-layer45.png">
<p>Để phân biệt giữa <em>HTTPS</em> và <em>HTTP</em>, chúng ta dùng Port 80 cho kết nối <em>HTTP</em>, và Port 443 cho kết nối <em>HTTPS</em>. Máy chủ có thể buộc người dùng sử dụng <em>HTTPS</em> bằng cách trả lời tất cả yêu cầu ở Port 80 bằng một lệnh chuyển hướng (<em>redirect</em>) sang Port 443.</p>
<h2 id="bắt-tay-tls-tls-handshake"><a class="header" href="#bắt-tay-tls-tls-handshake">Bắt tay TLS (<em>TLS Handshake</em>)</a></h2>
<p>Ở mức khái quát, <em>TLS</em> sử dụng mật mã học (<em>cryptography</em>) để mã hóa các thông điệp được gửi qua luồng byte. <em>TLS</em> cũng sử dụng các giao thức mật mã khác (<em>message authentication codes</em> – mã xác thực thông điệp) để ngăn kẻ tấn công thay đổi thông điệp khi chúng được gửi qua mạng.</p>
<p>Để mã hóa lưu lượng, <em>TLS</em> phải bắt đầu bằng một quá trình bắt tay bổ sung (<em>handshake</em>) để trao đổi khóa và xác minh danh tính của máy chủ (ví dụ: ngân hàng thật, chứ không phải kẻ giả mạo ngân hàng).</p>
<p>Vì <em>TLS</em> được xây dựng trên <em>TCP</em>, nên quá trình bắt tay ba bước của <em>TCP</em> (<em>TCP three-way handshake</em>) diễn ra trước như bình thường. Điều này tạo ra một luồng byte (chưa an toàn), cho phép tất cả các thông điệp tiếp theo, bao gồm cả bắt tay <em>TLS</em>, được truyền mà không cần quan tâm đến từng gói tin riêng lẻ.</p>
<p>Quá trình bắt tay <em>TLS</em> diễn ra như sau:</p>
<img width="400px" src="end-to-end/../assets/end-to-end/5-073-tls-handshake.png">
<ol>
<li>
<p><strong>Client</strong> và <strong>server</strong> trao đổi thông điệp <em>hello</em>. Các thông điệp <em>hello</em> chứa các số ngẫu nhiên, đảm bảo rằng mỗi lần bắt tay sẽ tạo ra các khóa bí mật khác nhau. (Sẽ rất nguy hiểm nếu chúng ta dùng cùng một khóa mỗi lần, và kẻ tấn công đánh cắp được khóa đó.) Các thông điệp <em>hello</em> cũng cho phép <em>client</em> và <em>server</em> thống nhất về các giao thức mật mã cụ thể sẽ sử dụng. <em>Client hello</em> liệt kê tất cả các thuật toán mật mã mà <em>client</em> hỗ trợ, và <em>server hello</em> chọn một thuật toán để sử dụng.</p>
</li>
<li>
<p><strong>Server</strong> gửi một chứng chỉ xác thực (<em>certificate of authenticity</em>). Điều này cho phép <em>client</em> xác minh rằng nó đang giao tiếp với máy chủ thật, chứ không phải kẻ giả mạo. Cách <em>client</em> thực sự xác minh chứng chỉ này có một số chi tiết phức tạp, nhưng chúng ta sẽ không bàn sâu ở đây.</p>
</li>
<li>
<p><strong>Client</strong> và <strong>server</strong> tạo ra một bí mật (<em>secret</em>) mà chỉ hai bên biết. Vì luồng byte ở thời điểm này vẫn chưa an toàn, họ cần một giao thức mật mã cho phép chia sẻ bí mật qua kênh không an toàn. Chúng ta sẽ không đi sâu vào chi tiết, nhưng nếu bạn quen với mã hóa khóa công khai <em>RSA</em> (ví dụ: từ môn CS 70 tại UC Berkeley), thì đây là một thuật toán mật mã có thể dùng. <em>Client</em> mã hóa bí mật bằng khóa công khai của <em>server</em> và gửi nó cho <em>server</em>. Chỉ <em>server</em> mới biết khóa riêng tương ứng và có thể giải mã thông điệp để biết bí mật.</p>
</li>
<li>
<p><strong>Client</strong> và <strong>server</strong> tạo ra các khóa bí mật (<em>secret keys</em>) dựa trên bí mật đã chia sẻ và các giá trị ngẫu nhiên từ thông điệp <em>hello</em>. Việc sử dụng bí mật đảm bảo rằng kẻ tấn công không thể biết được các khóa bí mật. Việc sử dụng giá trị ngẫu nhiên đảm bảo rằng mỗi lần bắt tay sẽ tạo ra một khóa khác nhau. Quá trình tạo khóa này được thực hiện cục bộ và độc lập bởi cả <em>client</em> và <em>server</em>. Các khóa bí mật này không bao giờ được gửi qua mạng, nên kẻ tấn công không có cơ hội biết được chúng.</p>
</li>
<li>
<p><strong>Client</strong> và <strong>server</strong> trao đổi một số thông điệp xác nhận (<em>acknowledgements</em>) để đảm bảo rằng họ đã tạo ra cùng một bí mật, và không ai đã can thiệp vào các thông điệp được gửi qua mạng cho đến thời điểm này (vì luồng byte vẫn chưa an toàn).</p>
</li>
</ol>
<p>Tại thời điểm này, quá trình bắt tay đã hoàn tất, và tất cả các thông điệp sau đó sẽ được mã hóa bằng khóa bí mật (các mã xác thực thông điệp cũng được sử dụng để ngăn việc giả mạo). Chúng ta đã thiết lập một luồng byte an toàn trên kết nối <em>TCP</em>, và các ứng dụng có thể trao đổi dữ liệu trên luồng byte an toàn này.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kết-nối-end-to-end"><a class="header" href="#kết-nối-end-to-end">Kết nối End-to-End</a></h1>
<h2 id="Động-lực"><a class="header" href="#Động-lực">Động lực</a></h2>
<p>Trong phần này, chúng ta sẽ đi qua từng bước về những gì xảy ra khi chúng ta bật máy tính, cắm nó vào mạng <em>Ethernet</em>, và gõ <em>www.berkeley.edu</em> vào trình duyệt web. Trong quá trình đó, chúng ta sẽ thấy cách tất cả các thành phần khác nhau của mạng làm việc cùng nhau để xử lý yêu cầu của người dùng.</p>
<p>Chúng ta sẽ giả định rằng chúng ta không cần phải khởi động Internet từ đầu. Ví dụ, các <em>routers</em> đã và đang chạy các giao thức định tuyến và đã điền vào <em>forwarding tables</em> của chúng một cách tương ứng.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-074-end1.png">
<h2 id="bước-1-dhcp"><a class="header" href="#bước-1-dhcp">Bước 1: DHCP</a></h2>
<p>Chúng ta bật máy tính và cắm nó vào một mạng <em>Ethernet</em>. Chúng ta chưa có bất kỳ thông tin nào về mạng, vì vậy chúng ta <em>broadcast</em> một yêu cầu <em>DHCP</em> (Giao thức Cấu hình Máy chủ Động).</p>
<p>Chúng ta sẽ giả định <em>router</em> gia đình là <em>DHCP server</em> (máy chủ DHCP), điều này phổ biến trong các mạng gia đình. <em>Router</em>/<em>server</em> sẽ <em>unicast</em> một gói tin đề nghị (offer) trở lại cho chúng ta. Gói tin đề nghị này chứa thông tin về mạng: <em>subnet mask</em> (mặt nạ mạng con), địa chỉ IP của <em>default gateway</em> (cổng mặc định), và địa chỉ IP của <em>DNS server</em> (máy chủ DNS). Gói tin đề nghị cũng cấp cho chúng ta một địa chỉ IP mà chúng ta có thể sử dụng.</p>
<p>Để hoàn tất giao thức <em>DHCP</em>, chúng ta gửi một thông điệp yêu cầu (request) xác nhận rằng chúng ta muốn sử dụng cấu hình đã được đề nghị, và <em>router</em>/<em>server</em> phản hồi bằng một thông điệp xác nhận (acknowledgement).</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-075-end2.png">
<h2 id="bước-2-tìm-router-ở-lớp-2"><a class="header" href="#bước-2-tìm-router-ở-lớp-2">Bước 2: Tìm Router ở Lớp 2</a></h2>
<p>Từ <em>DHCP</em>, chúng ta đã biết được địa chỉ IP của <em>router</em>, và <em>forwarding table</em> của chúng ta bây giờ cho biết rằng tất cả các <em>packets</em> không thuộc <em>local network</em> sẽ được chuyển tiếp đến <em>router</em> này. Chúng ta sắp sửa gửi một số <em>packets</em> đến <em>DNS server</em> (để tra cứu địa chỉ IP của <em>www.berkeley.edu</em>), và đến chính <em>server</em> Berkeley, cả hai đều có thể không thuộc <em>local network</em>.</p>
<p>Tuy nhiên, trước khi chúng ta có thể chuyển tiếp các <em>IP packets</em> đến <em>router</em>, chúng ta cần tìm ra <em>MAC address</em> <em>Layer 2</em> của <em>router</em>, để chúng ta có thể gửi <em>packet</em> đến <em>router</em> bên trong <em>local network</em>.</p>
<p>Đầu tiên, chúng ta có thể xác minh rằng địa chỉ IP của <em>router</em>, 192.168.1.1, thuộc về <em>subnet</em> cục bộ, 192.168.1.2/24. Điều này cho chúng ta biết rằng <em>router</em> nằm trong <em>local network</em>, và bằng cách gửi một <em>packet</em> <em>Ethernet</em> đến <em>MAC address</em> của <em>router</em>, chúng ta sẽ đến được <em>router</em>.</p>
<p>Để tìm <em>MAC address</em> của <em>router</em>, chúng ta <em>broadcast</em> một yêu cầu <em>ARP</em>, hỏi <em>MAC address</em> của 192.168.1.1 (địa chỉ IP của <em>router</em>). <em>Router</em> nghe thấy yêu cầu này và trả lời, &quot;Tôi là 192.168.1.1, và <em>MAC address</em> của tôi là 01:ab:cd:ef:42:01.&quot;</p>
<p>Bây giờ chúng ta có thể lưu trữ ánh xạ IP-tới-MAC này, và chúng ta đã biết <em>MAC address</em> của <em>router</em>. Miễn là mục nhập này còn trong bộ đệm, chúng ta sẽ không phải thực hiện lại cùng một yêu cầu <em>ARP</em>. Tất cả các yêu cầu trong tương lai ra Internet bên ngoài đều có thể được chuyển tiếp đến <em>MAC address</em> của <em>router</em>.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-076-end3.png">
<h2 id="bước-3-tra-cứu-dns"><a class="header" href="#bước-3-tra-cứu-dns">Bước 3: Tra cứu DNS</a></h2>
<p>Tiếp theo, chúng ta cần tra cứu địa chỉ IP của <em>www.berkeley.edu</em>. Tất cả điều này được thực hiện trong hệ điều hành, sau khi mã của trình duyệt gọi một hàm như <em>getaddrinfo</em> để kích hoạt việc tra cứu <em>DNS</em> (Hệ thống Tên miền).</p>
<p>Từ <em>DHCP</em>, chúng ta đã biết địa chỉ IP của <em>DNS server</em>, 8.8.8.8. Chúng ta cũng biết rằng chúng ta đang ở trong <em>subnet</em> 192.168.1.2/24. <em>DNS server</em> không nằm trong <em>local network</em> của chúng ta, vì vậy chúng ta cần chuyển tiếp <em>DNS packet</em> (gói tin DNS) đến <em>router</em>.</p>
<p>Bây giờ chúng ta có thể xây dựng <em>DNS packet</em> yêu cầu của mình, từ trên xuống dưới.</p>
<p><em>Layer 7</em> (Lớp 7): Trong phần Question, chúng ta thêm một <em>DNS record</em> (bản ghi DNS) yêu cầu <em>A record</em> (bản ghi A) với địa chỉ IP của <em>www.berkeley.edu</em>. Chúng ta thêm <em>header</em> <em>DNS</em> với ID, số lượng bản ghi, v.v.</p>
<p><em>Layer 4</em> (Lớp 4): <em>DNS</em> chạy trên <em>UDP</em> (Giao thức Gói dữ liệu Người dùng). Chúng ta chọn một <em>source port</em> (cổng nguồn) ngẫu nhiên bất kỳ, vì chúng ta là client. Chúng ta chọn <em>Port</em> 53 cho <em>destination port</em> (cổng đích), vì đây là nơi các <em>resolvers</em> và <em>name servers</em> lắng nghe các truy vấn <em>DNS</em>.</p>
<p><em>Layer 3</em>: <em>Source IP</em> là IP của chính chúng ta, được gán bởi <em>DHCP</em>. <em>Destination IP</em> là 8.8.8.8, địa chỉ IP của <em>DNS server</em>, mà chúng ta đã biết từ <em>DHCP</em>.</p>
<p><em>Layer 2</em>: <em>Source MAC</em> là <em>MAC address</em> của chúng ta, được ghi sẵn trong phần cứng. <em>Destination MAC</em> là <em>MAC address</em> của <em>router</em> (<em>hop</em> tiếp theo), mà chúng ta đã biết từ <em>ARP</em>.</p>
<p>Với <em>packet</em> được xây dựng hoàn chỉnh, chúng ta có thể gửi các bit đi trên dây (Lớp 1 - <em>Layer 1</em>).</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-077-end4.png">
<p>Khi <em>packet</em> đến <em>router</em>, nếu mạng đang sử dụng <em>NAT</em> (Network Address Translation - Biên dịch Địa chỉ Mạng), <em>router</em> có thể viết lại các <em>headers</em> <em>UDP</em>/<em>IP</em> để dịch địa chỉ IP riêng của chúng ta thành địa chỉ IP công cộng. Tuy nhiên, với tư cách là <em>end host</em>, chúng ta không cần phải lo lắng về <em>NAT</em>. <em>Router</em> sẽ thực hiện tất cả việc biên dịch cho chúng ta, tạo cho chúng ta ảo giác rằng chúng ta có thể sử dụng địa chỉ IP của riêng mình (từ <em>DHCP</em>).</p>
<p>Khi <em>packet</em> của chúng ta đến <em>recursive resolver</em> (bộ phân giải đệ quy) tại 8.8.8.8, nếu <em>resolver</em> chưa có câu trả lời của chúng ta trong bộ đệm, nó có thể cần thực hiện một số tra cứu bổ sung và hỏi các <em>authoritative name servers</em> (máy chủ tên miền có thẩm quyền) để lấy các bản ghi. Cuối cùng, <em>recursive resolver</em> tìm thấy câu trả lời và gửi <em>A record</em> trở lại cho chúng ta. Bây giờ chúng ta đã có địa chỉ IP của <em>www.berkeley.edu</em>.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-078-end5.png">
<h2 id="bước-4-kết-nối-đến-trang-web"><a class="header" href="#bước-4-kết-nối-đến-trang-web">Bước 4: Kết nối đến Trang web</a></h2>
<p>Bây giờ chúng ta đã có địa chỉ IP của <em>www.berkeley.edu</em>, chúng ta có thể gửi <em>packets</em> đến Berkeley. Chúng ta đang sử dụng trình duyệt web, vì vậy mục tiêu của chúng ta là thực hiện một yêu cầu <em>HTTP</em> (Giao thức Truyền tải Siêu văn bản) đến <em>server</em> này.</p>
<p><em>HTTP</em> chạy trên <em>TCP</em> (Giao thức Điều khiển Truyền vận), vì vậy trước tiên chúng ta phải thực hiện một <em>TCP handshake</em> (bắt tay TCP) để mở một kết nối với <em>server</em> Berkeley. Trình duyệt sẽ gọi một hàm như <em>connect</em> trên một <em>socket</em> (giao diện lập trình mạng) cụ thể để mở kết nối này, và hệ điều hành (nơi <em>TCP</em> đang chạy) sẽ thực hiện <em>handshake</em> và chuyển <em>packets</em> đến và đi từ trình duyệt.</p>
<p><em>TCP handshake</em> được thực hiện: Chúng ta gửi một gói <em>SYN</em>, Berkeley gửi một gói <em>SYN-ACK</em>, và chúng ta gửi một gói <em>ACK</em>. Bây giờ chúng ta có một <em>bytestream</em> (luồng byte) giữa máy tính của chúng ta và <em>server</em> Berkeley.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-079-end6.png">
<p>Bây giờ, chúng ta có thể xây dựng <em>packet</em> <em>HTTP</em> của mình, từ trên xuống dưới.</p>
<p><em>Layer 7</em>: Phương thức <em>HTTP</em> là GET. Tài nguyên chúng ta muốn là <em>/</em> (trang chủ). Phiên bản là HTTP/1.1.</p>
<p><em>Layer 4</em>: <em>HTTP</em> chạy trên <em>TCP</em>. Trình duyệt có thể chọn bất kỳ <em>source port</em> nào, vì nó là client. Nhìn chung, <em>port</em> này có thể được ứng dụng chỉ định thủ công, hoặc ứng dụng có thể chỉ định &quot;Port 0,&quot; là cách viết tắt để yêu cầu hệ điều hành chọn một <em>ephemeral port</em> (cổng tạm thời) ngẫu nhiên hiện không được sử dụng. (Ngoài lề, nghĩ lại về <em>NAT</em>, việc cho phép các ứng dụng chỉ định <em>ports</em> thủ công là lý do tại sao hai người dùng có thể chọn cùng một <em>source port</em>.) <em>Destination port</em> là 80, số <em>port</em> cố định cho <em>HTTP</em>.</p>
<p><em>Layer 3</em>: <em>Source IP</em> là IP của chính chúng ta, được gán bởi <em>DHCP</em>. <em>Destination IP</em> là 141.193.213.21, địa chỉ IP của <em>www.berkeley.edu</em> đã được trả về từ truy vấn <em>DNS</em> của chúng ta trước đó.</p>
<p><em>Layer 2</em>: Điều này giống như <em>DNS packet</em> của chúng ta trước đó. <em>Source MAC</em> là của chúng ta (được ghi sẵn trong phần cứng), và <em>destination MAC</em> là của <em>router</em> (được phát hiện và lưu trong bộ đệm từ <em>ARP</em>).</p>
<img width="800px" src="end-to-end/../assets/end-to-end/5-080-end7.png">
<p><em>HTTP response</em> (phản hồi HTTP) trả về với <em>status code</em> (mã trạng thái) 200 OK, và nội dung của phản hồi có mã <em>HTML</em> (Ngôn ngữ Đánh dấu Siêu văn bản) của trang web. Trình duyệt gọi hàm <em>read</em> trên <em>socket</em> để lấy các byte của <em>HTTP</em> <em>payload</em> (phần dữ liệu), cùng với <em>status code</em> và phản hồi, và xử lý chúng một cách tương ứng.</p>
<p>Trong <em>bytestream</em>, <em>HTTP</em> có thể thêm một số dấu phân cách như ký tự xuống dòng để biểu thị sự kết thúc của một yêu cầu hoặc phản hồi. Ngoài ra, các <em>header</em> <em>HTTP</em> như Content-Length có thể chỉ định độ dài của <em>payload</em>. Điều này cũng cho phép trình duyệt cấp phát đủ bộ nhớ để nhận phản hồi.</p>
<p><em>HTTP response</em> trả về có thể kích hoạt thêm các yêu cầu khác. Nếu <em>HTML</em> trong phản hồi có cú pháp như <em><img src="end-to-end/../logo.png"></em>, điều này báo cho trình duyệt thực hiện một yêu cầu <em>HTTP</em> khác để lấy tài nguyên <em>/logo.png</em>. Hoặc, người dùng có thể nhấp vào một liên kết trên trang web như <em>www.berkeley.edu/about.html</em>, điều này cũng sẽ kích hoạt một yêu cầu <em>HTTP</em> khác đến cùng một <em>server</em>.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-081-end8.png">
<p>Hãy nhớ lại rằng nhiều yêu cầu <em>HTTP</em> đến cùng một <em>server</em> có thể được <em>pipelined</em> (truyền theo đường ống) qua cùng một kết nối <em>TCP</em> để tăng hiệu quả, vì vậy chúng ta có thể giữ kết nối <em>TCP</em> mở và tiếp tục sử dụng nó cho các yêu cầu và phản hồi <em>HTTP</em> tiếp theo.</p>
<p>Cuối cùng, sau một vài lần <em>pipelining</em>, client hoặc <em>server</em> chọn đóng kết nối. Quá trình <em>handshake</em> ngắt kết nối thông thường xảy ra, trong đó mỗi bên gửi một gói <em>FIN</em>, và cả hai <em>packets</em> <em>FIN</em> đều được xác nhận (acked). Chúng ta đã hoàn tất!</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-082-end9.png">
<p>Lưu ý rằng các yêu cầu/phản hồi <em>HTTP</em> không nhất thiết phải chứa trong một <em>packet</em> duy nhất. <em>HTTP</em> được xây dựng trên <em>TCP bytestream</em>, vì vậy một yêu cầu hoặc phản hồi <em>HTTP</em> duy nhất có thể bị chia thành nhiều <em>packets</em> <em>TCP</em>/<em>IP</em>, trong đó mỗi <em>packet</em> có cùng các <em>headers</em> ở <em>Layers 1-3</em>, và các <em>headers</em> <em>Layer 4</em> khác nhau ở số thứ tự. Chỉ có một <em>header</em> duy nhất cho toàn bộ yêu cầu/phản hồi <em>HTTP</em>, ngay cả khi yêu cầu/phản hồi đó được chia trên nhiều <em>packets</em>. Với <em>HTTP</em>, không còn mối tương quan một-một từ một yêu cầu/phản hồi đến một <em>packet</em>.</p>
<h2 id="sockets"><a class="header" href="#sockets">Sockets</a></h2>
<p>Nếu bạn là người dùng truy cập một trang web trong trình duyệt, bạn không cần phải viết bất kỳ mã nào để chạy ứng dụng (<em>HTTP</em>) qua Internet. Tuy nhiên, nếu bạn là một lập trình viên viết ứng dụng của riêng mình, bạn có thể cần phải viết một số mã để tương tác với mạng.</p>
<p>Khái niệm trừu tượng <strong>socket</strong> cung cấp cho các lập trình viên một cách thuận tiện để tương tác với mạng. Khái niệm trừu tượng <em>socket</em> hoàn toàn tồn tại trong phần mềm, và có năm hoạt động cơ bản mà các lập trình viên có thể thực hiện:</p>
<p>Chúng ta có thể <strong>create</strong> (tạo) một <em>socket</em> mới, tương ứng với một kết nối mới. Trong một ngôn ngữ hướng đối tượng như Java, đây có thể là một lệnh gọi hàm tạo (constructor call).</p>
<p>Chúng ta có thể gọi <strong>connect</strong> (kết nối), để khởi tạo một kết nối <em>TCP</em> đến một máy ở xa. Điều này hữu ích nếu chúng ta là client trong một kết nối client-server.</p>
<p>Chúng ta có thể gọi <strong>listen</strong> (lắng nghe) trên một <em>port</em> cụ thể. Điều này không bắt đầu một kết nối, nhưng cho phép những người khác khởi tạo một kết nối với chúng ta trên <em>port</em> đã chỉ định.</p>
<p>Khi kết nối đã mở, chúng ta có thể gọi <strong>write</strong> (ghi) để gửi một số byte trên kết nối. Chúng ta cũng có thể gọi <strong>read</strong> (đọc), nhận một đối số N, để đọc N byte từ kết nối.</p>
<p>Khái niệm trừu tượng <em>socket</em> này cung cấp cho các lập trình viên một cách để viết các ứng dụng mà không cần suy nghĩ về các khái niệm trừu tượng ở cấp thấp hơn như <em>TCP</em>, <em>IP</em>, hay <em>Ethernet</em>.</p>
<p>Từ góc độ hệ điều hành, mỗi <em>socket</em> được liên kết với một số <em>port</em> <em>Layer 4</em>. Tất cả các <em>packets</em> đến và đi từ một <em>socket</em> duy nhất đều có cùng một số <em>port</em>, và hệ điều hành có thể sử dụng số <em>port</em> để phân kênh và gửi <em>packets</em> đến đúng <em>socket</em>.</p>
<h2 id="các-lớp-trong-hệ-điều-hành"><a class="header" href="#các-lớp-trong-hệ-điều-hành">Các Lớp trong Hệ điều hành</a></h2>
<p>Trong phần cứng, <em>Layers 1</em> và <em>2</em> được triển khai trên <em>Network Interface Card (NIC)</em> (Card Giao diện Mạng) của máy tính bạn. <em>Layers 3</em> và <em>4</em> được triển khai trong chồng giao thức mạng (networking stack) trong hệ điều hành. Các ứng dụng <em>Layer 7</em> được triển khai trong phần mềm. Lợi ích của việc đặt <em>Layers 3</em> và <em>4</em> trong HĐH là các ứng dụng không phải lo lắng về việc triển khai lại chúng mỗi lần.</p>
<p>Với sự phân công lao động này, ứng dụng chỉ cần nghĩ về dữ liệu. <em>NIC</em> chỉ cần nghĩ về các <em>packets</em>. Chồng giao thức mạng trong HĐH dịch giữa các kết nối và các <em>packets</em>.</p>
<h2 id="xem-các-gói-tin"><a class="header" href="#xem-các-gói-tin">Xem các Gói tin</a></h2>
<p>Các công cụ như tshark và wireshark tồn tại nếu bạn muốn xem các <em>packets</em> được gửi qua mạng. Những công cụ này hữu ích khi gỡ lỗi phần mạng trong mã của bạn.</p>
<p>Trong trình duyệt, bạn cũng có thể sử dụng tab Network của bảng điều khiển inspect element để xem dữ liệu được gửi và nhận.</p>
<p>Nếu bạn thực sự xem các <em>packets</em> thô được gửi qua mạng, bạn sẽ thấy một số phức tạp trong thế giới thực mà chúng ta đã không đề cập trong phần hướng dẫn đầu cuối-đến-đầu cuối của mình. Ví dụ, các <em>packets</em> có thể được mã hóa và gửi qua <em>TLS</em> (Transport Layer Security - An ninh Tầng Giao vận). Ngoài ra, nếu chúng ta đang sử dụng HTTP/3.0, các <em>packets</em> có thể được gửi qua <em>QUIC</em> (biến thể <em>UDP</em> được tối ưu hóa cho <em>HTTP</em>) thay vì <em>TCP</em>.</p>
<h2 id="nhìn-lại-về-phân-tầng"><a class="header" href="#nhìn-lại-về-phân-tầng">Nhìn lại về Phân tầng</a></h2>
<p>Bức tranh đầu cuối-đến-đầu cuối đầy đủ cho phép chúng ta thấy tại sao phân tầng là một nguyên tắc hữu ích để xây dựng mạng. Chúng ta đã có thể giải quyết các vấn đề cụ thể ở một lớp duy nhất, mà không cần suy nghĩ về tất cả các lớp cùng một lúc.</p>
<p>Thực tế, chúng ta hoàn toàn không thảo luận về <em>Layer 1</em> trong lớp học này. Chúng ta đã không nói về kỹ thuật điện hay vật lý cần thiết để gửi tín hiệu qua một sợi dây. Tuy nhiên, chúng ta vẫn có thể xây dựng các lớp khác trên <em>Layer 1</em>, mà không cần biết chính xác <em>Layer 1</em> hoạt động như thế nào.</p>
<p>Trong lớp học này, chúng ta đã thảo luận <em>HTTP</em> là giao thức <em>Layer 7</em> chủ yếu, nhưng <em>HTTP</em> là một giao thức tương đối đơn giản. Có thể nhiều ứng dụng muốn xây dựng cùng một chức năng phức tạp trên <em>HTTP</em>, nhưng họ không muốn mỗi người phải tự viết mã cho chức năng đó một cách độc lập. Để hỗ trợ điều này, chúng ta thực sự có thể xây dựng thêm các giao thức trên <em>HTTP</em>, để các lập trình viên không phải lúc nào cũng bắt đầu từ đầu với <em>HTTP</em>.</p>
<p>Một ví dụ về một giao thức trên <em>Layer 7</em> là một thư viện <em>remote procedure call (RPC)</em> (gọi thủ tục từ xa). Điều này cho phép một lập trình viên viết một số mã, trong đó một số hàm thực sự thực thi trên một máy tính khác ở nơi khác trong mạng. Sẽ rất phiền phức nếu mọi người phải tự viết <em>RPC</em> trên <em>HTTP</em> từ đầu, vì vậy thay vào đó, các thư viện như Apache Thrift và gRPC tồn tại để trừu tượng hóa thêm nhiều chi tiết hơn nữa khỏi lập trình viên.</p>
<img width="900px" src="end-to-end/../assets/end-to-end/5-083-layer8.png">
<p>Đây là một ví dụ về một số mã mạng mà một lập trình viên có thể viết. Nó lập trình một client để nói xin chào với một <em>server</em> ở xa.</p>
<p>Lưu ý rằng tất cả các giao thức mạng mà chúng ta đã thảo luận đều hoàn toàn bị ẩn đằng sau hai dòng lệnh gọi đến các thư viện mạng. Lập trình viên không cần phải suy nghĩ về <em>HTTP</em>, <em>TCP</em>, <em>IP</em>, <em>Ethernet</em>, <em>ARP</em>, <em>DHCP</em>, hoặc bất kỳ giao thức cấp thấp nào khác. Vẫn rất hữu ích khi biết về các giao lức này nếu chúng gặp sự cố, và việc hiểu các giao thức có thể giúp bạn tối ưu hóa mã của mình cho các giao thức cụ thể, nhưng cuối cùng, phân tầng là một công cụ trừu tượng hóa rất mạnh mẽ.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="datacenter-topology-cấu-trúc-liên-kết-mạng-của-trung-tâm-dữ-liệu"><a class="header" href="#datacenter-topology-cấu-trúc-liên-kết-mạng-của-trung-tâm-dữ-liệu">Datacenter Topology (Cấu trúc liên kết mạng của Trung tâm dữ liệu)</a></h1>
<h2 id="datacenter-là-gì"><a class="header" href="#datacenter-là-gì">Datacenter là gì?</a></h2>
<p>Cho đến nay, trong mô hình Internet của chúng ta, chúng ta đã thấy các <em>end hosts</em> (thiết bị đầu cuối) gửi các gói tin cho nhau. <em>End host</em> có thể là một <em>client machine</em> (máy khách) (ví dụ: máy tính cá nhân của bạn), hoặc một <em>server</em> (máy chủ) (ví dụ: YouTube). Nhưng, liệu YouTube có thực sự là một cỗ máy duy nhất trên Internet phục vụ video cho toàn thế giới không?</p>
<img width="800px" src="datacenter/../assets/datacenter/6-001-single-server.png">
<p>Thực tế, YouTube là cả một tòa nhà gồm các máy móc được kết nối với nhau, hoạt động cùng nhau để phục vụ video cho người dùng. Tất cả những cỗ máy này đều nằm trong cùng một <em>local network</em> (mạng cục bộ) và có thể giao tiếp với nhau để hoàn thành các yêu cầu (ví dụ: nếu video bạn yêu cầu được lưu trữ trên nhiều máy khác nhau).</p>
<img width="800px" src="datacenter/../assets/datacenter/6-002-many-servers.png">
<p>Hãy nhớ lại rằng trong mô hình mạng-của-các-mạng của Internet, mỗi nhà khai thác đều có quyền tự do quản lý <em>local network</em> của mình theo cách họ muốn. Trong phần này, chúng ta sẽ tập trung vào các <em>local networks</em> dành riêng cho việc kết nối các <em>servers</em> bên trong một <em>Datacenter</em> (Trung tâm dữ liệu) (trái ngược với việc kết nối người dùng như máy tính cá nhân của bạn). Chúng ta sẽ nói về những thách thức riêng biệt của các <em>local networks</em> này, và các giải pháp chuyên biệt cho các vấn đề mạng (ví dụ: <em>congestion control</em> (kiểm soát tắc nghẽn) và <em>routing</em> (định tuyến)) được thiết kế đặc biệt để hoạt động tốt trong bối cảnh <em>Datacenter</em>.</p>
<p>Trong thực tế, một <em>Datacenter</em> được đặt tại một địa điểm vật lý, thường là trên các khu đất chuyên dụng. Ngoài cơ sở hạ tầng tính toán (ví dụ: <em>servers</em>), <em>Datacenters</em> còn cần cơ sở hạ tầng hỗ trợ như hệ thống làm mát và nguồn điện, mặc dù chúng ta sẽ chỉ tập trung vào <em>local network</em> kết nối các <em>servers</em>.</p>
<p><em>Datacenters</em> phục vụ các ứng dụng (ví dụ: video YouTube, kết quả tìm kiếm Google, v.v.). Đây là cơ sở hạ tầng cho các <em>end hosts</em> mà bạn có thể muốn kết nối. Lưu ý rằng điều này khác với cơ sở hạ tầng Internet mà chúng ta đã thấy trước đây. Trước đó, chúng ta đã thấy <em>carrier hotels</em> (khách sạn viễn thông, nơi các mạng kết nối với nhau), những tòa nhà nơi rất nhiều mạng (thuộc sở hữu của các công ty khác nhau) kết nối với nhau bằng các <em>routers</em> (bộ định tuyến) hạng nặng. Đây là cơ sở hạ tầng cho các <em>routers</em> chuyển tiếp các gói tin của bạn đến nhiều đích khác nhau, nhưng các ứng dụng thường không được lưu trữ tại <em>carrier hotels</em>.</p>
<p>Một <em>Datacenter</em> thường thuộc sở hữu của một tổ chức duy nhất (ví dụ: Google, Amazon), và tổ chức đó có thể lưu trữ nhiều ứng dụng khác nhau (ví dụ: Gmail, YouTube, v.v.) trong một <em>Datacenter</em> duy nhất. Điều này có nghĩa là tổ chức đó có toàn quyền kiểm soát cơ sở hạ tầng mạng bên trong <em>local network</em> của <em>Datacenter</em>.</p>
<p>Trọng tâm của chúng ta là các <em>Datacenters</em> siêu quy mô hiện đại, được vận hành bởi các gã khổng lồ công nghệ như Google và Amazon. Quy mô lớn mang lại một số thách thức độc đáo, nhưng các khái niệm chúng ta sẽ tìm hiểu cũng hoạt động ở quy mô nhỏ hơn.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-003-wan1.png">
<p>Bản đồ này cho thấy <em>wide area network (WAN)</em> (mạng diện rộng) của tất cả các mạng do một gã khổng lồ công nghệ như Google sở hữu.</p>
<p>Các <em>peering locations</em> (địa điểm ngang hàng) kết nối Google với phần còn lại của Internet. Chúng chủ yếu bao gồm các <em>routers</em> do Google vận hành kết nối với các <em>autonomous systems</em> (hệ thống tự trị) khác.</p>
<img width="900px" class="real-photo" src="datacenter/../assets/datacenter/6-004-peering.png">
<p>Ngoài các <em>peering locations</em>, Google cũng vận hành nhiều <em>Datacenters</em>. Các ứng dụng trong <em>Datacenters</em> có thể giao tiếp với phần còn lại của Internet thông qua các <em>peering locations</em>. Các <em>Datacenters</em> và <em>peering locations</em> đều được kết nối thông qua các <em>routers</em> và <em>links</em> (liên kết) do Google quản lý trong <em>WAN</em> của Google.</p>
<img width="900px" class="real-photo" src="datacenter/../assets/datacenter/6-005-datacenter-irl1.png">
<p><em>Datacenters</em> và <em>peering locations</em> tối ưu hóa cho các mục tiêu hiệu suất khác nhau, vì vậy chúng thường được đặt ở những vị trí vật lý khác nhau.</p>
<p><em>Peering locations</em> quan tâm đến việc ở gần các công ty và mạng lưới khác về mặt vật lý. Do đó, <em>carrier hotels</em> thường được đặt tại các thành phố để gần gũi hơn với khách hàng và các công ty khác.</p>
<p>Ngược lại, <em>Datacenters</em> ít quan tâm hơn đến việc ở gần các công ty khác, và thay vào đó ưu tiên các yêu cầu như không gian vật lý, điện năng và làm mát. Do đó, <em>Datacenters</em> thường được đặt ở những khu vực ít dân cư hơn, đôi khi gần một con sông (để làm mát) hoặc một trạm điện (<em>Datacenters</em> có thể cần lượng điện năng gấp hàng trăm lần so với <em>peering locations</em>).</p>
<img width="800px" class="real-photo" src="datacenter/../assets/datacenter/6-006-datacenter-irl2.png">
<h2 id="tại-sao-datacenter-lại-khác-biệt"><a class="header" href="#tại-sao-datacenter-lại-khác-biệt">Tại sao Datacenter lại khác biệt?</a></h2>
<p>Điều gì làm cho <em>local network</em> của một <em>Datacenter</em> khác biệt so với các mạng đa dụng (mạng diện rộng) trên phần còn lại của Internet?</p>
<p>Mạng <em>Datacenter</em> được điều hành bởi một tổ chức duy nhất, điều này cho phép chúng ta kiểm soát nhiều hơn đối với mạng và các <em>hosts</em> (máy chủ/thiết bị). Không giống như trên Internet đa dụng, chúng ta có thể chạy phần cứng hoặc phần mềm tùy chỉnh của riêng mình, và chúng ta có thể thực thi rằng mọi máy đều tuân theo cùng một giao thức tùy chỉnh.</p>
<p><em>Datacenters</em> thường đồng nhất, nơi mọi <em>server</em> và <em>switch</em> (bộ chuyển mạch) đều được xây dựng và vận hành hoàn toàn giống nhau. Không giống như trên Internet đa dụng, chúng ta không phải xem xét một số <em>links</em> là không dây, và một số khác là có dây. Trên Internet đa dụng, một số máy tính có thể mới hơn những máy khác, nhưng trong một <em>Datacenter</em>, mọi máy tính thường thuộc cùng một thế hệ, và toàn bộ <em>Datacenter</em> được nâng cấp cùng một lúc.</p>
<p>Mạng <em>Datacenter</em> tồn tại ở một địa điểm vật lý duy nhất, vì vậy chúng ta không cần phải nghĩ về các <em>links</em> đường dài như cáp ngầm dưới biển. Trong một địa điểm duy nhất đó, chúng ta phải hỗ trợ <em>bandwidth</em> (băng thông) cực kỳ cao.</p>
<h2 id="các-mẫu-lưu-lượng-trong-datacenter"><a class="header" href="#các-mẫu-lưu-lượng-trong-datacenter">Các Mẫu Lưu lượng trong Datacenter</a></h2>
<p>Khi bạn gửi một yêu cầu đến một ứng dụng trong <em>Datacenter</em>, gói tin của bạn di chuyển qua các <em>routers</em> trên Internet đa dụng, cuối cùng đến được <em>router</em> do Google vận hành. <em>Router</em> đó chuyển tiếp gói tin của bạn đến một trong các <em>edge routers</em> (router biên) của <em>Datacenter</em>, sau đó <em>edge router</em> này sẽ chuyển tiếp gói tin của bạn đến một <em>server</em> riêng lẻ nào đó trong <em>Datacenter</em>.</p>
<p>Một <em>server</em> này có lẽ không có đủ tất cả thông tin để xử lý yêu cầu của bạn. Ví dụ, nếu bạn yêu cầu một bảng tin Facebook, các <em>servers</em> khác nhau có thể cần phải làm việc cùng nhau để kết hợp advertise, hình ảnh, bài đăng, v.v. Sẽ không thực tế nếu mọi <em>server</em> đều phải biết mọi thứ về Facebook để tự mình xử lý yêu cầu của bạn.</p>
<p>Để các <em>servers</em> khác nhau có thể phối hợp, <em>server</em> đầu tiên sẽ kích hoạt nhiều yêu cầu backend để thu thập tất cả thông tin cần thiết cho yêu cầu của bạn. Một yêu cầu duy nhất của người dùng có thể kích hoạt hàng trăm yêu cầu backend (trung bình là 521, theo một bài báo của Facebook năm 2013) trước khi phản hồi có thể được gửi lại cho người dùng. Nhìn chung, lưu lượng backend giữa các <em>servers</em> lớn hơn đáng kể, và lưu lượng bên ngoài với người dùng rất nhỏ khi so sánh.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-007-nsew-traffic1.png">
<p>Hầu hết các ứng dụng hiện đại đều bị chi phối bởi lưu lượng nội bộ giữa các máy. Ví dụ, nếu bạn chạy một chương trình phân tán như mapreduce, các <em>servers</em> khác nhau cần phải giao tiếp với nhau để cùng giải quyết truy vấn lớn của bạn. Một số ứng dụng thậm chí có thể không có lưu lượng mạng hướng tới người dùng nào cả. Ví dụ, Google có thể chạy các bản sao lưu định kỳ, đòi hỏi các <em>servers</em> phải giao tiếp với nhau, nhưng không tạo ra kết quả nào có thể thấy được cho người dùng cuối.</p>
<p>Các kết nối đi ra ngoài mạng (ví dụ: đến người dùng cuối hoặc các <em>Datacenters</em> khác) được mô tả là <em>north-south traffic</em> (lưu lượng bắc-nam). Ngược lại, các kết nối giữa các máy bên trong mạng được mô tả là <em>east-west traffic</em> (lưu lượng đông-tây). <em>East-west traffic</em> lớn hơn <em>north-south traffic</em> vài bậc độ lớn, và khối lượng của <em>east-west traffic</em> đang tăng lên trong những năm gần đây (ví dụ: với sự phát triển của học máy).</p>
<img width="300px" src="datacenter/../assets/datacenter/6-008-nsew-traffic2.png">
<h2 id="racks-giá-đỡ"><a class="header" href="#racks-giá-đỡ">Racks (Giá đỡ)</a></h2>
<p>Về cơ bản, một <em>Datacenter</em> bao gồm rất nhiều <em>servers</em>. Các <em>servers</em> được tổ chức trong các <em>racks</em> (giá đỡ) vật lý, mỗi <em>rack</em> có 40-48 đơn vị rack (khe cắm), và mỗi đơn vị rack có thể chứa 1-2 <em>servers</em>.</p>
<img width="500px" class="real-photo" src="datacenter/../assets/datacenter/6-009-rack1.png">
<p>Chúng ta muốn tất cả các <em>servers</em> trong <em>Datacenter</em> có thể giao tiếp với nhau, vì vậy chúng ta cần xây dựng một mạng lưới để kết nối tất cả chúng lại. Mạng lưới này trông như thế nào? Làm thế nào để chúng ta lắp đặt các <em>links</em> và <em>switches</em> một cách hiệu quả để đáp ứng các yêu cầu của mình?</p>
<p>Đầu tiên, chúng ta có thể kết nối tất cả các <em>servers</em> trong cùng một <em>rack</em>. Mỗi <em>rack</em> có một <em>switch</em> duy nhất được gọi là <em>top-of-rack (TOR) switch</em> (switch đỉnh giá), và mọi <em>server</em> trong <em>rack</em> đều có một <em>link</em> (được gọi là <em>access link</em> (liên kết truy cập) hoặc <em>uplink</em> (đường lên)) kết nối đến <em>switch</em> đó. <em>TOR</em> là một <em>router</em> tương đối nhỏ, với một chip chuyển tiếp duy nhất, và các cổng vật lý kết nối với tất cả các <em>servers</em> trên <em>rack</em>. Mỗi <em>uplink</em> của <em>server</em> thường có dung lượng khoảng 100 Gbps.</p>
<img width="500px" class="real-photo" src="datacenter/../assets/datacenter/6-010-rack2.png">
<p>Tiếp theo, chúng ta phải suy nghĩ về cách kết nối các <em>racks</em> với nhau. Lý tưởng nhất, chúng ta muốn mọi <em>server</em> có thể nói chuyện với mọi <em>server</em> khác ở <em>line rate</em> (tốc độ tối đa của đường truyền) của chúng (tức là sử dụng toàn bộ <em>bandwidth</em> của <em>uplink</em>).</p>
<img width="500px" src="datacenter/../assets/datacenter/6-011-rack3.png">
<h2 id="bisection-bandwidth-băng-thông-chia-đôi"><a class="header" href="#bisection-bandwidth-băng-thông-chia-đôi">Bisection Bandwidth (Băng thông chia đôi)</a></h2>
<p>Trước khi nghĩ về cách kết nối các <em>racks</em>, hãy phát triển một thước đo về mức độ kết nối của một tập hợp các máy tính.</p>
<img width="800px" src="datacenter/../assets/datacenter/6-012-bisection1.png">
<p>Một cách trực quan, mặc dù cả ba mạng đều được kết nối đầy đủ, mạng bên trái là kết nối tốt nhất, mạng ở giữa kém kết nối hơn, và mạng bên phải là kém kết nối nhất. Ví dụ, mạng bên trái và giữa có thể hỗ trợ các node 1-4 và 3-6 giao tiếp đồng thời ở <em>line rate</em>, trong khi mạng bên phải thì không.</p>
<p>Một cách để lập luận rằng mạng bên trái kết nối tốt hơn là nói: Chúng ta phải cắt nhiều <em>links</em> hơn để ngắt kết nối mạng. Điều này cho thấy có rất nhiều <em>links</em> dự phòng, cho phép chúng ta chạy nhiều kết nối <em>bandwidth</em> cao đồng thời. Tương tự, một cách để lập luận rằng mạng bên phải kém kết nối hơn là nói: Chúng ta chỉ cần cắt <em>link</em> 2-5 để ngắt kết nối mạng, điều này cho thấy sự tồn tại của một điểm nghẽn ngăn cản các kết nối <em>bandwidth</em> cao đồng thời.</p>
<p><em>Bisection bandwidth</em> (băng thông chia đôi) là một cách để định lượng mức độ kết nối của một mạng. Để tính <em>bisection bandwidth</em>, chúng ta tính số lượng <em>links</em> cần loại bỏ để phân chia mạng thành hai nửa không kết nối có kích thước bằng nhau. <em>Bisection bandwidth</em> là tổng của <em>bandwidths</em> trên các <em>links</em> mà chúng ta đã cắt.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-013-bisection2.png">
<p>Trong cấu trúc ngoài cùng bên phải, chúng ta chỉ cần loại bỏ một <em>link</em> để phân chia mạng, vì vậy <em>bisection bandwidth</em> chỉ là <em>bandwidth</em> của <em>link</em> đó. Ngược lại, trong cấu trúc ngoài cùng bên trái, chúng ta cần loại bỏ 9 <em>links</em> để phân chia mạng, vì vậy <em>bisection bandwidth</em> là <em>bandwidth</em> kết hợp của tất cả 9 <em>links</em> đó.</p>
<p>Một cách định nghĩa tương đương của <em>bisection bandwidth</em> là: Chúng ta chia mạng thành hai nửa, và mỗi nút ở một nửa muốn đồng thời gửi dữ liệu đến một nút tương ứng ở nửa còn lại. Trong tất cả các cách phân chia các nút có thể, <em>bandwidth</em> tối thiểu mà các nút có thể gửi đi chung là bao nhiêu? Việc xem xét trường hợp xấu nhất (<em>bandwidth</em> tối thiểu) buộc chúng ta phải nghĩ về các điểm nghẽn.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-014-bisection3.png">
<p>Mạng được kết nối tốt nhất có <em>bisection bandwidth</em> đầy đủ. Điều này có nghĩa là không có điểm nghẽn, và dù bạn phân chia các nút vào các phân vùng như thế nào, tất cả các nút trong một phân vùng đều có thể giao tiếp đồng thời với tất cả các nút trong phân vùng kia ở tốc độ tối đa. Nếu có N nút, và tất cả N/2 nút trong phân vùng bên trái đang gửi dữ liệu ở tốc độ tối đa R, thì <em>bisection bandwidth</em> đầy đủ là N/2 nhân R.</p>
<p><em>Oversubscription</em> (tỷ lệ quá tải băng thông) là một thước đo về mức độ chúng ta còn cách xa <em>bisection bandwidth</em> đầy đủ, hoặc tương đương, mức độ quá tải của phần nghẽn của mạng. Đó là tỷ lệ của <em>bisection bandwidth</em> so với <em>bisection bandwidth</em> đầy đủ (<em>bandwidth</em> nếu tất cả các <em>hosts</em> đều gửi ở tốc độ tối đa).</p>
<img width="900px" src="datacenter/../assets/datacenter/6-015-bisection4.png">
<p>Trong ví dụ ngoài cùng bên phải, giả sử tất cả các <em>links</em> là 1 Gbps, thì <em>bisection bandwidth</em> là 2 Gbps (để tách bốn <em>hosts</em> bên trái với bốn <em>hosts</em> bên phải). <em>Bisection bandwidth</em> đầy đủ, đạt được khi tất cả bốn <em>hosts</em> bên trái đồng thời gửi dữ liệu, là 4 Gbps. Do đó, tỷ lệ 2/4 cho chúng ta biết rằng các <em>hosts</em> chỉ có thể gửi ở 50% tốc độ tối đa của chúng. Nói cách khác, mạng của chúng ta bị <em>oversubscribed</em> gấp 2 lần, bởi vì nếu tất cả các <em>hosts</em> đều gửi ở tốc độ tối đa, các <em>links</em> nghẽn sẽ bị quá tải gấp 2 lần (4 Gbps trên các <em>links</em> 2 Gbps).</p>
<h2 id="datacenter-topology-cấu-trúc-liên-kết-mạng-của-trung-tâm-dữ-liệu-1"><a class="header" href="#datacenter-topology-cấu-trúc-liên-kết-mạng-của-trung-tâm-dữ-liệu-1">Datacenter Topology (Cấu trúc liên kết mạng của Trung tâm dữ liệu)</a></h2>
<p>Bây giờ chúng ta đã định nghĩa <em>bisection bandwidth</em>, một thước đo về khả năng kết nối phụ thuộc vào <em>topology</em> (cấu trúc liên kết mạng, hay topo mạng) của mạng. Trong một <em>Datacenter</em>, chúng ta có thể chọn <em>topology</em> của mình (ví dụ: chọn nơi lắp đặt cáp). Chúng ta nên xây dựng <em>topology</em> nào để tối đa hóa <em>bisection bandwidth</em>?</p>
<p>Một cách tiếp cận có thể là kết nối mọi <em>rack</em> với một <em>cross-bar switch</em> (switch chuyển mạch chéo) khổng lồ. Tất cả các <em>racks</em> ở phía bên trái có thể đồng thời gửi dữ liệu ở tốc độ tối đa vào <em>switch</em>, <em>switch</em> này sẽ chuyển tiếp tất cả dữ liệu đó đến phía bên phải ở tốc độ tối đa. Điều này sẽ cho phép chúng ta đạt được <em>bisection bandwidth</em> đầy đủ.</p>
<img width="500px" src="datacenter/../assets/datacenter/6-016-topology1.png">
<p>Một số vấn đề với cách tiếp cận này là gì? <em>Switch</em> sẽ cần một cổng vật lý cho mỗi <em>rack</em> (có thể lên đến 2500 cổng). Chúng ta đôi khi gọi số lượng cổng bên ngoài là <em>radix</em> (số lượng cổng) của <em>switch</em>, vì vậy <em>switch</em> này sẽ cần một <em>radix</em> lớn. Ngoài ra, <em>switch</em> này sẽ cần có dung lượng cực lớn (có thể là petabit mỗi giây) để hỗ trợ tất cả các <em>racks</em>. Không có gì ngạc nhiên khi <em>switch</em> này không thực tế để xây dựng (ngay cả khi chúng ta có thể, nó sẽ cực kỳ đắt đỏ).</p>
<p>Thông tin thú vị: Vào những năm 2000, Google đã thử yêu cầu các nhà cung cấp <em>switch</em> xây dựng một <em>switch</em> 10.000 cổng. Các nhà cung cấp đã từ chối, nói rằng không thể xây dựng thứ này, và ngay cả khi có thể, không ai yêu cầu nó ngoại trừ bạn (vì vậy không có lợi nhuận để xây dựng nó).</p>
<p>Một vấn đề khác là <em>switch</em> này là một điểm lỗi duy nhất, và toàn bộ mạng <em>Datacenter</em> sẽ ngừng hoạt động nếu <em>switch</em> này bị hỏng.</p>
<p>Một cách tiếp cận khác có thể là sắp xếp các <em>switches</em> theo <em>tree topology</em> (topo mạng hình cây). Điều này có thể giúp chúng ta giảm <em>radix</em> và <em>bandwidth</em> của mỗi <em>link</em>.</p>
<img width="500px" src="datacenter/../assets/datacenter/6-017-topology2.png">
<p>Một số vấn đề với cách tiếp cận này là gì? <em>Bisection bandwidth</em> thấp hơn. Một <em>link</em> duy nhất là điểm nghẽn giữa hai nửa của cây.</p>
<p>Để tăng <em>bisection bandwidth</em>, chúng ta có thể lắp đặt các <em>links</em> có <em>bandwidth</em> cao hơn ở các lớp cao hơn.</p>
<img width="500px" src="datacenter/../assets/datacenter/6-018-topology3.png">
<p>Trong trường hợp này, nếu bốn <em>links</em> dưới là 100 Gbps, và hai <em>links</em> trên là 300 Gbps, thì chúng ta đã loại bỏ được điểm nghẽn và khôi phục <em>bisection bandwidth</em> đầy đủ.</p>
<p><em>Topology</em> này có thể được sử dụng, mặc dù chúng ta vẫn chưa giải quyết được vấn đề <em>switch</em> ở đỉnh rất đắt và khả năng mở rộng kém.</p>
<h2 id="clos-networks-mạng-clos"><a class="header" href="#clos-networks-mạng-clos">Clos Networks (Mạng Clos)</a></h2>
<p>Cho đến nay, chúng ta đã thử xây dựng các mạng sử dụng các <em>switches</em> được chế tạo tùy chỉnh, có thể với <em>bandwidth</em> hoặc <em>radix</em> rất cao. Những <em>switches</em> này vẫn rất tốn kém để xây dựng. Liệu chúng ta có thể thiết kế một <em>topology</em> cho <em>bisection bandwidth</em> cao, sử dụng các thành phần hàng hóa giá rẻ không? Cụ thể, chúng ta muốn sử dụng một số lượng lớn các <em>switches</em> thương mại giá rẻ, trong đó tất cả các <em>switches</em> đều có cùng số cổng, mỗi <em>switch</em> có số lượng cổng thấp, và tất cả tốc độ <em>link</em> đều như nhau.</p>
<img width="600px" src="datacenter/../assets/datacenter/6-019-clos1.png">
<p>Một <em>Clos network</em> (mạng Clos) đạt được <em>bandwidth</em> cao với các bộ phận thương mại bằng cách tạo ra một số lượng lớn các đường đi giữa các nút trong mạng. Bởi vì có rất nhiều <em>links</em> và đường đi qua mạng, chúng ta có thể đạt được <em>bisection bandwidth</em> cao bằng cách cho mỗi nút gửi dữ liệu theo một đường đi khác nhau.</p>
<img width="600px" src="datacenter/../assets/datacenter/6-020-clos2.png">
<p>Không giống như các <em>switches</em> được chế tạo tùy chỉnh, nơi chúng ta mở rộng quy mô mạng bằng cách xây dựng một <em>switch</em> lớn hơn, chúng ta có thể mở rộng quy mô <em>Clos networks</em> bằng cách chỉ cần thêm nhiều <em>switches</em> giống nhau. Giải pháp này hiệu quả về chi phí và có khả năng mở rộng!</p>
<p><em>Clos networks</em> cũng đã được sử dụng trong các ứng dụng khác, và được đặt theo tên của nhà phát minh ra chúng (Charles Clos, 1952).</p>
<p>Trong một <em>Clos network</em> cổ điển, chúng ta sẽ có tất cả các <em>racks</em> ở bên trái gửi dữ liệu đến các <em>racks</em> ở bên phải. Trong <em>Datacenters</em>, các <em>racks</em> có thể vừa gửi vừa nhận dữ liệu, vì vậy thay vì có một lớp người gửi và người nhận riêng biệt, chúng ta có thể có một lớp duy nhất với tất cả các <em>racks</em> (đóng vai trò là người gửi hoặc người nhận). Sau đó, dữ liệu di chuyển theo một trong nhiều đường đi sâu hơn vào mạng, và sau đó quay trở ra để đến người nhận. Kết quả này được gọi là <em>folded Clos network</em> (mạng Clos gập), bởi vì chúng ta đã &quot;gập&quot; các lớp người gửi và người nhận lại thành một.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-021-clos3.png">
<h2 id="fat-tree-clos-topology-topo-clos-cây-béo"><a class="header" href="#fat-tree-clos-topology-topo-clos-cây-béo">Fat-Tree Clos Topology (Topo Clos Cây Béo)</a></h2>
<p><em>Fat-tree topology</em> (topo cây béo) có <em>radix</em> thấp trên mỗi <em>switch</em>, và đạt được <em>bisection bandwidth</em> đầy đủ. Tuy nhiên, <em>switch</em> ở đỉnh cây rất đắt, khả năng mở rộng kém, và vẫn là một điểm lỗi duy nhất.</p>
<p><em>Clos topology</em> cho phép chúng ta sử dụng các <em>switches</em> thương mại để mở rộng quy mô mạng của mình. Nếu chúng ta kết hợp <em>Clos topology</em> với <em>fat-tree topology</em>, chúng ta có thể xây dựng một <em>topology</em> có khả năng mở rộng từ các <em>switches</em> thương mại!</p>
<p><em>Topology</em> được trình bày ở đây đã được giới thiệu trong một bài báo SIGCOMM năm 2008 có tựa đề &quot;A Scalable, Commodity Data Center Network Architecture&quot; (Mohammad Al-Fares, Alexander Loukissas, Amin Vahdat).</p>
<p>Trong một <em>k-ary fat tree</em> (cây béo k-nhánh), chúng ta tạo ra k <em>pods</em> (cụm). Mỗi <em>pod</em> có k <em>switches</em>.</p>
<p>Trong một <em>pod</em>, k/2 <em>switches</em> nằm ở <em>aggregation layer</em> (lớp tổng hợp) trên, và k/2 <em>switches</em> còn lại nằm ở <em>edge layer</em> (lớp biên) dưới.</p>
<p>(Lưu ý: <em>Topology</em> này được định nghĩa cho k là số chẵn, để chúng ta có thể chia đều các <em>switches</em> giữa <em>aggregation layer</em> và <em>edge layer</em>).</p>
<img width="900px" src="datacenter/../assets/datacenter/6-022-pods1.png">
<p>Mỗi <em>switch</em> trong <em>pod</em> có k <em>links</em>. Một nửa số <em>links</em> (k/2) kết nối lên trên, và nửa còn lại (k/2) kết nối xuống dưới.</p>
<p>Hãy xem xét một <em>switch</em> trong <em>aggregation layer</em> trên. Một nửa (k/2) số <em>links</em> của nó kết nối lên <em>core layer</em> (lớp lõi) (lớp này kết nối các <em>pods</em>, sẽ được thảo luận thêm bên dưới). Nửa còn lại (k/2) số <em>links</em> của nó kết nối xuống k/2 <em>switches</em> trong <em>edge layer</em>.</p>
<p>Tương tự, hãy xem xét một <em>switch</em> trong <em>edge layer</em> dưới. Một nửa (k/2) số <em>links</em> của nó kết nối lên k/2 <em>switches</em> trong <em>aggregation layer</em>. Nửa còn lại (k/2) số <em>links</em> của nó kết nối xuống k/2 <em>hosts</em> trong <em>pod</em> này.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-023-pods2.png">
<p>Tiếp theo, hãy xem <em>core layer</em>, lớp kết nối các <em>pods</em> lại với nhau. Mỗi <em>core switch</em> có k <em>links</em>, kết nối đến mỗi trong số k <em>pods</em>.</p>
<p>Có $$(k/2)^2$$<em>core switches</em>. Chúng ta đã suy ra con số này như thế nào? Có k <em>pods</em>, và mỗi <em>pod</em> có k/2 <em>switches</em> trong <em>aggregation layer</em> trên, tổng cộng là$$k^2/2$$<em>switches</em> trong <em>aggregation layer</em>. Mỗi <em>switch</em> ở lớp <em>aggregation</em> có k/2 <em>links</em> hướng lên trên, tổng cộng là$$k^2/2 \times k/2 = k^3/4$$<em>links</em> hướng lên trên. Điều này có nghĩa là <em>core layer</em> sẽ cần có tổng cộng$$k^3/4$$ <em>links</em> hướng xuống dưới, để khớp với số lượng <em>links</em> hướng lên từ <em>aggregation layer</em>.</p>
<p>Mỗi <em>switch</em> ở <em>core layer</em> có k <em>links</em> hướng xuống dưới, vì vậy chúng ta cần $$k^2/4$$<em>switches</em> ở <em>core layer</em> (mỗi <em>switch</em> có k <em>links</em>) để tạo ra$$k^3/4$$ <em>links</em> hướng về phía dưới. Điều này cho phép số lượng <em>links</em> lên từ <em>aggregation layer</em> khớp với số lượng <em>links</em> xuống từ <em>core layer</em>.</p>
<p>Chúng ta cũng có thể tính toán rằng có $$(k/2)^2$$<em>hosts</em> trên mỗi <em>pod</em> trong <em>topology</em> này. Chúng ta đã suy ra con số này như thế nào? Có k/2 <em>switches</em> ở <em>edge layer</em> của mỗi <em>pod</em>. Mỗi <em>switch</em> ở <em>edge layer</em> có k/2 <em>links</em> hướng xuống <em>hosts</em>, tổng cộng là$$k/2 \times k/2 = (k/2)^2$$<em>hosts</em> trên mỗi <em>pod</em>. Lưu ý rằng mỗi <em>host</em> chỉ được kết nối với một <em>switch</em> ở <em>edge layer</em> (một <em>host</em> không được kết nối với nhiều <em>switches</em> trong <em>topology</em> này). Vì có tổng cộng k <em>pods</em>, chúng ta cũng có thể suy ra rằng có tổng cộng$$(k/2)^2 \times k$$ <em>hosts</em> trong <em>topology</em> này.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-024-pods3.png">
<p>k = 4, ví dụ nhỏ nhất, thật không may lại hơi khó hiểu vì một số con số tình cờ giống nhau (ví dụ: $$(k/2)^2 = k = 4$$). Để có một ví dụ rõ ràng hơn, chúng ta có thể xem xét k = 6.</p>
<p>Mỗi <em>pod</em> có k = 6 <em>switches</em>. k/2 = 3 <em>switches</em> nằm ở <em>aggregation layer</em> trên, và k/2 = 3 <em>switches</em> nằm ở <em>edge layer</em> dưới.</p>
<p>Một <em>switch</em> ở <em>edge layer</em> có k/2 = 3 <em>links</em> hướng xuống 3 <em>hosts</em>, và k/2 = 3 <em>links</em> hướng lên 3 <em>switches</em> <em>aggregation</em> trong cùng một <em>pod</em>.</p>
<p>Một <em>switch</em> ở <em>aggregation layer</em> có k/2 = 3 <em>links</em> hướng lên <em>core layer</em> (cụ thể là đến 3 <em>switches</em> khác nhau ở <em>core layer</em>), và k/2 = 3 <em>links</em> hướng xuống 3 <em>switches</em> <em>edge layer</em> trong cùng một <em>pod</em>.</p>
<p>Mỗi <em>pod</em> có k/2 = 3 <em>edge switches</em>, mỗi <em>switch</em> kết nối với k/2 = 3 <em>hosts</em>, vì vậy mỗi <em>pod</em> có tổng cộng $$(k/2)^2 = 9$$<em>hosts</em>. <em>Topology</em> có tổng cộng k <em>pods</em>, cho tổng số$$k \times (k/2)^2 = 54$$ <em>hosts</em>.</p>
<p>Tại <em>core layer</em>, chúng ta có $$(k/2)^2 = 9$$ <em>core switches</em>. Mỗi <em>switch</em> có k = 6 <em>links</em>, kết nối xuống mỗi trong số k = 6 <em>pods</em>.</p>
<p>Tổng cộng, <em>core layer</em> có $$(k/2)^2 \times k$$<em>links</em> hướng xuống (số lượng <em>core switches</em>, nhân với số lượng <em>links</em> trên mỗi <em>switch</em>). <em>Aggregation layer</em> có$$k \times (k/2) \times (k/2)$$ <em>links</em> hướng lên (số lượng <em>pods</em>, nhân với số lượng <em>aggregation switches</em> trên mỗi <em>pod</em>, nhân với số lượng <em>links</em> hướng lên trên mỗi <em>aggregation switch</em>). Hai biểu thức này khớp nhau (và cho kết quả là 54 với k = 6), cho phép <em>core layer</em> được kết nối đầy đủ với <em>aggregation layer</em>.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-025-pods4.png">
<p><em>Topology</em> này đạt được <em>bisection bandwidth</em> đầy đủ. Nếu bạn chia các <em>pods</em> thành hai nửa (ví dụ: nửa bên trái và nửa bên phải), thì mọi <em>host</em> ở nửa bên trái đều có một đường đi riêng đến một <em>host</em> tương ứng ở nửa bên phải. Điều này cho phép tất cả các <em>hosts</em> ghép cặp (một ở nửa bên trái, một ở nửa bên phải), và cho mỗi cặp giao tiếp dọc theo một đường đi riêng, không có điểm nghẽn.</p>
<p>Ngoài ra, hãy để ý rằng <em>topology</em> này có thể được xây dựng từ các <em>switches</em> thương mại. Mọi <em>switch</em> đều có <em>radix</em> là k <em>links</em>, bất kể <em>switch</em> đó ở lớp nào. Ngoài ra, mọi <em>link</em> đều có thể có cùng <em>bandwidth</em> (ví dụ: 1 Gbps), và khả năng mở rộng đến từ việc chúng ta đã tạo ra một đường đi riêng giữa bất kỳ cặp <em>hosts</em> nào.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-026-pods5.png">
<p>Một cách khác để thấy <em>bisection bandwidth</em> đầy đủ là xóa các <em>links</em> cho đến khi mạng được phân chia thành hai nửa (các <em>pods</em> ở nửa bên trái, và các <em>pods</em> ở nửa bên phải).</p>
<p>Mỗi <em>switch</em> ở <em>core layer</em> có k <em>links</em>, một <em>link</em> đến mỗi <em>pod</em>. Điều này cũng có nghĩa là mỗi <em>switch</em> ở <em>core layer</em> có k/2 <em>links</em> đến phía bên trái, và k/2 <em>links</em> đến phía bên phải.</p>
<p>Để cô lập hoàn toàn một bên (ví dụ: cô lập hoàn toàn phía bên trái), thì đối với mỗi <em>core switch</em>, chúng ta sẽ phải cắt k/2 <em>links</em> đến phía bên trái. Có $$(k/2)^2$$<em>core switches</em>, và chúng ta phải cắt k/2 <em>links</em> trên mỗi <em>switch</em>, tổng cộng là$$(k/2)^3$$<em>links</em> bị cắt. Điều này có nghĩa là <em>bisection bandwidth</em> của chúng ta là$$(k/2)^3$$ <em>links</em> (giả sử mọi <em>link</em> đều có <em>bandwidth</em> giống hệt nhau).</p>
<p>Có $$(k/2)^2$$<em>hosts</em> trên mỗi <em>pod</em>, và k/2 <em>pods</em> ở phía bên trái, tổng cộng là$$(k/2)^3$$<em>hosts</em> ở phía bên trái. Tương tự, có$$(k/2)^3$$<em>hosts</em> ở phía bên phải. Nếu mọi <em>host</em> ở phía bên trái muốn giao tiếp với mọi <em>host</em> ở phía bên phải, thì sẽ cần đến <em>bandwidth</em> tương đương với$$(k/2)^3$$ <em>links</em>. <em>Bisection bandwidth</em> của chúng ta khớp với con số này, có nghĩa là <em>bisection bandwidth</em> đầy đủ đã đạt được.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-027-pods6.png">
<p><em>Clos fat-tree topology</em> này liên quan như thế nào đến ý tưởng về <em>racks</em> và <em>top-of-rack switches</em> từ trước đó?</p>
<p>Đối với các giá trị k đẹp cụ thể, chúng ta có thể sắp xếp các <em>hosts</em> và <em>switches</em> bên trong một <em>pod</em> vào các <em>racks</em> riêng biệt, và kết nối các <em>racks</em> với nhau.</p>
<p>Ví dụ, hãy xem xét k = 48, giá trị ví dụ được sử dụng trong bài báo gốc. Điều này có nghĩa là bên trong một <em>pod</em>, có k/2 = 24 <em>aggregation layer switches</em>, k/2 = 24 <em>edge layer switches</em>, và $$(k/2)^2$$ = 576 <em>hosts</em> trên mỗi <em>pod</em>.</p>
<p>Chúng ta có thể sắp xếp các <em>switches</em> và <em>hosts</em> sao cho tất cả 48 <em>switches</em> nằm trong một <em>rack</em> mà chúng ta đặt ở giữa. Sau đó, chúng ta có thể bao quanh <em>rack</em> <em>switches</em> đó bằng 12 <em>racks</em>, mỗi <em>rack</em> chứa 48 <em>hosts</em>. Điều này giúp chúng ta xếp tất cả các <em>switches</em> và <em>hosts</em> vào các <em>racks</em> có kích thước giống hệt nhau (48 máy trên mỗi <em>rack</em>). Đặt các <em>switches</em> vào <em>rack</em> ở giữa cũng giúp giảm lượng dây cáp vật lý cần thiết để xây dựng <em>topology</em> này.</p>
<p><em>Rack</em> ở giữa có k = 48 <em>switches</em>. Mỗi <em>switch</em> có k = 48 <em>ports</em> (cổng), tổng cộng là $$48^2 = 2304$$ <em>ports</em> trong <em>rack</em> này.</p>
<p>Trong số $$k^2 = 2304$$<em>ports</em> này, một nửa trong số chúng ($$k^2/2 = 1152$$) kết nối các <em>switches</em> bên trong <em>rack</em> với nhau. Chúng ta đã suy ra$$k^2/2$$như thế nào? Có thể sẽ hữu ích khi xem một số sơ đồ khái niệm từ trước. Mỗi trong số k/2 <em>aggregation layer switches</em> có k/2 <em>links</em> hướng xuống, tổng cộng là$$(k/2)^2$$<em>ports</em> được sử dụng. Tương tự, mỗi trong số k/2 <em>edge layer switches</em> có k/2 <em>links</em> hướng lên, tổng cộng là$$(k/2)^2$$<em>ports</em> được sử dụng. Điều này cho tổng cộng$$2 \times (k/2)^2 = k^2/2$$ <em>ports</em> được sử dụng.</p>
<p>Lưu ý rằng các <em>links</em> giữa các <em>switches</em> <em>aggregation</em> và <em>edge</em> đang kết nối các <em>switches</em> trong cùng một <em>rack</em>. Do đó, cần hai <em>ports</em> cho mỗi <em>link</em> (một từ <em>aggregation switch</em>, và một từ <em>edge switch</em>), và đó là lý do tại sao chúng ta nhân đôi giá trị $$(k/2)^2$$ (hoặc tương đương, tính giá trị đó hai lần ở cả lớp <em>aggregation</em> và <em>edge</em>).</p>
<p>Trong số $$k^2 = 2304$$<em>ports</em>, một phần tư khác trong số chúng ($$k^2/4 = 576$$) kết nối các <em>switches</em> với các <em>hosts</em> bên trong cùng một <em>pod</em>. Chúng ta đã suy ra con số này như thế nào? Hãy nhớ rằng có$$(k/2)^2$$<em>hosts</em> trong một <em>pod</em>, và mỗi <em>host</em> được kết nối với đúng một <em>switch</em>. Do đó, chúng ta cần$$(k/2)^2 = k^2/4$$ <em>ports</em> trên các <em>switches</em> để kết nối với các <em>hosts</em>.</p>
<p>Cuối cùng, trong số $$k^2 = 2304$$<em>ports</em>, một phần tư còn lại ($$k^2/4 = 576$$) kết nối <em>pod</em> với <em>core layer</em>. Chúng ta đã suy ra con số này như thế nào? Hãy nhớ rằng có$$(k/2)^2$$<em>core switches</em>, và mỗi <em>core switch</em> có một <em>link</em> đến mỗi <em>pod</em>. Nói cách khác, một <em>pod</em> có một <em>link</em> duy nhất đến mỗi trong số$$(k/2)^2$$<em>core switches</em>. Do đó, chúng ta cần$$(k/2)^2 = k^2/4$$ <em>ports</em> trên các <em>switches</em> để kết nối với các <em>core switches</em>.</p>
<p>Tóm lại: Trong tổng số $$k^2$$ <em>ports</em>, một nửa trong số chúng được sử dụng để kết nối các <em>switches</em> <em>aggregation</em>/<em>edge</em> trong cùng một lớp (các kết nối hoàn toàn diễn ra bên trong <em>rack</em> ở giữa). Một phần tư khác được sử dụng để kết nối các <em>edge switches</em> với các <em>hosts</em> trong <em>pod</em> (kết nối giữa <em>rack</em> ở giữa và 12 <em>racks</em> xung quanh chứa <em>hosts</em>). Phần tư cuối cùng được sử dụng để kết nối các <em>aggregation switches</em> với <em>core layer</em> (kết nối giữa <em>rack</em> ở giữa và các <em>racks</em> <em>core-layer</em> khác).</p>
<img width="600px" src="datacenter/../assets/datacenter/6-028-pods7.png">
<h2 id="real-world-topologies-các-topo-trong-thế-giới-thực"><a class="header" href="#real-world-topologies-các-topo-trong-thế-giới-thực">Real-World Topologies (Các Topo trong thế giới thực)</a></h2>
<img width="900px" class="real-photo" src="datacenter/../assets/datacenter/6-029-irl-topology1.png">
<p>Trong ví dụ này (2008), có nhiều đường đi khác nhau giữa bất kỳ hai <em>end hosts</em> nào.</p>
<img width="900px" class="real-photo" src="datacenter/../assets/datacenter/6-030-irl-topology2.png">
<p>Trong bài báo này (2015), nhiều <em>topologies</em> khác nhau đã được khám phá.</p>
<p>Nhiều biến thể cụ thể tồn tại (2009, 2015), nhưng tất cả chúng đều có chung mục tiêu là đạt được <em>bandwidth</em> cao giữa bất kỳ hai <em>servers</em> nào.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kiểm-soát-tắc-nghẽn-trong-datacenter-congestion-control-in-datacenters"><a class="header" href="#kiểm-soát-tắc-nghẽn-trong-datacenter-congestion-control-in-datacenters"><strong>Kiểm soát tắc nghẽn trong Datacenter</strong> (Congestion Control in Datacenters)</a></h1>
<h2 id="tại-sao-datacenter-lại-khác-biệt-why-are-datacenters-different"><a class="header" href="#tại-sao-datacenter-lại-khác-biệt-why-are-datacenters-different"><strong>Tại sao Datacenter lại khác biệt?</strong> (Why are Datacenters Different?)</a></h2>
<p>Chúng ta đã thấy rằng mạng <strong>datacenter</strong> (trung tâm dữ liệu) có những ràng buộc bổ sung (ví dụ: nằm trong cùng một tòa nhà, thuộc sở hữu của một <strong>operator</strong> – nhà vận hành) so với các mạng đa dụng (<strong>general-purpose networks</strong>). Điều này có thể dẫn đến việc xuất hiện các <strong>protocol</strong> (giao thức) đặc thù, tận dụng các đặc điểm riêng của mạng. Trong phần này, chúng ta sẽ tìm hiểu các <strong>TCP congestion control algorithm</strong> (thuật toán kiểm soát tắc nghẽn TCP) có thể không hoạt động hiệu quả trên Internet nói chung, nhưng lại hiệu quả trong bối cảnh datacenter. Đây là một lĩnh vực nghiên cứu và phát triển đang rất sôi động.</p>
<p>Trước tiên, cần trả lời: Điều gì khiến kiểm soát tắc nghẽn trong datacenter khác biệt?</p>
<p>Nhớ rằng <strong>packet delay</strong> (độ trễ gói tin) bao gồm:</p>
<ul>
<li><strong>Transmission delay</strong> (độ trễ truyền): thời gian để phát tín hiệu bit lên đường truyền, phụ thuộc vào <strong>bandwidth</strong> (băng thông).</li>
<li><strong>Propagation delay</strong> (độ trễ lan truyền): thời gian để bit di chuyển qua đường truyền.</li>
<li><strong>Queuing delay</strong> (độ trễ hàng đợi).</li>
</ul>
<p>Trong datacenter, transmission delay thường rất nhỏ (vì có các liên kết tốc độ cao 10 Gbps). Propagation delay cũng nhỏ (vì tất cả server nằm trong cùng tòa nhà). Do đó, queuing delay thường là nguồn gây trễ chính. Ngược lại, trên Internet diện rộng (<strong>wide-area Internet</strong>), propagation delay có thể lớn hơn hàng bậc độ lớn (ví dụ: packet phải đi xuyên quốc gia) và thường là nguyên nhân chính gây trễ.</p>
<p>Nhớ rằng TCP congestion control cố tình làm đầy hàng đợi cho đến khi packet bị mất (phát hiện tắc nghẽn bằng cách kiểm tra mất gói). Các nhà thiết kế TCP ban đầu không tính đến bối cảnh datacenter, nơi queuing delay có thể ảnh hưởng lớn hơn nhiều đến hiệu năng.</p>
<p>Vấn đề hàng đợi lớn càng nghiêm trọng hơn trong datacenter vì, khác với Internet diện rộng, hầu hết kết nối trong datacenter thuộc một trong hai loại:</p>
<ul>
<li><strong>Mice</strong>: kết nối ngắn, nhạy cảm với độ trễ. Ví dụ: truy vấn tìm kiếm web và trang kết quả chỉ chứa lượng dữ liệu rất nhỏ, nhưng cần trả kết quả cho người dùng thật nhanh.</li>
<li><strong>Elephants</strong>: kết nối lớn, nhạy cảm với thông lượng (<strong>throughput</strong>). Ví dụ: sao lưu dữ liệu từ server này sang server khác cần kết nối dài, truyền lượng dữ liệu lớn với throughput cao.</li>
</ul>
<p>Nếu chạy TCP congestion control với cả hai loại kết nối này, các elephant sẽ tăng tốc độ cho đến khi hàng đợi đầy. Khi đó, các mice đến sau sẽ bị kẹt trong hàng đợi, gây trễ.</p>
<p>Để tối ưu hiệu năng cho các loại kết nối này, thuật toán kiểm soát tắc nghẽn trong datacenter phải tránh làm đầy hàng đợi. Nhiều giải pháp đặc thù cho datacenter đã được phát triển trong những năm gần đây.</p>
<p>Ví dụ: <strong>BBR</strong> được Google phát hành năm 2016. Thay vì phát hiện tắc nghẽn bằng cách kiểm tra mất gói (yêu cầu hàng đợi đầy), BBR phát hiện tắc nghẽn bằng cách kiểm tra <strong>packet delay</strong>.</p>
<h2 id="dctcp-phản-hồi-từ-router-dctcp-feedback-from-routers"><a class="header" href="#dctcp-phản-hồi-từ-router-dctcp-feedback-from-routers"><strong>DCTCP: Phản hồi từ Router</strong> (DCTCP: Feedback from Routers)</a></h2>
<p><strong>DCTCP</strong> (Datacenter TCP) được Microsoft phát hành năm 2010 và hiện được sử dụng rộng rãi (ví dụ: đã được triển khai trong <strong>Linux kernel</strong>).</p>
<p>Nhớ rằng <strong>IP header</strong> có một <strong>ECN bit</strong> (Explicit Congestion Notification), và <strong>router</strong> có thể bật bit này để báo hiệu đang tắc nghẽn. Khi packet đến đích, <strong>ACK</strong> cũng sẽ có ECN bit được bật, báo cho bên gửi giảm tốc độ.</p>
<p>Trong DCTCP, router sẽ bật ECN bit khi độ dài hàng đợi vượt quá một ngưỡng nhất định. Điều này cho phép bên gửi phát hiện và thích ứng với tắc nghẽn sớm hơn (khi hàng đợi đang đầy dần, trước khi đầy hoàn toàn).</p>
<p>Khi phát hiện tắc nghẽn, bên gửi giảm tốc độ <strong>tỷ lệ thuận</strong> với số lượng packet có ECN bit được đánh dấu. Điều này giúp điều chỉnh tốc độ nhẹ nhàng hơn. Thay vì quyết định nhị phân (có hoặc không tắc nghẽn), bên gửi có thể nhận biết mức độ tắc nghẽn và giảm tốc độ một chút để bù.</p>
<p>ECN bit không hiệu quả trên Internet diện rộng vì không phải tất cả router đều hỗ trợ. Tuy nhiên, trong datacenter, operator kiểm soát toàn bộ switch và có thể cấu hình chúng bật ECN một cách đồng bộ. Trên thực tế, triển khai DCTCP tại host và router chỉ cần thay đổi nhỏ.</p>
<p>Để đo hiệu năng của DCTCP, ta có thể đo <strong>Flow Completion Time (FCT)</strong> – thời gian từ khi byte đầu tiên được gửi đến khi byte cuối cùng được nhận. Chuẩn lý tưởng là thời gian hoàn thành nếu dùng một <strong>omniscient scheduler</strong> (bộ lập lịch toàn tri) có kiến thức toàn cục về toàn bộ mạng và tất cả kết nối, để lập lịch và phân bổ băng thông tối ưu.</p>
<img width="500px" src="datacenter/../assets/datacenter/6-031-fct-chart1.png">
<p>Biểu đồ này cho thấy <strong>normalized FCT</strong> (FCT chuẩn hóa) – tỷ lệ giữa FCT thực tế và FCT lý tưởng. Nó cho biết chúng ta kém lý tưởng bao nhiêu. Có thể thấy TCP congestion control tiêu chuẩn kém hơn lý tưởng 3 lần, và kém tới 10 lần nếu tải mạng cao. Ngược lại, DCTCP hoạt động tốt hơn đáng kể, kết nối hoàn thành nhanh hơn nhiều với ít queuing delay hơn.</p>
<h2 id="pfabric-Ưu-tiên-gói-tin-packet-priorities"><a class="header" href="#pfabric-Ưu-tiên-gói-tin-packet-priorities"><strong>pFabric: Ưu tiên gói tin</strong> (Packet Priorities)</a></h2>
<p>Chúng ta đã thấy vấn đề trong datacenter là mice có thể bị kẹt sau elephant trong hàng đợi. Vậy nếu cho mice cách “vượt hàng” để hoàn thành nhanh hơn thì sao?</p>
<p>Để ưu tiên mice, ta gán một <strong>priority number</strong> (số ưu tiên) cho mỗi packet. Số ưu tiên được tính dựa trên <strong>remaining flow size</strong> (kích thước luồng còn lại – số byte chưa được ACK). Số nhỏ hơn có ưu tiên cao hơn.</p>
<p>Với hệ thống này:</p>
<ul>
<li>Packet của mice sẽ có ưu tiên cao (flow size rất nhỏ).</li>
<li>Elephant sẽ có ưu tiên thấp, nhưng vài byte cuối của kết nối elephant sẽ có ưu tiên cao hơn. Điều này giúp ưu tiên các kết nối gần hoàn tất (dù là elephant).</li>
</ul>
<p>Để triển khai, nhớ rằng <strong>IP packet header</strong> có trường chỉ định ưu tiên. Trong <strong>pFabric</strong>, mỗi packet mang một số ưu tiên, và switch được chỉnh sửa để gửi packet có ưu tiên cao nhất. Nếu hàng đợi đầy, switch sẽ drop packet có ưu tiên thấp nhất.</p>
<p>Với hệ thống ưu tiên này, bên gửi có thể truyền và truyền lại packet ở <strong>full line rate</strong> (tốc độ tối đa của đường truyền) mà không cần điều chỉnh tốc độ vì tắc nghẽn. Chỉ khi mất gói nghiêm trọng (ví dụ: timeout) mới cần giảm tốc độ.</p>
<p>Nếu xem lại biểu đồ FCT, ta thấy pFabric còn tốt hơn DCTCP và gần với lý tưởng.</p>
<img width="500px" src="datacenter/../assets/datacenter/6-032-fct-chart2.png">
<p>Tại sao pFabric hoạt động tốt? Elephant và mice cùng truyền, mọi người đều gửi ở full line rate, đảm bảo tận dụng tối đa băng thông. Không mất thời gian cho <strong>slow start</strong>. Ngoài ra, tránh được sụp đổ vì hầu hết packet của elephant có ưu tiên thấp. Hệ thống ưu tiên đảm bảo packet của mice vẫn đi qua hàng đợi với độ trễ thấp.</p>
<p>Triển khai hệ thống này đòi hỏi thay đổi đáng kể ở cả switch và end host, và cần toàn quyền kiểm soát cả hai. Switch phải hỗ trợ hệ thống ưu tiên, và bên gửi phải thay thế TCP implementation để gửi ở full line rate. Dù vậy, pFabric là ví dụ điển hình về sự hợp tác giữa mạng (switch) và end host để đạt hiệu năng cao.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Định-tuyến-trong-datacenter-datacenter-routing"><a class="header" href="#Định-tuyến-trong-datacenter-datacenter-routing"><strong>Định tuyến trong Datacenter</strong> (Datacenter Routing)</a></h1>
<h2 id="tại-sao-datacenter-lại-khác-biệt-why-are-datacenters-different-1"><a class="header" href="#tại-sao-datacenter-lại-khác-biệt-why-are-datacenters-different-1"><strong>Tại sao Datacenter lại khác biệt?</strong> (Why are Datacenters Different?)</a></h2>
<p>Trong phần trước, chúng ta đã thiết kế các mạng <strong>Clos</strong>, tạo ra nhiều đường đi giữa các <strong>server</strong>. Các server có thể giao tiếp đồng thời với băng thông cao bằng cách sử dụng các đường đi khác nhau trong mạng.</p>
<p>Vậy sẽ có vấn đề gì nếu áp dụng các <strong>routing algorithm</strong> (thuật toán định tuyến) tiêu chuẩn vào các <strong>network topology</strong> (kiến trúc mạng) này?</p>
<p>Cho đến nay, các <strong>routing protocol</strong> (giao thức định tuyến) của chúng ta chọn một đường duy nhất giữa <strong>source</strong> (nguồn) và <strong>destination</strong> (đích). Nếu toàn bộ lưu lượng đều đi cùng một đường, chúng ta không tận dụng được tất cả các liên kết bổ sung trong mạng Clos. Lý tưởng nhất, chúng ta muốn chỉnh sửa giao thức định tuyến để một <strong>packet</strong> có thể sử dụng nhiều đường khác nhau giữa cùng một cặp điểm cuối.</p>
<img width="400px" src="datacenter/../assets/datacenter/6-033-dcrouting1.png">
<p>Giả sử A và B có băng thông uplink 200 Gbps, và các liên kết giữa switch với switch có băng thông 100 Gbps. Nếu toàn bộ lưu lượng giữa A và B bị buộc đi theo đường màu xanh lá, chúng ta đang bỏ phí đường màu đỏ. Chúng ta có thể truyền dữ liệu ở tốc độ tối đa nếu cho phép packet đi theo các đường khác nhau.</p>
<p>Ngoài ra, nếu có nhiều kết nối đồng thời, chúng ta muốn các kết nối đó sử dụng các đường khác nhau để tối đa hóa băng thông.</p>
<img width="400px" src="datacenter/../assets/datacenter/6-034-dcrouting2.png">
<p>Giả sử tất cả các liên kết đều có băng thông 100 Gbps. Trong ví dụ này, nhiều kết nối đang cạnh tranh băng thông. Nếu kết nối A-B và C-D đều chọn cùng một đường, các liên kết R1-R2 và R2-R4 sẽ bị quá tải (200 Gbps trên dung lượng 100 Gbps). Chúng ta có thể truyền dữ liệu ở tốc độ tối đa nếu A-B và C-D dùng các đường khác nhau.</p>
<h2 id="equal-cost-multi-path-ecmp-routing-Định-tuyến-đa-đường-có-chi-phí-bằng-nhau"><a class="header" href="#equal-cost-multi-path-ecmp-routing-Định-tuyến-đa-đường-có-chi-phí-bằng-nhau"><strong>Equal Cost Multi-Path (ECMP) Routing</strong> (Định tuyến đa đường có chi phí bằng nhau)</a></h2>
<p>Trong <strong>equal cost multi-path</strong> routing, mục tiêu là tìm tất cả các đường ngắn nhất (có chi phí bằng nhau) và <strong>load-balance</strong> (cân bằng tải) packet qua các đường này.</p>
<p>Nếu một packet đến <strong>router</strong>, nhưng có nhiều liên kết đầu ra đều là đường ngắn nhất hợp lệ, router sẽ chọn liên kết nào? Router cần một <strong>function</strong> (hàm – có thể hình dung như một đoạn mã) nhận packet và xuất ra lựa chọn liên kết. Hàm này phải cân bằng tải đúng cách giữa các đường có chi phí bằng nhau.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-035-ecmp1.png">
<p>Một chiến lược khả thi là <strong>round-robin</strong>. Nếu có hai liên kết đầu ra ngắn nhất, hàm có thể quy định: gửi tất cả packet lẻ qua Link 1 và packet chẵn qua Link 2.</p>
<p>Vấn đề của cách này là: đường có chi phí bằng nhau không nhất thiết có <strong>latency</strong> (độ trễ) bằng nhau. (Nhớ rằng chi phí được operator định nghĩa theo tiêu chí tùy ý.) Nếu gửi tất cả packet lẻ qua đường chậm và packet chẵn qua đường nhanh, <strong>TCP recipient</strong> (bên nhận TCP) có thể nhận tất cả packet chẵn trước packet lẻ. TCP quan tâm đến việc sắp xếp lại packet, nên bên nhận sẽ phải <strong>buffer</strong> (đệm) packet chẵn cho đến khi nhận đủ packet lẻ, gây giảm hiệu năng.</p>
<p>Một chiến lược thông minh hơn là xem xét một số trường trong <strong>packet header</strong> và dùng chúng để đưa ra lựa chọn liên kết một cách <strong>deterministic</strong> (xác định). Có thể xem xét những trường nào?</p>
<ul>
<li>Nếu dùng <strong>destination IP</strong> để chọn giữa các đường ngắn nhất: vấn đề là nếu nhiều nguồn gửi packet đến cùng một đích, tất cả packet có cùng destination IP sẽ bị ánh xạ vào cùng một liên kết ngắn nhất → không cân bằng tải.</li>
</ul>
<img width="400px" src="datacenter/../assets/datacenter/6-036-ecmp2.png">
<ul>
<li>Nếu dùng <strong>source IP</strong>: tương tự, nếu một nguồn gửi packet đến nhiều đích, tất cả packet có cùng source IP sẽ bị ánh xạ vào cùng một liên kết ngắn nhất.</li>
</ul>
<img width="400px" src="datacenter/../assets/datacenter/6-037-ecmp3.png">
<p>Giải pháp: dùng cả <strong>source IP</strong> và <strong>destination IP</strong>. Để cân bằng tải, ta có thể <strong>hash</strong> (băm) cặp địa chỉ này và ánh xạ kết quả băm tới một liên kết (tương tự như <strong>hash table</strong>). Cặp địa chỉ này chứa đủ <strong>entropy</strong> (độ ngẫu nhiên) để tránh vấn đề trước đó.</p>
<img width="400px" src="datacenter/../assets/datacenter/6-038-ecmp4.png">
<p>Vẫn còn một vấn đề: nếu có nhiều kết nối lớn giữa cùng một source và destination, ta không muốn tất cả chúng vào cùng một liên kết. Giải pháp: xem thêm <strong>source port</strong> và <strong>destination port</strong> trong <strong>TCP</strong> hoặc <strong>UDP header</strong>.</p>
<p>Nói chung, mọi vấn đề đã nêu (sắp xếp lại packet trong kết nối TCP, quá nhiều kết nối trên một liên kết) đều có thể giải quyết nếu đặt mỗi kết nối trên một liên kết riêng. Để định danh duy nhất một kết nối, cần <strong>5-tuple</strong> gồm: (source IP, destination IP, protocol, source port, destination port). Cần protocol để phân biệt giữa kết nối TCP và UDP dùng cùng IP/port. Hai packet thuộc cùng một kết nối khi và chỉ khi chúng có cùng 5-tuple.</p>
<img width="400px" src="datacenter/../assets/datacenter/6-039-ecmp5.png">
<p>Bằng cách băm cả 5 giá trị, ta đảm bảo packet trong cùng một kết nối đi cùng một đường (tránh sắp xếp lại), đồng thời cân bằng tải kết nối qua các đường khác nhau. Cách này gọi là <strong>per-flow load balancing</strong> (cân bằng tải theo luồng). Các router thương mại hiện đại thường hỗ trợ đọc 5 giá trị này.</p>
<p>Per-flow load balancing đảm bảo mỗi liên kết được dùng bởi số lượng kết nối xấp xỉ nhau, dù không tính đến kích thước kết nối. Việc tính đến kích thước kết nối là khả thi về mặt kỹ thuật nhưng tốn kém (router phải xử lý nhiều hơn) và lợi ích không đáng kể (per-flow đã cân bằng khá tốt), nên không áp dụng trong thực tế.</p>
<h2 id="multi-path-distance-vector-protocols-giao-thức-vectơ-khoảng-cách-đa-đường"><a class="header" href="#multi-path-distance-vector-protocols-giao-thức-vectơ-khoảng-cách-đa-đường"><strong>Multi-Path Distance-Vector Protocols</strong> (Giao thức vectơ khoảng cách đa đường)</a></h2>
<p>Để tối đa hóa băng thông, ta nên gửi packet qua các đường khác nhau, ngay cả khi chúng đến cùng một đích (ví dụ: nếu packet thuộc các kết nối khác nhau). Điều này nghĩa là phải chỉnh sửa routing protocol để router học tất cả các đường ngắn nhất, không chỉ một.</p>
<p>Trong <strong>distance-vector protocol</strong> tiêu chuẩn, nếu nhận được quảng bá về một đường mới có chi phí bằng chi phí tốt nhất hiện tại, ta sẽ bỏ qua đường mới. Nhưng để nhớ tất cả các đường có chi phí tối thiểu, ta nên chấp nhận cả đường bằng chi phí và lưu cả hai vào <strong>forwarding table</strong>. Khi đó, một đích có thể ánh xạ tới nhiều <strong>next hop</strong> miễn là chúng có cùng chi phí tối thiểu.</p>
<img width="600px" src="datacenter/../assets/datacenter/6-040-ecmp6.png">
<p>Ví dụ: R1 nhận quảng bá từ cả R4 và R3, đều cho biết có thể đến B trong 2 hop. Forwarding table lưu cả R4 và R3 là next hop khả thi, cùng chi phí tối thiểu là 3.</p>
<img width="600px" src="datacenter/../assets/datacenter/6-041-ecmp7.png">
<p>Khi chuyển tiếp packet, router sẽ băm 5-tuple để gửi khoảng một nửa kết nối qua R3 và nửa còn lại qua R2.</p>
<h2 id="multi-path-link-state-protocols-giao-thức-trạng-thái-liên-kết-đa-đường"><a class="header" href="#multi-path-link-state-protocols-giao-thức-trạng-thái-liên-kết-đa-đường"><strong>Multi-Path Link-State Protocols</strong> (Giao thức trạng thái liên kết đa đường)</a></h2>
<p>Trong <strong>link-state protocol</strong>, ta flood quảng bá để mọi nút có bức tranh đầy đủ về mạng. Thông thường, mỗi nút tính một đường ngắn nhất đến mỗi đích để điền vào forwarding table. Để hỗ trợ nhiều đường, mỗi nút cần tính <strong>tất cả</strong> các đường ngắn nhất đến mỗi đích.</p>
<p>Giống như trong distance-vector đã chỉnh sửa, forwarding table giờ có thể chứa nhiều next hop cho một đích nhất định.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="Địa-chỉ-hóa-trong-datacenter-datacenter-addressing"><a class="header" href="#Địa-chỉ-hóa-trong-datacenter-datacenter-addressing"><strong>Địa chỉ hóa trong Datacenter</strong> (Datacenter Addressing)</a></h1>
<h2 id="tại-sao-datacenter-lại-khác-biệt-why-are-datacenters-different-2"><a class="header" href="#tại-sao-datacenter-lại-khác-biệt-why-are-datacenters-different-2"><strong>Tại sao Datacenter lại khác biệt?</strong> (Why are Datacenters Different?)</a></h2>
<p>Trong phần trước, chúng ta đã thấy rằng có thể chỉnh sửa các giao thức định tuyến <strong>distance-vector</strong> (vectơ khoảng cách) và <strong>link-state</strong> (trạng thái liên kết) để tính toán tất cả các đường đi trong mạng <strong>datacenter</strong> (trung tâm dữ liệu).</p>
<p>Tuy nhiên, các giao thức này có thể <strong>scale</strong> (mở rộng) kém trong môi trường datacenter.</p>
<ul>
<li>Trong giao thức distance-vector, chúng ta phải tạo thông báo cho <strong>mỗi đích</strong> (destination), nghĩa là phải quảng bá hơn 100.000 đích.</li>
<li>Trong giao thức link-state, chúng ta phải <strong>flood</strong> (phát tràn) các thông báo dọc theo mọi liên kết, điều này mở rộng kém trong các mạng <strong>Clos</strong> có số lượng liên kết khổng lồ.</li>
</ul>
<p>Ngoài ra, hãy nhớ rằng các <strong>topology</strong> (kiến trúc liên kết) của datacenter thường sử dụng các <strong>commodity switch</strong> (switch thương mại giá rẻ), vốn có tài nguyên bộ nhớ và CPU hạn chế (ví dụ: <strong>forwarding table</strong> – bảng chuyển tiếp – không thể quá lớn).</p>
<p>Trong các mạng đa dụng (general-purpose networks), chúng ta giải quyết các vấn đề mở rộng này bằng cách giới thiệu <strong>hierarchical IP addressing</strong> (địa chỉ IP phân cấp). Các tổ chức cấp cao hơn (ví dụ: cấp quốc gia) có thể phân bổ dải địa chỉ cho các tổ chức nhỏ hơn (ví dụ: trường đại học). Datacenter không có cấu trúc phân cấp địa lý hoặc tổ chức để áp dụng cách tổ chức địa chỉ này.</p>
<p>Tuy nhiên, trong datacenter, chúng ta có thể tận dụng việc <strong>operator</strong> (nhà vận hành) kiểm soát <strong>physical topology</strong> (topology vật lý) của mạng, và gán địa chỉ cho <strong>server</strong> dựa trên vị trí của chúng trong tòa nhà. Chúng ta cũng có thể tận dụng việc topology có cấu trúc đều đặn (ví dụ: thường sắp xếp server thành hàng, thay vì đặt ngẫu nhiên trong tòa nhà).</p>
<h2 id="Địa-chỉ-hóa-nhận-thức-topology-topology-aware-addressing"><a class="header" href="#Địa-chỉ-hóa-nhận-thức-topology-topology-aware-addressing"><strong>Địa chỉ hóa nhận thức topology</strong> (Topology-Aware Addressing)</a></h2>
<img width="900px" src="datacenter/../assets/datacenter/6-042-dc-addressing.png">
<p>Trong topology cụ thể này, các <strong>rack</strong> (tủ máy) được tổ chức vật lý thành các <strong>pod</strong> riêng biệt trong tòa nhà. Một cách tiếp cận tự nhiên là phân bổ một dải địa chỉ cho mỗi pod. Sau đó, mỗi pod có thể phân bổ các <strong>sub-range</strong> (dải con) cho từng rack trong pod. Cuối cùng, mỗi rack có thể phân bổ một địa chỉ IP riêng cho từng server.</p>
<p>Nhà vận hành biết số lượng server trong mỗi rack và số lượng rack trong mỗi pod, vì vậy chúng ta có thể dùng thông tin này để phân bổ dải địa chỉ với kích thước phù hợp. Ví dụ: một rack có thể nhận một dải <em>/24</em>, cung cấp cho rack đó 256 địa chỉ cho các server của mình.</p>
<p>Cách phân bổ này cho phép <strong>aggregate routes</strong> (gộp tuyến) và lưu ít mục hơn trong bảng chuyển tiếp. Ví dụ: xét một <strong>spine router</strong> (router xương sống) ở phía trên cùng của sơ đồ. Router này không cần ghi nhớ đường đi đến từng server. Thay vào đó, bảng chuyển tiếp chỉ cần bốn mục, mỗi mục cho một pod. Khi một packet đến, router kiểm tra 16 bit đầu tiên để chuyển tiếp packet đến pod thích hợp.</p>
<p><strong>Route aggregation</strong> (gộp tuyến) cũng mang lại sự ổn định cao hơn. Nếu một host được thêm hoặc gỡ bỏ trong một rack cụ thể, spine router không cần biết. Miễn là chúng ta duy trì cùng sơ đồ địa chỉ, bảng chuyển tiếp hiện tại vẫn đúng mà không cần thay đổi. Do đó, các bản cập nhật định tuyến thường chỉ xảy ra khi liên kết hoặc switch gặp sự cố, chứ không phải khi host gặp sự cố.</p>
<p>Việc gán địa chỉ dựa trên topology của datacenter rất tốt cho khả năng mở rộng, nhưng cũng có một số hạn chế. Đặc biệt, nếu chúng ta di chuyển một server sang vị trí khác, chúng ta sẽ phải thay đổi địa chỉ của nó.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="virtualization-and-encapsulation-Ảo-hóa-và-Đóng-gói"><a class="header" href="#virtualization-and-encapsulation-Ảo-hóa-và-Đóng-gói">Virtualization and Encapsulation (Ảo hóa và Đóng gói)</a></h1>
<h2 id="hạn-chế-của-datacenter-vật-lý"><a class="header" href="#hạn-chế-của-datacenter-vật-lý">Hạn chế của Datacenter vật lý</a></h2>
<p>Các <em>Datacenters</em> (trung tâm dữ liệu) được tổ chức một cách cố định và có cấu trúc. Các <em>servers</em> (máy chủ) giống hệt nhau được tổ chức thành các <em>racks</em> (giá đỡ), và các <em>racks</em> được sắp xếp theo một <em>topology</em> (topo) cố định nào đó. Cách tiếp cận này có một số lợi ích. Ví dụ, nó cho chúng ta một cách tự nhiên để gán <em>hierarchical addresses</em> (địa chỉ phân cấp).</p>
<p>Tuy nhiên, khi chúng ta xem xét cách các ứng dụng được lưu trữ trên <em>datacenters</em>, việc tổ chức cố định của <em>datacenters</em> có một số nhược điểm. Giả sử Google giới thiệu một dịch vụ mới mà họ muốn lưu trữ trong một <em>datacenter</em> hiện có. Nếu chúng ta đặt ứng dụng đó trực tiếp lên một <em>physical server</em> (máy chủ vật lý), ai đó sẽ phải cài đặt vật lý một <em>server</em> mới, với <em>IP address</em> (địa chỉ IP) riêng, cho ứng dụng này. Nếu dịch vụ mở rộng, có thể cần phải cài đặt thêm nhiều <em>servers</em> hơn. Nếu <em>server</em> bị hỏng, chúng ta sẽ phải đợi ai đó sửa chữa nó. Vấn đề chính ở đây là việc thay đổi cơ sở hạ tầng vật lý rất khó khăn, nhưng chúng ta thường muốn thêm các <em>hosts</em> (máy chủ) mới, mở rộng quy mô các <em>hosts</em> hiện có, và di chuyển <em>hosts</em> một cách nhanh chóng và thường xuyên.</p>
<p>Việc đặt các ứng dụng trên các <em>physical servers</em> cũng gây ra các vấn đề về khả năng mở rộng. Giả sử dịch vụ mới của Google rất nhẹ, nhưng cần một <em>server</em> chuyên dụng (ví dụ: vì lý do bảo mật). Chúng ta sẽ phải gán toàn bộ một <em>physical server</em> cho dịch vụ nhẹ này, và hầu hết năng lực tính toán của <em>server</em> sẽ không được sử dụng.</p>
<p>Cách tiếp cận này cũng có các vấn đề về định tuyến. Giả sử chúng ta muốn di chuyển dịch vụ đến một phần khác của tòa nhà <em>datacenter</em> (ví dụ: vì một phần của tòa nhà đang được bảo trì). Đầu tiên, ai đó sẽ phải di chuyển vật lý <em>server</em> trong tòa nhà. Ngoài ra, trong mô hình <em>hierarchical address</em> của chúng ta, chúng ta sẽ cần gán cho dịch vụ này một <em>IP address</em> mới tương ứng với vị trí vật lý mới của nó. Lý tưởng nhất, ứng dụng sẽ muốn giữ nguyên địa chỉ, bất kể vị trí của nó trong <em>datacenter</em>.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-043-dc-address-scaling.png">
<h2 id="virtualization-Ảo-hóa"><a class="header" href="#virtualization-Ảo-hóa">Virtualization (Ảo hóa)</a></h2>
<p>Chúng ta có thể sử dụng <em>virtualization</em> để giải quyết những vấn đề này và mang lại cho các ứng dụng sự linh hoạt hơn, trong khi vẫn duy trì cấu trúc vật lý cứng nhắc của <em>datacenter</em>. <em><strong>Virtualization</strong></em> cho phép chúng ta chạy một hoặc nhiều <em>virtual servers</em> (máy chủ ảo) bên trong một <em>physical server</em>.</p>
<p><em>Virtual server</em> mang lại cho các ứng dụng ảo giác rằng chúng đang chạy trên một máy vật lý chuyên dụng. Tuy nhiên, trên thực tế, nhiều <em>virtual servers</em> có thể đang chạy trên cùng một máy. Khi ứng dụng cố gắng tương tác với phần cứng (ví dụ: đĩa, <em>network card</em> (card mạng)), nó thực sự đang tương tác với một <strong><em>hypervisor</em> (trình quản lý máy ảo)</strong> trong phần mềm. <em>Hypervisor</em> cung cấp cho mỗi ứng dụng ảo cùng một giao diện mà phần cứng thực sự sẽ có. Bản thân <em>hypervisor</em> chạy trên phần cứng vật lý thực tế, và có thể chuyển tiếp các yêu cầu của ứng dụng (ví dụ: ghi đĩa, gửi gói tin mạng) đến cấp độ phần cứng.</p>
<p>Với <em>virtualization</em>, nếu chúng ta có một ứng dụng mới, chúng ta có thể yêu cầu một <em>hypervisor</em> khởi động một <em>virtual machine</em> (máy ảo) mới cho ứng dụng này. <em>Hypervisor</em> chạy trong phần mềm, vì vậy không cần phải cài đặt bất kỳ <em>server</em> mới nào trong <em>datacenter</em> vật lý. Tương tự, chúng ta có thể di chuyển <em>hosts</em> đến một máy vật lý khác, hoàn toàn bằng phần mềm.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-044-vm.png">
<p><em>Virtualization</em> cho phép nhiều ứng dụng chia sẻ một <em>physical server</em>. Các ứng dụng có thể được tách biệt với nhau, và có thể được quản lý bởi những người khác nhau. Điều này cho phép chúng ta sử dụng các tài nguyên tính toán trong <em>datacenter</em> hiệu quả hơn. Điều này cũng cho phép chúng ta có nhiều <em>hosts</em> hơn trong <em>datacenter</em>. Ví dụ, một <em>rack</em> duy nhất với 40 <em>servers</em> có thể có nhiều hơn 40 <em>end hosts</em> (máy chủ đầu cuối).</p>
<h2 id="virtual-switches-bộ-chuyển-mạch-ảo"><a class="header" href="#virtual-switches-bộ-chuyển-mạch-ảo">Virtual Switches (Bộ chuyển mạch ảo)</a></h2>
<p><em>Physical server</em> có một <em>network card</em> và một <em>IP address</em> duy nhất, nhưng chúng ta cần mang lại cho mỗi <em>virtual machine</em> ảo giác rằng nó có <em>network card</em> và địa chỉ chuyên dụng của riêng mình. Ngoài ra, các <em>switches</em> (bộ chuyển mạch) giờ đây có thể có nhiều <em>virtual machines</em> kết nối với một <em>port</em> (cổng) vật lý duy nhất.</p>
<p>Để quản lý nhiều kết nối mạng trên cùng một máy vật lý, <em>server</em> cần một <em><strong>virtual switch</strong></em>. <em>Virtual switch</em> này chạy trong phần mềm trên <em>server</em> (nó không phải là một <em>router</em> vật lý), và thực hiện các hoạt động tương tự như một <em>switch</em> thực sự (ví dụ: chuyển tiếp gói tin). Mỗi <em>virtual machine</em> được kết nối với <em>virtual switch</em>, và <em>virtual switch</em> được kết nối với phần còn lại của mạng.</p>
<img width="500px" src="datacenter/../assets/datacenter/6-045-virtual-switch.png">
<p>Lưu ý: Các <em>switches</em> thường chạy trên phần cứng chuyên dụng để tối đa hóa hiệu quả. Các <em>virtual switches</em> có thể chạy trong phần mềm trên một <em>CPU</em> (đơn vị xử lý trung tâm) đa dụng vì chúng chỉ cần hỗ trợ một vài <em>virtual machines</em> (dung lượng thấp hơn so với những gì các <em>switches</em> thường xử lý).</p>
<h2 id="underlay-and-overlay-network-mạng-lớp-nền-và-mạng-lớp-phủ"><a class="header" href="#underlay-and-overlay-network-mạng-lớp-nền-và-mạng-lớp-phủ">Underlay and Overlay Network (Mạng lớp nền và Mạng lớp phủ)</a></h2>
<p>Với <em>virtualization</em>, chúng ta giờ đây có các <em>virtual hosts</em> (máy chủ ảo) chạy trên các <em>physical servers</em>. Không giống như <em>physical servers</em>, <em>virtual hosts</em> có thể được tạo, tắt và thay đổi nhanh chóng.</p>
<p>Các <em>virtual machines</em> không nhất thiết phải sử dụng cùng một sơ đồ địa chỉ như các <em>physical servers</em>. Các <em>IP addresses</em> của <em>physical server</em> được xác định bởi <em>topo</em> <em>datacenter</em> vật lý (ví dụ: pods, racks). Ngược lại, các <em>IP addresses</em> của <em>virtual machine</em> thường được xác định bởi một hệ thống phân cấp thực tế nào đó (ví dụ: quốc gia, tổ chức). Đặc biệt, các <em>virtual hosts</em> trên một <em>physical server</em> duy nhất không nhất thiết phải có cùng <em>IP prefixes</em> (tiền tố IP), vì vậy chúng ta không thể sử dụng các thủ thuật tổng hợp tương tự để mở rộng quy mô.</p>
<p>Nếu chúng ta cố gắng mở rộng một cách ngây thơ các sơ đồ định tuyến của mình để hỗ trợ các <em>virtual machines</em>, các <em>forwarding tables</em> (bảng chuyển tiếp) của chúng ta sẽ trở nên rất lớn, rất nhanh. Trước đây, chúng ta có thể tổng hợp bằng cách nói: &quot;tất cả các <em>servers</em> trong pod màu xanh có cùng <em>IP prefix</em>, và tất cả chúng đều có <em>next hop</em> (chặng kế tiếp) là R2.&quot; Bây giờ, các <em>servers</em> trong pod màu xanh đó có thể chứa hàng trăm <em>virtual hosts</em>, tất cả đều có các <em>IP addresses</em> khác nhau (không có tiền tố chung). Chúng ta sẽ cần một mục chuyển tiếp riêng cho mỗi <em>virtual host</em>. Ngoài ra, nếu một <em>virtual host</em> di chuyển đến một máy vật lý khác (giữ nguyên <em>IP address</em>), giao thức định tuyến sẽ phải khám phá lại các đường đi đến <em>virtual host</em> này. Liệu chúng ta có thể tìm ra cách để tránh việc mở rộng <em>datacenter</em> để hỗ trợ mọi địa chỉ <em>VM</em> không?</p>
<p>Vấn đề chính ở đây là chúng ta hiện có hai hệ thống địa chỉ khác nhau, một cho <em>virtual hosts</em>, và một cho <em>physical hosts</em>. Cả hai sơ đồ địa chỉ đều hoạt động ở <em>IP layer</em> (lớp IP), nhưng trong <em>IP layer</em>, hiện có hai lớp con trừu tượng mà chúng ta cần phải suy nghĩ đến.</p>
<p><strong><em>Underlay network</em> (mạng lớp nền)</strong> xử lý việc định tuyến giữa các máy vật lý. <em>Underlay network</em> chứa cơ sở hạ tầng <em>datacenter</em> như <em>top-of-rack switches</em> (bộ chuyển mạch đỉnh giá) và <em>spine switches</em> (bộ chuyển mạch trục). <em>Underlay network</em> có khả năng mở rộng tốt vì chúng ta xác định các <em>hierarchical addresses</em> sử dụng <em>topo</em> <em>datacenter</em> vật lý.</p>
<p><strong><em>Overlay network</em> (mạng lớp phủ)</strong> tồn tại trên <em>topo</em> vật lý (<em>underlay</em>), và nó chỉ suy nghĩ về việc định tuyến giữa các <em>virtual machines</em>. Trên thực tế, mỗi <em>virtual machine</em> thường chỉ cần giao tiếp với một vài <em>virtual machines</em> khác trong mạng. Do đó, <em>overlay network</em> có khả năng mở rộng tốt vì một <em>virtual machine</em> không cần phải biết về mọi <em>virtual machine</em> khác.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-046-virtual1.png">
<p>Lý tưởng nhất, chúng ta muốn hai lớp này suy nghĩ về việc đánh địa chỉ một cách riêng biệt. <em>Underlay network</em> không cần phải biết về các địa chỉ <em>virtual host</em> (nếu không, nó sẽ mở rộng kém). Tương tự, <em>overlay network</em> không cần phải biết về mọi <em>physical server</em> trong <em>datacenter</em> (mỗi <em>VM</em> chỉ cần biết về một vài <em>VMs</em> khác).</p>
<p>Nếu chúng ta không cho <em>underlay network</em> biết về các địa chỉ <em>virtual host</em>, thì nếu một <em>datacenter switch</em> nhận được một <em>packet</em> (gói tin) với một IP ảo làm đích, nó sẽ tìm trong <em>forwarding table</em> của mình, không tìm thấy IP ảo nào, và loại bỏ <em>packet</em> này. Chúng ta cần một cách nào đó để kết nối khoảng cách giữa <em>overlay</em> (suy nghĩ theo hướng ảo) và <em>underlay</em> (suy nghĩ theo hướng vật lý).</p>
<h2 id="encapsulation-Đóng-gói"><a class="header" href="#encapsulation-Đóng-gói">Encapsulation (Đóng gói)</a></h2>
<p>Để hợp nhất các lớp <em>overlay</em> và <em>underlay</em>, chúng ta có thể sử dụng các chiến lược tương tự với phân lớp và các <em>headers</em> (tiêu đề) mà chúng ta đã sử dụng khi thiết kế Internet!</p>
<p>Cho đến nay, chúng ta đã coi IP là một lớp duy nhất, và mỗi <em>packet</em> có một <em>IP header</em> duy nhất, hiểu hệ thống địa chỉ IP.</p>
<p>Bây giờ chúng ta có hai lớp con IP với hai hệ thống địa chỉ IP khác nhau, chúng ta có thể giới thiệu một <em>header</em> bổ sung vào <em>packet</em>. Ví dụ, chúng ta có thể có hai <em>IP headers</em>, trong đó một <em>header</em> hiểu <em>overlay network</em>, và <em>header</em> kia hiểu <em>underlay network</em>. Hoặc, chúng ta có thể sử dụng <em>IP header</em> ban đầu cho <em>underlay network</em>, và giới thiệu một loại <em>header</em> mới (khác với IP) cho <em>overlay network</em>.</p>
<img width="700px" src="datacenter/../assets/datacenter/6-047-virtual2.png">
<p>Bây giờ, chiến lược của chúng ta để định tuyến các <em>packets</em> có thể kết hợp <em>overlay</em> và <em>underlay networks</em>. Giả sử VM A muốn gửi một <em>packet</em> đến VM B.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-048-virtual3.png">
<ol>
<li>
<p>VM A tạo một <em>packet</em> với một <em>IP header</em> duy nhất, chứa địa chỉ IP ảo của B. (Hãy nhớ rằng, A đang suy nghĩ theo thuật ngữ của <em>overlay</em>, và không biết về các địa chỉ IP vật lý của <em>underlay</em>.) VM A chuyển tiếp <em>packet</em> này đến <em>virtual switch</em> (trên <em>physical server</em> của A).</p>
<img width="900px" src="datacenter/../assets/datacenter/6-049-virtual4.png">
</li>
<li>
<p><em>Virtual switch</em> đọc <em>header</em> để biết địa chỉ IP ảo của B. Sau đó, <em>virtual switch</em> tra cứu địa chỉ <em>physical server</em> tương ứng với địa chỉ IP ảo của B. (Chúng ta chưa mô tả cách thực hiện điều này.)</p>
<p><em>Virtual switch</em> thêm một <em>outer header</em> (tiêu đề bên ngoài) bổ sung chứa địa chỉ <em>physical server</em> của B. Việc thêm <em>header</em> đôi khi được gọi là <em><strong>encapsulation</strong></em>.</p>
<p>Tại thời điểm này, <em>packet</em> có hai <em>headers</em>. <em>Inner header</em> (tiêu đề bên trong) (lớp cao hơn, <em>overlay</em>, được thêm bởi VM A) chứa địa chỉ IP ảo của B, và <em>outer header</em> (lớp thấp hơn, <em>underlay</em>, được thêm bởi <em>virtual switch</em>) chứa địa chỉ <em>physical server</em> của B.</p>
<p><em>Virtual switch</em> chuyển tiếp <em>packet</em> này đến <em>switch</em> <em>next hop</em>, dựa trên địa chỉ <em>physical server</em>.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-050-virtual5.png">
</li>
<li>
<p><em>Packet</em> được gửi qua <em>underlay network</em>. Mỗi <em>switch</em> trong <em>datacenter</em> chỉ nhìn vào <em>outer header</em> (lớp nền, địa chỉ <em>physical server</em>) để quyết định cách chuyển tiếp <em>packet</em>. (Hãy nhớ rằng, các <em>datacenter switches</em> suy nghĩ theo thuật ngữ của <em>underlay</em>, và không biết về địa chỉ IP ảo của <em>overlay</em>.)</p>
<img width="900px" src="datacenter/../assets/datacenter/6-051-virtual6.png">
<img width="900px" src="datacenter/../assets/datacenter/6-052-virtual7.png">
</li>
<li>
<p>Cuối cùng, <em>packet</em> đến <em>virtual switch</em> của <em>physical server</em> đích. <em>Virtual switch</em> nhìn vào <em>outer header</em> (<em>underlay</em>) và nhận thấy rằng địa chỉ <em>physical server</em> đích là chính nó.</p>
<p><em>Virtual switch</em> loại bỏ <em>outer header</em>, để lộ <em>inner header</em> bên trong. Việc loại bỏ <em>outer header</em> đôi khi được gọi là <strong><em>decapsulation</em> (giải đóng gói)</strong>.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-053-virtual8.png">
</li>
</ol>
<p>Cuối cùng, <em>virtual switch</em> đọc <em>inner header</em> (<em>overlay</em>). Điều này cho <em>virtual switch</em> biết <em>packet</em> nên được chuyển tiếp đến <em>VM</em> nào trên <em>physical server</em>.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-054-virtual9.png">
<p>Trong quá trình này, <em><strong>encapsulation</strong></em> cho phép chúng ta suy nghĩ về việc định tuyến ở hai lớp khác nhau. <em>Underlay</em> có thể định tuyến các <em>packets</em> bằng cách sử dụng địa chỉ <em>physical server</em>, mà không cần suy nghĩ về <em>overlay</em>. Tương tự, <em>VM</em> trong <em>overlay</em> có thể gửi và nhận các <em>packets</em> mà không cần suy nghĩ về cách chuyển tiếp các <em>packets</em> trong <em>underlay</em>. Các <em>virtual switches</em> đã kết nối hai lớp bằng cách dịch địa chỉ <em>virtual machine</em> thành địa chỉ <em>physical server</em>, và thêm và bớt <em>header</em> <em>underlay</em> bổ sung.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-055-virtual10.png">
<img width="800px" src="datacenter/../assets/datacenter/6-056-virtual11.png">
<img width="900px" src="datacenter/../assets/datacenter/6-057-virtual12.png">
<h2 id="forwarding-tables-với-encapsulation"><a class="header" href="#forwarding-tables-với-encapsulation">Forwarding Tables với Encapsulation</a></h2>
<p>Chúng ta nên cài đặt những mục nào trong các <em>forwarding tables</em> để hỗ trợ định tuyến với <em>encapsulation</em>?</p>
<p>Các <em>virtual machines</em> nên cài đặt một <em>default route</em> (tuyến đường mặc định) để chuyển tiếp mọi <em>packet</em> đến <em>virtual switch</em> trên máy vật lý.</p>
<p>Các <em>virtual switches</em> cần triển khai thêm một số chức năng để kết nối hai lớp. Cụ thể, khi bạn thấy một địa chỉ ảo, bạn nên áp dụng <em>encapsulation</em> (thêm một lớp ngoài) với địa chỉ vật lý tương ứng. <em>Forwarding table</em> có các mục cho mọi <em>VM</em> đích mà bất kỳ <em>VM</em> nào trên <em>server</em> này có thể muốn nói chuyện. Chúng ta có thể hỗ trợ quy mô này vì chúng ta giả định các <em>VMs</em> sẽ không cần nói chuyện với mọi <em>VM</em> khác trong <em>datacenter</em>. Không giống như các thuật toán định tuyến tiêu chuẩn, chúng ta không cần định tuyến any-to-any (chúng ta không cần đường đi đến mọi <em>VM</em> khác).</p>
<p>Các <em>virtual switches</em> cũng cần một quy tắc bổ sung để <em>decapsulating</em> các <em>packets</em>. Nếu đích của <em>packet</em> ngoài (<em>underlay</em>) là chính <em>switch</em> đó, bạn nên <em>decapsulate</em> (loại bỏ <em>outer header</em>) và chuyển <em>packet</em> đến địa chỉ <em>VM</em> trong <em>inner header</em>. Quy tắc này mở rộng theo số lượng <em>VMs</em> trên <em>server</em>, thường đủ nhỏ để có thể quản lý được.</p>
<p>Việc thêm chức năng này có khó không? May mắn thay, các <em>virtual switches</em> được triển khai trong phần mềm, vì vậy việc thêm chức năng này chỉ cần viết mã lệnh (không cần thêm phần cứng). Tuy nhiên, trên thực tế, <em>encapsulation</em> phổ biến đến mức đôi khi nó vẫn được triển khai trong phần cứng.</p>
<p>Các <em>switches</em> trong <em>datacenter</em> hoạt động giống hệt như trước khi chúng ta giới thiệu <em>virtualization</em>. Các <em>forwarding tables</em> chỉ chứa địa chỉ <em>physical server</em>, và chúng ta biết rằng chúng có thể được mở rộng quy mô bằng các thủ thuật tổng hợp dựa trên <em>topo</em> vật lý.</p>
<h2 id="multi-tenancy-Đa-người-thuê-và-private-networks-mạng-riêng"><a class="header" href="#multi-tenancy-Đa-người-thuê-và-private-networks-mạng-riêng">Multi-Tenancy (Đa người thuê) và Private Networks (Mạng riêng)</a></h2>
<p>Các <em>Datacenters</em> được quản lý bởi một nhà khai thác duy nhất, nhưng các tổ chức khác nhau có thể đang chạy các ứng dụng bên trong <em>datacenter</em> đó. Ví dụ, một <em>datacenter</em> do Google điều hành có thể có một số <em>virtual servers</em> do Gmail chạy, và những <em>servers</em> khác do Google Maps chạy. Cách tiếp cận lưu trữ nhiều dịch vụ trong một <em>datacenter</em> này được gọi là <em><strong>multi-tenancy</strong></em>.</p>
<p>Các <em>Cloud providers</em> (nhà cung cấp đám mây) cũng sử dụng các <em>datacenters</em> để cung cấp <em>virtual machines</em> cho khách hàng. Ví dụ, <em>Amazon Web Services (AWS)</em> và <em>Google Cloud Platform (GCP)</em> cho phép người dùng khởi động một <em>virtual machine</em> trong một <em>datacenter</em>, làm bất cứ điều gì họ muốn, và phá hủy <em>virtual machine</em> khi họ hoàn thành.</p>
<p>Một vấn đề với <em>multi-tenancy</em> là, chúng ta không phải lúc nào cũng muốn các <em>tenants</em> (người thuê) khác nhau có thể giao tiếp với nhau. Ví dụ, nếu một khách hàng yêu cầu một <em>VM</em>, họ có lẽ không nên có thể kết nối với mọi <em>VM</em> khác trong <em>datacenter</em>.</p>
<p>Một vấn đề khác là, các <em>tenants</em> trong một <em>datacenter</em> không phối hợp với nhau khi chọn địa chỉ. Ví dụ, giả sử <em>datacenter</em> của chúng ta có hai <em>tenants</em>, Pepsi và Coke. Mỗi <em>tenant</em> tạo ra <em>private network</em> của riêng mình, nơi họ gán các <em>IP addresses</em> nội bộ cho các <em>virtual machines</em>. <em>Private network</em> chỉ dành cho các <em>hosts</em> bên trong <em>datacenter</em> giao tiếp với nhau, và các <em>hosts</em> này sẽ không bao giờ được liên lạc từ Internet công cộng. Vì các mạng là riêng tư, hai <em>tenants</em> đều có thể sử dụng các địa chỉ trong cùng một dải địa chỉ riêng được phân bổ đặc biệt (<em>RFC 1918 addresses</em> - các dải địa chỉ dành riêng cho mạng nội bộ). <em>Private network</em> của Pepsi có thể có một <em>VM</em> với <em>IP address</em> 192.0.2.2, và <em>private network</em> của Coke có thể có một <em>VM</em> khác với <em>IP address</em> 192.0.2.2. (Trên thực tế, chúng ta sử dụng các dải địa chỉ riêng để tái sử dụng các <em>IPv4 addresses</em> (địa chỉ IPv4), vì chúng ta đang cạn kiệt chúng.)</p>
<img width="900px" src="datacenter/../assets/datacenter/6-058-tenancy1.png">
<p>Từ góc độ của mỗi <em>tenant</em>, đây không phải là vấn đề. 192.0.2.2 của Pepsi sẽ không bao giờ giao tiếp với 192.0.2.2 của Coke, và cả hai <em>host</em> đều không thể truy cập từ Internet toàn cầu. Tuy nhiên, đây là một vấn đề đối với <em>datacenter</em>. Nếu chúng ta sử dụng <em>destination-based forwarding</em> (chuyển tiếp dựa trên đích), và chúng ta thấy một <em>packet</em> có đích là 192.0.2.2, chúng ta không biết địa chỉ này đang đề cập đến <em>VM</em> nào.</p>
<p>Các <em>IP addresses</em> trùng lặp xảy ra trong thực tế vì hai lý do. Thứ nhất, các <em>datacenters</em> thường không có quyền kiểm soát các địa chỉ mà các <em>tenants</em> đang gán cho các <em>VMs</em> của họ. Thứ hai, trong IP, thông lệ tiêu chuẩn là sử dụng các dải cụ thể cho các <em>private networks</em>, điều này thường dẫn đến các địa chỉ trùng lặp.</p>
<h2 id="encapsulation-cho-multi-tenancy"><a class="header" href="#encapsulation-cho-multi-tenancy">Encapsulation cho Multi-Tenancy</a></h2>
<p>Chúng ta có thể sử dụng lại ý tưởng <em>encapsulation</em> để giải quyết vấn đề này. Chúng ta có thể thêm một <em>header</em> mới chứa một <strong><em>virtual network ID</em> (mã định danh mạng ảo)</strong> để xác định một <em>tenant</em> cụ thể (ví dụ: Pepsi có ID 1, Coke có ID 2). <em>Header</em> mới này không chứa thông tin để chuyển tiếp và định tuyến, nhưng nó cung cấp thêm ngữ cảnh. Bây giờ, nếu một <em>physical server</em> có các <em>VMs</em> cho nhiều <em>tenants</em>, nó có thể chuyển <em>packet</em> lên đúng mạng ảo.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-059-tenancy2.png">
<img width="900px" src="datacenter/../assets/datacenter/6-060-tenancy3.png">
<p>Khi một <em>virtual switch</em> nhận được một <em>packet</em> và mở <em>outer header</em> (<em>underlay</em>), nó sẽ nhìn vào <em>header</em> mới của chúng ta để quyết định <em>packet</em> dành cho <em>tenant</em> nào. Sau đó, nó nhìn vào <em>overlay header</em> để chuyển tiếp <em>packet</em> đến một <em>VM</em> cụ thể thuộc về <em>tenant</em> chính xác.</p>
<h2 id="xếp-chồng-các-encapsulation"><a class="header" href="#xếp-chồng-các-encapsulation">Xếp chồng các Encapsulation</a></h2>
<p>Chúng ta có thể sử dụng ý tưởng <em>encapsulation</em> nhiều lần, thêm nhiều <em>headers</em> mới để hỗ trợ cả <em>virtualization</em> và <em>multi-tenancy</em>.</p>
<p>Để bắt đầu, <em>virtual machine</em> tạo ra một <em>packet</em> <em>TCP/IP</em> tiêu chuẩn, với một đích IP ảo.</p>
<p>Trong bước <em>encapsulation</em> đầu tiên, chúng ta thêm một <em>virtual network header</em>, cho chúng ta biết <em>tenant</em> nào đã gửi <em>packet</em> này. Điều này giúp chúng ta phân biệt hai <em>tenants</em> sử dụng cùng một địa chỉ, và cũng ngăn chặn các <em>packets</em> được gửi đến một <em>tenant</em> khác.</p>
<p>Trong bước <em>encapsulation</em> thứ hai, chúng ta thêm một <em>underlay network header</em>, cho chúng ta biết địa chỉ <em>physical server</em> tương ứng với đích IP ảo.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-061-stack1.png">
<p>Các lớp trừu tượng vẫn giữ nguyên khi chúng ta xếp chồng các <em>encapsulations</em>. <em>Underlay network</em> không cần biết rằng nhiều <em>tenants</em> đang ở trong cùng một <em>datacenter</em>. <em>Underlay network</em> chỉ nhìn vào <em>header</em> ngoài cùng nhất để tìm địa chỉ <em>physical server</em>, và chuyển tiếp <em>packet</em> tương ứng.</p>
<p>Bước <em>decapsulation</em> hoạt động theo thứ tự ngược lại. <em>Virtual switch</em> trên <em>server</em> đích nhận được một <em>packet</em> có hai <em>headers</em> bổ sung.</p>
<p>Trong bước <em>decapsulation</em> đầu tiên, chúng ta loại bỏ <em>outer underlay header</em>. Điều này không còn cần thiết vì <em>packet</em> đã đến <em>physical server</em> đích.</p>
<p>Trong bước <em>decapsulation</em> thứ hai, chúng ta sử dụng <em>virtual network header</em> để quyết định chúng ta nên xem xét tập hợp <em>VMs</em> nào. <em>Physical server</em> có thể có các <em>VMs</em> cho nhiều <em>tenants</em>, và điều này giúp thu hẹp xuống một <em>tenant</em> duy nhất.</p>
<p>Cuối cùng, chúng ta sử dụng <em>IP header</em> trong cùng nhất để gửi <em>packet</em> đến đúng <em>VM</em> trong đúng mạng ảo.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-062-stack2.png">
<p>Lưu ý: Với <em>encapsulation</em>, chúng ta phải cẩn thận khi đọc <em>5-tuple</em> (bộ 5 thông tin: IP nguồn, IP đích, cổng nguồn, cổng đích, và giao thức) để <em>load-balancing</em> (cân bằng tải) các <em>packets</em> trên nhiều đường đi. May mắn thay, phần cứng <em>router</em> hiện đại rất giỏi trong việc phân tích các <em>packets</em> để hiểu vị trí của các <em>headers</em> liên quan trong <em>packet</em>, ngay cả khi có thêm các <em>headers</em> được chèn vào.</p>
<p>Trên thực tế, có nhiều giao thức khác nhau tồn tại cho <em>encapsulation</em>. Chúng ta có thể sử dụng <em>IP-in-IP</em> để hỗ trợ hai <em>IP headers</em> (một cho <em>overlay</em>, một cho <em>underlay</em>).</p>
<p><em>MPLS</em> là một <em>header</em> đơn giản để thêm một nhãn xác định một dịch vụ (ví dụ: một mạng ảo, một <em>tenant</em>). Điều này có thể được sử dụng để thêm <em>encapsulation</em> cho <em>multi-tenancy</em>.</p>
<p>Khi các <em>datacenters</em> trở nên phổ biến hơn, nhiều giao thức khác như <em>GRE</em>, <em>VXLAN</em>, và <em>GENEVE</em> đã được phát triển. Hầu hết chúng hoạt động trên IP, vì vậy các giao thức tùy chỉnh này là <em>inner overlay header</em>, và IP thông thường là <em>outer underlay header</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="software-defined-networking-mạng-định-nghĩa-bằng-phần-mềm"><a class="header" href="#software-defined-networking-mạng-định-nghĩa-bằng-phần-mềm">Software-Defined Networking (Mạng định nghĩa bằng phần mềm)</a></h1>
<h2 id="tại-sao-lại-cần-software-defined-networking"><a class="header" href="#tại-sao-lại-cần-software-defined-networking">Tại sao lại cần Software-Defined Networking?</a></h2>
<p>Trước đây, chúng ta đã thấy cách các <em>routing protocols</em> (giao thức định tuyến) có thể được điều chỉnh để hoạt động trong bối cảnh <em>datacenter</em> (trung tâm dữ liệu) (ví dụ: <em>equal-cost multi-path</em> (đa đường chi phí bằng nhau)). Sẽ ra sao nếu chúng ta muốn tối ưu hóa các <em>routing protocols</em> của mình hơn nữa cho các ràng buộc và trường hợp sử dụng cụ thể của <em>network</em> (mạng) của chúng ta? Các <em>routing protocols</em> tiêu chuẩn có thể sẽ không còn hoạt động hiệu quả.</p>
<p>Trong phần này, chúng ta sẽ khám phá <em><strong>software-defined networking</strong></em>, một mô hình hoàn toàn mới để suy nghĩ về định tuyến và quản lý mạng. Trong bối cảnh định tuyến, <em>SDN architecture</em> (kiến trúc SDN) bao gồm việc có một trung tâm điều khiển tập trung để tính toán các tuyến đường và phân phối chúng đến từng <em>routers</em> (bộ định tuyến) riêng lẻ. Chúng ta sẽ xem <em>SDN</em> hoạt động như thế nào trong bối cảnh <em>datacenter</em> và <em>wide-area network</em> (mạng diện rộng), đồng thời thảo luận về các lợi ích và hạn chế của phương pháp tiếp cận mới này.</p>
<h2 id="lược-sử-của-software-defined-networking"><a class="header" href="#lược-sử-của-software-defined-networking">Lược sử của Software-Defined Networking</a></h2>
<p>Mặc dù chúng ta sẽ xem xét <em>SDN</em> như một phương pháp tiếp cận mới cho các <em>routing protocols</em> chuyên biệt, mô hình <em>SDN</em> ban đầu được thiết kế để giải quyết các vấn đề nhức nhối ở <em>management plane</em> (mặt phẳng quản lý).</p>
<p>Hãy nhớ lại rằng <em>management plane</em> rất quan trọng cho hoạt động của mạng. Các <em>routers</em> không thể làm gì trừ khi có người cấu hình chúng (ví dụ: gán chi phí cho các <em>links</em> (liên kết)) và chỉ dẫn chúng phải làm gì (ví dụ: chạy <em>routing protocol</em> nào). Ngoài ra, chúng ta cần các <em>routers</em> báo cáo lỗi để giữ cho mạng luôn hoạt động. Rất nhiều công việc quản lý này trong lịch sử đã được thực hiện thủ công.</p>
<p>Mặc dù <em>management plane</em> rất quan trọng, nhưng lại có tương đối ít sự tập trung vào việc đổi mới nó. Tại <em>control plane</em> (mặt phẳng điều khiển), chúng ta đã thấy rất nhiều <em>routing protocols</em> khác nhau, nhưng cách chúng ta cấu hình và điều khiển các <em>routers</em> lại phát triển chậm hơn.</p>
<p>Trong suốt lịch sử của Internet, đã có một sự phát triển chậm rãi theo hướng sử dụng các kịch bản (scripts) để tương tác với mạng một cách có lập trình. Các kịch bản này đảm nhận những công việc mà người vận hành sẽ làm thủ công và thực hiện chúng bằng mã lệnh (không có nhiều trí thông minh). Ví dụ, các kịch bản cho phép tự động hóa quá trình thêm <em>routers</em> và <em>links</em> vào mạng. Một kịch bản để sửa chữa mạng có thể nói: nếu một <em>router</em> bị lỗi, hãy kiểm tra xem nó có thực sự bị lỗi không, khởi động lại nó, và nếu vẫn không khắc phục được, hãy báo cáo cho người vận hành.</p>
<p>Bất chấp những tiến bộ, các hệ thống quản lý này đã là nút thắt cổ chai cho hoạt động mạng trong một thời gian dài. Chúng ta vẫn có thể phải chờ đợi sự can thiệp của con người mỗi khi một <em>router</em> mới được thêm vào.</p>
<p>Năm 2005, một bài báo của Albert Greenberg và cộng sự đã mô tả vấn đề này bằng cách nói: &quot;Các mạng dữ liệu ngày nay rất mong manh và khó quản lý một cách đáng ngạc nhiên. Chúng tôi cho rằng gốc rễ của những vấn đề này nằm ở sự phức tạp của <em>control plane</em> và <em>management plane</em>.&quot;</p>
<p>Để đối phó với những vấn đề này, các nhà nghiên cứu bắt đầu suy nghĩ về những cách khác nhau để vận hành một hệ thống mạng. Điều này đã dẫn đến những đề xuất cấp tiến hơn, tái định hình lại thiết kế cơ bản của <em>routers</em>.</p>
<p>Các khái niệm chúng ta sẽ thấy lần đầu tiên được xem xét vào năm 2003, mặc dù chúng không nhận được nhiều sự chú ý vào thời điểm đó. Sự thất vọng với việc quản lý mạng đã thúc đẩy sự phát triển của các mô hình quản lý mới. Đến năm 2008, đã có nhiều động lực hơn, dẫn đến giao diện <em>switch</em> (bộ chuyển mạch) <em>OpenFlow</em> (chúng ta sẽ sớm thấy).</p>
<p>Đến năm 2011, rõ ràng là ngành công nghiệp đang đi theo hướng mới này, và <em>Open Networking Foundation (ONF)</em> đã được thành lập bởi các nhà khai thác mạng lớn (Google, Yahoo, Verizon, Microsoft, Facebook) và các <em>vendors</em> (nhà cung cấp) (Cisco, Juniper, HP, Dell). Nicira, công ty khởi nghiệp tập trung vào <em>SDN</em> đã phát triển giao diện <em>OpenFlow</em>, là một công ty khởi nghiệp trị giá 40 triệu đô la vào năm 2012.</p>
<h2 id="routers-được-tích-hợp-theo-chiều-dọc-và-tiêu-chuẩn-hóa"><a class="header" href="#routers-được-tích-hợp-theo-chiều-dọc-và-tiêu-chuẩn-hóa">Routers được Tích hợp theo chiều dọc và Tiêu chuẩn hóa</a></h2>
<p>Nếu chúng ta muốn tái định hình thiết kế của <em>routers</em>, điều đó sẽ được thực hiện trong thực tế như thế nào? Các công nghệ trên <em>routers</em> thay đổi theo thời gian ra sao?</p>
<p>Nếu mạng của bạn cần một <em>router</em>, bạn có thể sẽ mua một cái từ một <em>vendor</em> thiết bị lớn như Cisco hoặc Juniper. Để đảm bảo rằng các <em>routers</em> tương thích với nhau, tất cả các <em>vendors</em> thiết bị lớn đều xây dựng <em>routers</em> của họ theo một số tiêu chuẩn được xác định trước.</p>
<p>Mô hình kinh doanh này có thể gây khó khăn cho sự đổi mới và thử nghiệm các phương pháp tiếp cận mới. Giả sử bạn có một ý tưởng mới cho một <em>routing protocol</em>. Bạn sẽ cần phải được một <em>standards body</em> (tổ chức tiêu chuẩn) phê duyệt giao thức đó, việc này có thể mất nhiều năm. Sau đó, bạn sẽ phải chờ các <em>vendors</em> nâng cấp quy trình sản xuất của họ để tuân thủ tiêu chuẩn mới.</p>
<p>Tiêu chuẩn hóa cũng làm cho <em>routers</em> kém linh hoạt hơn đối với người dùng triển khai các giải pháp tùy chỉnh. Nếu bạn có một vấn đề cụ thể cho mạng của mình, nhưng không ai khác gặp vấn đề này, giải pháp của bạn có thể sẽ không được <em>standards body</em> chấp nhận. Các <em>vendors</em> muốn tạo ra những <em>routers</em> đáp ứng nhu cầu của mọi người, và họ sẽ không nhất thiết phải triển khai một giải pháp hoàn hảo cho bạn, nếu không ai khác muốn nó.</p>
<p>Mặt khác, tiêu chuẩn hóa cũng có nghĩa là nếu người khác có một vấn đề mà bạn không có, <em>router</em> có thể đi kèm với một giải pháp cho vấn đề của họ, ngay cả khi bạn không cần nó. Điều này có thể làm cho <em>routers</em> trở nên phức tạp một cách không cần thiết cho các mục đích của mạng cụ thể của bạn.</p>
<p>Tiêu chuẩn hóa cũng gây khó khăn cho việc thử nghiệm và nghiên cứu. Nếu bạn muốn thử một ý tưởng mới để xem nó có hoạt động hay không, bạn có thể không mua được <em>routers</em> có thể triển khai ý tưởng mới của mình. Các <em>vendors</em> không muốn xây dựng các sản phẩm thử nghiệm, dành cho một khách hàng cụ thể, mà có thể thậm chí không hoạt động.</p>
<p>Một trở ngại lớn khác cho sự đổi mới và thử nghiệm là các <em>routers</em> được <strong><em>vertically integrated</em> (tích hợp theo chiều dọc)</strong>. <em>Router</em> bạn mua đã có sẵn chức năng cho cả ba mặt phẳng được tích hợp trên các con chip. Không có tính mô-đun nào cho phép bạn thay thế chỉ riêng <em>control plane</em>.</p>
<img width="300px" src="datacenter/../assets/datacenter/6-063-vertical-integration.png">
<h2 id="Đổi-mới-routers"><a class="header" href="#Đổi-mới-routers">Đổi mới Routers</a></h2>
<p>Nếu chúng ta muốn đổi mới <em>routers</em>, chúng ta có thể đổi mới những gì ở mỗi mặt phẳng, và chúng ta sẽ làm việc với những loại tiêu chuẩn có sẵn nào?</p>
<p><em>Data plane</em> (mặt phẳng dữ liệu) được tiêu chuẩn hóa bởi <em>IEEE</em> (nhóm kỹ thuật điện) và yêu cầu mọi người tuân thủ nghiêm ngặt các tiêu chuẩn. Nếu hai <em>routers</em> từ các <em>vendors</em> khác nhau được kết nối, chúng ta phải đảm bảo cả hai bên đều gửi các bit dọc theo dây vật lý theo cùng một định dạng nhất quán.</p>
<p>Sự đổi mới ở <em>data plane</em> thường được thúc đẩy bởi nhu cầu về các <em>routers</em> có băng thông cao hơn, và các tính năng mới không thường xuyên được giới thiệu. Sự phát triển này diễn ra khá chậm, trong khoảng 2-3 năm, bởi vì chúng ta phải giải quyết các vấn đề về phần cứng vật lý và thiết kế chip để tăng băng thông. Vì các tính năng cốt lõi của <em>data plane</em> tương đối ổn định, sự đổi mới <em>router</em> không thực sự tập trung vào <em>data plane</em>, và việc chu kỳ phát triển chậm cũng không sao.</p>
<p><em>Control plane</em> được tiêu chuẩn hóa bởi <em>IETF</em> (nhóm mạng đứng sau các RFC). Các <em>vendors</em> đôi khi thêm các phần mở rộng của riêng họ, mặc dù các tính năng cốt lõi hầu hết đều được tiêu chuẩn hóa. Ví dụ, chúng ta giả định rằng mọi <em>router</em> (ngay cả khi chúng đến từ các <em>vendors</em> khác nhau) đều tuân theo cùng một <em>routing protocol</em>.</p>
<p>Sự đổi mới ở <em>control plane</em> (ví dụ: <em>routing protocols</em> mới) có thể mất vài năm để được áp dụng. Bạn có thể phải gửi một bản dự thảo đề xuất RFC, và cộng đồng có thể dành thời gian thảo luận về đề xuất trước khi đồng ý về các điều khoản của nó.</p>
<p><em>Management plane</em> cũng được tiêu chuẩn hóa bởi <em>IETF</em>, mặc dù nó ít được tiêu chuẩn hóa hơn nhiều. Các nhà khai thác khác nhau có thể sử dụng phần mềm khác nhau để cấu hình <em>routers</em> của họ, và chúng ta không thực sự cần các <em>vendors</em> khác nhau phải đồng ý về một phần mềm được tiêu chuẩn hóa nào đó. Bởi vì mặt phẳng này chỉ được tiêu chuẩn hóa một cách lỏng lẻo, nhiều phương pháp tiếp cận khác nhau với các tính năng khác nhau tồn tại.</p>
<p>Tóm lại: <em>Data plane</em> được tiêu chuẩn hóa (nhưng chúng ta không thực sự có tính năng mới nào trong đầu), <em>control plane</em> được tiêu chuẩn hóa (nhưng chúng ta muốn thử các giải pháp mới), và <em>management plane</em> không thực sự được tiêu chuẩn hóa.</p>
<h2 id="Ý-tưởng-cấp-tiến-tách-rời-routers"><a class="header" href="#Ý-tưởng-cấp-tiến-tách-rời-routers">Ý tưởng cấp tiến: Tách rời Routers</a></h2>
<p>Tiêu chuẩn hóa và tích hợp theo chiều dọc đã gây khó khăn cho việc đổi mới và thử nghiệm. Điều này đã dẫn đến ý tưởng cấp tiến là tách rời các <em>routers</em> bằng cách chia các mặt phẳng thành các lớp trừu tượng khác nhau. Thay vì mua một <em>router</em> duy nhất với cả ba mặt phẳng, giờ đây chúng ta có thể mua riêng chức năng của <em>data plane</em> và <em>control plane</em>. Điều này cho phép chúng ta thay đổi các lớp một cách độc lập với nhau.</p>
<p>Để kết nối ba lớp, chúng ta cần một <em>API</em> (Giao diện lập trình ứng dụng) giữa các lớp trừu tượng. Trong một <em>router</em> được ghép nối theo chiều dọc, chúng ta không quan tâm <em>data plane</em> và <em>control plane</em> nói chuyện với nhau như thế nào. Tuy nhiên, nếu chúng ta mua <em>data plane</em> riêng và muốn thiết kế <em>control plane</em> tùy chỉnh của riêng mình trên đó, chúng ta cần một giao diện để tương tác với <em>data plane</em>.</p>
<img width="300px" src="datacenter/../assets/datacenter/6-064-sdn1.png">
<p>Một ý tưởng cấp tiến hơn nữa là ngừng suy nghĩ về ba mặt phẳng chỉ theo thuật ngữ của <em>router</em>, và thay vào đó thiết kế một kiến trúc hệ thống mới tự nhiên tách biệt <em>data plane</em> và <em>control plane</em>.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-065-sdn2.png">
<p>Ở dưới cùng, chúng ta có các <em>commodity network devices</em> (thiết bị mạng phổ thông). Bạn có thể coi chúng như việc chỉ mua riêng <em>data plane</em>. Các <em>routers</em> này nhận chỉ thị từ <em>control program</em> (chương trình điều khiển) thông qua <em>network OS</em> (hệ điều hành mạng), và chỉ đơn giản là chuyển tiếp các gói tin theo những chỉ thị đó. Các <em>routers</em> này hoàn toàn không cần phải suy nghĩ về <em>routing protocols</em>, vì vậy chúng có thể rẻ hơn.</p>
<p>Ở giữa, chúng ta có <em>network OS</em>. Bạn có thể coi đây là <em>API</em> kết nối các <em>routers</em> ở <em>data plane</em> và <em>control program</em> ở <em>control plane</em>. <em>Network OS</em> cung cấp một sự trừu tượng hóa của các <em>routers</em> (ví dụ: dưới dạng một đồ thị) có thể được truyền lên cho <em>control program</em>. Sau đó, <em>control program</em> có thể gửi các chỉ thị định tuyến đến <em>network OS</em>, mà không cần lo lắng về cách lập trình cho các <em>routers</em> cụ thể. <em>Network OS</em> có thể lấy những chỉ thị đó và lập trình chúng vào từng <em>routers</em> riêng lẻ.</p>
<p>Ở trên cùng, chúng ta có <em>control program</em>. Bạn có thể coi đây là việc mua hoặc tự triển khai <em>control plane</em>. Ở đây, người vận hành nhận được một sự trừu tượng hóa của mạng (ví dụ: đồ thị) từ <em>network OS</em>, và có thể sử dụng nó để viết <em>routing protocol</em> tùy chỉnh của riêng mình. Sau đó, các tuyến đường kết quả có thể được chuyển đến <em>network OS</em>, nơi sẽ lập trình chúng vào các <em>routers</em>.</p>
<h2 id="Định-dạng-api-openflow"><a class="header" href="#Định-dạng-api-openflow">Định dạng API OpenFlow</a></h2>
<p><em><strong>OpenFlow</strong></em> là một <em>API</em> để tương tác với <em>data plane</em> của một <em>router</em>. Người vận hành viết mã lệnh phức tạp của riêng họ, tách biệt khỏi <em>router</em>, để tính toán các tuyến đường trong mạng. Sau đó, những tuyến đường đó có thể được lập trình vào <em>forwarding chip</em> (chip chuyển tiếp).</p>
<img width="300px" src="datacenter/../assets/datacenter/6-066-openflow1.png">
<p>Mô hình <em>OpenFlow</em> khác với các <em>routers</em> truyền thống, nơi <em>control plane</em> được triển khai trong <em>router</em>, và không có một <em>API</em> rõ ràng nào để lập trình các tuyến đường tùy chỉnh vào <em>forwarding chip</em>.</p>
<p><em>API</em> <em>OpenFlow</em> định nghĩa một sự trừu tượng hóa là <strong><em>flow table</em> (bảng luồng)</strong> để mô tả các tuyến đường và quy tắc chuyển tiếp. Mã lệnh của người vận hành có thể xuất ra bất kỳ quy tắc và tuyến đường nào mà nó muốn, và cài đặt chúng trên <em>router</em>, miễn là chúng ở định dạng <em>flow table</em>.</p>
<p>Thành phần cơ bản của <em>API</em> là một <em>flow table</em>, bạn có thể coi nó như một phiên bản tổng quát của một <em>forwarding table</em> (bảng chuyển tiếp). Mỗi <em>flow table</em> bao gồm các cặp khóa-giá trị, giống như một <em>forwarding table</em>. Khóa chỉ định điều kiện để <strong><em>match</em> (đối sánh)</strong> với gói tin. Điều này có thể là một <em>destination prefix</em> (tiền tố đích), một đích chính xác, một <em>5-tuple</em> (bộ 5 thông tin gồm IP nguồn, IP đích, cổng nguồn, cổng đích, và giao thức), hoặc các phép <em>match</em> tương đối đơn giản khác. Giá trị tương ứng chỉ định <strong><em>action</em> (hành động)</strong> sẽ được thiết lập khi một gói tin khớp. <em>Action</em> có thể là gửi gói tin đến một chặng kế tiếp (giống như một <em>forwarding table</em>), nhưng cũng có thể chỉ định các <em>action</em> phức tạp hơn như thêm một <em>header</em> (tiêu đề) bổ sung.</p>
<p>Định dạng đầu ra là một chuỗi gồm một hoặc nhiều <em>flow tables</em> được đánh số, trong đó mỗi bảng có các mục <em>match-action</em> khác nhau. Những <em>flow tables</em> này sau đó có thể được lập trình vào <em>forwarding chip</em>.</p>
<img width="700px" src="datacenter/../assets/datacenter/6-068-openflow3.png">
<p>Khi một gói tin đến một <em>router</em>, nó được kiểm tra với từng bảng theo thứ tự (ví dụ: Bảng 0, Bảng 1, Bảng 2, v.v.), và khi có một sự <em>match</em>, chúng ta ghi lại <em>action</em> tương ứng (mà chưa thực thi nó). Cuối cùng, một khi gói tin được kiểm tra với bảng cuối cùng, bất kỳ <em>action</em> nào chúng ta đã ghi lại sẽ được áp dụng cho gói tin.</p>
<p>Cũng có các <em>action</em> đặc biệt để bỏ qua đến các bảng sau, mà chúng ta có thể sử dụng trong các quy tắc như: Nếu cổng nguồn khớp với số này, hãy bỏ qua đến bảng 5 để thiết lập các <em>action</em> bổ sung.</p>
<img width="800px" src="datacenter/../assets/datacenter/6-067-openflow2.png">
<p>Người vận hành có thể chạy bất kỳ mã lệnh nào họ muốn để tạo ra các <em>flow tables</em>, và các <em>flow tables</em> có thể tổng quát hơn một <em>forwarding table</em> đích/chặng-kế-tiếp. Tuy nhiên, các quy tắc (<em>match/action</em> pairs) mà chúng ta tạo ra vẫn bị giới hạn bởi phần cứng của <em>forwarding chip</em> chuyên dụng. <em>Forwarding chip</em> được tối ưu hóa cho tốc độ, và có lẽ không thể xử lý các quy tắc <em>match</em> phức tạp như &quot;nếu phần tải tin (payload) của TCP là tiếng Anh, hãy đặt <em>action</em> này.&quot;</p>
<p>Kết quả là, các <em>flow tables</em> chúng ta thấy trong thực tế cuối cùng trông khá giống với các bảng chúng ta đã thấy. Các quy tắc <em>match</em> phổ biến bao gồm <em>longest prefix matching</em> (khớp tiền tố dài nhất) trên đích IP, <em>5-tuples</em> để xác định các luồng, và khớp chính xác trên các <em>encapsulation headers</em> (tiêu đề đóng gói) (ví dụ: <em>MPLS</em>).</p>
<p>Nếu các quy tắc chuyển tiếp không khác biệt nhiều, tại sao lại sử dụng <em>OpenFlow</em>? Hãy nhớ rằng, lợi thế chính là nó cho phép người vận hành hoàn toàn tự do ở <em>control plane</em>. Chúng ta không còn bị giới hạn bởi các giao thức <em>distance-vector</em> (vector khoảng cách) hay <em>link-state</em> (trạng thái liên kết) nữa.</p>
<img width="400px" src="datacenter/../assets/datacenter/6-069-openflow4.png">
<h2 id="lợi-ích-của-một-control-plane-linh-hoạt"><a class="header" href="#lợi-ích-của-một-control-plane-linh-hoạt">Lợi ích của một Control Plane linh hoạt</a></h2>
<p>Kiến trúc mới của chúng ta mang lại cho người vận hành sự linh hoạt để triển khai <em>routing protocol</em> mới của họ tại <em>control plane</em>. Một số lợi ích của phương pháp này là gì?</p>
<p>Người vận hành có thể triển khai các <em>routing protocols</em> tùy chỉnh phù hợp nhất với nhu cầu cụ thể của họ. Người vận hành không còn bị ràng buộc bởi các <em>standards bodies</em> và <em>vendors</em>.</p>
<p>Sự linh hoạt cũng cho chúng ta cơ hội để đơn giản hóa. Ví dụ, nếu giao thức được tiêu chuẩn hóa bao gồm các tính năng chúng ta không cần, chúng ta không phải triển khai chúng trong giải pháp tùy chỉnh của mình. Các giao thức đơn giản hơn có thể có ít mã lệnh hơn và mã lệnh đơn giản hơn, điều này có thể cho phép phát triển và bảo trì giao thức đó dễ dàng hơn.</p>
<p>Cuối cùng, một <em>control plane</em> linh hoạt cho phép tính toán các tuyến đường một cách tập trung tại <em>control program</em>, thay vì phân tán trên nhiều <em>routers</em>. Sự tập trung hóa cũng đi kèm với một số lợi ích.</p>
<p>Sự tập trung hóa có thể dẫn đến các quyết định định tuyến thông minh hơn, mang lại hiệu suất xuất sắc. Trong một báo cáo năm 2013 từ Google, các kỹ sư đã triển khai một <em>SDN architecture</em> đã ghi nhận rằng &quot;<em>traffic engineering</em> (kỹ thuật lưu lượng) tập trung giúp các <em>links</em> đạt gần 100% hiệu suất sử dụng, trong khi phân chia các luồng ứng dụng trên nhiều đường đi để cân bằng dung lượng với mức độ ưu tiên/yêu cầu của ứng dụng.&quot; Một bài báo năm 2013 của Microsoft mô tả việc sử dụng một bộ điều khiển <em>OpenFlow</em> để &quot;đạt được hiệu suất sử dụng cao với WAN điều khiển bằng phần mềm.&quot;</p>
<p>Các quyết định định tuyến thông minh hơn có thể giúp tối ưu hóa các tiêu chí khác ngoài hiệu suất, mà một <em>routing protocol</em> tiêu chuẩn không thể dễ dàng tối ưu hóa. Ví dụ, một mạng của chính phủ Hoa Kỳ có thể triển khai một quy tắc khoanh vùng địa lý (geofencing) rằng, không gửi lưu lượng qua các <em>links</em> ở Canada. Hoặc, một mạng truyền hình quảng bá có thể muốn tối ưu hóa cho sự đa dạng của đường đi để tăng độ tin cậy. Chúng ta có thể thực thi rằng hai luồng di chuyển qua các đường đi không chia sẻ bất kỳ <em>links</em> nào, để nếu một <em>link</em> bị hỏng, chỉ một trong hai luồng bị ảnh hưởng. Hai đường đi có thể đóng vai trò dự phòng cho nhau.</p>
<p>Sự tập trung hóa cũng có thể giúp các <em>routing protocols</em> hội tụ dễ dàng hơn. Trong một giao thức phân tán, nếu mạng thay đổi, các <em>routers</em> phải phối hợp để hội tụ về một trạng thái định tuyến mới. Trong mô hình tập trung này, nếu một <em>link</em> bị lỗi, <em>router</em> đó có thể báo cho &quot;sếp&quot;, và &quot;sếp&quot; có thể tính toán lại các tuyến đường và cài đặt các tuyến đường mới trên các <em>routers</em>.</p>
<h2 id="traffic-engineering"><a class="header" href="#traffic-engineering">Traffic Engineering</a></h2>
<p>Một <em>control plane</em> linh hoạt cho phép chúng ta thực hiện <em><strong>traffic engineering</strong></em>, có nghĩa là chúng ta có thể định tuyến lưu lượng một cách thông minh và hiệu quả hơn so với một <em>routing protocol</em> phân tán tiêu chuẩn.</p>
<img width="700px" src="datacenter/../assets/datacenter/6-070-engineering1.png">
<p>Giả sử có hai kết nối, S1-D ở tốc độ 10 Gbps và S2-D ở tốc độ 10 Gbps. Nếu chúng ta chỉ chạy <em>least-cost routing</em> (định tuyến chi phí thấp nhất) tiêu chuẩn, cả hai luồng sẽ gửi lưu lượng dọc theo đường đi phía dưới. Đường đi phía dưới sẽ bị tắc nghẽn (20 Gbps trên <em>link</em> 10 Gbps), trong khi <em>bandwidth</em> (băng thông) của đường đi phía trên không được sử dụng.</p>
<p>Với một cơ chế định tuyến thông minh hơn, chúng ta có thể gửi lưu lượng S1-D dọc theo đường đi phía trên, và lưu lượng S2-D dọc theo đường đi phía dưới. Bằng cách sử dụng <em>traffic engineering</em>, chúng ta đã buộc một số gói tin phải đi một con đường dài hơn, để tận dụng tốt hơn <em>bandwidth</em> trong mạng.</p>
<img width="700px" src="datacenter/../assets/datacenter/6-071-engineering2.png">
<p>Để tính toán các tuyến đường này, chúng ta có thể sửa đổi <em>least-cost routing</em>, và thay vào đó thực thi rằng lưu lượng nên đi trên con đường ngắn nhất có đủ dung lượng. Chúng ta cũng có thể thực thi các ràng buộc khác thay vì dung lượng, chẳng hạn như <em>latency</em> (độ trễ). Thuật toán kết quả được gọi là <em><strong>constrained Shortest Path First (cSPF)</strong></em>.</p>
<p>Bây giờ, giả sử S1-D cần 12 Gbps, và S2-D cần 8 Gbps. <em>cSPF</em> sẽ gửi các luồng đi theo các đường khác nhau để tối đa hóa <em>bandwidth</em>, nhưng S1-D đang gửi 12 Gbps qua một <em>link</em> 10 Gbps.</p>
<p>Để khắc phục điều này, <em>traffic engineering</em> của chúng ta có thể còn thông minh hơn nữa, và chia lưu lượng trong một luồng qua các đường đi khác nhau. S1-D có thể gửi 10 Gbps lưu lượng của mình dọc theo đường đi phía trên, và 2 Gbps còn lại dọc theo đường đi phía dưới.</p>
<p>Một lần nữa, <em>traffic engineering</em> của chúng ta đã cho phép chúng ta triển khai logic tùy chỉnh mang lại hiệu quả sử dụng dung lượng mạng tốt hơn.</p>
<img width="700px" src="datacenter/../assets/datacenter/6-074-engineering5.png">
<p>Làm thế nào để chúng ta thực sự triển khai các đường đi được phân chia trong mạng, sử dụng <em>API OpenFlow</em> từ trước? Hãy nhớ rằng, các quyết định định tuyến của chúng ta vẫn nên tuân theo các quy tắc đơn giản mà các <em>forwarding tables</em> có thể hiểu được.</p>
<p>Một cách tiếp cận là sử dụng <em>encapsulation</em> (sự đóng gói). Tại bên gửi, chúng ta có thể thêm các quy tắc để thêm một <em>header</em> bổ sung, trong đó một số gói tin nhận nhãn 0, và phần còn lại nhận nhãn 1. Nhãn này cho chúng ta biết nên gửi lưu lượng theo đường nào.</p>
<img width="700px" src="datacenter/../assets/datacenter/6-075-engineering6.png">
<p>Bây giờ, tại R1, chúng ta có thể thêm các quy tắc đơn giản để định tuyến các gói tin có nhãn 0 lên R2, và các gói tin có nhãn 1 xuống R3. Ý tưởng này có thể được áp dụng ngoài các quy tắc khác mà chúng ta đã có cho <em>constrained least-cost routing</em> (ví dụ: các <em>flow tables</em> có thể có các mục khác cho các đích khác hoặc các luồng khác).</p>
<h2 id="traffic-engineering-tập-trung-và-các-quyết-định-tối-ưu-toàn-cục"><a class="header" href="#traffic-engineering-tập-trung-và-các-quyết-định-tối-ưu-toàn-cục">Traffic Engineering tập trung và các quyết định tối ưu toàn cục</a></h2>
<p>Một khác biệt lớn trong mô hình <em>SDN</em> của các <em>routing protocols</em> tùy chỉnh là sự tập trung hóa. Trong mô hình ban đầu, mỗi <em>router</em> đều chạy <em>routing protocol</em> của riêng mình. Bây giờ, chúng ta có thể có một máy tính duy nhất bên ngoài các <em>routers</em> tính toán tất cả các tuyến đường, và sau đó sử dụng <em>API flow table</em> để cài đặt những tuyến đường đó lên các <em>routers</em>.</p>
<p>Sự tập trung hóa cho phép chúng ta đưa ra các <strong><em>globally optimal decisions</em> (quyết định tối ưu toàn cục)</strong>. Trong một giao thức phân tán, mỗi <em>router</em> đang đưa ra quyết định tốt nhất cho chính nó, nhưng đó có thể không phải là quyết định tốt nhất cho các <em>routers</em> khác. Trong mô hình tập trung, &quot;sếp&quot; có thể sử dụng cái nhìn toàn cục về mạng để quyết định điều gì là tốt nhất cho mọi người, và yêu cầu các <em>routers</em> tuân theo quyết định đó.</p>
<img width="700px" src="datacenter/../assets/datacenter/6-072-engineering3.png">
<p>Hãy xem xét mạng này với hai luồng, S1-D ở tốc độ 20 Gbps, và S2-D ở tốc độ 100 Gbps. Giả sử chúng ta chưa triển khai hỗ trợ cho việc chia một luồng ra nhiều đường đi.</p>
<p>Giả sử luồng 20 Gbps S1-D bắt đầu trước. Sử dụng <em>constrained shortest path first</em>, S1 có thể chọn sử dụng đường đi phía dưới. Từ góc độ của S1, đây là một quyết định tối ưu cục bộ (đường đi trên và dưới đều tốt như nhau).</p>
<p>Sau đó, luồng 100 Gbps S2-D bắt đầu. Bây giờ, sử dụng <em>constrained shortest path first</em>, S2-D không có bất kỳ đường đi đơn lẻ nào đáp ứng được yêu cầu của nó. Cả đường đi phía trên (20 Gbps) và đường đi phía dưới (80 Gbps) đều không đủ dung lượng.</p>
<p>Vấn đề chính ở đây là, mỗi <em>router</em> riêng lẻ đã tự đưa ra quyết định của mình một cách độc lập, không có sự phối hợp.</p>
<p>Bằng cách giới thiệu một bộ điều khiển tập trung, bộ điều khiển có thể nhìn vào cấu trúc tổng thể của mạng và nhu cầu của mỗi luồng, và gán các đường đi cho mỗi luồng một cách thông minh hơn. Quyết định kết quả là tối ưu toàn cục, và tăng hiệu quả mạng.</p>
<img width="700px" src="datacenter/../assets/datacenter/6-073-engineering4.png">
<p><em>Traffic engineering</em> tập trung có thể đưa ra các quyết định định tuyến thông minh hơn nữa, tùy thuộc vào những gì người vận hành muốn tối ưu hóa. Ví dụ, chúng ta có thể phân loại các luồng thành luồng ưu tiên cao hoặc ưu tiên thấp, và đưa ra các quyết định tối ưu hóa cả việc sử dụng mạng và nhu cầu của các ứng dụng khác nhau.</p>
<h2 id="sdn-trong-datacenter-overlay"><a class="header" href="#sdn-trong-datacenter-overlay">SDN trong Datacenter Overlay</a></h2>
<p>Trong phần trước, chúng ta đã thấy rằng các <em>virtual switches</em> (bộ chuyển mạch ảo) có thể áp dụng <em>encapsulation</em> để kết nối mạng <em>overlay</em> (lớp phủ) và <em>underlay</em> (lớp nền). Với một <em>virtual address</em> (địa chỉ ảo), chúng ta có thể thêm một <em>header</em> với <em>physical address</em> (địa chỉ vật lý) tương ứng, cho phép gói tin được gửi đi trên mạng <em>underlay</em>. Nhưng, làm thế nào để chúng ta biết được sự ánh xạ giữa <em>virtual addresses</em> và <em>physical addresses</em>?</p>
<p>Chúng ta cũng đã thấy rằng <em>encapsulation</em> có thể được sử dụng để hỗ trợ nhiều <em>tenants</em> (người thuê) trong một <em>datacenter</em> duy nhất, mỗi <em>tenant</em> chạy mạng riêng của mình. Các <em>switches</em> có thể thêm các <em>headers</em> với một <em>virtual network ID</em> (mã định danh mạng ảo). Nhưng, làm thế nào để chúng ta biết nên sử dụng <em>virtual network ID</em> nào?</p>
<p>Một bộ điều khiển <em>SDN</em> tập trung có thể được sử dụng trong <em>datacenter</em> để giải quyết những vấn đề này. Mỗi <em>tenant</em> có thể vận hành bộ điều khiển của riêng mình. Khi một <em>VM</em> (Máy ảo) mới được tạo, <em>SDN</em> sẽ biết được <em>virtual address</em> và <em>physical address</em> của nó. Sau đó, <em>SDN</em> có thể cập nhật các <em>forwarding tables</em> trong các <em>virtual switches</em> khác, thêm các quy tắc <em>encapsulation</em> với ánh xạ địa chỉ ảo/vật lý mới.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-076-sdn-overlay.png">
<p>Ví dụ, giả sử Coke <em>VM</em> 2 được tạo với <em>virtual IP</em> (IP ảo) là 192.0.2.1 và <em>physical IP</em> (IP vật lý) là 2.2.2.2. <em>SDN</em> biết rằng Coke <em>VM</em> 1 đang ở trên <em>physical server</em> (máy chủ vật lý) 1.1.1.1, vì vậy nó có thể đến <em>virtual switch</em> trên 1.1.1.1 và thêm một quy tắc <em>encapsulation</em> cho Coke <em>VM</em> 2 mới.</p>
<p><em>Flow table</em> tại 1.1.1.1 có thể nói: Nếu bạn nhận được một gói tin có đích là 192.0.2.1, hãy thêm một <em>header</em> với <em>virtual network ID</em> của Coke là 42. Đồng thời, thêm một <em>header</em> với <em>physical address</em> tương ứng là 2.2.2.2. Sau đó, gửi gói tin đi trên mạng <em>underlay</em>.</p>
<h2 id="lợi-ích-của-sdn-trong-datacenter-overlay"><a class="header" href="#lợi-ích-của-sdn-trong-datacenter-overlay">Lợi ích của SDN trong Datacenter Overlay</a></h2>
<p>Tại sao chúng ta lại sử dụng kiến trúc <em>SDN</em> tập trung để hỗ trợ ảo hóa và <em>multi-tenancy</em> (đa người thuê) trong <em>datacenter</em>, thay vì một <em>routing protocol</em> tiêu chuẩn hơn?</p>
<p>Kiến trúc <em>SDN</em> tập trung cho phép chúng ta tách biệt rõ ràng mạng <em>overlay</em> và <em>underlay</em> thành hai lớp có khả năng mở rộng. Trong một kiến trúc truyền thống, các <em>routers</em> trong mạng <em>underlay</em> sẽ phải xử lý các <em>encapsulation headers</em> tùy chỉnh (ví dụ: <em>virtual network IDs</em>). <em>SDN</em> cho phép mạng <em>underlay</em> vẫn đơn giản, mà không cần phải suy nghĩ về ảo hóa hay <em>multi-tenancy</em>.</p>
<p>Sự tập trung hóa cho chúng ta một cách đơn giản để triển khai <em>control plane</em> tại các <em>end hosts</em> (máy chủ đầu cuối), mà không cần bất kỳ <em>routing protocols</em> phức tạp nào. Bộ điều khiển biết về một máy chủ mới và cập nhật các máy chủ khác tương ứng. Nếu không có bộ điều khiển tập trung, chúng ta có thể cần một cơ chế phân tán phức tạp nào đó để tìm ra nên thêm <em>encapsulation headers</em> nào.</p>
<p>Kiến trúc <em>SDN</em> này cũng cho chúng ta thấy tại sao các mạng <em>overlay</em> có thể mở rộng tốt. Bộ điều khiển <em>SDN</em> cho một <em>tenant</em> chỉ cần biết về các <em>VMs</em> thuộc về <em>tenant</em> cụ thể đó. Ngược lại, nếu chúng ta sử dụng kiến trúc truyền thống, một <em>VM</em> Coke mới có thể phải được quảng bá đến tất cả các <em>VMs</em> khác, ngay cả các <em>VMs</em> của Pepsi.</p>
<h2 id="sdn-trong-datacenter-underlay"><a class="header" href="#sdn-trong-datacenter-underlay">SDN trong Datacenter Underlay</a></h2>
<p><em>Datacenter underlay</em> là một mạng vật lý, giống như bất kỳ mạng nào khác, mặc dù có một topo đặc biệt. Nhiều thách thức mạng thông thường, như đạt được hiệu suất sử dụng cao của các <em>links</em>, cũng áp dụng cho các mạng <em>datacenter underlay</em>. Điều đó có nghĩa là chúng ta cũng có thể áp dụng <em>SDN</em> cho mạng <em>underlay</em>.</p>
<p><em>SDN</em> tại mạng <em>underlay</em> có thể giúp chúng ta định tuyến các gói tin qua <em>datacenter</em> một cách hiệu quả. Ví dụ, người vận hành có thể muốn gửi các <em>mice flows</em> (luồng chuột - các luồng dữ liệu nhỏ và ngắn) dọc theo các <em>links</em> có độ trễ nhỏ, và các <em>elephant flows</em> (luồng voi - các luồng dữ liệu lớn và kéo dài) dọc theo các <em>links</em> có <em>bandwidth</em> cao.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-077-sdn-underlay.png">
<p>Trong <em>Clos network</em> (mạng Clos) <em>underlay</em> của chúng ta, <em>per-flow load balancing</em> (cân bằng tải trên từng luồng) (sử dụng <em>hash 5-tuple</em> (hàm băm bộ 5 thông tin) để chọn đường đi) vẫn có thể gửi nhiều <em>elephant flows</em> đi cùng một đường. Ngay cả khi hai <em>elephant flows</em> sử dụng các đường đi khác nhau, các đường đi đó có thể chia sẻ các <em>links</em>, và những <em>links</em> đó có thể bị tắc nghẽn. Một bộ điều khiển <em>SDN</em> có thể giải quyết vấn đề này bằng cách phối hợp các luồng và đặt chúng vào các đường đi không chồng chéo.</p>
<img width="800px" src="datacenter/../assets/datacenter/6-078-sdn-paper.png">
<p>Bài báo năm 2022 này của Google mô tả việc loại bỏ các lớp trong <em>Clos network</em> (ít <em>links</em> hơn, <em>datacenter</em> rẻ hơn) bằng cách sử dụng <em>SDN</em> để định tuyến lưu lượng một cách thông minh hơn.</p>
<p>Các <em>Hyperscale datacenters</em> (trung tâm dữ liệu siêu quy mô) thường sử dụng <em>SDN</em> trong cả mạng <em>overlay</em> và <em>underlay</em>. Chúng thường được triển khai như các hệ thống tách rời. Có một <em>SDN</em> suy nghĩ về <em>underlay</em>, và một <em>SDN</em> riêng biệt suy nghĩ về <em>overlay</em>.</p>
<h2 id="sdn-trong-wide-area-networks"><a class="header" href="#sdn-trong-wide-area-networks">SDN trong Wide Area Networks</a></h2>
<p>Ngoài các <em>datacenter</em>, <em>SDN</em> có thể hữu ích trong các <em>Wide Area Networks</em> (WAN) nói chung, đặc biệt khi việc sử dụng <em>bandwidth</em> hiệu quả là rất quan trọng. Ví dụ, trong ví dụ về <em>traffic engineering</em> từ trước, hãy tưởng tượng nếu các <em>links</em> 10 Gbps của chúng ta là <em>undersea cables</em> (cáp ngầm dưới biển). Không có cách nào rẻ tiền để thêm <em>bandwidth</em> bổ sung, vì vậy các tối ưu hóa phải tập trung vào việc sử dụng hiệu quả <em>bandwidth</em> mà chúng ta có.</p>
<h2 id="hạn-chế-của-điều-khiển-tập-trung"><a class="header" href="#hạn-chế-của-điều-khiển-tập-trung">Hạn chế của điều khiển tập trung</a></h2>
<p>Sự tập trung hóa không phải là miễn phí và có một số hạn chế.</p>
<p>Một hạn chế là độ tin cậy. Trong một mạng truyền thống, nếu một <em>router</em> bị lỗi, <em>routing protocol</em> sẽ hội tụ xung quanh sự cố đó. Các <em>routers</em> khác có thể định tuyến lại lưu lượng dọc theo các đường đi khác. Ngược lại, nếu bộ điều khiển trung tâm bị lỗi, chúng ta không còn cách nào để cập nhật mạng nữa, và các <em>routers</em> không biết cách điều chỉnh theo những thay đổi.</p>
<p>Lưu ý: Chúng ta đã vẽ bộ điều khiển tập trung như một thực thể duy nhất, nhưng nó không cần phải chạy trên một máy chủ duy nhất. Việc tính toán ở <em>control plane</em> có thể diễn ra trên nhiều máy chủ, nơi các máy chủ đó phối hợp để hoạt động một cách tập trung về mặt logic. Điều này khác với mô hình ban đầu, nơi các <em>routers</em> phối hợp nhưng vẫn tự đưa ra các quyết định phân tán của riêng mình. Điều này giúp tránh có một <em>single point of failure</em> (điểm lỗi duy nhất) trong phần cứng, mặc dù bộ điều khiển với tư cách là một đơn vị logic vẫn có thể bị lỗi (ví dụ: lỗi trong mã lệnh).</p>
<p>Sự tập trung hóa cũng gây ra các vấn đề về <em>scalability</em> (khả năng mở rộng). Bộ điều khiển phải đưa ra quyết định cho tất cả mọi người, điều này có thể trở nên tốn kém đối với các mạng lớn. Ngược lại, trong một mạng truyền thống, mỗi <em>router</em> chỉ phải thực hiện các phép tính cho chính nó.</p>
<p>Sự tập trung hóa cũng có thể gây ra các loại phức tạp khác. Trong một mạng truyền thống, chúng ta có thể mua một <em>router</em> và kết nối nó, và nó gần như bắt đầu hoạt động ngay lập tức. Với một bộ điều khiển trung tâm, chúng ta có thêm những thách thức về cơ sở hạ tầng. Chúng ta nên đặt bộ điều khiển này ở đâu? Làm thế nào để kết nối nó với các <em>routers</em> riêng lẻ một cách đáng tin cậy?</p>
<p>Đây là một lĩnh vực nghiên cứu tích cực, bao gồm một dự án của Sylvia Ratnasamy và Rob Shakir (giảng viên khóa học Berkeley CS 168).</p>
<h2 id="sdn-trong-management-plane-và-data-plane"><a class="header" href="#sdn-trong-management-plane-và-data-plane">SDN trong Management Plane và Data Plane</a></h2>
<p>Chúng ta đã thấy <em>SDN</em> như một cách mới để triển khai <em>control plane</em>. Nhưng, sự thất vọng ban đầu dẫn đến sự phát triển của <em>SDN</em> là ở <em>management plane</em>.</p>
<p>Hóa ra, nhiều mô hình thiết kế mà <em>SDN</em> đã sử dụng ở <em>control plane</em> cũng có thể áp dụng cho <em>management plane</em>. Ví dụ, chúng ta đã thấy rằng <em>SDN</em> dựa trên các <em>APIs</em> được định nghĩa rõ ràng, có thể lập trình được (ví dụ: <em>OpenFlow</em>).</p>
<p>TODO ran out of time in SP24.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="host-networking-mạng-tại-máy-chủ"><a class="header" href="#host-networking-mạng-tại-máy-chủ"><strong>Host Networking</strong> (Mạng tại máy chủ)</a></h1>
<h2 id="host-networking-là-gì-what-is-host-networking"><a class="header" href="#host-networking-là-gì-what-is-host-networking"><strong>Host Networking là gì?</strong> (What is Host Networking?)</a></h2>
<p>Truyền thống trước đây, <strong>bottleneck</strong> (nút thắt cổ chai) của mạng nằm bên trong <strong>network infrastructure</strong> (hạ tầng mạng), chứ không phải ở <strong>end host</strong> (máy chủ đầu cuối). Tuy nhiên, trong các <strong>datacenter</strong> (trung tâm dữ liệu) hiệu năng cao hiện đại, khi nhu cầu hiệu năng mạng tiếp tục tăng, các end host đang gặp khó khăn để đáp ứng.</p>
<p>Cụ thể, <strong>CPU</strong> chạy các <strong>network protocol</strong> (giao thức mạng) như <strong>TCP</strong> không còn đủ khả năng cung cấp hiệu năng cao mà datacenter cần. CPU đắt đỏ, và để đạt hiệu năng cao, CPU phải dành toàn bộ thời gian chạy các giao thức mạng, khiến ít tài nguyên hơn được phân bổ cho việc chạy ứng dụng thực tế.</p>
<p>Ngoài ra, các giao thức mà chúng ta đang sử dụng, như <strong>IP</strong> và <strong>TCP</strong>, không còn đáp ứng được yêu cầu hiệu năng cao hiện đại.</p>
<p>Để giải quyết hai vấn đề này, chúng ta chuyển sang <strong>host networking</strong> – bao gồm các tối ưu hóa tại end host (trái ngược với tối ưu hóa bên trong mạng).</p>
<img width="700px" src="datacenter/../assets/datacenter/6-079-host-networking-taxonomy.png">
<h2 id="tối-ưu-hóa-shared-memory-trong-user-space-optimization-shared-memory-in-user-space"><a class="header" href="#tối-ưu-hóa-shared-memory-trong-user-space-optimization-shared-memory-in-user-space"><strong>Tối ưu hóa: Shared Memory trong User Space</strong> (Optimization: Shared Memory in User Space)</a></h2>
<p>Nhớ rằng tại end host:</p>
<ul>
<li><strong>Layer 1</strong> và <strong>Layer 2</strong> được triển khai bằng phần cứng tại <strong>Network Interface Card (NIC)</strong>.</li>
<li><strong>Layer 3</strong> và <strong>Layer 4</strong> được triển khai bằng phần mềm trong <strong>Operating System (OS)</strong> (trên CPU).</li>
<li><strong>Layer 7</strong> là chính ứng dụng.</li>
</ul>
<img width="800px" src="datacenter/../assets/datacenter/6-080-layers.png">
<p>Từ các môn học nền tảng (ví dụ: CS 61C tại UC Berkeley), chúng ta biết rằng máy tính hiện đại được thiết kế với <strong>virtual memory</strong> (bộ nhớ ảo), để mỗi ứng dụng có <strong>address space</strong> (không gian địa chỉ) riêng, tách biệt với ứng dụng khác. Cụ thể, mỗi ứng dụng Layer 7 có không gian địa chỉ riêng trong <strong>user space</strong>. Ngược lại, hệ điều hành chạy trong <strong>kernel space</strong> – vùng bộ nhớ đặc biệt mà ứng dụng trong user space không thể truy cập.</p>
<p>Mô hình quản lý bộ nhớ này có nghĩa là khi truyền packet xuống stack để gửi dữ liệu, chúng ta liên tục <strong>copy</strong> dữ liệu từ user space sang kernel space. Khi nhận dữ liệu, packet được truyền lên stack từ kernel space sang user space, cũng cần copy. Việc copy bit qua lại giữa kernel space và user space vừa tốn kém vừa không cần thiết.</p>
<p>Một vấn đề khác là lập trình trong kernel space rất khó. Nếu muốn chỉnh sửa TCP để tối ưu cho mục đích riêng, chúng ta phải can thiệp sâu vào hệ điều hành và lập trình ở mức rất thấp. Việc triển khai và kiểm thử trong kernel space khó khăn và chậm hơn so với user space.</p>
<img width="800px" src="datacenter/../assets/datacenter/6-081-kernel1.png">
<p>Để giải quyết hai vấn đề này, chúng ta có thể di chuyển <strong>networking stack</strong> (ví dụ: các giao thức Layer 3 và Layer 4) ra khỏi kernel space và đưa vào user space. Khi đó, Layer 3, 4 và 7 có thể truy cập cùng một không gian địa chỉ, không cần copy qua lại. Ngoài ra, việc phát triển và đổi mới trong user space cũng dễ dàng hơn.</p>
<img width="500px" src="datacenter/../assets/datacenter/6-082-kernel2.png">
<p>Việc sử dụng <strong>shared memory</strong> trong user space giúp loại bỏ một số công việc thừa như copy dữ liệu qua lại, nhưng vẫn chưa đủ để giúp host đáp ứng yêu cầu hiệu năng hiện đại.</p>
<h2 id="tối-ưu-hóa-offloading-sang-nic-optimization-offloading-to-nic"><a class="header" href="#tối-ưu-hóa-offloading-sang-nic-optimization-offloading-to-nic"><strong>Tối ưu hóa: Offloading sang NIC</strong> (Optimization: Offloading to NIC)</a></h2>
<p>CPU không đủ nhanh để chạy các giao thức mạng (ví dụ: IP, TCP) ở tốc độ hiệu năng hiện đại. Ngoài ra, dùng CPU để chạy giao thức mạng sẽ làm giảm tài nguyên CPU dành cho ứng dụng.</p>
<p>Để giải quyết, chúng ta có thể <strong>offload</strong> (chuyển tải) networking stack ra khỏi CPU (phần mềm) và đưa vào NIC (phần cứng).</p>
<p>NIC là nơi tự nhiên để thực hiện offload. Mọi packet đều phải đi qua NIC, nên NIC có thể xử lý thêm và giảm tải cho CPU.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-084-epoch0-1.png">
<p><strong>Network driver</strong> là phần mềm trong OS dùng để lập trình và quản lý NIC. Driver cung cấp <strong>API</strong> cho phép các chương trình cấp cao hơn trong OS tương tác với NIC. Có thể coi driver là cầu nối giữa phần cứng và phần mềm.</p>
<p><strong>Lợi ích của offloading</strong>:</p>
<ul>
<li>Giải phóng tài nguyên CPU cho ứng dụng.</li>
<li>Xử lý chuyên biệt bằng phần cứng có thể hiệu quả hơn CPU đa dụng (về tốc độ và tiêu thụ điện).</li>
<li>Thực thi trong phần cứng không chỉ giảm latency mà còn giúp latency ổn định và dự đoán được.</li>
</ul>
<p>Khi chạy ứng dụng trong phần mềm, CPU phải <strong>schedule</strong> (lập lịch) nhiều tiến trình, có thể gây trễ không đoán trước. Ví dụ: nếu có packet cần xử lý, CPU có thể phải hoàn thành tác vụ hiện tại trước khi xử lý packet đó.</p>
<h2 id="lược-sử-offloading-epoch-0-brief-history-of-offloading-epoch-0"><a class="header" href="#lược-sử-offloading-epoch-0-brief-history-of-offloading-epoch-0"><strong>Lược sử Offloading: Epoch 0</strong> (Brief History of Offloading: Epoch 0)</a></h2>
<p>Việc offload tác vụ từ OS (phần mềm) sang NIC (phần cứng) là một lĩnh vực nghiên cứu đang diễn ra. Có ba <strong>epoch</strong> (giai đoạn) phát triển, trong đó các tác vụ ngày càng phức tạp được offload sang NIC.</p>
<p><strong>Epoch 0</strong>: Trước khi có offloading, hãy xem NIC làm gì trong networking stack tiêu chuẩn.</p>
<p>NIC có một <strong>central controller processor</strong> (bộ xử lý điều khiển trung tâm) quản lý hoạt động trên card.</p>
<ul>
<li>
<p><strong>Packet đến</strong>: <strong>Transceiver</strong> chuyển tín hiệu điện thành tín hiệu số (1 và 0) và đưa vào <strong>buffer</strong>. NIC đọc bit từ buffer, phân tích thành <strong>Ethernet frame</strong>, xử lý frame (ví dụ: kiểm tra <strong>checksum</strong>), và loại bỏ <strong>Layer 2 header</strong>. Cuối cùng, NIC tạo <strong>interrupt</strong> để báo CPU dừng việc đang làm và lấy packet Layer 3 để xử lý tiếp.</p>
</li>
<li>
<p><strong>Packet đi</strong>: Packet từ network driver được đặt vào buffer. NIC đọc bit từ buffer, xử lý để tạo Ethernet frame, sau đó đưa frame tới transceiver để chuyển bit số thành tín hiệu điện.</p>
</li>
</ul>
<img width="900px" src="datacenter/../assets/datacenter/6-085-epoch0-2.png">
<p>Trong networking stack tiêu chuẩn, có thể coi NIC như một “tấm thảm chùi chân” – chỉ chuyển packet đến OS và gửi packet ra ngoài cho OS, nhưng xử lý rất tối thiểu trên các packet đó.</p>
<h2 id="lược-sử-offloading-epoch-1-brief-history-of-offloading-epoch-1"><a class="header" href="#lược-sử-offloading-epoch-1-brief-history-of-offloading-epoch-1"><strong>Lược sử Offloading: Epoch 1</strong> (Brief History of Offloading: Epoch 1)</a></h2>
<img width="700px" src="datacenter/../assets/datacenter/6-086-epoch-taxonomy.png">
<p>Những tác vụ đầu tiên mà chúng ta thử <strong>offload</strong> (chuyển tải) sang <strong>NIC</strong> (Network Interface Card – card giao tiếp mạng) là các tác vụ <strong>stateless</strong> (không trạng thái) đơn giản. Các tác vụ này có thể được thực hiện độc lập trên từng <strong>packet</strong> (gói tin), và NIC không cần ghi nhớ trạng thái giữa nhiều packet.</p>
<p>Một tác vụ stateless có thể offload là <strong>checksum computation</strong> (tính toán tổng kiểm tra), không chỉ ở <strong>Layer 2</strong> mà còn ở <strong>Layer 3</strong> và <strong>Layer 4</strong>. NIC có thể xác thực checksum (cho packet đến) và tính checksum (cho packet đi), để CPU không phải làm việc này.</p>
<p>Một tác vụ stateless khác có thể offload là <strong>segmentation</strong> (phân mảnh). Trong mô hình tiêu chuẩn, nếu ứng dụng có một tệp lớn để gửi, <strong>OS</strong> (Operating System – hệ điều hành) chịu trách nhiệm chia tệp thành các packet nhỏ. Ở phía nhận, OS chịu trách nhiệm ghép lại các packet này. Như một tối ưu hóa, chúng ta có thể để NIC xử lý việc chia nhỏ và ghép lại packet. Khi đó, OS không còn phải xử lý số lượng lớn packet nhỏ, mà chỉ xử lý một số packet lớn hơn, hiệu quả hơn (ví dụ: ít header hơn để xử lý).</p>
<img width="900px" src="datacenter/../assets/datacenter/6-087-reassemble.png">
<p>Với segmentation, có sự đánh đổi giữa kết nối mượt mà và hiệu quả CPU:</p>
<ul>
<li>Nếu ứng dụng gửi packet lớn cho NIC → CPU ít việc hơn, nhưng NIC nhận các đợt dữ liệu lớn, kết nối trở nên <strong>bursty</strong> (bùng nổ).</li>
<li>Nếu ứng dụng gửi packet nhỏ cho NIC → CPU nhiều việc hơn, nhưng NIC nhận luồng dữ liệu đều hơn, kết nối mượt hơn.</li>
</ul>
<p>Một số thách thức khi <strong>aggregate</strong> (gộp) packet nhỏ:</p>
<ul>
<li>Nếu một packet trung gian bị mất → NIC có thể phải chuyển lên nhiều packet nhỏ và không thể gộp thành packet lớn.</li>
<li>Nếu một số packet có <strong>flag</strong> (cờ) được bật (ví dụ: <strong>ECN</strong> cho tắc nghẽn) và số khác không → packet gộp cuối cùng có nên bật cờ hay không?</li>
</ul>
<p>Tác vụ stateless thứ ba là <strong>multi-queue support</strong> (hỗ trợ đa hàng đợi). Trong mô hình tiêu chuẩn, NIC có một hàng đợi cho packet đi và một hàng đợi cho packet đến, tất cả ứng dụng dùng chung. <strong>Network driver</strong> (trình điều khiển mạng – phần mềm) chịu trách nhiệm <strong>load balancing</strong> (cân bằng tải) nếu nhiều ứng dụng hoặc nhiều CPU gửi/nhận dữ liệu.</p>
<p>Chúng ta có thể offload công việc cân bằng tải này sang NIC. NIC sẽ có nhiều <strong>transmit queue</strong> (hàng đợi gửi) và nhiều <strong>receive queue</strong> (hàng đợi nhận). Ví dụ: trong hệ thống đa xử lý, mỗi CPU có hàng đợi gửi/nhận riêng. NIC duy trì các hàng đợi song song, đảm bảo cách ly và cân bằng tải giữa các CPU. NIC cũng có thể ưu tiên một số hàng đợi hơn hàng đợi khác.</p>
<p>Dù NIC có nhiều hàng đợi, cuối cùng vẫn phải gửi tất cả packet qua một dây. Do đó, NIC cần một <strong>packet scheduler</strong> (bộ lập lịch gói tin) để quyết định gửi từ hàng đợi nào tiếp theo. Bộ lập lịch có thể lập trình để đạt hành vi cân bằng tải mong muốn (ví dụ: ưu tiên một hàng đợi hơn hàng khác).</p>
<img width="400px" src="datacenter/../assets/datacenter/6-088-multiqueue.png">
<p>Một thách thức với multi-queue là ánh xạ packet vào hàng đợi. Khi CPU có dữ liệu để gửi, nó dùng hàng đợi nào? Đặc biệt, cần đảm bảo tất cả packet trong cùng một <strong>flow</strong> (luồng) vào cùng một hàng đợi (không bị phân tán), để đảm bảo packet trong flow được gửi <strong>in-order</strong> (đúng thứ tự). Nhớ rằng trong TCP, gửi packet sai thứ tự vẫn hoạt động nhưng giảm hiệu năng (bên nhận phải buffer packet sai thứ tự).</p>
<p>Khi xử lý packet đến từ nhiều receive queue, NIC có thể <strong>hash</strong> packet để quyết định CPU nào xử lý packet đó. Sau đó, NIC <strong>interrupt</strong> CPU đó để xử lý. Hành vi dựa trên hash này tương tự <strong>ECMP</strong> (Equal-Cost Multi-Path Routing) và giúp đảm bảo tất cả packet trong cùng một flow được xử lý theo thứ tự bởi cùng một CPU.</p>
<h2 id="lược-sử-offloading-epoch-2-brief-history-of-offloading-epoch-2"><a class="header" href="#lược-sử-offloading-epoch-2-brief-history-of-offloading-epoch-2"><strong>Lược sử Offloading: Epoch 2</strong> (Brief History of Offloading: Epoch 2)</a></h2>
<p>Sau đó, chúng ta bắt đầu offload các tác vụ <strong>stateful</strong> (có trạng thái) phức tạp hơn sang NIC.</p>
<p>Sự phát triển của Epoch 2 được thúc đẩy bởi <strong>virtualization</strong> (ảo hóa) trong datacenter, nơi nhiều <strong>virtual machine (VM)</strong> chạy trên cùng một <strong>physical server</strong>. Ví dụ: trong ảo hóa, chúng ta cần một <strong>virtual switch</strong> để chuyển tiếp packet đến đúng VM. Virtual switch có thể chạy bằng phần mềm, nhưng cũng có thể triển khai bằng phần cứng.</p>
<p><strong>Firewall</strong> (tường lửa) và <strong>bandwidth management</strong> (quản lý băng thông) là ví dụ khác của stateful offload. Trong phần mềm, ta có thể triển khai firewall để thực thi <strong>security policy</strong> (chính sách bảo mật) – ví dụ: drop tất cả packet đến từ IP độc hại. Ta cũng có thể áp dụng chính sách quản lý băng thông giữa người dùng – ví dụ: User A chỉ được gửi 100 packet/phút, vượt quá sẽ bị drop. Các chính sách này có thể được kiểm tra bởi phần cứng.</p>
<p>Để triển khai các tác vụ stateful này, ta có thể dùng <strong>match-action pair table</strong> (bảng cặp điều kiện-hành động), tương tự bảng <strong>OpenFlow</strong> (trong phần SDN). API này cho phép phần mềm lập trình các chính sách lên phần cứng, để phần cứng xử lý packet theo chính sách. <strong>Match</strong> có thể dựa trên 5-tuple hoặc các trường header khác. <strong>Action</strong> có thể là drop packet, forward packet tới <strong>next-hop</strong> cụ thể, hoặc sửa header.</p>
<img width="600px" src="datacenter/../assets/datacenter/6-089-flowtable.png">
<h2 id="lược-sử-offloading-epoch-3-brief-history-of-offloading-epoch-3"><a class="header" href="#lược-sử-offloading-epoch-3-brief-history-of-offloading-epoch-3"><strong>Lược sử Offloading: Epoch 3</strong> (Brief History of Offloading: Epoch 3)</a></h2>
<p>Đây là kỷ nguyên hiện tại của offloading. Có nhiều nỗ lực offload toàn bộ <strong>protocol</strong> (giao thức) như TCP ra khỏi OS và đưa vào NIC. Epoch này được thúc đẩy bởi nhu cầu hiệu năng cao hơn nữa, đặc biệt với các ứng dụng <strong>AI/ML</strong> (Artificial Intelligence / Machine Learning) yêu cầu hiệu năng lớn.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-090-epoch3.png">
<p>Lý tưởng nhất, chúng ta muốn ứng dụng gửi dữ liệu trực tiếp cho phần cứng, và phần cứng thực hiện toàn bộ xử lý mạng ở Layer 4, 3, 2, 1. OS hoàn toàn không tham gia, và tất cả giao thức mạng được triển khai trực tiếp trong phần cứng.</p>
<p>Dù đã có thử nghiệm offload các giao thức mạng tiêu chuẩn như TCP vào NIC, nhưng chưa triển khai ở quy mô lớn. Thay vào đó, chúng ta thiết kế các giao thức mới như <strong>RDMA</strong> (Remote Direct Memory Access), được thiết kế đặc biệt để triển khai trực tiếp trong phần cứng.</p>
<h2 id="rdma-remote-direct-memory-access-truy-cập-bộ-nhớ-từ-xa-trực-tiếp"><a class="header" href="#rdma-remote-direct-memory-access-truy-cập-bộ-nhớ-từ-xa-trực-tiếp"><strong>RDMA: Remote Direct Memory Access</strong> (Truy cập bộ nhớ từ xa trực tiếp)</a></h2>
<p><strong>RDMA</strong> cung cấp một <strong>abstraction</strong> (mô hình trừu tượng) cho phép <strong>Server A</strong> truy cập trực tiếp bộ nhớ của <strong>Server B</strong> mà không cần sự tham gia của <strong>OS</strong> (Operating System – hệ điều hành) hoặc <strong>CPU</strong> của bất kỳ server nào. RDMA có thể được triển khai trực tiếp trong phần cứng, thay thế <strong>TCP/IP software networking stack</strong> (ngăn xếp mạng phần mềm TCP/IP) tiêu chuẩn.</p>
<p>Giả sử Server A muốn gửi một tệp 10 GB cho Server B. Trong networking stack tiêu chuẩn, CPU đọc tệp từ bộ nhớ, xử lý nó (ví dụ: TCP/IP), và chuyển các <strong>packet</strong> (gói tin) kết quả cho <strong>NIC</strong> (Network Interface Card – card giao tiếp mạng). Ở phía nhận, NIC chuyển packet cho CPU, CPU xử lý packet và ghi <strong>payload</strong> (dữ liệu tải) của tệp vào bộ nhớ. Lưu ý rằng CPU tham gia xử lý từng packet của tệp 10 GB.</p>
<img width="800px" src="datacenter/../assets/datacenter/6-091-pre-rdma.png">
<p>Trong abstraction RDMA, NIC đọc tệp từ bộ nhớ và gửi đi, <strong>không cần CPU tham gia</strong>. Ở phía nhận, NIC xử lý các byte đến và ghi vào bộ nhớ, cũng không cần CPU tham gia. Lưu ý rằng CPU vẫn cần ở giai đoạn đầu để thiết lập quá trình truyền và ở giai đoạn cuối để hoàn tất. Nhưng phần lớn quá trình truyền tệp 10 GB được thực hiện mà không cần CPU.</p>
<img width="800px" src="datacenter/../assets/datacenter/6-092-post-rdma.png">
<p>Để sử dụng RDMA, lập trình viên không còn dùng <strong>socket abstraction</strong> nữa. Thay vào đó, mô hình trừu tượng chính được sử dụng là <strong>queue pair</strong> (cặp hàng đợi). <strong>Send work queue</strong> (hàng đợi công việc gửi) chứa tất cả các tác vụ đang chờ, nơi dữ liệu cần được truyền từ tôi tới một máy khác. <strong>Receive work queue</strong> (hàng đợi công việc nhận) chứa tất cả các tác vụ đang chờ, nơi tôi cần nhận dữ liệu từ máy khác. Một NIC có thể có nhiều queue pair, mỗi cặp cung cấp dịch vụ khác nhau cho lập trình viên. Ví dụ: một cặp có thể cung cấp dịch vụ truyền tin cậy, đúng thứ tự (<strong>reliable, in-order delivery</strong>), trong khi một cặp khác có thể cung cấp dịch vụ không tin cậy (<strong>unreliable delivery</strong>). Một queue pair được cấu hình để truyền tin cậy và đúng thứ tự là gần giống nhất với một kết nối TCP truyền thống.</p>
<img width="300px" src="datacenter/../assets/datacenter/6-093-queue1.png">
<p>Mỗi phần tử trong queue được gọi là <strong>Work Queue Element (WQE)</strong> (phần tử hàng đợi công việc). Một WQE cho phép ứng dụng mô tả công việc cần thực hiện. Ví dụ, WQE trong receive queue có thể nói: “Lấy 100 MB bắt đầu từ địa chỉ <em>0xffff1234</em> trên server từ xa, và ghi chúng vào địa chỉ <em>0xffff7890</em> trong bộ nhớ cục bộ của tôi.” Trong mã nguồn, WQE là một <strong>struct</strong> chứa các chỉ dẫn này, ví dụ: một <strong>pointer</strong> (con trỏ) tới nơi sẽ ghi dữ liệu nhận được.</p>
<img width="400px" src="datacenter/../assets/datacenter/6-094-queue2.png">
<p>Lưu ý rằng abstraction WQE cung cấp cho giao thức RDMA một cái nhìn ở mức cao hơn về ứng dụng. Trong TCP/IP stack, mạng chỉ thấy một <strong>bytestream</strong> (luồng byte), nhưng trong RDMA, WQE cho phép ứng dụng mô tả công việc chi tiết hơn (ví dụ: chỉ định điểm bắt đầu và kết thúc của một khối dữ liệu được truyền).</p>
<p>Khi một tác vụ hoàn tất, WQE được gỡ khỏi queue, và NIC tạo một <strong>Completion Queue Element (CQE)</strong> (phần tử hàng đợi hoàn tất) mới, mô tả điều gì đã xảy ra với tác vụ (ví dụ: thành công hoặc thất bại). CQE này được lưu trong <strong>Completion Queue</strong> và chờ cho đến khi ứng dụng sẵn sàng đọc CQE để biết kết quả của tác vụ.</p>
<img width="300px" src="datacenter/../assets/datacenter/6-095-queue3.png">
<p>Lưu ý rằng RDMA hoạt động <strong>asynchronous</strong> (bất đồng bộ). Ứng dụng có thể thêm tác vụ (WQE) vào queue pair bất cứ lúc nào, và NIC sẽ xử lý các tác vụ theo thứ tự. Tương tự, khi tác vụ hoàn tất, một CQE được đặt vào completion queue, và ứng dụng có thể đọc CQE bất cứ lúc nào. (So sánh với TCP/IP stack, nơi dữ liệu đến sẽ kích hoạt một <strong>interrupt</strong> cho CPU để xử lý dữ liệu đó.)</p>
<h2 id="ví-dụ-rdma-rdma-example"><a class="header" href="#ví-dụ-rdma-rdma-example"><strong>Ví dụ RDMA</strong> (RDMA Example)</a></h2>
<p><strong>RDMA</strong> (Remote Direct Memory Access – truy cập bộ nhớ từ xa trực tiếp) có thể được sử dụng cho nhiều loại thao tác khác nhau giữa các <strong>server</strong>. Mỗi thao tác có các thông số hiệu năng riêng (ví dụ: <strong>latency</strong> – độ trễ – khác nhau) và <strong>semantics</strong> (ngữ nghĩa) khác nhau (ví dụ: thông báo lỗi khác nhau). Ví dụ dưới đây minh họa một thao tác <strong>RDMA send</strong>, trong đó <strong>Server A</strong> đọc một tệp từ bộ nhớ của mình, truyền dữ liệu đó, và <strong>Server B</strong> ghi tệp này vào bộ nhớ của nó.</p>
<ol>
<li>
<p>Mỗi server chỉ định một vùng bộ nhớ để <strong>NIC</strong> (Network Interface Card – card giao tiếp mạng) có thể truy cập cho các phiên truyền RDMA. Server A chỉ định vùng bộ nhớ chứa tệp là <strong>NIC-readable</strong> (NIC có thể đọc). Server B chỉ định một <strong>blank buffer</strong> (bộ đệm trống) nơi nó sẽ nhận tệp là NIC-readable.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-096-rdma1.png">
</li>
<li>
<p>Mỗi server thiết lập các <strong>queue</strong> (hàng đợi). Cả hai NIC hiện có <strong>send queue</strong> (hàng đợi gửi), <strong>receive queue</strong> (hàng đợi nhận) và <strong>completion queue</strong> (hàng đợi hoàn tất). Lưu ý: bước này có thể thực hiện <strong>out-of-band</strong> (ngoài băng), sử dụng một giao thức truyền thống như <strong>TCP</strong> để phối hợp giữa hai server.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-097-rdma2.png">
</li>
<li>
<p>Server A tạo một <strong>WQE</strong> (Work Queue Element – phần tử hàng đợi công việc) trong send queue. WQE này chứa <strong>pointer</strong> (con trỏ) tới tệp, chỉ định dữ liệu cần gửi. Ở phía bên kia, Server B tạo một WQE trong receive queue. WQE này chứa con trỏ tới blank buffer, chỉ định nơi dữ liệu nhận được sẽ được ghi vào.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-098-rdma3.png">
<img width="900px" src="datacenter/../assets/datacenter/6-099-rdma4.png">
</li>
<li>
<p>Khi việc truyền đã được xếp hàng ở cả hai phía, quá trình truyền dữ liệu có thể diễn ra mà không cần phần mềm tham gia. NIC xử lý mọi thứ, bao gồm <strong>reliability</strong> (độ tin cậy), <strong>congestion control</strong> (kiểm soát tắc nghẽn), v.v.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-100-rdma5.png">
</li>
<li>
<p>Khi truyền xong, các WQE được gỡ khỏi queue. Cả hai NIC tạo một <strong>CQE</strong> (Completion Queue Element – phần tử hàng đợi hoàn tất), cho biết quá trình truyền đã hoàn tất và kèm theo các thông báo trạng thái liên quan (ví dụ: thông báo lỗi). CQE của Server A cho biết dữ liệu đã được gửi thành công, và CQE của Server B cho biết dữ liệu đã được nhận thành công.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-101-rdma6.png">
</li>
<li>
<p>Cuối cùng, ứng dụng đọc CQE để biết điều gì đã xảy ra với quá trình truyền.</p>
<img width="900px" src="datacenter/../assets/datacenter/6-102-rdma7.png">
</li>
</ol>
<h2 id="Ưu-nhược-điểm-và-ứng-dụng-của-rdma-rdma-pros-cons-applications"><a class="header" href="#Ưu-nhược-điểm-và-ứng-dụng-của-rdma-rdma-pros-cons-applications"><strong>Ưu, nhược điểm và ứng dụng của RDMA</strong> (RDMA Pros, Cons, Applications)</a></h2>
<p>RDMA mang lại khả năng truyền dữ liệu hiệu năng cao (<strong>low latency</strong> – độ trễ thấp, <strong>high bandwidth</strong> – băng thông cao) và giải phóng CPU cho ứng dụng. Tuy nhiên, RDMA không miễn phí: nó yêu cầu phần cứng và phần mềm chuyên dụng, và thường phức tạp hơn <strong>networking stack</strong> (ngăn xếp mạng) truyền thống. Hãy nhớ rằng RDMA thay thế <strong>TCP/IP stack</strong>, nên nó phải triển khai toàn bộ chức năng của TCP/IP như reliability và congestion control, tất cả trực tiếp trong phần cứng.</p>
<p>RDMA cũng có một số hạn chế, và thường hoạt động tốt nhất trong datacenter khi hai server ở gần nhau về mặt vật lý. Nếu hai server ở xa, độ trễ chủ yếu đến từ việc truyền dữ liệu qua mạng, và lợi ích thời gian từ RDMA là không đáng kể. Ngược lại, nếu hai server ở gần, thời gian xử lý packet tại host có thể là nguyên nhân chính gây trễ, nên RDMA mang lại lợi ích đáng kể.</p>
<p>RDMA đã được áp dụng trong nhiều bối cảnh yêu cầu tính toán hiệu năng cao, độ trễ thấp, ví dụ: nghiên cứu khoa học, mô hình tài chính, dự báo thời tiết, <strong>machine learning</strong> (học máy) và truy vấn tìm kiếm. Trong <strong>cloud computing</strong> (điện toán đám mây), RDMA có thể dùng để di chuyển một <strong>VM</strong> (Virtual Machine – máy ảo) lớn từ server vật lý này sang server khác, giải phóng CPU cho khách hàng. Trong huấn luyện AI/ML, RDMA không chỉ giải phóng CPU và giảm độ trễ, mà còn mang lại độ trễ <strong>predictable</strong> (dự đoán được), điều này quan trọng khi nhiều server cần phối hợp để huấn luyện mô hình AI/ML.</p>
<h2 id="triển-khai-rdma-implementing-rdma"><a class="header" href="#triển-khai-rdma-implementing-rdma"><strong>Triển khai RDMA</strong> (Implementing RDMA)</a></h2>
<p>Hãy nhớ rằng RDMA thay thế TCP/IP networking stack, nên RDMA chịu trách nhiệm cho reliability, congestion control, v.v. Có hai triết lý chính để triển khai:</p>
<ul>
<li><strong>Cách 1:</strong> Triển khai các tính năng này trong chính mạng, ví dụ: đảm bảo reliability tại <strong>switch</strong>. Đây là ý tưởng đằng sau <strong>Nvidia's InfiniBand</strong>.</li>
<li><strong>Cách 2:</strong> Triển khai các tính năng này trong NIC, bên dưới <strong>queue-pair abstraction</strong> (mô hình trừu tượng cặp hàng đợi). Đây là hướng tiếp cận hiện đang được Google theo đuổi.</li>
</ul>
<p>Trong cả hai trường hợp, ứng dụng và OS ở tầng phần mềm đều có <strong>ảo giác</strong> về việc truyền tin cậy, đúng thứ tự thông qua queue pair abstraction. Sự khác biệt nằm ở cách RDMA thực sự triển khai các đảm bảo dịch vụ đó.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multicast"><a class="header" href="#multicast"><strong>Multicast</strong></a></h1>
<h2 id="Động-lực-multicast-motivation-multicast"><a class="header" href="#Động-lực-multicast-motivation-multicast"><strong>Động lực: Multicast</strong> (Motivation: Multicast)</a></h2>
<p>Trong tất cả các chủ đề mà chúng ta đã tìm hiểu cho đến nay, chúng ta đều nói rằng mục tiêu của Internet là truyền dữ liệu giữa các <strong>host</strong> (máy chủ/máy trạm). Đặc biệt, chúng ta đã giả định mô hình truyền <strong>unicast</strong> (truyền đơn hướng), nghĩa là có một nguồn duy nhất gửi dữ liệu tới một đích duy nhất.</p>
<p>Nhiều giao thức mà chúng ta đã thấy (ví dụ: <strong>HTTP</strong>, <strong>DNS</strong>, <strong>TCP</strong>, <strong>TLS</strong>) dựa trên mô hình <strong>client-server</strong> (máy khách – máy chủ), vốn dựa trên mô hình truyền unicast. Trong mô hình client-server, có một client và một server trao đổi dữ liệu, điều này ngụ ý rằng chúng đang gửi dữ liệu unicast cho nhau.</p>
<p>Phần lớn lưu lượng trên Internet thực sự là unicast, nhưng vẫn có một số ngoại lệ. Đặc biệt, một số ứng dụng liên quan đến việc giao tiếp theo nhóm giữa các host. Ví dụ: một trò chơi nhiều người chơi (<strong>multi-player game</strong>), một ứng dụng truyền nội dung trực tiếp (<strong>live content delivery app</strong>, ví dụ: họp trực tuyến qua Zoom, phát trực tiếp một trận đấu thể thao), hoặc một tài liệu cộng tác (ví dụ: Google Docs). Cũng có những ứng dụng nhóm đặc thù hơn, như <strong>discovery</strong> (tìm kiếm thiết bị, ví dụ: gửi một thông điệp tới tất cả thiết bị Apple để tìm loa gần nhất), hoặc huấn luyện AI (chúng ta sẽ nghiên cứu phần này sau).</p>
<p>Mô hình client-server không phải là cách tự nhiên nhất để hình dung các tình huống này. Trong một trò chơi nhiều người chơi hoặc một ứng dụng hội nghị truyền hình, không tồn tại một client hoặc một server duy nhất. Vậy mạng nên hỗ trợ các ứng dụng này như thế nào để giúp lập trình viên dễ dàng phát triển chúng hơn?</p>
<p>Một câu trả lời khả dĩ là: Mạng <strong>không cần</strong> hỗ trợ gì cả. Giao tiếp nhóm có thể được triển khai bằng unicast. Ví dụ: khi bạn cập nhật một tài liệu cộng tác, bạn có thể gửi một gói tin unicast riêng tới từng thành viên khác trong nhóm để họ biết về bản cập nhật của bạn.</p>
<img width="500px" src="beyond-client-server/../assets/beyond-client-server/7-001-unicast-model.png">
<p>Tuy nhiên, cách tiếp cận chỉ dùng unicast này có thể kém hiệu quả. Xét ví dụ topology mạng, trong đó bạn ở Mỹ và tất cả các thành viên khác của nhóm ở châu Âu. Nếu bạn gửi các gói tin unicast riêng tới từng thành viên, bạn đang gửi nhiều bản sao trùng lặp của dữ liệu qua tuyến cáp quang biển đắt đỏ. Ngoài ra, điều này buộc bên gửi phải gửi nhiều gói tin unicast trùng lặp, dẫn đến khả năng mở rộng kém (ví dụ: tưởng tượng một server duy nhất phát trực tiếp một trận đấu thể thao cho hàng triệu người dùng).</p>
<p>Một cách tiếp cận tự nhiên hơn là chỉ gửi <strong>một</strong> gói tin qua tuyến cáp biển, sau đó để một thiết bị ở châu Âu (ví dụ: một <strong>router</strong> hoặc một host) phân phối bản sao gói tin đó tới các thành viên trong nhóm. Lý tưởng nhất, chúng ta muốn tránh gửi các bản sao trùng lặp của một gói tin trên cùng một liên kết. Nói cách khác, mỗi liên kết chỉ nên mang gói tin đó <strong>một lần</strong> (hoặc không mang, nếu không có thành viên nhóm nào ở phía đó).</p>
<img width="500px" src="beyond-client-server/../assets/beyond-client-server/7-002-multicast-model.png">
<p>Cách tiếp cận này đòi hỏi mạng phải có hỗ trợ bổ sung và cần phát triển một số giao thức mới.</p>
<h2 id="Định-nghĩa-multicast-multicast-definitions"><a class="header" href="#Định-nghĩa-multicast-multicast-definitions"><strong>Định nghĩa Multicast</strong> (Multicast Definitions)</a></h2>
<p>Hãy nhớ rằng chúng ta đã thấy bốn mô hình truyền gói tin cho đến nay:</p>
<ul>
<li><strong>Unicast:</strong> Gửi gói tin tới đúng một đích duy nhất.</li>
<li><strong>Anycast:</strong> Gửi gói tin tới một trong số các đích có thể. Chỉ cần một thành viên trong tập đích nhận được gói tin.</li>
<li><strong>Broadcast:</strong> Gửi gói tin tới tất cả các đích. Định nghĩa “tất cả” phụ thuộc vào ngữ cảnh, nhưng bạn có thể hình dung là tất cả host trong một mạng cục bộ.</li>
<li><strong>Multicast:</strong> Gửi gói tin tới tất cả các thành viên trong một nhóm. Host có thể tham gia/rời nhóm bất kỳ lúc nào. Lưu ý rằng bạn có thể gửi gói tin tới một nhóm ngay cả khi bạn không phải là thành viên của nhóm đó.</li>
</ul>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-003-uni-any-multi-broadcast.png">
<p>Mô hình multicast có thể được sử dụng để giải quyết các vấn đề giao tiếp nhóm đã nêu ở trên. Ví dụ: tất cả host quan tâm đến việc nhận phát trực tiếp một trận đấu thể thao có thể tham gia vào một <strong>multicast group</strong>. Sau đó, dịch vụ phát trực tiếp có thể gửi gói tin multicast tới toàn bộ nhóm.</p>
<p>Một ví dụ khác: nếu muốn dùng multicast cho mục đích discovery, chúng ta có thể để tất cả máy in trong tòa nhà tham gia vào một multicast group. Khi đó, người dùng có thể gửi gói tin multicast tới toàn nhóm để tìm các máy in mà họ có thể sử dụng.</p>
<h2 id="ip-multicast-và-overlay-multicast-ip-vs-overlay-multicast"><a class="header" href="#ip-multicast-và-overlay-multicast-ip-vs-overlay-multicast"><strong>IP Multicast và Overlay Multicast</strong> (IP vs. Overlay Multicast)</a></h2>
<p>Một cuộc tranh luận lâu dài trong lịch sử multicast là câu hỏi về kiến trúc: <strong>Chúng ta nên triển khai multicast ở tầng nào?</strong></p>
<ul>
<li>
<p>Một lựa chọn là triển khai multicast ở <strong>Layer 3</strong>, đôi khi gọi là <strong>IP multicast</strong>. Trong cách tiếp cận này, chúng ta bổ sung hỗ trợ chuyên biệt cho các router để chúng hiểu cách gửi gói tin multicast. Cách này cho hiệu năng tốt hơn, nhưng khó triển khai hơn.</p>
</li>
<li>
<p>Lựa chọn khác là triển khai multicast ở <strong>Layer 7</strong>, đôi khi gọi là <strong>overlay multicast</strong>. Trong cách tiếp cận này, ứng dụng sẽ xử lý toàn bộ chức năng multicast. Cách này giữ nguyên Layer 3, nên các router chỉ cần hiểu unicast. Cách này cho hiệu năng kém hơn, nhưng dễ triển khai hơn.</p>
</li>
</ul>
<p>Không có lựa chọn nào là tuyệt đối tốt hơn. Chúng ta sẽ nghiên cứu cả hai cách và phân tích các đánh đổi giữa chúng.</p>
<img width="500px" src="beyond-client-server/../assets/beyond-client-server/7-004-multicast-taxonomy.png"><div style="break-before: page; page-break-before: always;"></div><h1 id="ip-multicast"><a class="header" href="#ip-multicast"><strong>IP Multicast</strong></a></h1>
<h2 id="lược-sử-ip-multicast-brief-history-of-ip-multicast"><a class="header" href="#lược-sử-ip-multicast-brief-history-of-ip-multicast"><strong>Lược sử IP Multicast</strong> (Brief History of IP Multicast)</a></h2>
<p><strong>IP multicast</strong> đã được nghiên cứu và phát triển mạnh mẽ trong những năm 1990 và 2000. Động lực phát triển xuất phát từ kỳ vọng rằng ứng dụng “sát thủ” (<strong>killer application</strong>) của Internet sẽ là truyền hình hoặc phát thanh trực tiếp qua mạng. (Thông tin thú vị: Một trong những buổi hòa nhạc được phát trực tiếp sớm nhất là của Rolling Stones vào năm 1994.)</p>
<p>Nhìn lại, các giao thức IP multicast được phát triển trong thập niên 1990 và 2000 có mức độ thành công hỗn hợp về mặt triển khai thực tế. Các <strong>router</strong> hiện đại có hỗ trợ các giao thức IP multicast mà chúng ta sẽ tìm hiểu, nhưng các nhà vận hành mạng không phải lúc nào cũng kích hoạt chúng trên router. (Vô hiệu hóa giao thức trên router đồng nghĩa với việc router đó không hiểu hoặc không hỗ trợ giao thức này.)</p>
<p>Các giao thức IP multicast đôi khi được sử dụng trong phạm vi một miền (ví dụ: bên trong mạng <strong>datacenter</strong>). Tuy nhiên, IP multicast hiếm khi hoặc gần như không bao giờ được triển khai xuyên qua nhiều miền khác nhau. Điều này có nghĩa là người dùng không thể kỳ vọng sử dụng IP multicast ở quy mô toàn cầu, ví dụ: nếu một nhóm người dùng trên khắp thế giới cùng tham gia một <strong>multicast group</strong>, thì Internet hiện đại sẽ không tự động hỗ trợ gửi multicast tới nhóm đó.</p>
<p>Mặc dù các giao thức này không được triển khai toàn cầu, nhưng các kỹ thuật được sử dụng trong chúng có thể áp dụng để giải quyết các vấn đề mạng khác. Đặc biệt, các kỹ thuật này đang trở nên phù hợp trở lại để giải quyết các vấn đề liên quan đến huấn luyện AI (chúng ta sẽ nghiên cứu khi bàn về <strong>collectives</strong>).</p>
<h2 id="mô-hình-dịch-vụ-ip-multicast-ip-multicast-service-model"><a class="header" href="#mô-hình-dịch-vụ-ip-multicast-ip-multicast-service-model"><strong>Mô hình dịch vụ IP Multicast</strong> (IP Multicast Service Model)</a></h2>
<p>Làm thế nào để định nghĩa một nhóm? Mỗi <strong>multicast group</strong> được định nghĩa bởi một địa chỉ IP. Các địa chỉ từ <em>224.0.0.0</em> đến <em>239.255.255.255</em> là địa chỉ multicast, và mọi người đều biết rằng các địa chỉ trong dải cố định này là địa chỉ multicast.</p>
<img width="500px" src="beyond-client-server/../assets/beyond-client-server/7-005-multicast-addresses.png">
<p>Để tham gia một nhóm, bạn sẽ thông báo địa chỉ multicast của nhóm mà bạn muốn tham gia. Ít nhất một router phải nhận được thông báo này (ví dụ: router gia đình của bạn), sau đó các router sẽ phối hợp với nhau để lan truyền thông tin này (ví dụ: thông qua một giao thức định tuyến). Cuối cùng, tất cả các router sẽ biết rằng bạn là thành viên của nhóm đó.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-006-join-message.png">
<p>Tương tự, bạn có thể thông báo rằng mình rời nhóm, và bạn cũng sử dụng địa chỉ multicast để xác định nhóm mà bạn đang đề cập.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-007-leave-message.png">
<p>Để gửi một gói tin tới nhóm, tất cả những gì bạn cần làm là điền địa chỉ multicast của nhóm vào trường <strong>IP destination</strong>. Sau đó, các router sẽ sử dụng địa chỉ nhóm này để chuyển tiếp gói tin tới tất cả các thành viên của nhóm. Lưu ý rằng với tư cách là bên gửi, bạn không cần quan tâm ai thuộc nhóm, vì các router sẽ tự xác định điều đó.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-008-multicast-forwarding.png">
<p>Tóm lại, mô hình dịch vụ IP multicast định nghĩa ba thao tác cho <strong>end host</strong> (máy đầu cuối):</p>
<ul>
<li>Bạn có thể gửi gói tin tới một nhóm (ngay cả khi bạn không phải là thành viên của nhóm đó).</li>
<li>Bạn có thể thông báo rằng mình tham gia một nhóm.</li>
<li>Bạn có thể thông báo rằng mình rời một nhóm.</li>
</ul>
<p>Trong cả ba thao tác, nhiệm vụ của bạn chỉ là gửi gói tin. Các router sẽ xử lý các gói tin này, phối hợp với nhau (ví dụ: chạy một giao thức định tuyến), và quyết định cách định tuyến gói multicast tương ứng.</p>
<p>Bây giờ, khi đã biết cách các host tương tác với IP multicast (gửi, tham gia và rời nhóm), chúng ta có thể nghĩ về cách các router phân phối gói multicast.</p>
<p>Trong mô hình unicast, một router nhận gói tin và chuyển tiếp nó qua một <strong>next-hop</strong> duy nhất. Trong mô hình IP multicast, khi một router nhận gói multicast (tức là đích là địa chỉ multicast group), router sẽ chuyển tiếp gói tin qua 0, 1 hoặc nhiều liên kết đầu ra, để gói tin đến được tất cả các thành viên nhóm.</p>
<p>Để triển khai multicast, router cần một số <strong>state</strong> (trạng thái) bổ sung để theo dõi thành viên nhóm, nhằm chỉ chuyển tiếp gói tin tới các next-hop dẫn tới thành viên nhóm. Nếu một next-hop không dẫn tới thành viên nào, không cần gửi gói tin qua đó. Khi người dùng tham gia hoặc rời nhóm, các next-hop của router cho nhóm đó có thể thay đổi.</p>
<h2 id="triển-khai-multicast-implementing-multicast"><a class="header" href="#triển-khai-multicast-implementing-multicast"><strong>Triển khai Multicast</strong> (Implementing Multicast)</a></h2>
<p>Với mô hình dịch vụ đã được định nghĩa, chúng ta sẵn sàng triển khai IP multicast trên các router. Hãy nhớ mục tiêu cuối cùng: Người dùng tương tác với mạng bằng cách gửi gói tin, thông báo tham gia và rời nhóm. Các router phải lấy thông tin này và sử dụng nó để chuyển tiếp chính xác gói multicast tới tất cả thành viên của nhóm (được xác định bởi địa chỉ multicast).</p>
<p>Chúng ta có thể chia vấn đề này thành hai phần:</p>
<ol>
<li>
<p><strong>Làm thế nào để router biết các nhóm mà các host kết nối trực tiếp thuộc về?</strong> Chúng ta sẽ sử dụng một giao thức gọi là <strong>IGMP (Internet Group Management Protocol)</strong> để giải quyết.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-009-igmp-taxonomy.png">
</li>
<li>
<p><strong>Làm thế nào để router chuyển tiếp gói tin qua mạng để đến các thành viên nhóm đích?</strong> Chúng ta sẽ xem xét hai giao thức để giải quyết: <strong>DVMRP</strong> và <strong>CBT</strong>. Cả hai giao thức đều đạt cùng mục tiêu, vì vậy bạn có thể chọn một trong hai để triển khai (giống như bạn có thể chọn <strong>distance-vector</strong> hoặc <strong>link-state</strong>, nhưng không dùng cả hai).</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-010-dvmrp-cbt-taxonomy.png">
</li>
</ol>
<h2 id="igmp-các-host-kết-nối-trực-tiếp-igmp-directly-connected-hosts"><a class="header" href="#igmp-các-host-kết-nối-trực-tiếp-igmp-directly-connected-hosts"><strong>IGMP: Các host kết nối trực tiếp</strong> (IGMP: Directly-Connected Hosts)</a></h2>
<p>Trước khi giải quyết vấn đề lớn hơn là định tuyến multicast, hãy bắt đầu với một vấn đề nhỏ hơn. Giả sử một router được kết nối trực tiếp với nhiều host. Router cần một cách để biết mỗi host thuộc nhóm nào. Chúng ta sẽ sử dụng giao thức <strong>IGMP</strong> để thực hiện điều này.</p>
<p>Ở mức khái quát, router và các host trao đổi thông điệp để router biết được thành viên nhóm của tất cả host. Một số loại thông điệp có thể được trao đổi:</p>
<ul>
<li><strong>Queries:</strong> Router định kỳ gửi <strong>Query</strong> tới các host. Các thông điệp này hỏi: “Bạn thuộc nhóm nào?”</li>
<li><strong>Reports:</strong> Để trả lời, host gửi <strong>Report</strong> về cho router. Report trả lời câu hỏi: “Đây là (các) nhóm mà tôi thuộc về.” Host cũng có thể gửi <strong>unsolicited Report</strong> (tức là không cần chờ Query).</li>
</ul>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-011-igmp-queries-reports.png">
<p>Bằng cách định kỳ trao đổi Query và Report, router luôn được cập nhật thông tin thành viên nhóm mới nhất. Nếu router không nhận được Report về một thành viên trong thời gian dài, router sẽ giả định rằng thành viên đó đã hết hiệu lực và xóa bỏ.</p>
<p>IGMP giúp router biết về các host kết nối trực tiếp. Tuy nhiên, router vẫn không biết gì về các host ở nơi khác trong mạng, vì vậy chúng ta sẽ cần các thuật toán định tuyến cho phần đó.</p>
<p>So sánh với định tuyến <strong>distance-vector</strong>, bạn có thể coi IGMP như phiên bản multicast của <strong>static routing</strong>, nơi router chỉ biết về các host kết nối trực tiếp (nhưng không biết về các host ở nơi khác trong mạng).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dvmrp"><a class="header" href="#dvmrp">DVMRP</a></h1>
<h2 id="thuật-toán-ngây-thơ-flooding-naive-algorithm-flooding"><a class="header" href="#thuật-toán-ngây-thơ-flooding-naive-algorithm-flooding"><strong>Thuật toán ngây thơ: Flooding</strong> (Naive Algorithm: Flooding)</a></h2>
<p>Hãy nhớ lại mục tiêu của <strong>multicast routing</strong> (định tuyến multicast): Chúng ta có một gói tin mà đích đến là một nhóm, và các <strong>router</strong> cần phối hợp để chuyển tiếp gói tin này tới tất cả các thành viên của nhóm.</p>
<p>Cách triển khai ngây thơ nhất là <strong>flooding</strong> (phát tràn). Khi một router nhận được gói tin, nó đơn giản chuyển tiếp gói tin đó ra tất cả các cổng (trừ cổng nhận vào).</p>
<img width="500px" src="beyond-client-server/../assets/beyond-client-server/7-012-dvmrp-flooding.png">
<p><strong>Tại sao flooding hoạt động?</strong> Nó đảm bảo mọi <strong>host</strong> trên mạng đều nhận được gói tin, bao gồm tất cả các thành viên của nhóm đích.</p>
<p><strong>Điểm tốt của flooding:</strong> Khái niệm đơn giản, không cần chạy bất kỳ giao thức định tuyến nào.</p>
<p><strong>Vấn đề của flooding:</strong> Có hai vấn đề chính, chúng ta sẽ giải quyết từng vấn đề một:</p>
<ol>
<li>Flooding lãng phí băng thông khi gửi cùng một dữ liệu qua nhiều đường, trong khi dữ liệu đó chỉ cần được gửi qua một đường duy nhất.</li>
<li>Flooding lãng phí băng thông khi gửi gói tin tới các nút không phải thành viên.</li>
</ol>
<p>Ngoài ra, các vòng lặp có thể gây ra <strong>broadcast storm</strong> (bão quảng bá) khi cùng một gói tin được chuyển tiếp vô hạn trong vòng lặp, mặc dù điều này có thể được giải quyết bằng cách để router loại bỏ gói tin nếu đã thấy trước đó.</p>
<h2 id="reverse-path-broadcasting-rpb"><a class="header" href="#reverse-path-broadcasting-rpb"><strong>Reverse Path Broadcasting (RPB)</strong></a></h2>
<p>Bây giờ, hãy tập trung vào vấn đề đầu tiên. (Lưu ý: Điều này có nghĩa là hiện tại chúng ta vẫn sẽ gửi gói multicast tới tất cả mọi người, bao gồm cả các nút không phải thành viên. Chúng ta sẽ giải quyết vấn đề này sau.)</p>
<p>Flooding gửi gói tin tới tất cả mọi người, nhưng lãng phí băng thông khi gửi dữ liệu qua các liên kết dư thừa. Ví dụ: nếu có nhiều đường giữa R1 và R4, flooding sẽ khiến các bản sao gói tin đi qua mọi đường từ R1 tới R4. Sau đó, R4 sẽ loại bỏ tất cả các bản sao trùng lặp.</p>
<img width="500px" src="beyond-client-server/../assets/beyond-client-server/7-013-redundant-paths.png">
<p>Lý tưởng nhất, chúng ta muốn gói tin chỉ đi qua <strong>một</strong> đường duy nhất từ R1 tới R4, và tương tự giữa mọi cặp router khác.</p>
<p>Điều này gợi nhớ đến cấu trúc dữ liệu nào? <strong>Tree</strong> (cây) chỉ có một đường duy nhất giữa mọi cặp nút!</p>
<img width="500px" src="beyond-client-server/../assets/beyond-client-server/7-014-single-path.png">
<p>Cụ thể, chúng ta muốn xây dựng một <strong>spanning tree</strong> (cây bao trùm), để mọi người chỉ nhận gói tin qua một đường duy nhất.</p>
<p>Chúng ta có thể xây dựng spanning tree từ đầu, nhưng có thể tận dụng công việc đã làm trước đó. Chúng ta đã thấy spanning tree ở đâu?</p>
<p>Khi chạy <strong>distance-vector routing</strong> cho gói unicast, chúng ta đã xây dựng một spanning tree hướng về đích. Điều này cho phép tất cả gói tin chảy “lên” trong đồ thị mạng, hướng tới một đích duy nhất (gốc của cây).</p>
<img width="500px" src="beyond-client-server/../assets/beyond-client-server/7-015-unicast-trees.png">
<p>Nếu đảo ngược tất cả các mũi tên trong đồ thị này, chúng ta sẽ có một spanning tree phù hợp cho gói multicast. Gốc của cây bây giờ là <strong>sender</strong> (nguồn gửi), và các bản sao gói tin chảy “xuống” trong đồ thị mạng, rời khỏi nguồn và đi qua mạng để đến mọi đích.</p>
<img width="500px" src="beyond-client-server/../assets/beyond-client-server/7-016-multicast-trees.png">
<p>Để tránh nhầm lẫn khi nghĩ về mũi tên đảo ngược, chúng ta sẽ dùng thuật ngữ quen thuộc hơn: Trong cây router, mỗi router có đúng một <strong>parent</strong> (nút cha) và 0 hoặc nhiều <strong>child</strong> (nút con). Router ở “đỉnh” cây là <strong>root</strong> (gốc), và các router ở “đáy” cây không có con được gọi là <strong>leaf</strong> (lá).</p>
<ul>
<li>Trong unicast routing, root là <strong>destination</strong> (đích). Mọi nút nhận gói tin từ con của mình và chuyển tiếp “lên” cho cha, hướng về đích.</li>
<li>Trong multicast routing, root là <strong>source</strong> (nguồn). Mọi nút nhận gói tin từ cha và chuyển tiếp “xuống” cho các con, hướng tới tất cả các đích.</li>
</ul>
<p><strong>Quy tắc chuyển tiếp multicast:</strong> Nếu nhận gói tin từ cha, gửi nó tới tất cả các con. Nếu nhận gói tin từ ai khác (không phải cha), loại bỏ gói tin.</p>
<p>Quy tắc này giúp tránh việc gói tin đi qua nhiều đường. Dù có nhiều đường tới bạn, bạn chỉ nhận gói tin từ cha một lần và chuyển tiếp cho các con. Nếu nhận bản sao từ nút khác (không phải cha), bạn sẽ loại bỏ nó.</p>
<h2 id="rpm-xác-định-cha-và-con-rpm-learning-your-parent-and-children"><a class="header" href="#rpm-xác-định-cha-và-con-rpm-learning-your-parent-and-children"><strong>RPM: Xác định cha và con</strong> (RPM: Learning Your Parent and Children)</a></h2>
<p>Làm thế nào để triển khai quy tắc này? Mỗi router cần biết cha của mình và tất cả các con.</p>
<p><strong>Xác định cha:</strong> Dễ dàng. Cây này giống hệt cây từ distance-vector cho unicast. Trong <strong>unicast forwarding table</strong> (bảng chuyển tiếp unicast), <strong>next-hop</strong> tới root chính là cha của bạn. Bạn có thể tái sử dụng thông tin này.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-017-learning-parents.png">
<p><strong>Xác định con:</strong> Khó hơn một chút. Bảng chuyển tiếp chỉ cho biết cha (next-hop về phía root), nhưng không cho biết con (previous-hop, rời khỏi root).</p>
<p>Vì bạn không biết con của mình, nên các con phải tự thông báo cho bạn. Cụ thể, mọi nút gửi <strong>multicast routing advertisement</strong> (thông báo định tuyến multicast) tới cha của mình: “Tôi là con của bạn (trong cây gốc A).” (Mọi nút biết cha của mình từ bảng chuyển tiếp unicast.)</p>
<img width="600px" src="beyond-client-server/../assets/beyond-client-server/7-018-learning-children.png">
<p>Sau đó, mỗi router nhận các thông báo này và lưu thông tin về các con của mình. Đây là thông tin mới, được thêm riêng cho multicast routing. <strong>Multicast forwarding table</strong> (bảng chuyển tiếp multicast) này tách biệt với bảng chuyển tiếp unicast.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-019-learning-children-tables.png">
<p><strong>Tóm tắt:</strong> Khi nhận gói tin, dùng bảng chuyển tiếp unicast (liệt kê cha) để kiểm tra xem gói tin có đến từ cha không. Nếu có, dùng bảng chuyển tiếp multicast (chứa danh sách con) để gửi cho các con.</p>
<img width="700px" src="beyond-client-server/../assets/beyond-client-server/7-020-rpb-recap.png">
<p><strong>Vai trò của từng bảng:</strong></p>
<ul>
<li><strong>Unicast forwarding table:</strong> Liệt kê cha, dùng để unicast gói tin, kiểm tra gói multicast có từ cha không, và gửi multicast routing advertisement cho cha.</li>
<li><strong>Multicast forwarding table:</strong> Liệt kê con, được xây dựng từ các advertisement nhận từ con, dùng để gửi gói multicast cho tất cả các con.</li>
</ul>
<p><strong>Lưu ý quan trọng:</strong> Trong distance-vector unicast routing, chúng ta xây dựng một spanning tree cho mỗi đích, nên bảng chuyển tiếp unicast có một next-hop cho mỗi đích (một cha cho mỗi cây). Khi đảo mũi tên, chúng ta có một spanning tree cho mỗi nguồn. Bảng chuyển tiếp multicast có danh sách con cho mỗi nguồn. Ví dụ: “Nếu nhận gói tin từ nguồn A, gửi cho các con R6, R7.”</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-021-multiple-rpb-trees-1.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-022-multiple-rpb-trees-2.png">
<h2 id="reverse-path-multicasting-rpm-pruning-cắt-tỉa-trong-định-tuyến-multicast-theo-đường-ngược"><a class="header" href="#reverse-path-multicasting-rpm-pruning-cắt-tỉa-trong-định-tuyến-multicast-theo-đường-ngược"><strong>Reverse Path Multicasting (RPM): Pruning</strong> (Cắt tỉa trong định tuyến multicast theo đường ngược)</a></h2>
<p>Quy tắc <strong>Reverse Path Broadcasting</strong> (RPB) của chúng ta đảm bảo rằng các gói tin di chuyển dọc theo một <strong>spanning tree</strong> (cây bao trùm), bắt đầu từ <strong>source</strong> (nguồn – gốc cây) và đi “xuống” qua mạng tới tất cả các đích. Việc sử dụng cây đã giải quyết vấn đề đầu tiên (gói tin đi theo nhiều đường và lãng phí băng thông).</p>
<p>Tuy nhiên, chúng ta vẫn còn vấn đề thứ hai cần giải quyết. Cho đến nay, các gói tin của chúng ta vẫn đang được <strong>broadcast</strong> (phát quảng bá) tới tất cả mọi người, bao gồm cả các host không thuộc nhóm. Điều này gây lãng phí băng thông.</p>
<p>Để giải quyết, chúng ta sẽ <strong>prune</strong> (cắt tỉa) cây bằng cách loại bỏ các nhánh không có thành viên nhóm.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-023-pruning-end-goal-1.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-024-pruning-end-goal-2.png">
<p>Quá trình cắt tỉa được lan truyền từ các <strong>child</strong> (nút con) lên <strong>parent</strong> (nút cha). Giả sử bạn là R5, và được kết nối trực tiếp với 3 host. Sử dụng <strong>IGMP</strong> (trao đổi thông tin với các host này), bạn biết rằng không host nào thuộc nhóm. Điều này có nghĩa là không có lý do gì để bạn tiếp tục là một phần của cây này.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-025-pruning-igmp.png">
<p>Bạn có thể gửi một <strong>advertisement</strong> (thông báo) tới cha của mình: “Tôi là con của bạn, nhưng không có hậu duệ nào của tôi tham gia nhóm này, vì vậy đừng gửi gói dữ liệu cho tôi.” Cha của bạn sau đó có thể cập nhật <strong>multicast forwarding table</strong> (bảng chuyển tiếp multicast) để loại bạn khỏi danh sách con. Lưu ý rằng thông điệp pruning chỉ được gửi tới cha trực tiếp của bạn (không được chuyển tiếp xa hơn).</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-026-pruning-message-1.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-027-pruning-message-2.png">
<p>Việc cắt tỉa cũng có thể xảy ra ở các mức cao hơn của cây. Xét R3, một router có 2 con. Giả sử cả hai con đều gửi thông báo pruning, nói rằng chúng không tham gia nhóm này. Nếu không con nào của bạn tham gia nhóm, thì bạn cũng không cần tham gia. Do đó, bạn có thể loại mình khỏi cây bằng cách gửi thông báo pruning tới cha, để cha ngừng gửi dữ liệu cho bạn.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-028-pruning-message-3.png">
<p><strong>Lưu ý:</strong> Các router ở mức cao hơn có thể vừa có con là router, vừa có host kết nối trực tiếp. Trong trường hợp này, router chỉ có thể loại mình khỏi cây nếu <strong>tất cả</strong> các con gửi thông báo pruning <strong>và</strong> tất cả các host kết nối trực tiếp không thuộc nhóm.</p>
<img width="700px" src="beyond-client-server/../assets/beyond-client-server/7-029-pruning-children-and-igmp.png">
<p>Việc cắt tỉa làm cho bảng chuyển tiếp multicast phức tạp hơn một chút. Trước đây, mỗi mục ánh xạ một nguồn tới danh sách các con: “Nếu nhận gói tin từ nguồn A, chuyển tiếp tới các con R11, R12.” Tuy nhiên, danh sách con giờ đây còn phụ thuộc vào <strong>destination group</strong> (nhóm đích). Ví dụ: có thể R11 và R2 đều có hậu duệ thuộc nhóm G1, nhưng chỉ R11 có hậu duệ thuộc nhóm G2 (tức là R12 đã gửi thông báo prune cho bạn).</p>
<p>Để xử lý, bảng chuyển tiếp multicast phải có một mục cho mỗi <strong>(source, group)</strong>. Ví dụ: “Nếu nhận gói tin từ nguồn A tới nhóm G1, chuyển tiếp tới các con R11, R12.”</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-030-pruning-multiple-tables-1.png">
<p>Một mục khác: “Nếu nhận gói tin từ nguồn A tới nhóm G2, chuyển tiếp tới con R11.”</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-031-pruning-multiple-tables-2.png">
<p>Một cách khác để hình dung: Trước đây, chúng ta có một cây cho mỗi nguồn, cho thấy nguồn đó gửi gói multicast tới tất cả mọi người. Giờ đây, chúng ta cắt bỏ các nhánh tùy theo nhóm đích. Do đó, chúng ta cần một cây cho mỗi <strong>(source, destination group)</strong>.</p>
<p><strong>Lưu ý cuối:</strong> Có thể hiện tại không con nào của bạn thuộc nhóm, nhưng sau đó một hậu duệ của bạn tham gia nhóm. Để xử lý, mỗi router sẽ định kỳ xóa toàn bộ thông tin pruning, để không ai bị cắt tỉa nữa. Điều này khiến mọi thứ quay lại hành vi RPB ban đầu, nơi bạn luôn chuyển tiếp cho tất cả các con.</p>
<p>Bằng cách này, nếu một hậu duệ của bạn tham gia nhóm, thì sau khi bộ đếm thời gian hết hạn, bạn sẽ không còn bị cắt tỉa và sẽ tham gia lại cây. Ngược lại, nếu vẫn không có hậu duệ nào thuộc nhóm, bạn chỉ cần gửi lại thông báo pruning cho cha để được loại khỏi cây.</p>
<h2 id="tóm-tắt-các-quy-tắc-dvmrp-summary-of-dvmrp-rules"><a class="header" href="#tóm-tắt-các-quy-tắc-dvmrp-summary-of-dvmrp-rules"><strong>Tóm tắt các quy tắc DVMRP</strong> (Summary of DVMRP Rules)</a></h2>
<p><strong>Quy tắc định tuyến (Routing Rules):</strong></p>
<p>Với mỗi spanning tree của một nguồn, bạn cần biết cha và các con của mình.</p>
<ol>
<li><strong>Xác định cha:</strong> Không cần hành động gì. Bảng chuyển tiếp unicast của bạn đã xác định cha.</li>
<li><strong>Xác định con:</strong> Mọi nút gửi advertisement tới cha. Khi nhận được advertisement, bạn biết ai là con của mình.</li>
</ol>
<p><strong>Quy tắc chuyển tiếp (Forwarding Rules):</strong></p>
<ol>
<li>Khi nhận gói tin, dùng bảng chuyển tiếp unicast cho nguồn đó để kiểm tra xem gói tin có đến từ cha không.</li>
<li>Nếu gói tin đến từ cha, dùng bảng chuyển tiếp multicast để gửi cho các con. Chỉ gửi cho các con <strong>không bị cắt tỉa</strong> đối với nhóm đích.</li>
<li>Nếu gói tin không đến từ cha, loại bỏ gói tin.</li>
</ol>
<p><strong>Quy tắc cắt tỉa (Pruning Rules):</strong></p>
<p>Với mỗi cặp <strong>(destination group, source)</strong>:</p>
<ol>
<li>Nếu nhận thông báo pruning từ một con, loại con đó khỏi mục bảng chuyển tiếp multicast cho nhóm đích này.</li>
<li>Nếu không hậu duệ nào (host kết nối trực tiếp hoặc con) thuộc nhóm, gửi thông báo pruning cho cha.</li>
<li>Định kỳ xóa toàn bộ thông tin pruning (quay lại chuyển tiếp cho tất cả các con).</li>
</ol>
<h2 id="Ưu-và-nhược-điểm-của-dvmrp-dvmrp-pros-and-cons"><a class="header" href="#Ưu-và-nhược-điểm-của-dvmrp-dvmrp-pros-and-cons"><strong>Ưu và nhược điểm của DVMRP</strong> (DVMRP Pros and Cons)</a></h2>
<p><strong>Nhược điểm:</strong></p>
<ul>
<li>Thông tin pruning được xóa định kỳ. Khi điều này xảy ra, gói tin lại được broadcast tới tất cả mọi người cho đến khi quá trình pruning hội tụ lại (nhớ rằng không có pruning thì gói tin được gửi tới tất cả).</li>
<li>Bảng chuyển tiếp mở rộng kém: cần một mục cho mỗi <strong>(source, destination group)</strong>.</li>
</ul>
<p><strong>Ưu điểm:</strong></p>
<ul>
<li><strong>DVMRP</strong> là một phần mở rộng đơn giản, tinh gọn của giao thức định tuyến hiện có (<strong>distance-vector</strong>). Chúng ta có thể tái sử dụng bảng chuyển tiếp unicast để triển khai DVMRP. Ví dụ: không cần suy nghĩ nhiều về cách xác định cha vì đã có sẵn.</li>
<li>Vì tái sử dụng cây phân phối từ giao thức distance-vector, các cây này cũng là <strong>least-cost tree</strong> (cây chi phí thấp nhất). Nói cách khác, chúng cung cấp đường tốt nhất từ nguồn tới tất cả thành viên nhóm. Đây là lý do tại sao ta nói IP multicast là tối ưu: DVMRP đạt hiệu năng tốt nhất xét theo chi phí trong topology mạng.</li>
</ul>
<p><strong>Hạn chế:</strong> Việc gắn kết multicast và unicast routing khiến việc chuyển đổi giao thức khó hơn. Ví dụ: nếu chuyển giao thức unicast từ distance-vector sang <strong>link-state</strong>, chúng ta cũng phải thiết kế lại giao thức multicast.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="core-based-trees-cbt--cây-dựa-trên-lõi"><a class="header" href="#core-based-trees-cbt--cây-dựa-trên-lõi"><strong>Core-Based Trees (CBT)</strong> – Cây dựa trên lõi</a></h1>
<h2 id="Định-nghĩa-cbt-cbt-definition"><a class="header" href="#Định-nghĩa-cbt-cbt-definition"><strong>Định nghĩa CBT (CBT Definition)</strong></a></h2>
<p>Mục tiêu của <strong>multicast routing</strong> (định tuyến quảng bá nhóm) vẫn giống như trước: Chúng ta có một gói tin mà đích đến là một nhóm, và các <strong>router</strong> (bộ định tuyến) cần phối hợp để chuyển tiếp gói tin này tới tất cả các thành viên của nhóm.</p>
<p>Tuy nhiên, bây giờ chúng ta sẽ thử một cách tiếp cận khác, hoàn toàn khác với <strong>DVMRP (Distance Vector Multicast Routing Protocol)</strong>.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-032-cbt-taxonomy.png">
<p>Trong phương pháp <strong>Core-Based Tree (CBT)</strong>, mỗi nhóm đích sẽ có một cây riêng. CBT cho một nhóm đích đơn giản là một cây kết nối tới mọi thành viên của nhóm đó.</p>
<img width="600px" src="beyond-client-server/../assets/beyond-client-server/7-033-cbt-end-goal.png">
<p>Có thể gây nhầm lẫn khi nghĩ về cây CBT và cây DVMRP cùng lúc. Tạm thời, bạn có thể coi chúng là hai loại cây hoàn toàn khác nhau, không có điểm chung.</p>
<h2 id="xây-dựng-cbt-building-cbts"><a class="header" href="#xây-dựng-cbt-building-cbts"><strong>Xây dựng CBT (Building CBTs)</strong></a></h2>
<p>Để xây dựng một <strong>core-based tree</strong>, cây cần một gốc, gọi là <strong>core</strong> (lõi). Core là một router bất kỳ trong mạng, được chọn trước.</p>
<p>Bây giờ, chúng ta sẽ xây dựng một cây kết nối tới mọi thành viên của nhóm, với core là gốc.</p>
<p>Nếu một thành viên muốn tham gia nhóm, thành viên đó sẽ <strong>unicast</strong> (gửi đơn hướng) một thông điệp <strong>join</strong> (tham gia) tới core. Gói tin này sẽ đi qua nhiều router để tới core. Tất cả các router trên đường đi này cũng sẽ tham gia vào cây, để cây có đường từ core tới thành viên mới.</p>
<img width="800px" src="beyond-client-server/../assets/beyond-client-server/7-034-cbt-join-1.png">
<img width="600px" src="beyond-client-server/../assets/beyond-client-server/7-035-cbt-join-2.png">
<p>Cụ thể hơn, nếu bạn là một router và nhận được thông điệp join cho một nhóm cụ thể, bạn biết rằng mình hiện là một phần của cây nhóm đó. <strong>Incoming link</strong> (liên kết đầu vào) của thông điệp join là <strong>child</strong> (nhánh con) của bạn – liên kết hướng ra xa gốc. <strong>Outgoing link</strong> (liên kết đầu ra – bước nhảy tiếp theo tới gốc) là <strong>parent</strong> (nhánh cha) của bạn – liên kết hướng về gốc. Bạn có thể ghi lại thông tin về parent và các child của mình để nhớ vị trí của mình trong cây. Không có một thực thể trung tâm nào ghi nhớ toàn bộ cây; mỗi router trên cây tự chịu trách nhiệm ghi nhớ parent và child của mình.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-036-cbt-join-recap.png">
<p>Nếu một thành viên muốn rời nhóm, thành viên đó có thể unicast một thông điệp <strong>quit</strong> (rời nhóm) tới <strong>parent</strong> trực tiếp của mình trên cây. Nếu tất cả các child của bạn trên cây đã gửi thông điệp quit, điều đó có nghĩa là bạn cũng có thể rời cây, và gửi thông điệp quit tới parent trực tiếp của mình. Thông điệp quit chỉ được gửi tới parent trực tiếp và không được chuyển tiếp xa hơn.</p>
<img width="700px" src="beyond-client-server/../assets/beyond-client-server/7-037-cbt-leave-1.png">
<img width="600px" src="beyond-client-server/../assets/beyond-client-server/7-038-cbt-leave-2.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-039-cbt-quit-recap.png">
<p>Hãy nhớ rằng chúng ta xây dựng <strong>một cây cho mỗi nhóm</strong>. Điều này có nghĩa là các router phải ghi nhớ parent và child của mình cho từng cây mà chúng tham gia. Đồng thời, các thông điệp join và leave phải gắn với nhóm cụ thể, ví dụ: “Tôi muốn tham gia nhóm G2.”</p>
<img width="600px" src="beyond-client-server/../assets/beyond-client-server/7-040-multiple-1.png">
<img width="600px" src="beyond-client-server/../assets/beyond-client-server/7-041-multiple-2.png">
<p><strong>Một số lưu ý về core</strong> (không phải là trực giác chính của giao thức):</p>
<ul>
<li>Vì core là một router, nó có địa chỉ IP unicast, và mọi người đều có thể gửi gói tin unicast tới core.</li>
<li>Chúng ta xây dựng một cây cho mỗi nhóm. Các nhóm khác nhau có thể dùng các core khác nhau.</li>
<li>Giả định rằng mọi người đều biết ánh xạ từ nhóm tới core, ví dụ: “Nhóm G1 dùng R2 làm core.” Ánh xạ này có thể được công bố qua một cơ chế như DNS (nhớ rằng DNS hữu ích để phân phối các cặp khóa–giá trị).</li>
<li>Core không phải là thành viên nhóm. Trong mô hình này, chúng ta giả định rằng host có thể tham gia/rời nhóm, không phải router. Core là router, nên nó không tham gia nhóm multicast.</li>
</ul>
<p><strong>Một số lưu ý về thông điệp join và quit</strong>:</p>
<ul>
<li>Thông điệp join và quit về mặt kỹ thuật được gửi bởi <strong>first-hop router</strong> (router đầu tiên). Router này dùng <strong>IGMP (Internet Group Management Protocol)</strong> để phát hiện một host kết nối trực tiếp đã tham gia hoặc rời nhóm, và first-hop router sẽ gửi thông điệp join hoặc quit.</li>
<li>Thực tế, một thông điệp <strong>JOIN-ACK</strong> được gửi để phản hồi join, và router ghi lại parent/child khi JOIN-ACK được gửi. Tương tự, một thông điệp <strong>QUIT-ACK</strong> được gửi để phản hồi quit. Trong phạm vi bài học này, chúng ta sẽ bỏ qua chi tiết này.</li>
</ul>
<h2 id="sử-dụng-cbt-using-cbts"><a class="header" href="#sử-dụng-cbt-using-cbts"><strong>Sử dụng CBT (Using CBTs)</strong></a></h2>
<p>Sau khi đã xây dựng CBT cho một nhóm, làm thế nào để sử dụng nó để gửi thông điệp tới nhóm đó?</p>
<p><strong>Trường hợp 1:</strong> Nếu bạn là thành viên nhóm, nghĩa là bạn đã nằm trên cây. Do đó, bạn chỉ cần <strong>broadcast</strong> (phát quảng bá) thông điệp tới tất cả mọi người trên cây.</p>
<p>Cụ thể hơn, bạn bắt đầu bằng cách chuyển tiếp gói tin tới parent của mình trên cây. Sau đó, mỗi router trên cây nhận gói tin và <strong>flood</strong> (lan truyền) gói tin tới tất cả các liên kết cây của nó (cả liên kết parent và child).</p>
<img width="700px" src="beyond-client-server/../assets/beyond-client-server/7-042-cbt-forwarding-1.png">
<p><strong>Trường hợp 2:</strong> Nếu bạn không phải là thành viên nhóm, bạn không nằm trên cây, nên chiến lược ở Trường hợp 1 sẽ không hiệu quả. Thay vào đó, bạn có thể unicast gói tin tới core. Sau đó, core sẽ broadcast thông điệp tới tất cả mọi người trên cây.</p>
<p>Cụ thể hơn, khi bạn unicast gói tin tới core, bạn cần <strong>encapsulate</strong> (đóng gói) gói tin. <strong>Outer header</strong> (tiêu đề ngoài) chứa thông tin unicast để tới core. <strong>Inner header</strong> (tiêu đề trong) chứa thông tin multicast.</p>
<p>Khi core nhận gói tin, nó gỡ bỏ outer header và thấy gói tin multicast bên trong. Core sau đó có thể broadcast gói tin này dọc theo cây. Giống như Trường hợp 1, mỗi router trên cây nhận gói tin và flood gói tin tới tất cả các liên kết cây của nó (cả parent và child).</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-043-cbt-forwarding-2.png">
<h2 id="lợi-ích-khả-năng-mở-rộng-tốt-hơn-benefit-better-scaling"><a class="header" href="#lợi-ích-khả-năng-mở-rộng-tốt-hơn-benefit-better-scaling"><strong>Lợi ích: Khả năng mở rộng tốt hơn</strong> (Benefit: Better Scaling)</a></h2>
<p>Hãy nhớ rằng DVMRP mở rộng kém vì các router phải duy trì một cây cho mỗi <strong>source</strong> (nguồn) và mỗi nhóm đích. Mỗi cây thể hiện đường đi ngắn nhất từ một nguồn tới tất cả thành viên của một nhóm đích.</p>
<p>Trong phương pháp CBT, CBT cho một nhóm đích đơn giản là một cây kết nối tới mọi thành viên của nhóm đó.</p>
<p>Lưu ý rằng CBT giống nhau cho tất cả các nguồn. Không giống DVMRP (một cây cho mỗi nguồn và mỗi nhóm đích), giờ đây chúng ta chỉ cần một cây cho mỗi nhóm đích.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-044-dvmrp-cbt-scaling.png">
<p>Việc so sánh cây DVMRP và cây CBT giúp thấy rõ khả năng mở rộng của các giao thức, nhưng ngoài điều đó, các cây trong mỗi giao thức có ý nghĩa hoàn toàn khác nhau. Nếu bạn thấy khó hiểu, hãy coi chúng như hai khái niệm hoàn toàn tách biệt.</p>
<p>Hãy nhớ rằng một vấn đề khác về khả năng mở rộng của DVMRP là trạng thái <strong>pruning</strong> (cắt tỉa) được xóa định kỳ, và khi điều đó xảy ra, gói tin sẽ được broadcast tới tất cả mọi người trên mạng (bao gồm cả các thiết bị không thuộc nhóm). CBT cũng giải quyết vấn đề này, vì chẳng có lý do gì để sử dụng CBT khi gói tin phải được phát sóng đến tất cả các thiết bị. Tree cho biết vị trí của các thành viên trong nhóm, do đó đảm bảo rằng các thiết bị không thuộc nhóm sẽ không bao giờ nhận được gói tin.</p>
<h2 id="phân-tích-hiệu-suất-efficiency-analysis"><a class="header" href="#phân-tích-hiệu-suất-efficiency-analysis"><strong>Phân tích hiệu suất</strong> (Efficiency Analysis)</a></h2>
<p>Hãy nhớ rằng <strong>DVMRP (Distance Vector Multicast Routing Protocol)</strong> xây dựng các cây <strong>least-cost</strong> (chi phí thấp nhất) từ <strong>sender</strong> (nguồn gửi) tới tất cả các thành viên của nhóm. Bằng cách chuyển tiếp các gói tin dọc theo các cây này, chúng ta đảm bảo rằng các gói tin sẽ được chuyển tiếp theo các đường đi có chi phí thấp nhất tới tất cả các thành viên nhóm.</p>
<p>Ngược lại, các cây <strong>CBT (Core-Based Tree)</strong> không liên quan đến sender, vì vậy không còn đảm bảo tính tối ưu. Các đường đi từ sender tới tất cả các thành viên nhóm không nhất thiết là các đường đi có chi phí thấp nhất.</p>
<p>CBT đánh đổi giữa khả năng mở rộng (<strong>scalability</strong>) và hiệu suất (<strong>efficiency</strong>). CBT có khả năng mở rộng tốt hơn vì cần xây dựng ít cây hơn (tức là các router lưu trữ ít trạng thái hơn), nhưng đổi lại, các gói tin có thể được chuyển tiếp theo các đường đi không tối ưu.</p>
<p>Hiệu suất của CBT phụ thuộc rất nhiều vào việc router nào được chọn làm <strong>core</strong>. Ví dụ, hãy xem xét cấu trúc mạng dưới đây với các lựa chọn core khác nhau.</p>
<img width="700px" src="beyond-client-server/../assets/beyond-client-server/7-045-core-choice-1.png">
<img width="700px" src="beyond-client-server/../assets/beyond-client-server/7-046-core-choice-2.png">
<img width="700px" src="beyond-client-server/../assets/beyond-client-server/7-047-core-choice-3.png">
<p>Trong mọi lựa chọn core, luôn có ít nhất một cặp router được kết nối bằng một đường đi không tối ưu. Chúng ta không còn có một cây đường đi ngắn nhất được đảm bảo từ một nguồn tới tất cả các thành viên nhóm.</p>
<p>Ví dụ, nếu A dự định gửi nhiều gói tin tới nhóm, R2 có thể là một lựa chọn core tốt, vì nó tình cờ kết nối A với B và C theo các đường đi ngắn nhất. Tuy nhiên, nếu B muốn gửi gói tin tới nhóm, các gói tin sẽ phải đi theo một đường không tối ưu tới C.</p>
<p>Việc tìm core tối ưu là không khả thi, đặc biệt vì các thành viên có thể tham gia hoặc rời nhóm bất kỳ lúc nào. Trên thực tế, các nhà vận hành thường chọn core thủ công.</p>
<h2 id="các-ưu-và-nhược-điểm-khác-của-cbt-other-cbt-pros-and-cons"><a class="header" href="#các-ưu-và-nhược-điểm-khác-của-cbt-other-cbt-pros-and-cons"><strong>Các ưu và nhược điểm khác của CBT</strong> (Other CBT Pros and Cons)</a></h2>
<p>CBT tạo ra một <strong>single point of failure</strong> (điểm lỗi đơn) tại gốc. Để bổ sung khả năng chịu lỗi (<strong>fault-tolerance</strong>), chúng ta cần cây có nhiều core. Điều này có thể thực hiện được, nhưng sẽ làm tăng độ phức tạp. Chúng ta sẽ không bàn sâu về cây đa-core, nhưng bạn có thể tham khảo bài báo liên kết bên dưới nếu quan tâm.</p>
<p>Hãy nhớ rằng DVMRP được xây dựng như một phần mở rộng của <strong>distance-vector</strong>, dẫn đến việc giao thức multicast (DVMRP) và giao thức unicast (distance-vector) bị ràng buộc chặt chẽ. Thay đổi một giao thức sẽ yêu cầu cập nhật cả giao thức còn lại. Ngược lại, CBT được tách rời (<strong>decoupled</strong>) khỏi giao thức định tuyến unicast. CBT có sử dụng bảng chuyển tiếp unicast (ví dụ: để chuyển tiếp thông điệp join tới gốc), nhưng không quan trọng các bảng này được tạo ra bằng cách nào (distance-vector, link-state, cấu hình cố định, v.v.). Do đó, CBT không phụ thuộc vào bất kỳ giao thức unicast cụ thể nào và có thể hoạt động với mọi giao thức unicast.</p>
<p>Tài liệu tham khảo thêm về CBT: <a href="https://people.eecs.berkeley.edu/%7Esylvia/cs268-2019/papers/cbt.pdf">https://people.eecs.berkeley.edu/~sylvia/cs268-2019/papers/cbt.pdf</a></p>
<p><strong>DVMRP hay CBT tốt hơn?</strong> Như chúng ta đã thấy, có những sự đánh đổi giữa hai giao thức này.</p>
<ul>
<li>
<p>Nếu bạn có <strong>một nguồn</strong> gửi dữ liệu tới <strong>một nhóm lớn</strong>, thì DVMRP có thể là giải pháp tốt hơn, vì nó đảm bảo tất cả dữ liệu này đi theo các đường tối ưu trong mạng. Khi lượng dữ liệu gửi lớn (tới nhiều thành viên nhóm), việc sử dụng đường tối ưu sẽ tiết kiệm đáng kể băng thông. Ngoài ra, nếu nhóm lớn (ví dụ: bao gồm hầu hết mọi người trong mạng), thì việc DVMRP thỉnh thoảng <strong>flooding</strong> (phát tràn) cũng không phải là vấn đề lớn.</p>
</li>
<li>
<p>Ngược lại, nếu bạn có <strong>một nhóm nhỏ</strong> với các thành viên phân tán trên một mạng lớn, thì CBT có thể là giải pháp tốt hơn. CBT sẽ tránh việc flooding gói tin tới các nút không phải thành viên, điều này sẽ lãng phí nhiều băng thông (vì hầu hết các nút không thuộc nhóm).</p>
</li>
</ul>
<p>Trên thực tế, cả DVMRP và CBT đều đang được sử dụng ngày nay. DVMRP đôi khi được gọi là <strong>PIM-DM (Protocol Independent Multicast – Dense Mode)</strong>, phản ánh việc DVMRP phù hợp cho các nhóm lớn. CBT đôi khi được gọi là <strong>PIM-SM (Protocol Independent Multicast – Sparse Mode)</strong>, phản ánh việc CBT phù hợp cho các nhóm nhỏ hơn.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="thách-thức-của-ip-multicast-ip-multicast-challenges"><a class="header" href="#thách-thức-của-ip-multicast-ip-multicast-challenges"><strong>Thách thức của IP Multicast</strong> (IP Multicast Challenges)</a></h1>
<h2 id="Định-tuyến-liên-miền-inter-domain-routing"><a class="header" href="#Định-tuyến-liên-miền-inter-domain-routing"><strong>Định tuyến liên miền</strong> (Inter-Domain Routing)</a></h2>
<p>Các giao thức mà chúng ta đã mô tả trước đây (<strong>IGMP</strong>, <strong>DVMRP</strong>, <strong>CBT</strong>) có thể được sử dụng cho <strong>intra-domain multicast routing</strong> (định tuyến multicast trong nội miền). Tuy nhiên, chúng không thể dễ dàng mở rộng để hỗ trợ <strong>inter-domain multicast routing</strong> (định tuyến multicast liên miền).</p>
<p>Một vấn đề lớn ở đây là <strong>scalability</strong> (khả năng mở rộng). Ví dụ: nếu chúng ta sử dụng DVMRP ở quy mô toàn cầu, thì định kỳ, khi trạng thái <strong>pruning</strong> (cắt tỉa) bị xóa, các gói tin sẽ bị <strong>flood</strong> (phát tràn) ra toàn bộ Internet, điều này là không khả thi.</p>
<p>Ngoài ra, hãy nhớ rằng định tuyến liên miền còn có thách thức về <strong>AS autonomy</strong> (tính tự chủ của hệ thống tự trị) và <strong>privacy</strong> (quyền riêng tư). Ví dụ: nếu chúng ta sử dụng CBT ở quy mô toàn cầu, thì <strong>core router</strong> (bộ định tuyến lõi) có thể nằm trong một mạng khác, và điều này yêu cầu bạn phải tin tưởng người khác kiểm soát core router đó.</p>
<p>Định tuyến multicast liên miền là một vấn đề khó, và đã có nhiều nghiên cứu để phát triển giải pháp. Ví dụ: vấn đề chọn core trong CBT có thể được giải quyết bằng cách có nhiều core (mỗi mạng một core) và các core này giao tiếp với nhau. Tuy nhiên, trên thực tế, việc triển khai multicast liên miền rất ít được áp dụng.</p>
<h2 id="tính-phí-charging"><a class="header" href="#tính-phí-charging"><strong>Tính phí</strong> (Charging)</a></h2>
<p>Mô hình dịch vụ <strong>IP multicast</strong> về cơ bản mâu thuẫn với mô hình kinh doanh mà các <strong>ISP</strong> hiện đại sử dụng. Ví dụ: xét đồ thị AS dưới đây, trong đó AS A và AS B là <strong>peers</strong> (ngang hàng):</p>
<img width="400px" src="beyond-client-server/../assets/beyond-client-server/7-048-multicast-charging-1.png">
<p>Là peers, AS A và AS B nên trao đổi một lượng lưu lượng tương đương, nhưng multicast khiến việc định nghĩa “lưu lượng tương đương” trở nên khó khăn. Ví dụ: giả sử AS A gửi một gói multicast tới AS B. Có thể AS B có nhiều <strong>children</strong> (nút con) là thành viên của nhóm. Điều này có nghĩa là AS B nhận một gói, nhưng phải gửi ra nhiều gói. AS B đã sử dụng nhiều băng thông hơn AS A. Liệu AS A có cần trả thêm phí cho AS B vì điều này không? (Đây là một câu hỏi mở, chưa có câu trả lời rõ ràng.)</p>
<p>Ví dụ khác: xét đồ thị AS dưới đây, trong đó AS A là <strong>provider</strong> (nhà cung cấp) và AS B là <strong>customer</strong> (khách hàng):</p>
<img width="200px" src="beyond-client-server/../assets/beyond-client-server/7-049-multicast-charging-2.png">
<p>AS B trả tiền cho AS A để sử dụng dịch vụ. Nếu AS B gửi một gói multicast, và AS A phải chuyển tiếp nhiều bản sao của gói đó tới nhiều đích khác nhau, thì AS A có nên tính phí cao hơn so với một gói unicast không? Nếu có, thì nên tính thêm bao nhiêu? (Cũng là một câu hỏi mở, chưa có câu trả lời rõ ràng.)</p>
<p>Việc thiết kế mô hình kinh doanh trở nên khó khăn hơn bởi vì mô hình IP multicast không theo dõi rõ ràng kích thước nhóm. Nếu muốn tính phí dựa trên kích thước nhóm đích, thì không có cách rõ ràng nào để xác định kích thước của một nhóm đích bất kỳ. <strong>Forwarding table</strong> (bảng chuyển tiếp) chỉ cho bạn biết về <strong>parent</strong> và <strong>children</strong> của bạn trên các cây phân phối khác nhau, nhưng không cho biết tổng số <strong>end host</strong> sẽ nhận gói tin này.</p>
<h2 id="kiểm-soát-tắc-nghẽn-congestion-control"><a class="header" href="#kiểm-soát-tắc-nghẽn-congestion-control"><strong>Kiểm soát tắc nghẽn</strong> (Congestion Control)</a></h2>
<p>Xét một nguồn gửi gói multicast xuống <strong>delivery tree</strong> (cây phân phối) tới nhiều người nhận. Nguồn cần chọn một tốc độ gửi hợp lý để tránh quá tải mạng. Vậy tốc độ nào là phù hợp?</p>
<img width="800px" src="beyond-client-server/../assets/beyond-client-server/7-050-multicast-congestion.png">
<p>Lưu lượng sẽ đi qua nhiều đường khác nhau, và mỗi đường có thể có dung lượng khác nhau. Nguồn có thể gửi ở tốc độ 1 Mbps để tránh quá tải bất kỳ liên kết nào, nhưng điều này để lại dung lượng chưa sử dụng ở các đường khác. Ngược lại, nguồn có thể gửi ở tốc độ 100 Mbps để tối đa hóa hiệu năng, nhưng điều này sẽ làm một số liên kết bị quá tải. Không có câu trả lời rõ ràng cho tốc độ tối ưu.</p>
<p>Trên thực tế, một giải pháp khả thi là định nghĩa các nhóm khác nhau tùy theo hiệu năng. Ví dụ: chúng ta có thể định nghĩa bốn nhóm multicast khác nhau, mỗi nhóm nhận cùng một luồng video nhưng với chất lượng khác nhau. Khi đó, người nhận có thể thử tham gia các nhóm khác nhau để xem nhóm nào cho hiệu năng tốt nhất.</p>
<h2 id="Độ-tin-cậy-reliability"><a class="header" href="#Độ-tin-cậy-reliability"><strong>Độ tin cậy</strong> (Reliability)</a></h2>
<p>Giống như <strong>IP unicast</strong>, IP multicast là <strong>best-effort</strong> (nỗ lực tối đa nhưng không đảm bảo), điều này làm tăng độ phức tạp. Ví dụ: bạn có thể gửi một gói tin, và nó có thể đến một số, nhưng không phải tất cả, thành viên nhóm.</p>
<p>Chúng ta có thể thử thêm <strong>ack</strong> (xác nhận) để giải quyết, nhưng điều này cũng có vấn đề. Nếu nhóm có hàng triệu thành viên, một nguồn gửi sẽ không thể xử lý hàng triệu ack cho mỗi gói tin.</p>
<p>Một cách tiếp cận khác là sử dụng <strong>negative acknowledgement</strong> (<strong>nack</strong>), trong đó một thành viên nhóm không gửi gì nếu nhận được gói, và gửi nack nếu không nhận được (ví dụ: khi bộ đếm thời gian hết hạn). Tuy nhiên, nếu nhóm có hàng triệu thành viên, nguồn gửi có thể bị quá tải.</p>
<p>Trong cách tiếp cận nack, cũng không rõ cách khôi phục sau lỗi. Nếu ai đó không nhận được gói, chúng ta có nên multicast lại gói đó cho toàn nhóm không? Điều này lãng phí băng thông vì một số thành viên đã nhận được và sẽ nhận bản sao trùng lặp.</p>
<p>Một cách khác là unicast gói tin chỉ tới những thành viên gửi nack. Nếu nhiều thành viên không nhận được gói, điều này cũng lãng phí vì phải unicast nhiều bản sao của cùng một gói. Ví dụ: nếu liên kết đầu tiên làm rơi gói, nghĩa là <strong>không thành viên nào</strong> nhận được gói.</p>
<p>Cách truyền lại nào tốt hơn? Không rõ ràng, và còn phụ thuộc vào số lượng thành viên nhận được gói.</p>
<p>Trên thực tế, một số ứng dụng IP multicast hiện đại không triển khai độ tin cậy. Hoặc, họ triển khai bằng cách mã hóa thêm <strong>redundancy</strong> (dữ liệu dự phòng) vào luồng dữ liệu (ví dụ: <strong>error-correcting codes</strong> – mã sửa lỗi) để các lỗi và mất mát có thể được khôi phục từ chính dữ liệu, không cần sự hỗ trợ của mạng.</p>
<p>Việc mã hóa dự phòng đồng nghĩa với việc cần nhiều bit hơn để mã hóa cùng một lượng dữ liệu. Ví dụ: nếu muốn gửi dữ liệu tương đương 5 gói, bạn có thể gửi 10 gói, và mã hóa sao cho bất kỳ 5 gói nào cũng có thể khôi phục dữ liệu gốc.</p>
<h2 id="bảo-mật-security"><a class="header" href="#bảo-mật-security"><strong>Bảo mật</strong> (Security)</a></h2>
<p>Một hạn chế khác của IP multicast là thiếu <strong>access control</strong> (kiểm soát truy cập). Bất kỳ ai cũng có thể tham gia một nhóm, và bất kỳ ai cũng có thể gửi thông điệp tới bất kỳ nhóm nào. Nếu muốn áp dụng kiểm soát truy cập (ví dụ: chỉ người dùng trả phí mới được xem trận đấu), bạn phải xây dựng chức năng này riêng.</p>
<p>Việc thiếu kiểm soát truy cập dẫn đến các lỗ hổng bảo mật. Một kẻ tấn công có thể flood gói tin tới một nhóm multicast cụ thể, khiến tất cả thành viên nhóm bị quá tải. Lưu ý rằng điều này hiệu quả hơn so với unicast, nơi kẻ tấn công phải flood gói tin tới từng thành viên riêng lẻ.</p>
<p>Các biện pháp bảo mật bổ sung như <strong>encryption</strong> (mã hóa) cũng khó triển khai. Giả sử bạn mã hóa thông điệp multicast bằng cách cung cấp cho mỗi thành viên nhóm một <strong>shared secret key</strong> (khóa bí mật chung). Nếu ai đó rời nhóm, nhưng bạn vẫn dùng cùng khóa, người đó vẫn có thể đọc thông điệp. Một cách là chuyển sang dùng khóa mới, nhưng khi đó bạn cần một cách để phân phối khóa mới này một cách an toàn tới các thành viên còn lại.</p>
<h2 id="ip-multicast-trong-thực-tế-ip-multicast-in-practice"><a class="header" href="#ip-multicast-trong-thực-tế-ip-multicast-in-practice"><strong>IP Multicast trong thực tế</strong> (IP Multicast in Practice)</a></h2>
<p>Vì tất cả những thách thức trên, IP multicast ngày nay chủ yếu được sử dụng trong phạm vi một miền duy nhất, chứ không phải trong đủ các tên miền khác nhau.</p>
<p>Một số ứng dụng vẫn có thể cần giao tiếp nhóm qua nhiều mạng (ví dụ: trò chơi đa người chơi, hội nghị truyền hình). Thay vì dựa vào IP multicasting, vốn không hỗ trợ giao tiếp giữa các mạng, nhiều ứng dụng đã triển khai các giải pháp tùy chỉnh riêng cho giao tiếp nhóm.</p>
<p>Ví dụ, nếu nhóm đủ nhỏ, ứng dụng có thể triển khai một máy chủ trung gian. Giao tiếp nhóm được truyền unicast đến máy chủ trung gian, sau đó máy chủ này truyền tin nhắn unicast đến các thành viên khác trong nhóm.</p>
<p>Hoặc, nếu nhóm đủ nhỏ, giải pháp unicast đơn giản (gửi các gói tin unicast riêng lẻ đến từng thành viên trong nhóm) có thể hoạt động tốt.</p>
<p>Nếu IP multicast không hoạt động giữa các miền và các giải pháp tùy chỉnh yêu cầu công sức thêm để triển khai và mở rộng quy mô, các ứng dụng hiện đại xử lý giao tiếp nhóm như thế nào? Một giải pháp là sử dụng overlay multicast, một giải pháp thay thế cho IP multicast thực hiện chức năng mạng ở Lớp 7 thay vì Lớp 3. Chúng ta sẽ tìm hiểu về overlay multicast trong phần tiếp theo.</p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><h1 id="collective-operations-các-thao-tác-tập-thể"><a class="header" href="#collective-operations-các-thao-tác-tập-thể"><strong>Collective Operations</strong> (Các thao tác tập thể)</a></h1>
<h2 id="Động-lực-ai-training-huấn-luyện-trí-tuệ-nhân-tạo"><a class="header" href="#Động-lực-ai-training-huấn-luyện-trí-tuệ-nhân-tạo"><strong>Động lực: AI Training</strong> (Huấn luyện trí tuệ nhân tạo)</a></h2>
<p>Như bạn có thể đã đọc trên các bản tin, <strong>AI (Artificial Intelligence – Trí tuệ nhân tạo)</strong> là một lĩnh vực nghiên cứu rất sôi động. Các hệ thống AI hiện đại đòi hỏi phải huấn luyện mô hình trên một lượng dữ liệu khổng lồ.</p>
<p>Trong phạm vi ghi chú này, chúng ta sẽ hoàn toàn bỏ qua chi tiết về cách các mô hình này hoạt động. Tất cả những gì bạn cần biết là chúng ta bắt đầu với một mô hình chưa được huấn luyện: hãy hình dung nó như một ma trận lớn chứa đầy các số ngẫu nhiên. Sau đó, chúng ta huấn luyện mô hình này bằng một lượng dữ liệu huấn luyện khổng lồ: hãy hình dung quá trình này như việc thực hiện rất nhiều phép nhân ma trận (tức là các phép nhân và cộng) giữa dữ liệu huấn luyện và mô hình. Cuối cùng, đầu ra là một mô hình đã được huấn luyện: hãy hình dung nó như ma trận lớn ban đầu, nhưng giờ đây chứa đầy các con số hữu ích.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-062-ai-model.png">
<p>Trên thực tế, quá trình huấn luyện AI phức tạp hơn nhiều. Ví dụ, quá trình huấn luyện mang tính lặp (<strong>iterative</strong>): bạn sẽ chạy mô hình trên một tập dữ liệu huấn luyện, và xem kết quả đạt được. Sau đó, bạn tính toán một giá trị sai số (<strong>error term</strong>) dựa trên những lỗi đã mắc phải, và sử dụng nó để cập nhật mô hình. Chúng ta sẽ không quan tâm đến các chi tiết này. Ở đây, chúng ta chỉ coi quá trình huấn luyện như một “hộp đen” (<strong>black box</strong>) thực hiện rất nhiều phép nhân ma trận trên các bộ dữ liệu cực lớn.</p>
<h2 id="distributed-training-huấn-luyện-phân-tán"><a class="header" href="#distributed-training-huấn-luyện-phân-tán"><strong>Distributed Training</strong> (Huấn luyện phân tán)</a></h2>
<p>Các tác vụ huấn luyện AI quá lớn để có thể chạy tuần tự trên một máy tính duy nhất. Nếu bạn thực hiện phép nhân ma trận bằng cách nhân từng số một, tác vụ huấn luyện sẽ không bao giờ hoàn thành. Thay vào đó, chúng ta cần <strong>parallelize</strong> (song song hóa) các tác vụ này để nhiều phép toán (ví dụ: phép nhân) được thực hiện đồng thời. Có nhiều cách tiếp cận <strong>distributed computing</strong> (tính toán phân tán), mỗi cách song song hóa công việc theo một chiều khác nhau:</p>
<ul>
<li>Chúng ta có thể chia nhỏ dữ liệu huấn luyện để mỗi <strong>node</strong> (nút) huấn luyện trên một tập con dữ liệu khác nhau.</li>
<li>Chúng ta có thể chia nhỏ chính mô hình, để mỗi node huấn luyện một tập con của mô hình.</li>
<li>Chúng ta có thể <strong>pipeline</strong> (xâu chuỗi) các phép toán, để mỗi node thực hiện một tập con các phép toán. Ví dụ: nếu thao tác mong muốn là “cộng 5” rồi “bình phương số đó”, chúng ta có thể chia ra sao cho node của bạn thực hiện phép cộng, sau đó chuyển kết quả cho tôi để node của tôi thực hiện phép bình phương. Khi đó, mỗi mẩu dữ liệu sẽ đi qua node của bạn trước, rồi đến node của tôi, để hoàn thành toàn bộ thao tác.</li>
</ul>
<p>Một lần nữa, chúng ta sẽ hoàn toàn bỏ qua chi tiết về cách công việc được phân chia. Chúng ta chỉ biết rằng có một tác vụ lớn, và nó đã được chia thành các tác vụ con nhỏ hơn.</p>
<p>Điều quan trọng mà chúng ta quan tâm là cách các node này <strong>synchronize</strong> (đồng bộ) với nhau. Các node thường cần giao tiếp với nhau để đảm bảo trạng thái của chúng nhất quán. Ngoài ra, sau khi thực hiện một phép toán, có thể mỗi node sẽ giữ một phần của kết quả, và tất cả cần phối hợp để ghép các phần đó thành kết quả đầy đủ.</p>
<p>Kết hợp hình dung về mô hình huấn luyện với hình dung về tính toán phân tán, chúng ta có một cái nhìn tổng quan ở mức cao về huấn luyện phân tán:</p>
<ol>
<li>
<p><strong>Chia tác vụ thành các tác vụ con</strong>. Mỗi node thực hiện một tác vụ con.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-063-distributed-1.png">
</li>
<li>
<p><strong>Sau khi mọi node hoàn thành tác vụ con</strong>, tất cả trao đổi một lượng lớn trạng thái.</p>
<img width="800px" src="beyond-client-server/../assets/beyond-client-server/7-064-distributed-2.png">
</li>
<li>
<p><strong>Chuyển sang tác vụ tiếp theo</strong>, và lặp lại bước 1–2 cho tác vụ tiếp theo.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-065-distributed-3.png">
</li>
</ol>
<p>Trọng tâm của chúng ta là <strong>quá trình trao đổi dữ liệu ở bước thứ hai</strong>, và cách làm cho quá trình trao đổi dữ liệu này hiệu quả hơn.</p>
<p>Một lần nữa, chúng ta không quan tâm chính xác dữ liệu nào được trao đổi. Tùy thuộc vào cách phân chia công việc và tùy thuộc vào mô hình AI cụ thể mà chúng ta xây dựng, bản chất của dữ liệu trao đổi có thể hơi khác nhau. Điều chúng ta tập trung là <strong>cách dữ liệu đó được trao đổi</strong>.</p>
<h2 id="hạ-tầng-huấn-luyện-phân-tán-distributed-training-infrastructure"><a class="header" href="#hạ-tầng-huấn-luyện-phân-tán-distributed-training-infrastructure"><strong>Hạ tầng huấn luyện phân tán</strong> (Distributed Training Infrastructure)</a></h2>
<p>Khi chúng ta chia nhỏ một tác vụ huấn luyện cho nhiều <strong>node</strong> (nút), thì chính xác mỗi node là gì?</p>
<p>Mỗi node có thể là một máy tính chạy <strong>CPU</strong> tiêu chuẩn, nhưng trên thực tế, các node thường là <strong>GPU (Graphics Processing Unit – Bộ xử lý đồ họa)</strong> chuyên dụng. Đây là các chip xử lý được thiết kế đặc biệt để thực hiện các tác vụ AI (ví dụ: nhân ma trận) một cách rất hiệu quả. Thay vì GPU, các node cũng có thể là <strong>TPU (Tensor Processing Unit)</strong> – chip tối ưu hóa cho AI do Google phát triển.</p>
<p>Một tác vụ huấn luyện có thể chạy trên vài trăm node, hoặc thậm chí hàng chục nghìn node, tùy thuộc vào kích thước, bối cảnh tác vụ và sức mạnh của từng node.</p>
<p>Các GPU được kết nối với nhau trong một mạng có cấu trúc giống <strong>datacenter</strong> (trung tâm dữ liệu), mang lại các lợi ích của datacenter mà chúng ta đã thấy trước đây:</p>
<ul>
<li>Các node nằm gần nhau về mặt vật lý (ví dụ: trong cùng một tòa nhà).</li>
<li>Các node được tổ chức theo một topology có cấu trúc (ví dụ: <strong>Clos network</strong>).</li>
<li>Các node đồng nhất (được xây dựng giống nhau).</li>
<li>Các liên kết có băng thông rất cao.</li>
</ul>
<p>Nếu bạn nhìn vào bên trong một datacenter huấn luyện AI, bạn sẽ thấy các <strong>server</strong> (máy chủ) được tổ chức thành các <strong>rack</strong> (giá đỡ), giống như trong bất kỳ datacenter nào khác. Tuy nhiên, khác với các datacenter thông thường, mỗi server chứa một hoặc nhiều GPU để tính toán AI. Server cũng có thể có một CPU đa dụng thông thường cho các tác vụ phụ, mặc dù CPU này thường không mạnh và không đảm nhận phần lớn công việc tính toán. Tất cả GPU trên server sử dụng cùng một <strong>NIC (Network Interface Card – card giao tiếp mạng)</strong> để trao đổi dữ liệu với các server khác.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-066-distributed-infra.png">
<p>Vì mỗi server có nhiều GPU, chúng ta cần điều chỉnh một chút mô hình trừu tượng topology mạng. Giống như trước đây, các server được kết nối với nhau qua <strong>switch</strong> và các liên kết băng thông cao. Tuy nhiên, giờ đây chúng ta cũng phải xem xét khả năng hai node trên cùng một server giao tiếp với nhau. Giao tiếp trong cùng một server cực kỳ hiệu quả so với giao tiếp giữa các server, nên chúng ta có thể mô hình hóa liên kết nội bộ server như một liên kết có băng thông vô hạn và <strong>latency</strong> (độ trễ) bằng 0.</p>
<p>Mỗi GPU có thể có bộ nhớ riêng, và chúng ta có thể sử dụng các kỹ thuật như <strong>RDMA (Remote Direct Memory Access)</strong> để tăng tốc việc truyền dữ liệu giữa bộ nhớ của các GPU.</p>
<p>Có nhiều topology khác nhau để kết nối giữa các rack, nhưng trong phạm vi này, chúng ta sẽ sử dụng topology <strong>fat-tree Clos</strong> để kết nối các rack. Dù sử dụng topology nào, một số cặp GPU sẽ gần nhau hơn (ví dụ: GPU trong cùng một server có thể giao tiếp mà không cần qua mạng), một số cặp sẽ xa hơn (ví dụ: GPU trên các server khác nhau nhưng cùng rack, kết nối qua một switch), và một số cặp sẽ xa nhất (ví dụ: GPU trên các rack khác nhau, kết nối qua nhiều hop). Các cặp GPU gần nhau có thể giao tiếp với băng thông cao hơn và độ trễ thấp hơn so với các cặp xa nhau. Tóm lại, nếu chọn ngẫu nhiên một cặp node, sẽ có cặp được kết nối tốt hơn cặp khác.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-067-clos-with-gpus.png">
<p>Ngoài ra còn có các topology khác. TPU được tích hợp sẵn <strong>router</strong> trên chip, nên có thể kết nối trực tiếp TPU vào mạng mà không cần switch. Một topology phổ biến với TPU là kết nối chúng thành <strong>3D torus</strong> (khối lập phương 3D có các cạnh nối vòng). Ví dụ: nếu bạn đi tới đỉnh của khối lập phương và tiếp tục theo liên kết hướng lên, bạn sẽ quay lại đáy khối; hoặc nếu bạn đi tới mặt trước và tiếp tục theo liên kết hướng ra trước, bạn sẽ quay lại mặt sau. Giống như topology Clos, một số cặp node sẽ gần nhau (ví dụ: neighbour trực tiếp), trong khi các cặp khác sẽ xa hơn (ví dụ: cách nhau nhiều hop).</p>
<img width="400px" src="beyond-client-server/../assets/beyond-client-server/7-068-2d-torus.png">
<img width="600px" src="beyond-client-server/../assets/beyond-client-server/7-069-3d-torus.png">
<h2 id="collective-communication-Định-nghĩa"><a class="header" href="#collective-communication-Định-nghĩa"><strong>Collective Communication: Định nghĩa</strong></a></h2>
<p>Bây giờ, khi chúng ta đã biết tác vụ (<strong>distributed computing – tính toán phân tán</strong>) và hạ tầng để chạy tác vụ đó (mạng datacenter-like của GPU/TPU), chúng ta có thể chính thức định nghĩa vấn đề cần giải quyết.</p>
<p><strong>Định nghĩa trong sách giáo khoa</strong> của <strong>collective communication</strong> (giao tiếp tập thể) là: Một nhóm node trao đổi dữ liệu theo cách phối hợp như một phần của tính toán nhóm. Nói một cách không chính thức, ý tưởng là nhiều node cùng làm việc để đạt một mục tiêu chung, và các node phải trao đổi dữ liệu trong quá trình đó.</p>
<p>Các ý tưởng và thuật ngữ về collective communication đã được phát triển từ nhiều thập kỷ trước trong bối cảnh <strong>supercomputer</strong> (siêu máy tính). Chủ đề này một lần nữa trở thành lĩnh vực nghiên cứu sôi động nhờ những tiến bộ gần đây trong AI. Các triển khai hiện đại của <strong>Collectives Communication Libraries</strong> bao gồm <strong>NCCL</strong> (Nvidia), <strong>MSCCL</strong> (Microsoft), <strong>TCCL</strong> (Thunder Research Group), v.v. Mã nguồn của NCCL có sẵn trực tuyến nếu bạn quan tâm.</p>
<p>Điều gì khiến collective communication khác với những gì chúng ta đã thấy trước đây? Có 3 điểm khác biệt chính:</p>
<p><strong>1. Giao tiếp có cấu trúc cao (Highly structured communication):</strong><br />
Trước đây, khi nghĩ về mạng, chúng ta thường trừu tượng hóa dữ liệu được trao đổi. Chúng ta không biết trước ai sẽ giao tiếp với ai, và xây dựng mạng sao cho bất kỳ cặp host nào cũng có thể giao tiếp bất cứ lúc nào.</p>
<p>Ngược lại, trong collective communication, có một mục tiêu rất cụ thể mà các node muốn đạt được, và chúng ta biết mục tiêu này từ trước. Điều này có nghĩa là, không giống Internet chung, chúng ta có một cấu trúc rất rõ ràng về dữ liệu nào sẽ được trao đổi qua mạng, và khi nào dữ liệu đó cần được trao đổi. Nói cách khác, chúng ta có một kịch bản trao đổi dữ liệu và tính toán được lập trình chặt chẽ mà tất cả các node sẽ cùng phối hợp thực hiện.</p>
<p><strong>2. Hạ tầng mạng chuyên dụng (Dedicated network infrastructure):</strong><br />
Trước đây, chúng ta xây dựng mạng có thể hỗ trợ nhiều kết nối đồng thời. Ngay cả trong mạng datacenter, nhiều <strong>tenant</strong> (người thuê) có thể gửi dữ liệu qua mạng cùng lúc.</p>
<p>Ngược lại, các tác vụ huấn luyện AI thường rất lớn và thường chạy trên hạ tầng chuyên dụng. Tác vụ huấn luyện là tác vụ duy nhất chạy trên mạng, và không có dữ liệu nào khác được gửi qua mạng. Điều này có nghĩa là chúng ta có thể dự đoán chính xác lượng băng thông được sử dụng tại bất kỳ thời điểm nào.</p>
<p><strong>3. Dữ liệu được biến đổi khi trao đổi (Data is transformed as it's exchanged):</strong><br />
Trước đây, khi nghĩ về việc gửi dữ liệu qua Internet (ví dụ: qua <strong>HTTP/TCP/IP stack</strong>), mô hình quen thuộc là máy chủ có một dữ liệu (ví dụ: một tệp) và muốn gửi một bản sao dữ liệu đó cho người dùng.</p>
<p>Ngược lại, khi chạy một thao tác collective, dữ liệu có thể được biến đổi khi truyền qua mạng. Điều này khác với những gì chúng ta đã thấy. Các phép toán thường khá đơn giản (ví dụ: tính tổng), nhưng điều đó có nghĩa là dữ liệu do bên gửi gửi đi không nhất thiết giống dữ liệu mà bên nhận nhận được.</p>
<p>Chúng ta có thể thiết kế một sơ đồ giao tiếp phối hợp từ đầu cho mỗi mô hình AI, nhưng điều này sẽ tốn công và lặp lại nhiều công việc. Thay vào đó, chúng ta sẽ định nghĩa một tập hợp các mẫu giao tiếp cơ bản gọi là <strong>collectives</strong>. Sau đó, chúng ta có thể sử dụng các collectives này như các khối xây dựng cơ bản để thiết kế các sơ đồ giao tiếp phối hợp cho các tác vụ cụ thể. Bạn có thể coi các thao tác collective cơ bản như <strong>API</strong> cho giao tiếp phân tán, ví dụ: các hàm thư viện có sẵn cho người dùng. Người dùng có thể gọi các hàm collective này theo nhiều cách khác nhau để đạt mục tiêu cụ thể.</p>
<p>Thực tế cho thấy, chúng ta chỉ cần một số lượng tương đối nhỏ các thao tác collective nguyên thủy, và hầu hết các tác vụ trong huấn luyện AI có thể được phân rã thành các thao tác này, rồi biểu diễn dưới dạng nhiều cách kết hợp khác nhau của chúng.</p>
<p>Trọng tâm của chúng ta sẽ là <strong>các thao tác collective này là gì</strong> và <strong>chúng được triển khai như thế nào trong mạng</strong>. Chúng ta sẽ không bàn về lý do tại sao huấn luyện AI lại dẫn đến những thao tác collective cụ thể này. Lý do chúng ta chọn những thao tác này làm khối xây dựng cơ bản liên quan nhiều hơn đến bản chất của tính toán AI, điều này nằm ngoài phạm vi của chúng ta.</p>
<h2 id="collective-operations-setup-thiết-lập-các-thao-tác-tập-thể"><a class="header" href="#collective-operations-setup-thiết-lập-các-thao-tác-tập-thể"><strong>Collective Operations: Setup</strong> (Thiết lập các thao tác tập thể)</a></h2>
<p>Chúng ta sẽ định nghĩa 7 thao tác collective cơ bản. Chúng ta sẽ định nghĩa <strong>chức năng</strong> của các thao tác này bằng cách chỉ rõ <strong>đầu vào</strong> (dữ liệu mỗi node đang giữ trước khi thao tác diễn ra) và <strong>đầu ra</strong> tương ứng (dữ liệu mỗi node giữ sau khi thao tác hoàn tất). Ở đây, chúng ta <strong>không</strong> chỉ định cách thao tác được triển khai trong mạng (phần này sẽ được đề cập sau).</p>
<p><strong>Đầu vào:</strong> Có $$p$$ node. Trong các ví dụ, chúng ta đặt $$p=4$$, nhưng các giá trị khác cũng được.</p>
<p>Mỗi node có một vector dữ liệu gồm $$p$$ phần tử. Trong các ví dụ này, bạn có thể hình dung dữ liệu như một mảng gồm 4 số nguyên. Trong thực tế, dữ liệu này có thể có số chiều cao hơn, ví dụ: 4 hàng của một ma trận, hoặc 4 phần dữ liệu huấn luyện có kích thước bằng nhau.</p>
<p><strong>Đầu ra:</strong> Các phần tử được di chuyển giữa các node theo một cách xác định trước. Đầu ra chỉ rõ giá trị nào sẽ nằm ở ô nào sau khi thao tác hoàn tất.</p>
<p>Ngoài ra, đôi khi các phần tử có thể được <strong>aggregate</strong> (tổng hợp), ví dụ: cộng lại với nhau. Đầu ra cũng chỉ rõ phép tính nào (nếu có) được thực hiện trong thao tác này, và kết quả được đặt vào ô nào.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-070-collective-setup.png">
<p>Trước khi thao tác collective diễn ra, cần có một số bước <strong>phối hợp bổ sung</strong> để mỗi node biết số thứ tự của mình và tổng số node (ví dụ: “Bạn là node 1, và có tổng cộng 4 node”). Việc phối hợp bổ sung này nằm ngoài phạm vi của chúng ta, nhưng bạn có thể hình dung rằng một <strong>scheduler</strong> hoặc <strong>controller</strong> tập trung sẽ phân phát thông tin này tới các node và thiết lập tác vụ.</p>
<p>Để thực thi một thao tác collective, mỗi node chạy <strong>chính xác cùng một đoạn mã</strong>, song song, tại cùng một thời điểm. Tất cả cùng gọi thao tác collective giống nhau để bắt đầu, và khi thao tác hoàn tất, đầu ra phải khớp với định nghĩa của thao tác. Lý tưởng nhất là các node có tài nguyên phần cứng giống nhau, để tất cả hoàn thành cùng lúc. Nếu một số node chậm hơn, thao tác sẽ ở trạng thái <strong>blocking</strong> (chặn), nghĩa là phải chờ tất cả hoàn thành trước khi chuyển sang tác vụ tiếp theo.</p>
<p><strong>Tóm lại</strong>, các thao tác collective được điều phối bởi một controller thiết lập tác vụ. Thao tác này <strong>đồng bộ</strong> (mọi node bắt đầu cùng lúc), <strong>đồng nhất</strong> (lý tưởng là hoàn thành cùng lúc) và <strong>blocking</strong> (phải chờ tất cả hoàn thành trước khi tiếp tục).</p>
<p>Với phần thiết lập đã xong, chúng ta sẵn sàng xem định nghĩa của 7 thao tác collective. Các thao tác này có thể chia thành 2 nhóm:</p>
<ul>
<li>4 thao tác về <strong>redistribution</strong> (phân phối lại dữ liệu mà không biến đổi nó)</li>
<li>3 thao tác về <strong>consolidation</strong> (tổng hợp nhiều mảnh dữ liệu thành một đầu ra duy nhất).</li>
</ul>
<h3 id="operation-broadcast"><a class="header" href="#operation-broadcast"><strong>Operation: Broadcast</strong></a></h3>
<p><strong>Mô tả:</strong> Lấy toàn bộ vector trong một <strong>root node</strong> (nút gốc) được chỉ định, và gửi một bản sao của toàn bộ vector đó tới mọi node.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-071-broadcast.png">
<p><strong>Ghi chú:</strong></p>
<ul>
<li>Sơ đồ minh họa Broadcast với Node 1 là root, nhưng có thể chọn node khác làm root. Người dùng phải chỉ định root node như một “tham số” của thao tác.</li>
<li>Vector đầu vào ở các node không phải root <strong>không</strong> được dùng để tạo đầu ra (giống như tham số hàm không được sử dụng).</li>
<li>Vị trí lưu vector đầu vào và đầu ra không nhất thiết phải giống nhau. Nếu dùng cùng địa chỉ bộ nhớ, một số thao tác (như Broadcast) sẽ ghi đè dữ liệu đầu vào. Có thể dùng địa chỉ bộ nhớ khác để lưu đầu ra.</li>
</ul>
<h3 id="operation-scatter"><a class="header" href="#operation-scatter"><strong>Operation: Scatter</strong></a></h3>
<p><strong>Mô tả:</strong> Lấy toàn bộ vector trong một root node được chỉ định. Gửi phần tử thứ $$i$$ của vector này tới node thứ $$i$$.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-072-scatter.png">
<p><strong>Ghi chú:</strong> Giống như Broadcast, có thể chỉ định bất kỳ node nào làm root. Vector đầu vào ở các node không phải root không được dùng để tạo đầu ra.</p>
<h3 id="operation-gather"><a class="header" href="#operation-gather"><strong>Operation: Gather</strong></a></h3>
<p><strong>Mô tả:</strong> Tạo một vector mới, trong đó phần tử thứ $$i$$ được lấy từ phần tử thứ $$i$$ của node thứ $$i$$. Gửi vector này tới một root node được chỉ định.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-073-gather.png">
<p><strong>Ghi chú:</strong> Trong thao tác này, không có dữ liệu nào được lưu vào bộ đệm nhận của các node không phải root.</p>
<h3 id="operation-allgather"><a class="header" href="#operation-allgather"><strong>Operation: AllGather</strong></a></h3>
<p><strong>Mô tả:</strong> Tạo một vector mới, trong đó phần tử thứ $$i$$ được lấy từ phần tử thứ $$i$$ của node thứ $$i$$. Gửi một bản sao của vector này tới mọi node.</p>
<p><strong>Mô tả thay thế:</strong> Node $$i$$ thực hiện Broadcast phần tử thứ $$i$$ của mình, để nó trở thành phần tử thứ $$i$$ trong vector đầu ra của mọi node.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-074-allgather.png">
<h3 id="operation-reduce"><a class="header" href="#operation-reduce"><strong>Operation: Reduce</strong></a></h3>
<p><strong>Mô tả:</strong> Tính tổng theo từng phần tử (<strong>element-wise sum</strong>) của tất cả các vector, và gửi vector tổng này tới một root node được chỉ định.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-075-reduce.png">
<p><strong>Ghi chú:</strong> Trong phần này, chúng ta dùng phép cộng làm phép <strong>reduction</strong> (giảm dữ liệu), nhưng có thể thay bằng phép khác (ví dụ: nhân). Các phép reduction thường <strong>associative</strong> (kết hợp) và <strong>commutative</strong> (giao hoán), nghĩa là có thể thực hiện theo bất kỳ thứ tự nào mà vẫn cho kết quả giống nhau.</p>
<h3 id="operation-allreduce"><a class="header" href="#operation-allreduce"><strong>Operation: AllReduce</strong></a></h3>
<p><strong>Mô tả:</strong> Tính tổng theo từng phần tử của tất cả các vector, và gửi một bản sao của vector tổng này tới tất cả các node.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-076-allreduce.png">
<h3 id="operation-reducescatter"><a class="header" href="#operation-reducescatter"><strong>Operation: ReduceScatter</strong></a></h3>
<p><strong>Mô tả:</strong> Tính tổng theo từng phần tử của tất cả các vector. Gửi phần tử thứ $$i$$ của vector tổng tới node thứ $$i$$.</p>
<p><strong>Mô tả thay thế:</strong> Phần tử thứ $$i$$ của mỗi node được cộng lại, và kết quả (một số vô hướng) được gửi tới node $$i$$.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-077-reducescatter.png">
<h2 id="duals-các-cặp-thao-tác-đối-ngẫu"><a class="header" href="#duals-các-cặp-thao-tác-đối-ngẫu"><strong>Duals</strong> (Các cặp thao tác đối ngẫu)</a></h2>
<p>Một số cặp thao tác là <strong>dual</strong> của nhau, nghĩa là một thao tác là “đảo ngược” của thao tác kia. Khi xét dual, chúng ta bỏ qua các phép reduction, chỉ quan tâm ô nào được ghi dữ liệu trong đầu ra.</p>
<ul>
<li><strong>Broadcast</strong> và <strong>Reduce</strong> là dual của nhau: Broadcast đọc từ 4 ô trong root node và ghi vào tất cả 16 ô của mọi node. Reduce làm ngược lại: đọc từ tất cả 16 ô và ghi vào 4 ô trong root node.</li>
</ul>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-078-duals-1.png">
<ul>
<li><strong>Scatter</strong> và <strong>Gather</strong> là dual của nhau: Scatter đọc từ 4 ô trong root node và ghi vào ô thứ $$i$$ của node $$i$$ (tổng 4 ô). Gather làm ngược lại.</li>
</ul>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-079-duals-2.png">
<ul>
<li><strong>AllGather</strong> và <strong>ReduceScatter</strong> là dual của nhau: AllGather đọc từ ô thứ $$i$$ của node $$i$$ và ghi vào tất cả 16 ô. ReduceScatter làm ngược lại.</li>
</ul>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-080-duals-3.png">
<ul>
<li><strong>AllReduce</strong> không có dual, hoặc có thể coi nó là dual của chính nó.</li>
</ul>
<p>Ý tưởng về dual hữu ích khi nghĩ về triển khai: với cùng topology và phương án định tuyến, một thao tác và dual của nó sẽ có hiệu năng giống nhau (ví dụ: cùng tổng băng thông sử dụng), vì tổng lượng dữ liệu gửi và nhận là như nhau.</p>
<h2 id="compositing-operations-kết-hợp-thao-tác"><a class="header" href="#compositing-operations-kết-hợp-thao-tác"><strong>Compositing Operations</strong> (Kết hợp thao tác)</a></h2>
<p>Người dùng có thể kết hợp nhiều thao tác để tạo ra thao tác mong muốn.</p>
<p>Ví dụ: AllReduce could equivalently be expressed as a ReduceScatter, followed by an AllGather.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-081-composition.png">
<div style="break-before: page; page-break-before: always;"></div><h1 id="triển-khai-collective-collective-implementations"><a class="header" href="#triển-khai-collective-collective-implementations"><strong>Triển khai Collective</strong> (Collective Implementations)</a></h1>
<h2 id="Động-lực-triển-khai-allreduce-motivation-implementing-allreduce"><a class="header" href="#Động-lực-triển-khai-allreduce-motivation-implementing-allreduce"><strong>Động lực: Triển khai AllReduce</strong> (Motivation: Implementing AllReduce)</a></h2>
<p>Bây giờ, khi chúng ta đã có định nghĩa của 7 <strong>collective</strong> (tập hợp thao tác truyền thông tin giữa nhiều nút), chúng ta có thể bắt đầu suy nghĩ về cách triển khai chúng trong một mạng. Để triển khai một collective, có hai câu hỏi cần trả lời:</p>
<ul>
<li>Chúng ta sử dụng <strong>topology</strong> (kiến trúc kết nối) nào để kết nối các nút?</li>
<li>Dữ liệu nào cần được trao đổi giữa các nút để hoàn thành thao tác một cách hiệu quả?</li>
</ul>
<p>Khi đã quyết định topology sẽ dùng và dữ liệu cần trao đổi, chúng ta có thể phân tích hiệu năng của thiết kế. Tổng lượng <strong>network bandwidth</strong> (băng thông mạng) đã sử dụng là bao nhiêu? Thời gian để hoàn thành thao tác là bao lâu? Có thể tập trung vào các chỉ số hiệu năng khác, nhưng trong phần này, chúng ta sẽ tập trung vào hai chỉ số này.</p>
<p>Để đo hiệu năng, chúng ta định nghĩa một số biến: Có tổng cộng $$p$$ nút. Mỗi vector có tổng cộng $$D$$ byte. Điều này có nghĩa là mỗi phần tử vector (mỗi ô trong hình minh họa) có kích thước $$D/p$$ byte.</p>
<p>Trong phần này, chúng ta đặt $$p=5$$ để một số ví dụ minh họa dễ hình dung hơn. Lưu ý rằng điều này cũng có nghĩa là mỗi vector bây giờ có 5 phần tử thay vì 4 phần tử. (Ghi chú: Hãy nhớ rằng vector đại diện cho dữ liệu bất kỳ, và chúng ta chia mỗi vector thành $$p$$ <strong>sub-vector</strong> (vector con) có kích thước bằng nhau, trong đó $$p$$ là tổng số nút. Việc tăng $$p$$ từ 4 lên 5 không nhất thiết nghĩa là có nhiều dữ liệu hơn, mà có thể chỉ là chia cùng một lượng dữ liệu thành 5 phần thay vì 4 phần.)</p>
<p>Trong phần này, chúng ta sẽ tập trung vào việc triển khai collective <strong>AllReduce</strong>, mặc dù các ý tưởng có thể áp dụng cho các collective khác. Nhắc lại rằng AllReduce tính tổng theo từng phần tử của các vector, sau đó gửi vector tổng này tới tất cả các nút.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-082-allreduce-reminder.png">
<h2 id="cách-tiếp-cận-1-full-mesh-approach-1-full-mesh"><a class="header" href="#cách-tiếp-cận-1-full-mesh-approach-1-full-mesh"><strong>Cách tiếp cận 1: Full Mesh</strong> (Approach 1: Full Mesh)</a></h2>
<p>Topology đầu tiên chúng ta xem xét là <strong>full-mesh</strong> (lưới đầy đủ), trong đó mỗi nút có một liên kết trực tiếp tới mọi nút khác.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-083-mesh-1.png">
<p>Với topology này, chúng ta có thể triển khai AllReduce theo các bước:</p>
<ol>
<li>Mỗi nút gửi toàn bộ vector của mình trực tiếp tới mọi nút khác.</li>
</ol>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-084-mesh-2.png">
<ol start="2">
<li>Sau đó, mỗi nút cộng tất cả các vector mà nó nhận được.</li>
</ol>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-085-mesh-3.png">
<p><strong>Băng thông sử dụng:</strong> Mỗi nút cần gửi toàn bộ vector ($$D$$ byte) của mình tới tất cả $$p-1$$ nút khác, nên mỗi nút gửi $$D(p-1)$$ byte. Có tổng cộng $$p$$ nút, nên tổng dữ liệu gửi là $$Dp(p-1) = O(D \cdot p^2)$$ byte.</p>
<p><strong>Thời gian thực hiện:</strong> Phụ thuộc vào giới hạn tài nguyên của các nút và liên kết, nhưng giả sử không có giới hạn tài nguyên, tất cả việc gửi vector có thể diễn ra đồng thời, hoàn thành trong một bước thời gian (<strong>time step</strong>). Nói cách khác, Node 1 gửi dữ liệu tới tất cả các nút khác, sử dụng đồng thời tất cả các liên kết ra của nó. Cùng lúc đó, Node 2 cũng gửi dữ liệu tới tất cả các nút khác, sử dụng đồng thời tất cả các liên kết ra của nó. Giả sử không có giới hạn tài nguyên, cách tiếp cận này chỉ mất một time step để hoàn thành, trong đó mỗi nút cần gửi và nhận $$2 \cdot D \cdot (p-1)$$ byte mỗi time step (mỗi nút gửi $$D \cdot (p-1)$$ byte và nhận $$D \cdot (p-1)$$ byte, cộng lại thành hệ số 2).</p>
<h2 id="cách-tiếp-cận-2-reduce-tại-một-nút-approach-2-reduce-at-one-node"><a class="header" href="#cách-tiếp-cận-2-reduce-tại-một-nút-approach-2-reduce-at-one-node"><strong>Cách tiếp cận 2: Reduce tại một nút</strong> (Approach 2: Reduce at One Node)</a></h2>
<p>Trong topology tiếp theo, chúng ta để một nút duy nhất thực hiện toàn bộ công việc tính toán:</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-086-root-1.png">
<p>Để chạy AllReduce:</p>
<ol>
<li>Tất cả các nút (trừ Node 1) gửi vector của mình tới Node 1.</li>
</ol>
<img width="800px" src="beyond-client-server/../assets/beyond-client-server/7-087-root-2.png">
<ol start="2">
<li>Node 1 tính tổng, và gửi vector tổng này trở lại cho tất cả các nút.</li>
</ol>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-088-root-3.png">
<p><strong>Băng thông sử dụng:</strong></p>
<ul>
<li>Bước 1: Mỗi nút (trừ Node 1) cần gửi toàn bộ vector tới Node 1, tức là $$D$$ byte. Có $$p-1$$ nút gửi dữ liệu, nên tổng dữ liệu gửi trong bước này là $$D(p-1)$$ byte.</li>
<li>Bước 2: Node 1 phải gửi vector tổng tới tất cả các nút khác. Vector tổng có kích thước $$D$$ byte, gửi tới $$p-1$$ nút, nên tổng dữ liệu gửi trong bước này cũng là $$D(p-1)$$ byte.</li>
</ul>
<p>Tổng cộng, qua hai bước, chúng ta gửi $$2 \cdot D \cdot (p-1) = O(D \cdot p)$$ byte. Lưu ý rằng đây là cải thiện hệ số $$p$$ so với $$O(D \cdot p^2)$$ byte trong cách tiếp cận full-mesh.</p>
<p><strong>Thời gian thực hiện:</strong> Giả sử không có giới hạn tài nguyên, tất cả các nút có thể gửi vector của mình tới Node 1 cùng lúc. Sau đó, chúng ta phải chờ Node 1 tính tổng. Khi tổng đã được tính, Node 1 có thể gửi vector tổng tới tất cả các nút khác cùng lúc. Tổng cộng, cách tiếp cận này mất 2 time step để hoàn thành, trong đó Node 1 phải gửi hoặc nhận $$D \cdot (p-1)$$ byte mỗi time step.</p>
<p>Chúng ta không đo chính xác độ dài của một time step ở đây, nhưng điểm so sánh chính là: với cách tiếp cận này, toàn bộ việc gửi ở bước 1 phải hoàn tất trước khi việc gửi ở bước 2 bắt đầu. Ngược lại, trong cách tiếp cận đầu tiên, toàn bộ dữ liệu có thể được gửi đồng thời.</p>
<p><strong>Nhược điểm:</strong> Cách tiếp cận này tạo ra một <strong>single point of failure</strong> (điểm lỗi đơn) tại Node 1. Do đó, cách này không thường được sử dụng trong thực tế.</p>
<h2 id="cách-tiếp-cận-3-tree-based-dựa-trên-cấu-trúc-cây"><a class="header" href="#cách-tiếp-cận-3-tree-based-dựa-trên-cấu-trúc-cây"><strong>Cách tiếp cận 3: Tree-Based</strong> (Dựa trên cấu trúc cây)</a></h2>
<p>Trong topology tiếp theo, chúng ta sẽ xây dựng một <strong>binary tree</strong> (cây nhị phân). Ở đây, “binary” nghĩa là mỗi nút có tối đa 2 <strong>child</strong> (nút con).</p>
<img width="800px" src="beyond-client-server/../assets/beyond-client-server/7-089-tree-1.png">
<p>Để chạy <strong>AllReduce</strong>: Bắt đầu từ các <strong>leaf node</strong> (nút lá) ở đáy cây, mỗi nút gửi vector của mình tới <strong>parent</strong> (nút cha).</p>
<img width="800px" src="beyond-client-server/../assets/beyond-client-server/7-090-tree-2.png">
<p>Khi nhận được tất cả vector từ các child, bạn sẽ cộng chúng với vector của mình.</p>
<img width="800px" src="beyond-client-server/../assets/beyond-client-server/7-091-tree-3.png">
<p>Sau đó, bạn gửi vector tổng này lên parent.</p>
<img width="700px" src="beyond-client-server/../assets/beyond-client-server/7-092-tree-4.png">
<p>Sau khi lặp lại bước này qua tất cả các tầng của cây, <strong>root</strong> (nút gốc) sẽ tính được tổng cuối cùng.</p>
<img width="700px" src="beyond-client-server/../assets/beyond-client-server/7-093-tree-5.png">
<p>Tiếp theo, ở bước thứ hai, root gửi vector tổng này xuống cây, tới các child của nó. Khi nhận được vector tổng từ parent, bạn sẽ gửi một bản sao của vector tổng đó tới tất cả các child của mình.</p>
<img width="800px" src="beyond-client-server/../assets/beyond-client-server/7-094-tree-6.png">
<img width="800px" src="beyond-client-server/../assets/beyond-client-server/7-095-tree-7.png">
<p><strong>Băng thông sử dụng:</strong></p>
<ul>
<li>Bước 1: Mỗi nút nhận tối đa 2 vector từ các child (vì cây là nhị phân) và gửi 1 vector tới parent. Điều này cho giới hạn trên là $$3D$$ byte mỗi nút, tổng cộng $$3D \cdot p$$ byte trong Bước 1.</li>
<li>Bước 2: Mỗi nút nhận 1 vector từ parent và gửi tối đa 2 vector tới các child. Giới hạn trên vẫn là $$3D$$ byte mỗi nút, tổng cộng $$3D \cdot p$$ byte trong Bước 2.</li>
</ul>
<p>Tổng cộng, qua hai bước, chúng ta gửi $$6 \cdot D \cdot p = O(D \cdot p)$$ byte. Đây là cải thiện hệ số $$p$$ so với <strong>full-mesh</strong>, và bằng với cách tiếp cận <strong>reduce-at-one-node</strong>.</p>
<p><strong>Thời gian thực hiện:</strong> Bạn phải chờ nhận vector từ các child trước khi có thể gửi vector tổng (tổng vector của bạn và vector của các child) lên parent. Tổng cộng, cách tiếp cận này mất $$O(\log p)$$ <strong>time step</strong> để gửi vector lên cây, và thêm $$O(\log p)$$ time step để gửi vector tổng xuống cây, tức tổng cộng $$O(\log p)$$ time step. Mỗi nút phải gửi hoặc nhận tối đa $$3D$$ byte mỗi time step (ít hơn so với các cách tiếp cận khác). So sánh chính xác về thời gian cần thay thế giá trị $$D$$ và giới hạn tài nguyên mạng, nhưng nhìn chung, cách này cần nhiều time step hơn, song mỗi time step có thể hoàn thành nhanh hơn vì lượng dữ liệu truyền nhỏ hơn.</p>
<p>Lưu ý rằng chúng ta đã tận dụng phép <strong>reduction</strong> (giảm dữ liệu) trong triển khai này. Mỗi nút cộng vector của mình với vector của các child, nên chỉ cần gửi một vector tổng duy nhất lên parent. Trong cách tiếp cận ngây thơ hơn, mỗi nút sẽ gửi cả 3 vector (vector của mình và của 2 child) lên parent, nhưng ở đây chúng ta đã tiết kiệm băng thông.</p>
<p>Nói chung, các collective dạng hợp nhất dữ liệu (<strong>Reduce</strong>, <strong>ReduceScatter</strong>, <strong>AllReduce</strong>) cho phép tối ưu triển khai. Trong Reduce và ReduceScatter, tổng lượng dữ liệu nhận thực tế nhỏ hơn lượng dữ liệu gửi, và chúng ta có thể tận dụng điều này. Ví dụ, nếu biết đầu ra là tổng của tất cả vector, và bạn nhận 2 vector, bạn có thể cộng chúng lại và gửi một vector tổng duy nhất, thay vì gửi riêng từng vector.</p>
<h2 id="cách-tiếp-cận-4-ring-based-naive-dựa-trên-vòng--ngây-thơ"><a class="header" href="#cách-tiếp-cận-4-ring-based-naive-dựa-trên-vòng--ngây-thơ"><strong>Cách tiếp cận 4: Ring-Based (Naive)</strong> (Dựa trên vòng – Ngây thơ)</a></h2>
<p>Trong hai cách tiếp cận cuối, chúng ta sẽ xây dựng topology dạng <strong>ring</strong> (vòng). Lưu ý rằng liên kết vòng từ Node 1 tới Node 5 không có gì đặc biệt so với các liên kết khác (việc liên kết này dài hơn không mang ý nghĩa gì).</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-096-naive-ring-1.png">
<p>Để chạy AllReduce theo cách ngây thơ: Node 5 bắt đầu bằng cách gửi vector của mình sang trái.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-097-naive-ring-2.png">
<p>Khi nhận vector từ <strong>neighbor</strong> (nút láng giềng) bên phải, bạn cộng nó với vector của mình.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-098-naive-ring-3.png">
<p>Sau đó, bạn gửi vector tổng này sang <strong>neighbor</strong> bên trái.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-099-naive-ring-4.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-100-naive-ring-5.png">
<p>Quá trình này sẽ tiếp tục quanh vòng.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-101-naive-ring-6.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-102-naive-ring-7.png">
<p>Cuối cùng, Node 1 sẽ tính được vector tổng cuối cùng.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-103-naive-ring-8.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-104-naive-ring-9.png">
<p>Sau đó, ở bước thứ hai, chúng ta gửi vector tổng này quanh vòng để mọi nút đều có bản sao. Node 5 bắt đầu bằng cách gửi vector tổng sang trái. Khi nhận vector tổng từ neighbor bên phải, bạn gửi một bản sao sang neighbor bên trái. Quá trình này tiếp tục quanh vòng cho đến khi mọi nút nhận được vector tổng.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-105-naive-ring-10.png">
<p><strong>Băng thông sử dụng:</strong></p>
<ul>
<li>Bước 1: Mỗi nút nhận 1 vector từ neighbor bên phải và gửi 1 vector sang neighbor bên trái. Giới hạn trên là $$2D$$ byte mỗi nút, tổng cộng $$2D \cdot p$$ byte.</li>
<li>Bước 2: Mỗi nút lại nhận 1 vector và gửi 1 vector. Giới hạn trên vẫn là $$2D$$ byte mỗi nút, tổng cộng $$2D \cdot p$$ byte.</li>
</ul>
<p>Tổng cộng, qua hai bước, chúng ta gửi $$4 \cdot D \cdot p = O(D \cdot p)$$ byte.</p>
<p><strong>Thời gian thực hiện:</strong> Bạn phải chờ nhận vector (từ bên trái) trước khi có thể gửi vector (sang bên phải). Tổng cộng, cách này mất $$p$$ time step để vòng lặp hoàn tất ở bước 1, và thêm $$p$$ time step để gửi vector tổng ở bước 2, tức tổng cộng $$2p = O(p)$$ time step. Mỗi nút phải gửi hoặc nhận tối đa $$2D$$ byte mỗi time step.</p>
<p>Giống như topology dạng cây, so sánh thời gian chính xác cần thay thế giá trị $$D$$ và giới hạn tài nguyên mạng. Nhìn chung, so với hai cách tiếp cận đầu tiên, cách này cần nhiều time step hơn, nhưng mỗi time step có thể hoàn thành nhanh hơn vì lượng dữ liệu truyền nhỏ hơn.</p>
<p><strong>Lưu ý:</strong> Chúng ta chọn Node 5 làm điểm bắt đầu, nhưng các điểm bắt đầu khác cũng có thể hoạt động. Tương tự, chúng ta có thể di chuyển theo chiều trái–phải thay vì phải–trái.</p>
<h2 id="cách-tiếp-cận-5-ring-based-optimized-dựa-trên-vòng--tối-ưu"><a class="header" href="#cách-tiếp-cận-5-ring-based-optimized-dựa-trên-vòng--tối-ưu"><strong>Cách tiếp cận 5: Ring-Based (Optimized)</strong> (Dựa trên vòng – Tối ưu)</a></h2>
<p>Các cách tiếp cận trước đây đều cho ra kết quả đúng, nhưng tạo ra <strong>bursty workload</strong> (tải công việc dồn cục). Trong cách ring-based ngây thơ, mỗi nút dành phần lớn thời gian ở trạng thái chờ, không làm gì. Tại một thời điểm, bạn đột ngột nhận toàn bộ vector, phải ngay lập tức cộng vector đó với vector của mình, rồi gửi kết quả sang trái. Mọi nút khác phải chờ bạn hoàn thành thao tác này.</p>
<p>Để tạo tải công việc ít dồn cục hơn và cân bằng hơn, chúng ta có thể <strong>stagger</strong> (xen kẽ) các bước của AllReduce dạng ring-based <em>ngây thơ</em> (naive ring-based AllReduce). Việc gửi toàn bộ vector sang trái cùng lúc sẽ khiến nó bị quá tải. Thay vào đó, bạn có thể gửi vector về bên trái theo từng lượt một, mỗi element một lần gửi.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-106-optimized-ring-1.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-107-optimized-ring-2.png">
<p>Khi bạn nhận được <strong>một phần tử</strong> (từ bên trái), bạn có thể cộng phần tử đó với phần tử tương ứng của mình. Sau đó, bạn gửi kết quả tổng này (vẫn chỉ là một phần tử) sang bên trái.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-108-optimized-ring-3.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-109-optimized-ring-4.png">
<p>Ngoài việc <strong>stagger</strong> (xen kẽ) việc gửi từng phần tử của vector, hãy chú ý rằng <strong>điểm bắt đầu</strong> cũng được sắp xếp xen kẽ. Thay vì điểm bắt đầu là Node 5 gửi tất cả các phần tử của nó, bây giờ chúng ta bắt đầu bằng cách để nút thứ $$i$$ gửi phần tử thứ $$i$$ của nó.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-110-optimized-ring-5.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-111-optimized-ring-6.png">
<p>Bằng cách xen kẽ thao tác theo cả hai chiều này (mỗi nút gửi một phần tử tại một thời điểm, và mỗi nút bắt đầu ở một phần tử khác nhau), chúng ta có thể tạo ra một <strong>workload</strong> (tải công việc) cân bằng hơn. Ở mỗi <strong>time step</strong>, mỗi nút nhận đúng một phần tử từ bên phải, tính một phép cộng, và gửi đúng một phần tử sang bên trái.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-112-optimized-ring-7.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-113-optimized-ring-8.png">
<p>Nếu chúng ta lặp lại quá trình này $$p$$ lần, thì mỗi phần tử sẽ đi hết một vòng quanh vòng tròn.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-114-optimized-ring-9.png">
<p>Tuy nhiên, không phải mọi nút đều biết tất cả các phần tử của vector tổng, vì vậy chúng ta phải chạy thêm một vòng nữa. Giống như trong cách tiếp cận <strong>naive</strong> (ngây thơ), ở vòng thứ hai này, khi bạn nhận được một phần tử của vector tổng, bạn chỉ cần gửi một bản sao sang bên phải.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-115-optimized-ring-10.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-116-optimized-ring-11.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-117-optimized-ring-12.png">
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-118-optimized-ring-13.png">
<p>Khi xem bản demo động này, hãy chú ý vào <strong>hai chiều</strong> mà chúng ta đang xen kẽ thao tác:</p>
<ul>
<li>Nếu bạn tập trung vào một <strong>cột</strong>, bạn sẽ thấy rằng chúng ta gửi từng phần tử một, và nhận từng phần tử một.</li>
<li>Nếu bạn tập trung vào một <strong>hàng</strong>, bạn sẽ thấy rằng mỗi nút nhận tổng của tất cả các phần tử thứ $$i$$ cho đến thời điểm đó, cộng thêm phần tử thứ $$i$$ của mình, và gửi tổng mới sang trái. Vì thao tác này đi qua tất cả các nút, chúng ta biết rằng cuối cùng sẽ cộng được tất cả các phần tử thứ $$i$$ lại với nhau.</li>
</ul>
<p><strong>Tóm lại</strong>, <strong>optimized ring-based AllReduce</strong> thực hiện chính xác các thao tác giống như <strong>naive ring-based AllReduce</strong>. Điểm khác biệt duy nhất là chúng ta đã xen kẽ việc gửi và nhận vector, để giảm tính “dồn cục” (<strong>burstiness</strong>) của tải công việc tại mỗi nút.</p>
<p><strong>Phân tích băng thông và thời gian</strong> của optimized ring-based AllReduce giống với naive ring-based AllReduce:</p>
<ul>
<li>Mỗi nút nhận/gửi $$2D$$ byte ở bước đầu tiên, và thêm $$2D$$ byte ở bước thứ hai, tổng cộng $$4 \cdot D \cdot p = O(D \cdot p)$$ byte.</li>
<li>Chúng ta vẫn cần $$O(p)$$ time step để hoàn thành hai vòng quanh vòng tròn.</li>
</ul>
<p>Tuy nhiên, <strong>băng thông trên mỗi time step</strong> đã được cải thiện trong cách tối ưu. Trong cách naive, mỗi nút phải nhận và gửi toàn bộ vector trong một time step, tổng cộng $$2D$$ byte truyền trong một time step. Trong cách tối ưu, mỗi nút chỉ phải nhận và gửi <strong>một phần tử</strong> tại mỗi time step, tổng cộng $$2D/p$$ byte truyền trong một time step.</p>
<h2 id="overlay-và-underlay-topologies"><a class="header" href="#overlay-và-underlay-topologies"><strong>Overlay và Underlay Topologies</strong></a></h2>
<p>Hãy nhớ rằng các thao tác collective này được định nghĩa sao cho <strong>user</strong> (ví dụ: chương trình huấn luyện AI) có thể chọn bất kỳ tập hợp $$p$$ host nào và yêu cầu chúng chạy một thao tác AllReduce. Khi user chọn $$p$$ host, rất có thể chúng không được kết nối sẵn theo topology vòng. Làm thế nào để triển khai AllReduce dạng vòng ngay cả khi các host không được kết nối vật lý theo topology vòng?</p>
<p>Câu trả lời là sử dụng <strong>overlay</strong>. Chúng ta có thể vẽ các liên kết ảo để kết nối các host thành topology vòng:</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-119-ring-overlay-1.png">
<p>Khi Node D gửi vector tới Node B, ở góc nhìn <strong>overlay</strong>, Node D đang gửi vector qua một liên kết ảo duy nhất tới neighbor trực tiếp của nó. Ở góc nhìn <strong>underlay</strong>, vector này thực tế phải đi qua nhiều <strong>hop</strong> (bước nhảy) trước khi đến đích là Node B.</p>
<p>Như đã thấy khi thảo luận về <strong>overlay-based multicast</strong>, hiệu năng của overlay phụ thuộc vào mức độ khớp giữa topology overlay và mạng underlay. Trong bối cảnh huấn luyện AI, hiệu năng đặc biệt quan trọng vì chúng ta đang truyền một lượng dữ liệu khổng lồ.</p>
<p>Để minh họa tại sao topology overlay quan trọng, giả sử có 4 nút muốn chạy AllReduce. Làm thế nào để <strong>đánh số</strong> các nút nhằm đạt hiệu năng tốt nhất?</p>
<p>Trước hết, lưu ý rằng <strong>bất kỳ cách đánh số nào</strong> cũng sẽ cho ra kết quả AllReduce đúng. Nói cách khác, bất kỳ nút nào cũng có thể là Node 1, Node 2, v.v. (Điều này không đúng với tất cả các thao tác collective, nhưng đúng với AllReduce.)</p>
<p>Dưới đây là hai cách đánh số nút:</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-120-ring-overlay-2.png">
<p>Cách đầu tiên dẫn đến <strong>average stretch</strong> (độ giãn trung bình) là 3.5. Đặc biệt, hãy chú ý rằng các liên kết ảo C–D và B–A phải đi qua nhiều liên kết trong mạng underlay.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-121-ring-overlay-3.png">
<p>Ngược lại, cách thứ hai dẫn đến average stretch là 2.5. Tập hợp các liên kết ảo này đặt các liên kết liền kề trong vòng gần nhau hơn.</p>
<img width="900px" src="beyond-client-server/../assets/beyond-client-server/7-122-ring-overlay-4.png">
<p>Nói chung, để tối ưu hiệu năng của AllReduce dạng vòng, chúng ta muốn các nút liền kề (ví dụ: Node $$i$$ và Node $$i+1$$) gần nhau trong mạng.</p>
<p>Sơ đồ này minh họa một topology underlay bất kỳ, nhưng ý tưởng tương tự áp dụng cho các topology dạng <strong>datacenter-like</strong> (giống trung tâm dữ liệu) được sử dụng trong huấn luyện AI. Hãy nhớ rằng trong các topology này, một số nút có kết nối hiệu năng rất cao (ví dụ: hai GPU trên cùng một máy), trong khi các nút khác có kết nối kém hơn (ví dụ: hai GPU ở các rack khác nhau).</p>
<p>Các tác vụ huấn luyện AI có tính dự đoán, và topology cơ sở hạ tầng là cố định và có cấu trúc. Điều này có nghĩa là chúng ta có nhiều cơ hội để tối ưu hiệu năng của tác vụ huấn luyện. Ví dụ: chúng ta có thể gán các tác vụ cụ thể cho các nút cụ thể, sao cho các thao tác collective được thực hiện trên các nút gần nhau (ví dụ: tất cả các nút trong cùng một rack). Việc tìm cách tối ưu hóa các tác vụ huấn luyện AI là một lĩnh vực nghiên cứu đang rất sôi động.</p>
<h2 id="các-lớp-trừu-tượng-layers-of-abstraction"><a class="header" href="#các-lớp-trừu-tượng-layers-of-abstraction"><strong>Các lớp trừu tượng</strong> (Layers of Abstraction)</a></h2>
<p>Tóm lại, bạn có thể hình dung các thao tác collective ở <strong>ba lớp trừu tượng</strong>:</p>
<ol>
<li>
<p><strong>Definitions</strong> (Định nghĩa): Ở lớp trừu tượng cao nhất, chúng ta định nghĩa thao tác bằng cách chỉ rõ đầu vào và đầu ra mong đợi. User chỉ cần hiểu các định nghĩa này để sử dụng collective, mà không cần biết cách triển khai.</p>
</li>
<li>
<p><strong>Overlay</strong>: Giảm xuống một lớp trừu tượng, chúng ta xem xét dữ liệu được trao đổi trong the overlay topology. At this level, you can assume that the nodes are organized in a useful topology (e.g. tree or ring), and can send data along virtual links in that topology.</p>
</li>
<li>
<p>Underlay. At the lowest level of abstraction, we think about how the virtual links (overlay) correspond to actual physical links in the underlay. When Node 5 sends a vector to Node 4, that vector actually has to be forwarded across several physical routers and links.</p>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="kết-nối-không-dây-wireless-links"><a class="header" href="#kết-nối-không-dây-wireless-links">Kết nối Không dây (Wireless Links)</a></h1>
<h2 id="giới-thiệu-về-công-nghệ-không-dây-wireless-technologies"><a class="header" href="#giới-thiệu-về-công-nghệ-không-dây-wireless-technologies">Giới thiệu về Công nghệ Không dây (Wireless Technologies)</a></h2>
<p>Các công nghệ truyền thông không dây thực tế đã xuất hiện trước cả Internet. Vào những năm 1880, thiết bị <strong>photophone</strong> (Bell và Tainter) đã thử nghiệm gửi dữ liệu không dây bằng cách sử dụng chùm ánh sáng. Vào những năm 1890, <strong>wireless telegraph</strong> (Marconi) đã thử nghiệm gửi dữ liệu bằng sóng vô tuyến (radio waves). Cũng trong những năm 1890, đã có các thí nghiệm với <strong>millimeter waves</strong> (sóng milimet) của Bose, và ngày nay, sóng milimet đang trở thành một lĩnh vực nghiên cứu sôi động trở lại.</p>
<p>Về mặt khái niệm, bạn có thể hình dung rằng truyền thông không dây bao gồm các hạt vô hình di chuyển dọc theo một liên kết tưởng tượng từ điểm A đến điểm B, nhưng thực tế thì không hoàn toàn chính xác như vậy. Thực tế, truyền thông không dây giống như những gợn sóng trên mặt hồ. Khi bạn truyền dữ liệu không dây, bạn tạo ra các gợn sóng lan tỏa ra ngoài và yếu dần theo khoảng cách. Nếu những người khác cũng đang truyền dữ liệu, các gợn sóng này có thể giao thoa cộng hưởng hoặc triệt tiêu lẫn nhau. Các gợn sóng cũng có thể phản xạ hoặc khúc xạ khi gặp các vật thể như thuyền trên hồ hoặc bờ hồ.</p>
<img width="500px" src="wireless/../assets/wireless/8-001-wireless-intro.png">
<p>Trong phần này, chúng ta sẽ xem xét bốn điểm khác biệt chính giữa truyền thông có dây và không dây. Các khác biệt này chủ yếu ảnh hưởng đến <strong>Layer 1 (Physical)</strong> và <strong>Layer 2 (Link)</strong>, với một vài ngoại lệ mà chúng ta sẽ tìm hiểu sau (đáng chú ý là việc phá vỡ <strong>End-to-end Principle</strong> (Nguyên tắc đầu-cuối) và triển khai cơ chế đảm bảo độ tin cậy ở Layer 2 để cải thiện hiệu năng).</p>
<p><strong>Khác biệt 1:</strong> Kết nối không dây về bản chất là môi trường dùng chung. Kết nối có dây thì không.</p>
<p><strong>Khác biệt 2:</strong> Tín hiệu không dây yếu dần khi khoảng cách tăng. Tín hiệu có dây thì không.</p>
<p><strong>Khác biệt 3:</strong> Môi trường không dây có thể thay đổi nhanh chóng. Môi trường có dây thì không.</p>
<p><strong>Khác biệt 4:</strong> Việc phát hiện va chạm gói tin (packet collisions) trong hệ thống không dây khó hơn nhiều.</p>
<h2 id="khác-biệt-không-dây-là-môi-trường-dùng-chung-shared-medium"><a class="header" href="#khác-biệt-không-dây-là-môi-trường-dùng-chung-shared-medium">Khác biệt: Không dây là môi trường dùng chung (Shared Medium)</a></h2>
<p><strong>Khác biệt 1:</strong> Kết nối không dây về bản chất là môi trường dùng chung. Kết nối có dây thì không.</p>
<p>Các kết nối có dây mặc định là kết nối riêng (point-to-point). Trực quan mà nói, một sợi dây kết nối hai thiết bị. Việc tạo ra một <strong>multi-point bus</strong> (bus đa điểm), nơi một sợi dây được kết nối với nhiều thiết bị, đòi hỏi thêm công đoạn. Tín hiệu bên ngoài khó có thể gây nhiễu cho tín hiệu trên dây (ví dụ: chúng ta có thể bọc lớp chắn quanh dây). Trên dây, chúng ta sử dụng tín hiệu điện để truyền dữ liệu (ví dụ: điện áp cao biểu thị 1, điện áp thấp biểu thị 0).</p>
<p>Kết nối không dây có đặc tính ngược lại. Mặc định, kết nối không dây là môi trường dùng chung. Trực quan mà nói, nếu bạn truyền một tín hiệu, tín hiệu đó sẽ lan tỏa ra mọi hướng. Việc tạo ra một kết nối riêng point-to-point giữa hai máy chủ đòi hỏi thêm công đoạn. Khó có thể che chắn tín hiệu khỏi nhiễu bên ngoài. Thay vì tín hiệu điện, chúng ta mã hóa các bit bằng sóng vô tuyến (radio waves) để truyền dữ liệu.</p>
<h2 id="mã-hóa-dữ-liệu-qua-kết-nối-không-dây-encoding-data-over-wireless-link"><a class="header" href="#mã-hóa-dữ-liệu-qua-kết-nối-không-dây-encoding-data-over-wireless-link">Mã hóa dữ liệu qua kết nối không dây (Encoding Data over Wireless Link)</a></h2>
<p>Làm thế nào để chúng ta mã hóa dữ liệu vào sóng điện từ ở <strong>Layer 1</strong>? Chúng ta có thể lấy chuỗi 1 và 0 và vẽ nó thành dạng sóng, nhưng dạng sóng thu được thường có tần số thấp, và tín hiệu tần số thấp thì yếu và khó truyền.</p>
<img width="500px" src="wireless/../assets/wireless/8-002-modulation1.png">
<p>Thay vào đó, chúng ta phải sử dụng <strong>modulation</strong> (điều chế) để truyền dữ liệu. Chúng ta bắt đầu với <strong>carrier signal</strong> (tín hiệu sóng mang), vốn là một sóng có tần số cố định (ví dụ: sóng sin). Sóng này không mang thông tin, nhưng có tần số cao nên dễ truyền hơn. Sau đó, chúng ta chồng tín hiệu dữ liệu (còn gọi là <strong>modulation signal</strong> – tín hiệu điều chế) lên trên sóng mang. Dạng sóng thu được vừa có tần số cao (dễ truyền), vừa chứa dữ liệu cần gửi. Lưu ý rằng phía thu sẽ cần tách dạng sóng đã điều chế để khôi phục lại chuỗi 1 và 0.</p>
<p>Có nhiều chiến lược điều chế tín hiệu dữ liệu lên sóng mang. Trong <strong>amplitude modulation (AM)</strong> (điều chế biên độ), chúng ta thay đổi độ cao của sóng mang dựa trên tín hiệu đầu vào. Để truyền bit 1, làm sóng sin cao; để truyền bit 0, làm sóng sin thấp. Trong <strong>frequency modulation (FM)</strong> (điều chế tần số), chúng ta thay đổi tần số (độ rộng) của sóng mang dựa trên tín hiệu đầu vào. Để truyền bit 1, làm sóng sin hẹp (tần số cao hơn); để truyền bit 0, làm sóng sin rộng (tần số thấp hơn). Ngoài ra còn có các chiến lược điều chế phức tạp hơn, như <strong>phase modulation</strong> (điều chế pha), hoặc kết hợp giữa điều chế biên độ và điều chế pha.</p>
<img width="900px" src="wireless/../assets/wireless/8-003-modulation2.png">
<h2 id="nhiễu-và-can-nhiễu-noise-and-interference"><a class="header" href="#nhiễu-và-can-nhiễu-noise-and-interference">Nhiễu và can nhiễu (Noise and Interference)</a></h2>
<p>Vì kết nối không dây là môi trường dùng chung, chúng ta cần xử lý <strong>noise</strong> (nhiễu) và <strong>interference</strong> (can nhiễu), những yếu tố có thể làm hỏng tín hiệu nhận được. Nhiễu luôn tồn tại, ngay cả khi không có ai khác gần đó đang truyền dữ liệu. (Ví dụ: ngay cả khi không ai xung quanh bạn nói chuyện, vẫn có tiếng ồn môi trường từ thiên nhiên.) Nhiễu nền này được gọi là <strong>noise floor</strong> (mức nhiễu nền). Ngược lại, can nhiễu đề cập đến việc các bộ phát khác cố tình gửi tín hiệu gây nhiễu cho tín hiệu của chúng ta.</p>
<p><strong>SINR (Signal to Interference and Noise Ratio)</strong> là một chỉ số dùng để đo chất lượng kết nối không dây tại phía thu. Đúng như tên gọi, SINR là công suất của tín hiệu chia cho tổng công suất của can nhiễu và nhiễu.</p>
<p>$$\text{SINR} = \frac{P_\text{signal}}{P_\text{interference} + P_\text{noise}}$$</p>
<p>SINR là một đại lượng không thứ nguyên, vì nó là tỷ số của hai giá trị. Nó cũng có thể được biểu diễn theo đơn vị <strong>decibel (dB)</strong>, là cách đo tỷ số theo thang logarit. Ở mức 0 dB, tỷ số là 1, và khi SINR tăng thêm 10 dB, tỷ số thực tế lớn hơn gấp 10 lần (ví dụ: tín hiệu mạnh hơn gấp 10 lần, hoặc nhiễu/can nhiễu yếu hơn gấp 10 lần).</p>
<img width="400px" src="wireless/../assets/wireless/8-004-decibels.png">
<p>$$\text{SINR}<em>\text{dB} = 10 \cdot \log</em>{10}\left(\frac{P_\text{signal}}{P_\text{interference} + P_\text{noise}}\right)$$</p>
<p>Phương trình này cho chúng ta biết rằng nếu có nhiều nhiễu hơn, chúng ta phải truyền tín hiệu với công suất lớn hơn. Ngoài ra, có thể áp dụng <strong>coding gain</strong> (lợi ích từ mã hóa – ví dụ: mã sửa lỗi), để ngay cả khi tín hiệu yếu và bị trộn lẫn với nhiễu và can nhiễu, chúng ta vẫn gửi tín hiệu với đủ dữ liệu dự phòng để phía thu có thể khôi phục lại tín hiệu.</p>
<p><strong>Dung lượng Shannon</strong> (<strong>Shannon capacity</strong>) đưa ra giới hạn lý thuyết về lượng dữ liệu tối đa có thể truyền qua một kênh trong một đơn vị thời gian, với mức nhiễu (<strong>noise</strong>) và can nhiễu (<strong>interference</strong>) nhất định trên kênh đó. Công thức này áp dụng không chỉ cho các kết nối không dây (<strong>wireless links</strong>), mà còn cho các loại kết nối khác (ví dụ: kết nối có dây).</p>
<p>$$C = B \cdot \log_2(1 + \text{SINR})$$</p>
<p>Trong phương trình này, $$B$$ là <strong>bandwidth</strong> (băng thông) của kênh. $$\text{SINR}$$ là <strong>signal-to-interference-and-noise ratio</strong> (tỷ số tín hiệu trên nhiễu và can nhiễu). $$C$$ là giới hạn lý thuyết về lượng dữ liệu tối đa có thể truyền qua kênh trong một đơn vị thời gian, được đo bằng <strong>bits per second</strong> (bit trên giây). Lưu ý rằng trong phương trình này, băng thông được đo bằng hiệu giữa tần số cao nhất và tần số thấp nhất mà bộ thu có thể hiểu.</p>
<p>Phương trình này cho chúng ta biết rằng khi băng thông tăng, chúng ta có thể truyền nhiều dữ liệu hơn trong một đơn vị thời gian. Nó cũng cho thấy rằng khi SINR tăng (tín hiệu mạnh hơn hoặc ít nhiễu hơn), chúng ta có thể truyền nhiều dữ liệu hơn. Nếu chúng ta cần một kết nối với dung lượng mục tiêu cụ thể (ví dụ: 1 Mbps), chúng ta có thể thay các thông số vật lý của kết nối vào phương trình này để kiểm tra xem kết nối có đáp ứng được dung lượng mong muốn hay không.</p>
<p>Ví dụ, hãy xét hệ thống điện thoại cố định truyền thống (<strong>plain old telephone system</strong>). Hệ thống này có băng thông 3 kHz, nghĩa là điện thoại có thể xử lý các tần số từ 300 Hz đến 3300 Hz. Ngoài ra, hệ thống này có SINR xấp xỉ 20 dB, tương đương tỷ số 100 (0 dB = 1x, 10 dB = 10x, 20 dB = 100x, 30 dB = 1000x, v.v.). Thay các giá trị này vào phương trình, ta có:</p>
<p>$$C = 4000 \cdot \log_2(1 + 100) \approx 20000$$</p>
<p>Điều này cho thấy hệ thống điện thoại có thể truyền khoảng 20 kbps (<strong>kilobits per second</strong> – kilobit trên giây).</p>
<h2 id="khác-biệt-attenuation-suy-hao-tín-hiệu"><a class="header" href="#khác-biệt-attenuation-suy-hao-tín-hiệu">Khác biệt: <strong>Attenuation</strong> (Suy hao tín hiệu)</a></h2>
<p>Tín hiệu không dây (<strong>wireless signals</strong>) yếu đi đáng kể khi khoảng cách tăng. Ngược lại, tín hiệu có dây (<strong>wired signals</strong>) cũng yếu đi theo khoảng cách, nhưng mức độ nhỏ hơn nhiều. Trong các hệ thống không dây, thiết kế phải tính đến hiện tượng suy hao tín hiệu, trong khi ở hệ thống có dây, suy hao thường không phải là yếu tố thiết kế chính.</p>
<p>Điều này tạo ra một sự đánh đổi cơ bản khi thiết kế hệ thống không dây: chúng ta muốn tối đa hóa hiệu năng bằng cách làm cho kết nối chính xác, nhanh và có tầm xa; nhưng đồng thời muốn giảm thiểu việc sử dụng tài nguyên bằng cách tiết kiệm năng lượng (ví dụ: pin laptop) và sử dụng ít phổ tần (<strong>frequency spectrum</strong>) hơn (việc cấp phép phổ tần có thể tốn kém). Tuy nhiên, để có tín hiệu tốt hơn, cần nhiều công suất hơn hoặc băng thông tần số lớn hơn.</p>
<h2 id="free-space-model-mô-hình-không-gian-tự-do"><a class="header" href="#free-space-model-mô-hình-không-gian-tự-do"><strong>Free Space Model</strong> (Mô hình không gian tự do)</a></h2>
<p>Một cách đơn giản để mô hình hóa suy hao tín hiệu là <strong>free-space model</strong> (mô hình không gian tự do, còn gọi là <strong>line-of-sight model</strong> – mô hình đường thẳng tầm nhìn), trong đó giả định rằng bộ phát (<strong>transmitter</strong>) và bộ thu (<strong>receiver</strong>) tồn tại trong một môi trường hoàn toàn trống rỗng. Tín hiệu lan tỏa ra mọi hướng, không có vật cản (ngay cả bề mặt Trái Đất).</p>
<p>Trong mô hình này, công suất tín hiệu tỉ lệ nghịch với bình phương khoảng cách giữa bộ phát và bộ thu, theo <strong>inverse-square law</strong> (định luật nghịch đảo bình phương):</p>
<p>$$P_r \propto \frac{P_t}{d^2}$$</p>
<p>Trong phương trình này, $$P_r$$ là công suất tại bộ thu, $$P_t$$ là công suất tại bộ phát, và $$d$$ là khoảng cách giữa bộ phát và bộ thu. Nếu khoảng cách tăng gấp đôi, tín hiệu tại bộ thu sẽ yếu đi còn $$1/4$$. Nếu khoảng cách tăng gấp 10 lần, tín hiệu tại bộ thu sẽ yếu đi còn $$1/100$$.</p>
<img width="200px" src="wireless/../assets/wireless/8-005-freespace1.png">
<p>Trực quan mà nói, định luật nghịch đảo bình phương áp dụng ở đây vì tín hiệu lan tỏa ra mọi hướng. Tại một thời điểm, tín hiệu đã lan ra thành một hình cầu bao quanh bộ phát, và hình cầu này lớn dần khi tín hiệu lan xa hơn. Diện tích bề mặt của hình cầu bán kính $$r$$ là $$4\pi r^2$$, vì vậy khi tín hiệu lan ra, nó được phân bố trên một diện tích tăng theo bình phương khoảng cách. Ví dụ, khi khoảng cách tăng gấp đôi, diện tích bề mặt hình cầu tăng gấp 4 lần, do đó tín hiệu yếu đi còn $$1/4$$.</p>
<img width="300px" src="wireless/../assets/wireless/8-006-freespace2.png">
<p>Ngoài khoảng cách, chúng ta cũng cần xem xét loại <strong>antenna</strong> (ăng-ten) được sử dụng ở bộ phát và bộ thu. Điều này dẫn đến <strong>Friis equation</strong> (phương trình Friis) để đo cường độ tín hiệu theo khoảng cách:</p>
<p>$$\begin{align*}
P_r &amp;= P_t \cdot G_t \cdot G_r \cdot \left(\frac{\lambda^2}{4\pi}\right) \left(\frac{1}{4\pi d^2}\right) \
&amp;= P_t \cdot G_t \cdot G_r \cdot \left(\frac{\lambda}{4\pi d}\right)^2 \
\end{align*}$$</p>
<p>Trong phương trình này, $$P_r$$ là công suất tại bộ thu, $$P_t$$ là công suất tại bộ phát. $$G_t$$ là <strong>gain</strong> (độ lợi) của bộ phát, $$G_r$$ là độ lợi của bộ thu. $$\lambda$$ là <strong>wavelength</strong> (bước sóng), được dùng để biểu diễn diện tích hiệu dụng của ăng-ten. $$d$$ là khoảng cách giữa các ăng-ten.</p>
<p>Ý nghĩa của phương trình: để tính công suất tín hiệu tại bộ thu, bắt đầu từ công suất tại bộ phát $$P_t$$, nhân với độ lợi của hai ăng-ten $$G_t$$ và $$G_r$$. Độ lợi cao hơn nghĩa là ăng-ten tốt hơn trong việc phát hoặc thu tín hiệu.</p>
<p>Như đã thấy, khoảng cách ảnh hưởng đến cường độ tín hiệu theo định luật nghịch đảo bình phương, giải thích cho thành phần $$\frac{1}{4\pi d^2}$$.</p>
<p>Thành phần $$\frac{\lambda^2}{4\pi}$$ liên quan đến <strong>aperture</strong> (diện tích hiệu dụng) của ăng-ten thu. Trực quan, nếu bạn chiếu ánh sáng vào một tờ giấy, ánh sáng sẽ chiếu vào tờ giấy đó; nếu tờ giấy lớn hơn, nhiều ánh sáng hơn sẽ chiếu vào. Diện tích hiệu dụng của ăng-ten có thể tính bằng $$\frac{\lambda^2}{4\pi}$$. Lưu ý rằng $$(4\pi)^2$$ trong phương trình xuất phát từ hai yếu tố $$4\pi$$: một từ định luật nghịch đảo bình phương và một từ công thức diện tích hiệu dụng.</p>
<p>Chúng ta cũng có thể viết lại phương trình Friis bằng cách chia cả hai vế cho $$P_t$$:</p>
<p>$$\frac{P_r}{P_t} = G_t \cdot G_r \cdot \left(\frac{\lambda}{4\pi d}\right)^2$$</p>
<p>Phương trình này cho thấy tỷ lệ công suất tín hiệu tại bộ thu so với bộ phát (ví dụ: bằng một nửa, hoặc $$1/100$$ so với công suất tại bộ phát) phụ thuộc vào độ lợi của ăng-ten, nghịch đảo bình phương khoảng cách, và diện tích hiệu dụng của ăng-ten.</p>
<p>Một cách khác để viết phương trình Friis là lấy logarit hai vế, cho phép biểu diễn công suất và độ lợi theo đơn vị <strong>decibel (dB)</strong>:</p>
<p>$$P_r^\text{dB} = P_t^\text{dB} + G_t^\text{dB} + G_r^\text{dB} + 20 \log_{10} \left(\frac{\lambda}{4\pi d}\right)$$</p>
<p>Mô hình không gian trống là một mô hình lý thuyết hữu ích để đo lường cường độ tín hiệu lý tưởng tại bộ thu, tuy nhiên trên thực tế, các chướng ngại vật vật lý (ví dụ: bề mặt Trái Đất) ngăn cản chúng ta đạt được giá trị lý tưởng này.</p>
<h2 id="link-budget-ngân-sách-liên-kết"><a class="header" href="#link-budget-ngân-sách-liên-kết"><strong>Link Budget</strong> (Ngân sách liên kết)</a></h2>
<p>Nếu tín hiệu yếu dần theo khoảng cách, làm thế nào để biết một liên kết có thực sự hoạt động hay không? Nói cách khác, làm thế nào để biết bộ thu (<strong>receiver</strong>) có thể phát hiện được một tín hiệu đủ rõ ràng để giải mã hay không?</p>
<p>Để đo lường khả năng hoạt động của một liên kết, chúng ta có thể tính <strong>link budget</strong> (ngân sách liên kết), bao gồm tất cả các <strong>gains</strong> (độ lợi) và <strong>losses</strong> (suy hao) trên đường truyền.</p>
<p>$$P_r^\text{dB} = P_t^\text{dB} + \sum \text{gains} - \sum \text{losses}$$</p>
<p>Trong phương trình này, $$P_r$$ là công suất tín hiệu tại bộ thu, và $$P_t$$ là công suất tín hiệu tại bộ phát (<strong>sender</strong>). Tất cả các độ lợi (ví dụ: độ lợi ăng-ten cao hơn) sẽ cộng vào ngân sách liên kết, và tất cả các suy hao (ví dụ: <strong>path loss</strong> – suy hao đường truyền do khoảng cách xa) sẽ trừ khỏi ngân sách liên kết.</p>
<p>Cộng tất cả độ lợi và trừ tất cả suy hao sẽ cho chúng ta biết cường độ tín hiệu tại bộ thu. Chúng ta có thể so sánh giá trị này với <strong>receiver sensitivity</strong> (độ nhạy của bộ thu) – tức là mức tín hiệu tối thiểu mà bộ thu cần để trích xuất thông tin hữu ích. So sánh này cho ra <strong>link budget</strong>. Nếu ngân sách tổng thể dương, liên kết khả thi và có thể hoạt động tốt. Nếu ngân sách âm, liên kết không khả thi.</p>
<p>Lưu ý rằng <strong>link budget</strong> được tính theo đơn vị <strong>decibel (dB)</strong>, là thang đo logarit. Điều này cho phép chúng ta sử dụng phép cộng và trừ thay vì nhân và chia. Ví dụ: độ lợi công suất gấp 1000 lần được biểu diễn bằng cách cộng 30 dB, và suy hao xuống còn 1% công suất được biểu diễn bằng cách trừ 20 dB.</p>
<img width="900px" src="wireless/../assets/wireless/8-007-link-budget.png">
<p><strong>Ví dụ:</strong> Công suất tín hiệu tại bộ phát là 10 dB. Tín hiệu đi qua một đoạn cáp, một <strong>lightning arrestor</strong> (thiết bị chống sét – bạn không cần biết chi tiết), và một đoạn cáp khác, lần lượt mất 0,44 dB, 0,1 dB và 2,21 dB. Sau đó, tín hiệu được phát qua ăng-ten, tăng thêm 25 dB. Tín hiệu truyền qua 10 km không gian, mất 120 dB. Tín hiệu được thu bởi ăng-ten, tăng thêm 25 dB. Sau đó, tín hiệu đi qua thêm các đoạn cáp, mất 0,44 dB, 0,1 dB và 2,21 dB, trước khi đến bộ thu. Cộng tất cả độ lợi và trừ tất cả suy hao, ta tính được công suất tín hiệu tại bộ thu là -65,5 dB.</p>
<p>So sánh với độ nhạy bộ thu là -80 dB: bộ thu có thể nhận bất kỳ tín hiệu nào mạnh hơn -80 dB. Vì -65,5 dB &gt; -80 dB, <strong>link budget</strong> là dương, và liên kết sẽ hoạt động.</p>
<p><strong>Link margin</strong> (biên độ liên kết) là hiệu giữa công suất tín hiệu tại bộ thu và độ nhạy của bộ thu. Nếu nhận được tín hiệu 30 dB và độ nhạy cho phép phát hiện tín hiệu trên 10 dB, thì link margin là 20 dB. Trong ví dụ trên, link margin là 14,5 dB.</p>
<p><strong>Link margin</strong> cho biết chất lượng của liên kết. Nếu link margin âm, liên kết sẽ không hoạt động và tín hiệu sẽ không được nhận. Link margin càng cao càng tốt, vì tín hiệu sẽ ổn định và ít bị ảnh hưởng bởi nhiễu hoặc các vấn đề khác.</p>
<h2 id="khác-biệt-environments-change-môi-trường-thay-đổi"><a class="header" href="#khác-biệt-environments-change-môi-trường-thay-đổi">Khác biệt: <strong>Environments Change</strong> (Môi trường thay đổi)</a></h2>
<p>Môi trường không dây (<strong>wireless environment</strong>) có thể thay đổi nhanh chóng. Các thiết bị có thể di chuyển. Môi trường có thể thay đổi (ví dụ: một vật cản xuất hiện giữa các thiết bị). Các kết nối khác có thể bắt đầu gây nhiễu cho liên lạc của chúng ta.</p>
<p>Trong <strong>free-space model</strong> (mô hình không gian tự do) đã đề cập trước đó, khoảng cách $$d$$ giữa các thiết bị được coi là hằng số. Nhưng nếu thiết bị di chuyển thì sao? Chúng ta cũng giả định không có vật cản và không có tín hiệu gây nhiễu. Vậy mô hình sẽ thay đổi thế nào khi có các yếu tố này?</p>
<p>Trong <strong>free-space model</strong>, giả sử ăng-ten không đổi (cùng độ lợi, cùng diện tích hiệu dụng), chúng ta có đồ thị mượt mà, trong đó cường độ tín hiệu giảm dần khi khoảng cách tăng. Khi tính đến môi trường thay đổi, đồ thị khoảng cách – cường độ tín hiệu trở nên dao động mạnh hơn.</p>
<img width="900px" src="wireless/../assets/wireless/8-008-obstacle1.png">
<p>Đồ thị này thực chất là tổng của ba đồ thị nhỏ hơn, mỗi đồ thị thể hiện một đặc tính môi trường ảnh hưởng đến cường độ tín hiệu theo khoảng cách. Một số đặc tính thay đổi chậm khi khoảng cách tăng, trong khi một số thay đổi nhanh và thất thường.</p>
<img width="900px" src="wireless/../assets/wireless/8-009-obstacle2.png">
<ol>
<li><strong>Free-space path loss</strong> – suy hao đường truyền trong không gian tự do: tín hiệu giảm chậm và đều theo khoảng cách, tuân theo <strong>inverse-square law</strong> (định luật nghịch đảo bình phương).</li>
<li><strong>Shadowing</strong> – hiện tượng bóng che: xảy ra khi vật cản vật lý nằm giữa bộ phát và bộ thu chặn tín hiệu. Tín hiệu phải khúc xạ hoặc phản xạ để đi vòng qua vật cản, khiến tín hiệu đến bộ thu yếu hơn. Khi di chuyển, tín hiệu có thể yếu đi hoặc mạnh lên tùy vị trí vật cản.</li>
<li><strong>Multipath fading</strong> – hiện tượng suy giảm đa đường: xảy ra khi sóng phản xạ và khúc xạ trên các vật cản, tạo ra các bản sao tín hiệu đến bộ thu với độ trễ khác nhau. Nếu các tín hiệu này lệch pha, chúng có thể gây giao thoa và làm suy yếu tín hiệu.</li>
</ol>
<p><strong>Multipath fading</strong> có thể gây ra biến đổi rất nhỏ nhưng rõ rệt trong cường độ tín hiệu – chỉ cần thay đổi khoảng cách một chút cũng có thể làm tín hiệu mạnh hơn hoặc yếu đi.</p>
<p>Khi xét cả ba yếu tố này cùng lúc, đồ thị tổng thể sẽ thể hiện sự biến thiên phức tạp của tín hiệu theo khoảng cách. Nếu thiết bị đứng yên, tín hiệu sẽ ở một điểm cố định trên đồ thị; nếu di chuyển, tín hiệu sẽ thay đổi theo đường cong này. Khi môi trường thay đổi (vật cản xuất hiện hoặc biến mất), bản thân đồ thị cũng thay đổi.</p>
<h2 id="approximating-path-loss-xấp-xỉ-suy-hao-đường-truyền"><a class="header" href="#approximating-path-loss-xấp-xỉ-suy-hao-đường-truyền"><strong>Approximating Path Loss</strong> (Xấp xỉ suy hao đường truyền)</a></h2>
<p>Việc xấp xỉ <strong>path loss</strong> (suy hao đường truyền) từ <strong>free-space loss</strong>, <strong>shadowing</strong> và <strong>multipath fading</strong> là rất khó, đặc biệt khi có vật cản khiến tín hiệu đi theo nhiều đường khác nhau và gây giao thoa lệch pha tại bộ thu.</p>
<p>Một mô hình đơn giản hơn để xấp xỉ suy hao là <strong>two-ray model</strong> (mô hình hai tia). Trong mô hình này, tín hiệu truyền theo hai đường: một đường thẳng <strong>line-of-sight</strong> (tầm nhìn thẳng) từ bộ phát đến bộ thu, và một đường phản xạ từ mặt đất (<strong>ground-bounce</strong>) đến bộ thu. Đây vẫn là một tín hiệu phát ra từ bộ phát, nhưng một phần sóng đến trực tiếp, phần khác phản xạ từ mặt đất.</p>
<img width="900px" src="wireless/../assets/wireless/8-010-obstacle3.png">
<p>Nếu khoảng cách đủ xa, hai sóng từ hai đường sẽ lệch pha 180°, gây giao thoa triệt tiêu (<strong>destructive interference</strong>) và làm tín hiệu tại bộ thu yếu đi đáng kể. Khi đó, cường độ tín hiệu không còn tỉ lệ với $$1/d^2$$ mà tỉ lệ với $$1/d^4$$ – tức là suy giảm nhanh hơn nhiều khi khoảng cách tăng.</p>
<p>Trong <strong>free-space model</strong>, không tính đến vật cản (kể cả bề mặt Trái Đất), nên tín hiệu tỉ lệ với $$1/d^2$$. Trong <strong>two-ray model</strong>, tính đến bề mặt Trái Đất khiến tín hiệu tỉ lệ với $$1/d^4$$.</p>
<img width="900px" src="wireless/../assets/wireless/8-011-obstacle4.png">
<p>Nếu tồn tại các vật cản khác ngoài bề mặt Trái Đất, <strong>two-ray model</strong> (mô hình hai tia) sẽ không tính đến chúng. Trong các môi trường phức tạp hơn, chúng ta có thể xây dựng <strong>general ray tracing models</strong> (mô hình dò tia tổng quát), mô phỏng việc tín hiệu bị phản xạ (<strong>reflected</strong>), tán xạ (<strong>scattered</strong>) và nhiễu xạ (<strong>diffracted</strong>). Các mô hình này yêu cầu thông tin chi tiết về môi trường (ví dụ: vị trí các vật cản) và có thể được xây dựng bằng mô phỏng máy tính. Trong các mô hình này, các phiên bản tín hiệu bị phản xạ thường chiếm ưu thế so với tín hiệu truyền thẳng không bị cản (<strong>unobstructed line-of-sight</strong>).</p>
<img width="900px" src="wireless/../assets/wireless/8-012-obstacle5.png">
<p>Từ các mô hình này, chúng ta có thể rút ra một mô hình suy hao đường truyền (<strong>path loss model</strong>) đơn giản hơn, liên hệ giữa khoảng cách và cường độ tín hiệu:</p>
<p>$$P_r = P_t K d^\gamma$$</p>
<p>Trong phương trình này, như trước, $$P_r$$ và $$P_t$$ lần lượt là công suất tín hiệu tại bộ thu (<strong>receiver signal power</strong>) và công suất tín hiệu tại bộ phát (<strong>transmitter signal power</strong>), $$d$$ là khoảng cách.</p>
<p>$$K$$ và $$\gamma$$ là các hằng số được xác định thực nghiệm, dựa trên môi trường và mô hình. Ví dụ, nếu có nhiều vật cản đặt ở vị trí bất lợi, $$K$$ có thể rất nhỏ, khiến tín hiệu tại bộ thu yếu.</p>
<p>Trong thực tế, $$\gamma$$ nằm trong khoảng từ 2 đến 8. Trong trường hợp tốt nhất, cường độ tín hiệu tỉ lệ với $$1/d^2$$, tương tự <strong>free-space model</strong> (mô hình không gian tự do). Trong trường hợp xấu nhất, cường độ tín hiệu tỉ lệ với $$1/d^8$$, và tín hiệu yếu đi nhanh hơn nhiều khi khoảng cách tăng.</p>
<h2 id="khác-biệt-detecting-collisions-phát-hiện-va-chạm"><a class="header" href="#khác-biệt-detecting-collisions-phát-hiện-va-chạm">Khác biệt: <strong>Detecting Collisions</strong> (Phát hiện va chạm)</a></h2>
<p>Trong kết nối có dây (<strong>wired</strong>), việc phát hiện va chạm (<strong>collision</strong>) thường dễ dàng. Trên một kết nối <strong>point-to-point</strong> (điểm-điểm), va chạm có thể không xảy ra. Chúng ta thường có thể phát hiện va chạm chỉ bằng cách cảm nhận tín hiệu trên dây. Có thể tồn tại vấn đề về <strong>propagation delay</strong> (độ trễ lan truyền), nhưng về cơ bản, chỉ có một tín hiệu trên dây cần được cảm nhận.</p>
<p>Ngược lại, trong kết nối không dây (<strong>wireless</strong>), việc phát hiện va chạm khó hơn nhiều, vì va chạm còn phụ thuộc vào yếu tố không gian. Sóng có thể va chạm ở một vị trí nhưng không va chạm ở vị trí khác.</p>
<img width="500px" src="wireless/../assets/wireless/8-013-collision1.png">
<p>Thiết kế cơ chế phát hiện và tránh va chạm (<strong>collision detection</strong> và <strong>collision avoidance</strong>) trong hệ thống không dây phức tạp hơn, nhưng vẫn cần thiết để nhiều thiết bị có thể truyền trên cùng một môi trường dùng chung (<strong>shared medium</strong>). Có nhiều phương pháp <strong>multiple access</strong> (truy nhập đa điểm), bao gồm phân bổ tần số cố định (<strong>fixed frequency allocation</strong>) hoặc điều phối thời gian truyền. Phương pháp nào hiệu quả nhất phụ thuộc vào môi trường. Ví dụ, ở nơi hẻo lánh, có thể chấp nhận để va chạm xảy ra và xử lý sau. Trong phần này, chúng ta tập trung vào phương pháp <strong>CSMA (Carrier Sense Multiple Access)</strong> – cảm nhận sóng mang và không truyền nếu phát hiện có thiết bị khác đang truyền.</p>
<p>Để đơn giản, trong phần này, chúng ta bỏ qua vật cản, nghĩa là tín hiệu lan tỏa ra mọi hướng. Giả sử tín hiệu lan truyền đến một khoảng cách nhất định với cường độ tối đa, và không thể phát hiện được ngoài khoảng cách đó. Ngoài ra, trong các ví dụ minh họa, giả sử tất cả thiết bị được bố trí trên một đường thẳng, nên chỉ cần xét tín hiệu lan sang trái và phải. Trong thực tế, tín hiệu lan tỏa trong không gian ba chiều.</p>
<h2 id="vấn-đề-với-csma"><a class="header" href="#vấn-đề-với-csma">Vấn đề với <strong>CSMA</strong></a></h2>
<p>Để kiểm tra xem có thiết bị khác đang truyền hay không, bộ thu phát (<strong>radio</strong>) sẽ cố gắng phát hiện năng lượng vượt quá một ngưỡng nhất định. Nếu phát hiện, kết luận rằng có thiết bị khác đang truyền.</p>
<p>Chiến lược này hoạt động tốt nếu hai cặp thiết bị ở xa nhau.</p>
<img width="800px" src="wireless/../assets/wireless/8-014-collision2.png">
<p>Ví dụ: A và B muốn liên lạc, C và D cũng muốn liên lạc. A không phát hiện tín hiệu nào và bắt đầu truyền cho B. Lưu ý rằng tín hiệu của A lan tỏa ra mọi hướng, không chỉ về phía B. Sau đó, C cũng không phát hiện tín hiệu (vì nằm ngoài phạm vi của A), nên bắt đầu truyền cho D.</p>
<p>Chiến lược này cũng hoạt động tốt nếu hai cặp thiết bị ở trong phạm vi của nhau.</p>
<img width="600px" src="wireless/../assets/wireless/8-015-collision3.png">
<p>Ví dụ: A và B muốn liên lạc, C và D cũng muốn liên lạc. A không phát hiện tín hiệu và bắt đầu truyền cho B. Sau đó, C phát hiện tín hiệu (vì A đang truyền và C nằm trong phạm vi), nên C sẽ chờ đến khi A kết thúc mới truyền cho D.</p>
<p>Tuy nhiên, đôi khi chiến lược này gây ra vấn đề.</p>
<img width="700px" src="wireless/../assets/wireless/8-016-collision4.png">
<p>Giả sử A và C đều muốn truyền cho B. A không phát hiện tín hiệu và bắt đầu truyền cho B. Sau đó, C cũng không phát hiện tín hiệu (vì nằm ngoài phạm vi của A), nên cũng bắt đầu truyền cho B. Kết quả là xảy ra va chạm tại B.</p>
<p>Trường hợp này gọi là <strong>hidden terminal problem</strong> (vấn đề nút ẩn). Hai bộ phát (A và C) nằm ngoài phạm vi của nhau, nên không thể phát hiện rằng đang có truyền dữ liệu.</p>
<p>Dưới đây là một trường hợp khác mà <strong>CSMA (Carrier Sense Multiple Access)</strong> gặp vấn đề:</p>
<img width="600px" src="wireless/../assets/wireless/8-017-collision5.png">
<p>Trong trường hợp này, giả sử B muốn truyền dữ liệu cho A, và C muốn truyền dữ liệu cho D. Đầu tiên, B không phát hiện tín hiệu nào và bắt đầu truyền cho A. Hãy nhớ rằng tín hiệu của B lan tỏa ra mọi hướng, bao gồm cả đến C. Lúc này, C muốn truyền cho D nhưng phát hiện tín hiệu của B nên giữ im lặng.</p>
<p>Nếu quan sát kỹ, B và C thực ra có thể truyền đồng thời. Đúng là sẽ có va chạm (<strong>collision</strong>) ở vùng giữa B và C, nhưng các bộ thu (<strong>receiver</strong>) là A và D sẽ không phát hiện bất kỳ va chạm nào.</p>
<p>Trường hợp này được gọi là <strong>exposed terminal problem</strong> (vấn đề nút lộ). Trong tình huống này, hai phiên truyền hoàn toàn có thể diễn ra đồng thời, nhưng một phiên bị ngăn lại vì C phát hiện nhầm là có va chạm.</p>
<h2 id="maca-for-collision-avoidance-maca-để-tránh-va-chạm"><a class="header" href="#maca-for-collision-avoidance-maca-để-tránh-va-chạm"><strong>MACA for Collision Avoidance</strong> (MACA để tránh va chạm)</a></h2>
<p>Thay vì sử dụng CSMA, <strong>MACA (Multiple Access with Collision Avoidance)</strong> là một phương pháp truy nhập đa điểm (<strong>multiple access</strong>) giúp giải quyết <strong>hidden terminal problem</strong> (vấn đề nút ẩn).</p>
<p>Vấn đề chính của CSMA là bộ phát (<strong>sender</strong>) phát hiện va chạm ở phía phát, trong khi vấn đề thực sự là va chạm xảy ra ở phía thu (<strong>receiver</strong>). Để giải quyết, MACA cho phép bộ thu thông báo xem nó có phát hiện va chạm hay không.</p>
<p>Giả sử A muốn gửi dữ liệu cho B. Một phiên truyền dữ liệu thành công gồm 3 bước:</p>
<img width="900px" src="wireless/../assets/wireless/8-018-maca1.png">
<ol>
<li>A gửi một gói <strong>RTS (Request To Send)</strong> kèm độ dài dữ liệu. Đây là cách A nói: “Tôi muốn gửi k bit cho B.”</li>
<li>B gửi lại một gói <strong>CTS (Clear To Send)</strong> kèm độ dài dữ liệu. Điều này báo cho A rằng có thể gửi dữ liệu an toàn và xác nhận rằng không có va chạm ở phía thu. Gói CTS cũng cảnh báo tất cả các thiết bị trong phạm vi của B: “Tôi là B, tôi sắp nhận k bit, vui lòng không truyền trong thời gian này.”</li>
<li>A truyền dữ liệu và B nhận dữ liệu. Cảnh báo CTS đảm bảo tất cả các thiết bị khác trong phạm vi của bộ thu giữ im lặng trong thời gian này.</li>
</ol>
<p>Giao thức này giải quyết được <strong>hidden terminal problem</strong>. Hãy nhớ rằng, trong vấn đề nút ẩn, A và C đều cảm nhận kênh trống và bắt đầu truyền, gây va chạm tại B. Với giao thức này, nếu A gửi RTS, B sẽ gửi CTS, cảnh báo tất cả các thiết bị trong phạm vi của B (bao gồm C) giữ im lặng.</p>
<img width="700px" src="wireless/../assets/wireless/8-019-maca2.png">
<p>Nếu bạn nghe thấy một gói RTS, điều đó có nghĩa là bạn nằm trong phạm vi của bộ phát. Bộ phát sắp lắng nghe CTS. Do đó, bạn cần giữ im lặng và chờ một <strong>time slot</strong> (khoảng thời gian) đủ lâu để không làm nhiễu CTS tại bộ phát bằng dữ liệu của bạn. Nói cách khác, bạn cần giữ im lặng để bộ phát nhận được CTS.</p>
<p>Sau khi RTS được gửi, nếu bạn nghe thấy CTS, điều đó có nghĩa là bạn cũng nằm trong phạm vi của bộ thu, vì vậy bạn cũng phải giữ im lặng trong suốt quá trình truyền dữ liệu. Nếu bạn không nghe thấy CTS, điều đó có nghĩa là bạn nằm ngoài phạm vi của bộ thu và có thể tự do truyền dữ liệu.</p>
<p>Với một số giả định nhất định, giao thức này cũng giải quyết được <strong>exposed terminal problem</strong>. Hãy nhớ rằng, trong vấn đề nút lộ, B đang gửi cho A và C đang gửi cho D. Với CSMA, C phát hiện tín hiệu của B và giữ im lặng, mặc dù thực tế có thể truyền an toàn. Với giao thức này, nếu B gửi RTS, C sẽ trì hoãn một time slot (để tránh làm nhiễu CTS tại B). Sau đó, vì C không nghe thấy CTS, điều này có nghĩa là C nằm ngoài phạm vi của bộ thu (A), nên C có thể bắt đầu truyền cho D một cách an toàn.</p>
<img width="900px" src="wireless/../assets/wireless/8-020-maca3.png">
<p>Giả định để điều này hoạt động là C phải nghe được CTS từ D. Hãy nhớ rằng, ngay cả khi C là bộ phát, nó phải nhận được CTS trước khi bắt đầu truyền. Tuy nhiên, C thực tế cũng đang nghe dữ liệu từ B, nên có thể không nghe được CTS để bắt đầu truyền. Vấn đề chính ở đây là: Trong CSMA, bộ phát chỉ truyền. Nhưng trong MACA, bộ phát phải nhận được CTS trước khi truyền, và CTS này có thể bị nhiễu trong trường hợp <strong>exposed terminal</strong>.</p>
<img width="900px" src="wireless/../assets/wireless/8-021-maca4.png">
<p>Nếu chúng ta gửi RTS nhưng không nghe thấy CTS tương ứng, điều đó có nghĩa là chúng ta <strong>không được phép truyền</strong>. Có thể đang có va chạm ở phía thu, ví dụ: bộ thu đang nhận dữ liệu hoặc nhận hai yêu cầu cùng lúc. Nếu điều này xảy ra, chúng ta áp dụng <strong>binary exponential backoff</strong> (cơ chế lùi thời gian theo cấp số nhân nhị phân, tương tự CSMA/CD) và chờ lâu gấp đôi trước khi gửi lại RTS.</p>
<p>Trong MACA, mỗi thiết bị duy trì một giá trị <strong>CW (Contention Window)</strong>, cho biết sau một va chạm cần chờ bao lâu trước khi gửi lại yêu cầu. Nếu phát hiện va chạm (không nhận được CTS), thiết bị chọn ngẫu nhiên một số trong khoảng từ 0 đến CW và chờ thời gian tương ứng trước khi gửi lại. Giá trị tối thiểu là 2 time slots và tối đa là 64 time slots, trong đó một time slot là thời gian cần để truyền một gói RTS. Khi RTS/CTS thành công, CW được đặt lại về giá trị tối thiểu là 2. Khi RTS thất bại (không có CTS), CW được nhân đôi, nhưng không vượt quá giá trị tối đa 64.</p>
<h2 id="tính-năng-macaw-ack-Để-đảm-bảo-độ-tin-cậy"><a class="header" href="#tính-năng-macaw-ack-Để-đảm-bảo-độ-tin-cậy">Tính năng MACAW: <strong>ACK</strong> (Để đảm bảo độ tin cậy)</a></h2>
<p><strong>MACAW (Multiple Access Collision Avoidance for Wireless)</strong> mang đến một số cải tiến so với giao thức <strong>MACA</strong>.</p>
<p>Cải tiến đầu tiên là bổ sung <strong>acknowledgement</strong> (gói xác nhận – ACK) để đảm bảo độ tin cậy. Như trước đây, bộ phát (<strong>sender</strong>) gửi một gói <strong>RTS (Request To Send)</strong>, bộ thu (<strong>receiver</strong>) gửi một gói <strong>CTS (Clear To Send)</strong>, và bộ phát truyền dữ liệu. Giờ đây, chúng ta thêm một bước nữa ở cuối, trong đó bộ thu gửi một gói ACK.</p>
<img width="300px" src="wireless/../assets/wireless/8-022-macaw-acks.png">
<p>Nếu dữ liệu bị mất, sẽ không có ACK, và bộ phát sẽ phải thử lại, bắt đầu lại với một RTS mới. Nếu dữ liệu được gửi chính xác nhưng ACK bị mất, bộ phát sẽ thử lại với một RTS mới, nhưng bộ thu có thể trả lời ngay bằng ACK thay vì CTS.</p>
<p>Tại sao chúng ta thêm ACK? Hãy nhớ rằng <strong>End-to-end Principle</strong> (Nguyên tắc đầu-cuối) cho rằng độ tin cậy phải được triển khai tại các máy đầu cuối để đảm bảo tính đúng đắn. Tuy nhiên, trong trường hợp này, chúng ta triển khai độ tin cậy ngay trong mạng, trên một liên kết đơn lẻ, chỉ nhằm cải thiện hiệu năng. Nếu không triển khai độ tin cậy ở tầng liên kết, <strong>TCP</strong> vẫn đảm bảo tính đúng đắn, nhưng một gói tin bị mất sẽ khiến TCP giảm tốc độ đáng kể (nhớ rằng cửa sổ tắc nghẽn – <strong>congestion window</strong> – sẽ bị giảm một nửa). Ngược lại, bằng cách triển khai độ tin cậy ở tầng liên kết, chúng ta có thể khôi phục sau mất gói hiệu quả hơn.</p>
<h2 id="tính-năng-macaw-better-backoff-Để-đảm-bảo-công-bằng"><a class="header" href="#tính-năng-macaw-better-backoff-Để-đảm-bảo-công-bằng">Tính năng MACAW: <strong>Better Backoff</strong> (Để đảm bảo công bằng)</a></h2>
<p>Giao thức MACA thiếu công bằng khi hai nút va chạm cùng muốn gửi dữ liệu. Cụ thể, “người thắng” thường tiếp tục thắng, còn “người thua” tiếp tục thua.</p>
<p>Ví dụ về sự thiếu công bằng: Giả sử A và B đều có giá trị <strong>CW (Contention Window)</strong> là 2, và cả hai đồng thời cố gắng đặt chỗ kênh truyền. Giả sử A thắng, B thua. Khi đó, CW của A vẫn là 2, còn CW của B tăng gấp đôi thành 4. Điều này có nghĩa là A có khả năng đặt chỗ kênh sớm hơn và nhiều khả năng lại thắng. Khi B thử lại, A đã chiếm kênh, và CW của B lại tăng gấp đôi thành 8. Mẫu này tiếp diễn: A liên tục chiếm kênh nhanh chóng, còn B liên tục thất bại và phải chờ lâu hơn trước khi thử lại (và lại thất bại).</p>
<img width="800px" src="wireless/../assets/wireless/8-023-maca-unfair.png">
<p>Để giải quyết vấn đề này, thay vì mỗi thiết bị có CW riêng, tất cả sẽ dùng chung một CW. Phần tiêu đề gói tin (<strong>packet header</strong>) giờ đây có một trường chứa giá trị CW, và nếu bạn nhận được một gói tin, bạn sẽ đặt CW của mình bằng giá trị trong gói đó. Vì tất cả cùng có CW như nhau, cơ chế thử lại sẽ không thiên vị thiết bị nào. Mỗi thiết bị chọn ngẫu nhiên một giá trị từ 0 đến CW và chờ tương ứng. (Lưu ý: Chúng ta đang đơn giản hóa một chút, điều này đúng nếu tất cả thiết bị đều trong phạm vi của nhau.)</p>
<p>MACAW cũng thay đổi quy tắc cập nhật CW để “mềm” hơn. Như trước, giá trị tối thiểu là 2 và tối đa là 64. Khi RTS thất bại (không nhận được CTS), CW được nhân với 1,5 (thay vì gấp đôi), và vẫn giới hạn không vượt quá 64. Khi truyền thành công một chuỗi RTS/CTS/DATA/ACK, CW giảm đi 1 (thay vì đặt lại về 2). Lưu ý rằng khi RTS/CTS thành công nhưng ACK thất bại, CW không thay đổi. Cách tiếp cận này đôi khi được gọi là <strong>Multiplicative Increase, Linear Decrease (MILD)</strong>.</p>
<h2 id="tính-năng-macaw-ds-Để-xử-lý-exposed-terminals"><a class="header" href="#tính-năng-macaw-ds-Để-xử-lý-exposed-terminals">Tính năng MACAW: <strong>DS</strong> (Để xử lý Exposed Terminals)</a></h2>
<p>Hãy nhớ lại ví dụ <strong>exposed terminal</strong> (nút lộ) trước đó, khi B muốn liên lạc với A. B gửi RTS, A gửi CTS, và B bắt đầu truyền dữ liệu. Lúc này, C không nghe thấy CTS, nghĩa là C nằm ngoài phạm vi của bộ thu và có thể truyền dữ liệu an toàn. Tuy nhiên, để truyền, C phải nghe được CTS. Điều này có thể không xảy ra, vì C cũng đang nghe dữ liệu từ B, và có thể xảy ra va chạm giữa dữ liệu của B và CTS từ D.</p>
<p>MACAW kết luận rằng trong trường hợp <strong>exposed terminal</strong>, các cặp B–A và C–D thực tế không thể truyền dữ liệu đồng thời. Nói cách khác, cả MACAW lẫn CSMA đều không giải quyết được vấn đề nút lộ.</p>
<p>Điều này có nghĩa là nếu chúng ta nằm trong phạm vi của bộ phát khác, chúng ta không thể truyền dữ liệu (ngay cả khi không nằm trong phạm vi của bộ thu kia). Nguyên nhân là vì chúng ta sẽ nghe dữ liệu từ bộ phát kia, và do đó không thể nghe được CTS cần thiết để bắt đầu truyền.</p>
<p>Để giải quyết vấn đề này, MACAW thêm một gói <strong>DS (Data Sending)</strong> trước khi truyền dữ liệu. Đây là cách bộ phát cảnh báo mọi thiết bị: “Tôi sắp gửi k bit dữ liệu, vui lòng giữ im lặng trong thời gian này.”</p>
<img width="900px" src="wireless/../assets/wireless/8-024-ds1.png">
<p>Giao thức giờ đây có 5 bước:</p>
<ol>
<li>Bộ phát gửi RTS, yêu cầu truyền k bit dữ liệu.</li>
<li>Bộ thu gửi CTS, thông báo cho mọi thiết bị trong phạm vi: Giữ im lặng, tôi đang nhận k bit dữ liệu.</li>
<li>Bộ phát gửi DS, thông báo cho mọi thiết bị trong phạm vi: Giữ im lặng, tôi đang gửi k bit dữ liệu. (Các thiết bị khác không thể gửi dữ liệu, vì dữ liệu của tôi sẽ làm nhiễu CTS mà bạn cần nhận cho phiên truyền của mình.)</li>
<li>Bộ phát truyền dữ liệu.</li>
<li>Bộ thu gửi ACK.</li>
</ol>
<p>Lưu ý rằng RTS và DS không trùng lặp chức năng. RTS là yêu cầu có thể bị từ chối (ví dụ: không nhận được CTS). DS xác nhận rằng yêu cầu đã được chấp thuận và buộc mọi thiết bị trong phạm vi của bộ phát phải giữ im lặng.</p>
<h2 id="tính-năng-macaw-ds-Đồng-bộ-hóa--for-synchronization"><a class="header" href="#tính-năng-macaw-ds-Đồng-bộ-hóa--for-synchronization">Tính năng MACAW: <strong>DS</strong> (Đồng bộ hóa – For Synchronization)</a></h2>
<p><strong>DS</strong> có một mục đích quan trọng thứ hai. Hãy xem lại ví dụ <strong>exposed terminal</strong> (nút lộ) trước đó, nhớ rằng <strong>MACAW</strong> chấp nhận “thất bại” và buộc hai phiên truyền phải diễn ra tách biệt.</p>
<p>Giả sử không có gói DS. Khi đó, như trước, B gửi một gói <strong>RTS (Request To Send)</strong>, A gửi một gói <strong>CTS (Clear To Send)</strong>, và B bắt đầu truyền dữ liệu. C nghe thấy RTS và trì hoãn một <strong>time slot</strong> (khoảng thời gian) để tránh làm gián đoạn B. Tuy nhiên, C không nghe thấy CTS. Lúc này, C sẽ gửi một RTS vô ích và sẽ không bao giờ nghe được CTS (vì CTS bị “chìm” trong dữ liệu từ B). C sẽ tiếp tục thử lại và gửi các yêu cầu RTS vô ích, nhưng không hề biết khi nào B sẽ ngừng truyền dữ liệu.</p>
<p>Ngược lại, B biết chính xác khi nào nó sẽ ngừng truyền dữ liệu. Điều này mang lại cho B lợi thế lớn trong vòng tranh chấp (<strong>contention</strong>) tiếp theo. Khi B truyền xong, nó có thể ngay lập tức gửi yêu cầu mới và nhiều khả năng sẽ thắng, tiếp tục giữ quyền truyền dữ liệu. Trong khi đó, C không biết khi nào B sẽ ngừng, nên phải đoán ngẫu nhiên thời điểm gửi yêu cầu mới. Khả năng cao là C sẽ đoán sai và gửi yêu cầu khi B vẫn đang truyền, dẫn đến thất bại và yêu cầu không được chấp nhận (va chạm).</p>
<img width="900px" src="wireless/../assets/wireless/8-025-ds2.png">
<p>Sự thiếu đồng bộ này dẫn đến mất công bằng. Nếu tôi thắng, tôi có khả năng sẽ thắng tiếp, vì tôi biết chính xác khi nào vòng tranh chấp tiếp theo diễn ra (ngay khi tôi truyền xong). Nếu bạn thua, bạn có khả năng sẽ tiếp tục thua, vì bạn không biết khi nào vòng tranh chấp tiếp theo diễn ra (bạn không biết khi nào tôi truyền xong). Thời gian tranh chấp thường rất ngắn, vì phần lớn thời gian được dùng để truyền dữ liệu. Tôi biết chính xác thời điểm đó, còn bạn thì không, nên tôi sẽ liên tục thắng.</p>
<p>Gói DS giải quyết vấn đề này, vì nó cho phép bộ phát thông báo cho mọi người khi nào vòng tranh chấp tiếp theo sẽ diễn ra. Giờ đây, B sử dụng gói DS để thông báo cho mọi người: “Tôi bắt đầu gửi k bit dữ liệu.” Nhờ đó, C không chỉ biết rằng mình không nên gửi các yêu cầu RTS vô ích, mà còn biết khi nào B sẽ truyền xong. Điều này giúp C có cơ hội công bằng hơn để thắng trong vòng tranh chấp tiếp theo.</p>
<img width="900px" src="wireless/../assets/wireless/8-026-ds3.png">
<h2 id="tính-năng-macaw-rrts-Đồng-bộ-hóa--for-synchronization"><a class="header" href="#tính-năng-macaw-rrts-Đồng-bộ-hóa--for-synchronization">Tính năng MACAW: <strong>RRTS</strong> (Đồng bộ hóa – For Synchronization)</a></h2>
<p>Có một trường hợp khác mà đồng bộ hóa là yếu tố then chốt để đảm bảo công bằng. Giả sử A muốn gửi dữ liệu cho B, và D muốn gửi dữ liệu cho C.</p>
<p>A truyền cho B (A gửi RTS, B gửi CTS, A gửi DS và truyền dữ liệu). C nghe thấy CTS và phải giữ im lặng trong khi dữ liệu được truyền. Lúc này, D hoàn toàn “mù thông tin” và thất thế. D sẽ gửi RTS, nhưng sẽ không nghe thấy CTS vì C đang giữ im lặng. D sẽ tiếp tục thử lại vào những thời điểm ngẫu nhiên và liên tục thất bại, vì không biết khi nào A sẽ ngừng truyền dữ liệu.</p>
<p>Ngược lại, A biết chính xác khi nào nó sẽ ngừng truyền dữ liệu. Giống như trước, điều này mang lại cho A lợi thế lớn trong vòng tranh chấp tiếp theo. A có thể ngay lập tức gửi yêu cầu mới và giành quyền truyền. Trong khi đó, D không biết khi nào nên gửi lại yêu cầu. Cách duy nhất để D thắng là cực kỳ may mắn, gửi yêu cầu ngay sau khi A truyền xong nhưng trước khi A gửi lại yêu cầu.</p>
<img width="900px" src="wireless/../assets/wireless/8-027-rrts1.png">
<p>Lưu ý rằng gói DS không giúp ích trong trường hợp này, vì hai bộ phát A và D nằm ngoài phạm vi của nhau. A sẽ gửi gói DS và thông báo khi nó đang truyền dữ liệu, nhưng D sẽ không nghe thấy, nên vẫn thất thế.</p>
<p>Để giải quyết vấn đề này, chúng ta sẽ để bộ thu tranh chấp thay cho bộ phát. D không biết khi nào nên gửi lại yêu cầu, nhưng C thì biết, vậy hãy để C gửi yêu cầu thay.</p>
<p>Khi D gửi RTS, C biết rằng D muốn liên lạc, nhưng C phải giữ im lặng cho đến vòng tranh chấp tiếp theo. Lưu ý rằng C biết khi nào vòng tranh chấp tiếp theo diễn ra, vì nó sẽ nghe thấy gói ACK từ B. Khi vòng tranh chấp tiếp theo bắt đầu, C gửi một gói mới gọi là <strong>RRTS (Request-for-RTS)</strong>. Gói này ngay lập tức báo cho D rằng vòng tranh chấp đã bắt đầu, cho phép D gửi RTS ngay lập tức. Điều này giúp D có cơ hội công bằng hơn để thắng vòng tranh chấp.</p>
<img width="900px" src="wireless/../assets/wireless/8-028-rrts2.png">
<p>Nếu bạn nghe thấy một gói RRTS, điều đó có nghĩa là có ai đó trong phạm vi của bạn đang cố gắng gửi yêu cầu, vì vậy bạn nên giữ im lặng trong 2 time slots để họ thực hiện trao đổi RTS/CTS.</p>
<p>Trong ví dụ, nếu C gửi RRTS, B sẽ nghe thấy và giữ im lặng trong 2 time slots, cho phép D gửi RTS và C gửi CTS. CTS sẽ yêu cầu B giữ im lặng, và cho phép phiên truyền D–C diễn ra.</p>
<p>Nói chung, bạn nên gửi RRTS nếu bạn nghe thấy RTS nhưng không được phép phản hồi, vì có ai đó đã yêu cầu bạn giữ im lặng.</p>
<p>DS và RRTS giúp đồng bộ hóa và đảm bảo các vòng tranh chấp công bằng hơn, nhưng chúng không giải quyết được mọi vấn đề. Xét trường hợp A gửi cho B và C gửi cho D. Giả sử C bắt đầu gửi cho D. Lúc này, nếu A gửi RTS, B sẽ không nghe thấy vì RTS bị “chìm” trong dữ liệu từ C. Cách duy nhất để RTS của A đến được B là trong khoảng trống rất ngắn giữa các lần truyền của C. Trong tình huống này, A chắc chắn sẽ thua, vì nó không biết khi nào C sẽ ngừng truyền, trong khi C biết chính xác thời điểm đó. Lưu ý rằng RRTS cũng không giúp được ở đây, vì RRTS chỉ được gửi nếu bạn nghe thấy RTS, nhưng B thậm chí không nghe thấy RTS. B sẽ không bao giờ biết rằng A muốn liên lạc, nên sẽ không gửi RRTS thay mặt A. Bài báo gốc về MACAW để lại vấn đề này chưa được giải quyết.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mạng-di-động-cellular"><a class="header" href="#mạng-di-động-cellular">Mạng Di động (Cellular)</a></h1>
<h2 id="tại-sao-nên-nghiên-cứu-về-mạng-di-động"><a class="header" href="#tại-sao-nên-nghiên-cứu-về-mạng-di-động">Tại sao nên nghiên cứu về Mạng Di động?</a></h2>
<p>Kết nối di động không dây là tiêu chuẩn hiện đại. Điện thoại của bạn có thể kết nối Internet trong khi bạn đang ở trên một chiếc xe hơi đang di chuyển.</p>
<p>Các mạng Internet truyền thống không thể hỗ trợ điều này. Bạn có thể di chuyển từ phòng ngủ đến nhà bếp và vẫn có quyền truy cập Internet. Trong trường hợp đó, bạn đang ở trong phạm vi phủ sóng của <strong>Router</strong> (Bộ định tuyến) không dây tại nhà, thiết bị này sau đó được kết nối qua dây dẫn đến phần còn lại của Internet. Tuy nhiên, Internet truyền thống không cung cấp các kết nối liền mạch trên các khoảng cách xa (ví dụ: khi di chuyển bằng ô tô).</p>
<p>Có nhiều cách để triển khai kết nối di động không dây, nhưng mạng di động là công nghệ truy cập chiếm ưu thế hiện nay. Hơn một nửa lưu lượng web ngày nay bắt nguồn từ một thiết bị di động!</p>
<p>Mạng di động chỉ là một trong nhiều công nghệ có thể cung cấp kết nối di động không dây. Các công nghệ khác như vệ tinh hoặc quang học không gian tự do cũng tồn tại, mặc dù mạng di động vẫn là phương pháp chủ đạo ngày nay.</p>
<p>Trong tương lai, các ứng dụng hiệu suất cao yêu cầu công nghệ di động không dây, như ô tô tự lái hoặc thực tế ảo, có thể dẫn đến nhiều sự đổi mới hơn. Các mạng di động hiện tại có thể trở nên đắt đỏ một cách cấm đoán khi chúng ta cố gắng mở rộng quy mô để hỗ trợ các ứng dụng trong tương lai. Ngoài ra, các nhà khai thác mạng di động như AT&amp;T và Verizon không có tiếng là đổi mới nhanh chóng. Sự đồng thuận chung là đây là một lĩnh vực chín muồi cho sự đột phá trong tương lai gần và là một lĩnh vực nghiên cứu tích cực.</p>
<h2 id="lược-sử-mạng-di-động"><a class="header" href="#lược-sử-mạng-di-động">Lược sử Mạng Di động</a></h2>
<p>Công nghệ di động bắt nguồn từ hệ thống điện thoại cũ. Các mạng di động lần đầu tiên được phát triển để cho phép người dùng thực hiện các cuộc gọi điện thoại không dây, thay vì trên một đường dây điện thoại cố định có dây. Chiếc điện thoại di động đầu tiên được bán vào năm 1983 với giá $4,000 (cao hơn rất nhiều ngày nay, sau khi tính lạm phát).</p>
<p>Do công nghệ di động bắt nguồn từ mạng điện thoại (chứ không phải Internet), nhiều lựa chọn thiết kế khác với Internet truyền thống. Trong nhiều năm, công nghệ di động (ví dụ: điện thoại di động tiền-smartphone cho các cuộc gọi thoại) và Internet đã phát triển song song, mỗi bên có một bộ lựa chọn kiến trúc khác nhau.</p>
<p>Ví dụ, mạng di động sử dụng cơ chế <strong>resource reservations</strong> (dành riêng tài nguyên), trong khi Internet hiện đại sử dụng <strong>packet switching</strong> (chuyển mạch gói). Các mạng di động thường tư duy theo từng người dùng cá nhân, trong khi Internet chủ yếu tư duy theo từng luồng hoặc gói tin cá nhân. Mô hình kinh doanh của các mạng di động (ví dụ: tính phí người dùng theo phút) khác với Internet, vốn thường không theo dõi việc sử dụng nhiều như vậy.</p>
<p>Trong những năm gần đây, các mạng di động đã trở nên tương thích hơn với Internet truyền thống. Ngày nay, bạn có thể coi mạng di động như một mạng cục bộ Lớp 2 chuyên dụng có thể tương tác với phần còn lại của Internet <strong>TCP/IP</strong> truyền thống.</p>
<h2 id="các-tiêu-chuẩn-di-động"><a class="header" href="#các-tiêu-chuẩn-di-động">Các Tiêu chuẩn Di động</a></h2>
<p>Trong Internet truyền thống, chúng ta đã thấy rằng các cơ quan tiêu chuẩn hóa giúp chúng ta chuẩn hóa các giao thức như <strong>TCP</strong> và <strong>IP</strong>. Mạng di động cũng có nhiều cơ quan tiêu chuẩn hóa hợp tác để tạo ra một tiêu chuẩn.</p>
<p>Ở một số khía cạnh, các cơ quan tiêu chuẩn hóa mạng di động có sự phức tạp chính trị trong đời thực nhiều hơn các cơ quan tiêu chuẩn hóa Internet. Để đạt được khả năng tương tác, tất cả các nhà sản xuất điện thoại di động và tất cả các nhà khai thác mạng (ví dụ: Verizon xây dựng các trạm phát sóng di động) cần phải đồng ý về các giao thức, xuống tận lớp vật lý.</p>
<p>Cơ quan tiêu chuẩn hóa chính trong thế giới di động là <strong>3GPP</strong> (Dự án Đối tác Thế hệ thứ 3). Các nhà cung cấp thiết bị lớn và các công ty viễn thông đều tham gia vào tổ chức này. <strong>3GPP</strong> đề xuất các tiêu chuẩn, sau đó được chuyển đến <strong>ITU</strong> (Liên minh Viễn thông Quốc tế). <strong>ITU</strong> là một phần của Liên Hợp Quốc và mỗi quốc gia có một phiếu bầu, vì vậy cũng có một số yếu tố chính trị liên quan đến các tiêu chuẩn. (Thông tin thú vị: Mỗi quốc gia có một phiếu bầu, vì vậy Mỹ có thể bị Liên minh châu Âu bỏ phiếu áp đảo.)</p>
<p>Thông thường, một thế hệ công nghệ mới được giới thiệu sau mỗi 10 năm. Bây giờ bạn đã biết các con số trong 2G, 3G, 4G và 5G đại diện cho điều gì (các thế hệ công nghệ di động). Mạng 5G được định nghĩa vào khoảng năm 2020, và các nhà khai thác vẫn đang triển khai công nghệ này. Việc lập kế hoạch cho tiêu chuẩn 6G sẽ bắt đầu trong vài năm tới (cuối những năm 2020).</p>
<p>Mỗi thế hệ cố gắng cải tiến so với thế hệ trước trên nhiều phương diện, bao gồm tốc độ dữ liệu lý thuyết cao nhất, tốc độ dữ liệu trung bình mà người dùng trải nghiệm, tính di động (kết nối trong khi người dùng đang di chuyển ở tốc độ cao), mật độ kết nối (số lượng thiết bị trong một khu vực cụ thể), v.v. Mỗi thế hệ thường hoạt động tốt hơn khoảng 10 lần so với thế hệ trước trên tất cả các phương diện này.</p>
<p>Ngoài những cải tiến về hiệu suất, thiết kế kiến trúc cũng đã phát triển qua các thế hệ, để chuyển từ thiết kế mạng điện thoại sang thiết kế Internet. Điện thoại 1G hoàn toàn là analog, được thiết kế cho các cuộc gọi thoại. 2G/3G vẫn chủ yếu là chuyển mạch kênh, tập trung vào lưu lượng thoại (một chút tin nhắn, hầu như không có lưu lượng Internet). Từ 4G trở đi, chúng ta đã chuyển sang kiến trúc <strong>packet-switched</strong>, và thoại giờ đây chỉ là một trong nhiều ứng dụng chạy trên mạng.</p>
<p>Các thông số kỹ thuật di động dài hàng nghìn trang và bao gồm hàng trăm tài liệu, và gần như không ai thực sự đọc hết chúng. Một đặc điểm bất tiện của các tiêu chuẩn này là mọi thứ đều được đổi tên khi chúng ta chuyển từ thế hệ này sang thế hệ tiếp theo. Ví dụ, các trạm phát sóng di động đã được gọi là &quot;base station&quot;, &quot;nodeB&quot;, &quot;evolved NodeB (eNodeB)&quot;, và &quot;next-gen Node B (gNB)&quot;, tất cả đều có nghĩa giống nhau. Trong lớp học này, chúng ta sẽ tự đặt ra thuật ngữ riêng để làm cho các tên gọi trở nên trực quan hơn. Nếu bạn xem qua một cuốn sách giáo khoa hoặc một thông số kỹ thuật, bạn có thể thấy các tên gọi khác nhau, nhưng các ý tưởng chúng ta sẽ thấy nhìn chung nên nhất quán về mặt khái niệm với sách giáo khoa và thông số kỹ thuật.</p>
<h2 id="thách-thức-chính-tính-di-động-mobility"><a class="header" href="#thách-thức-chính-tính-di-động-mobility">Thách thức chính: Tính di động (Mobility)</a></h2>
<p>Thách thức chính khiến mạng di động trở nên khó khăn là <strong>mobility</strong> (tính di động). Hãy nhớ rằng, hãy nghĩ về <strong>mobility</strong> như việc điện thoại của bạn đang phát video khi bạn đang di chuyển trên đường cao tốc (tuy nhiên đừng xem video khi đang lái xe). Có bốn thách thức cơ bản mà chúng ta sẽ nghiên cứu:</p>
<ol>
<li><strong>Discovery</strong> (Khám phá): Khi tôi đang di chuyển, làm cách nào để biết nên kết nối với trạm phát sóng di động nào?</li>
<li><strong>Authentication</strong> (Xác thực): Trạm phát sóng của AT&amp;T có thể chỉ muốn cung cấp kết nối cho khách hàng của mình, chứ không phải các khách hàng khác. Làm thế nào trạm phát sóng di động đạt được điều này?</li>
<li><strong>Seamless communication</strong> (Giao tiếp liền mạch): Nếu tôi di chuyển ra khỏi phạm vi của một trạm phát sóng và vào phạm vi của một trạm phát sóng khác, kết nối của tôi phải liền mạch, không bị gián đoạn.</li>
<li><strong>Accountability</strong> (Giải trình trách nhiệm): Nếu khách hàng chỉ trả tiền cho 6GB dữ liệu, mạng nên ngừng cung cấp kết nối cho khách hàng (hoặc cung cấp kết nối kém hơn) sau khi khách hàng đã vượt quá giới hạn của họ. Yêu cầu này xuất phát từ mạng di động cũ (trả tiền theo phút gọi thoại), và vẫn tồn tại vì tài nguyên trong mạng di động rất khan hiếm.</li>
</ol>
<h2 id="các-thành-phần-hạ-tầng-trạm-phát-sóng-vô-tuyến-radio-towers"><a class="header" href="#các-thành-phần-hạ-tầng-trạm-phát-sóng-vô-tuyến-radio-towers">Các thành phần hạ tầng: Trạm phát sóng vô tuyến (Radio Towers)</a></h2>
<p>Các thành phần của một mạng di động là gì? Đầu tiên, có trạm phát sóng vô tuyến.</p>
<p>Trạm phát sóng vô tuyến có một ăng-ten. Bên trong trạm là một bộ thu phát vô tuyến, có chức năng chuyển đổi các bit kỹ thuật số thành tín hiệu analog được gửi qua giao diện không gian.</p>
<p>Cũng bên trong trạm là một bộ điều khiển vô tuyến, quyết định cách phân bổ tài nguyên vô tuyến.</p>
<p>Bạn có thể coi bộ điều khiển như một CPU đang chạy một bộ lập lịch. Bộ điều khiển phân bổ các đoạn tần số và thời gian khác nhau cho các khách hàng khác nhau, tùy thuộc vào nhu cầu và mô hình kinh doanh (ví dụ: khách hàng đang trả bao nhiêu tiền). Đây thực sự là một bài toán lập lịch khá khó, mặc dù chúng ta sẽ không thảo luận thêm ở đây.</p>
<p>Đây là một mô hình đơn giản hóa về việc bộ điều khiển vô tuyến phân bổ tài nguyên. Mỗi hình chữ nhật có màu cho chúng ta thấy rằng một người dùng (được ký hiệu bằng màu) có thể sử dụng tần số cụ thể đó, tại thời điểm cụ thể đó.</p>
<p>Mỗi mặt cắt dọc đại diện cho một khe thời gian, và cho bạn thấy các tần số đã được phân bổ cho người dùng trong mặt cắt đó như thế nào. Ví dụ, trong khe thời gian đầu tiên, người dùng màu xanh lam nhận được 3 khe tần số, người dùng màu cam nhận được 5 khe tần số và người dùng màu xám nhận được 4 khe tần số.</p>
<p>Mỗi mặt cắt ngang đại diện cho một tần số, và cho bạn thấy tần số cụ thể đó được phân bổ cho người dùng theo thời gian như thế nào. Ví dụ, hàng trên cùng cho thấy một tần số được phân bổ cho màu xám, sau đó là màu xanh lá cây, sau đó là màu xanh lam, sau đó là màu đỏ, và cứ thế tiếp tục.</p>
<p>Lưu ý rằng mô hình này đang chia sẻ tài nguyên bằng cách sử dụng <strong>reservations</strong> (cơ chế đặt trước), không phải nỗ lực tối đa. Một người dùng chỉ có thể gửi trong một tần số và thời gian đã được bộ điều khiển phân bổ cho họ.</p>
<p>Các bộ điều khiển vô tuyến trước đây thường được lắp đặt trong trạm phát sóng hoặc gần trạm, tuy nhiên ngày nay, đã có những nỗ lực để chuyển các bộ điều khiển lên đám mây để bảo trì và quản lý dễ dàng hơn.</p>
<p>Mỗi nhà khai thác vận hành nhiều trạm phát sóng di động, được bố trí khắp cả nước, để người dùng có thể kết nối với một trạm dù họ ở bất cứ đâu. Kết quả là một <strong>Radio Access Network (RAN)</strong> (Mạng Truy cập Vô tuyến).</p>
<p>Thông thường, mỗi trạm phát sóng nhận được một bộ tần số riêng mà nó có thể sử dụng, và các tần số được gán sao cho các trạm lân cận nhận được các dải tần số khác nhau. Điều này đảm bảo rằng các trạm lân cận không sử dụng cùng tần số và gây nhiễu cho nhau. Trong hình này, mỗi màu tương ứng với một bộ tần số. Có thể hai trạm cùng sử dụng bộ tần số màu xanh lam, nhưng chúng không nằm cạnh nhau nên sẽ không gây nhiễu. Bất kỳ trạm lân cận nào cũng đang sử dụng các tần số không chồng chéo. Lưu ý rằng các tần số thường được phân bổ theo nhu cầu, do đó một trạm phát sóng di động ở trung tâm thành phố San Francisco sẽ nhận được nhiều tần số hơn một trạm ở giữa một nơi hẻo lánh.</p>
<h2 id="các-thành-phần-hạ-tầng-lõi-mạng-di-động-cellular-core"><a class="header" href="#các-thành-phần-hạ-tầng-lõi-mạng-di-động-cellular-core">Các thành phần hạ tầng: Lõi Mạng Di động (Cellular Core)</a></h2>
<p>Một người dùng di động giờ đây có thể gửi dữ liệu đến một trạm phát sóng di động. Trạm phát sóng di động giờ cần gửi dữ liệu đó đến phần còn lại của Internet.</p>
<p>Mỗi trạm phát sóng di động có một kết nối có dây đến <strong>cellular core</strong> (lõi mạng di động). Bạn có thể coi <strong>cellular core</strong> là hạ tầng backend của mạng di động (không phải phần hướng tới người dùng).</p>
<p><strong>Cellular core</strong> chứa một số thành phần mặt phẳng dữ liệu. Bạn có thể coi chúng như các <strong>router</strong> và <strong>switch</strong> thông thường chuyển tiếp các gói tin giữa người dùng (thông qua các trạm phát sóng) và phần còn lại của mạng. Chúng ta sẽ tập trung vào hai loại <strong>router</strong> đặc biệt trong <strong>cellular core</strong>.</p>
<p><strong>Radio gateway</strong> (Cổng vô tuyến) là ranh giới giữa <strong>RAN</strong> (các trạm phát sóng di động) và <strong>cellular core</strong>. Một trạm phát sóng di động chuyển tiếp dữ liệu của mình đến một trong những <strong>radio gateway</strong> này. Ở đầu kia của lõi, <strong>packet gateway</strong> (cổng gói tin) là ranh giới giữa mạng di động và phần còn lại của Internet. Dữ liệu từ người dùng cuối cùng sẽ đến <strong>packet gateway</strong> và được gửi ra Internet dưới dạng một gói <strong>TCP/IP</strong> tiêu chuẩn.</p>
<p><strong>Cellular core</strong> cũng chứa một số thành phần mặt phẳng điều khiển. Chúng ta không có những thành phần này trong Internet truyền thống. Lưu lượng của người dùng không đến các thành phần này. Chúng ta sẽ tập trung vào hai thành phần mặt phẳng điều khiển.</p>
<p><strong>Database</strong> (Cơ sở dữ liệu) lưu trữ thông tin về khách hàng, chẳng hạn như: Khách hàng sở hữu những thiết bị nào? Khách hàng có gói dữ liệu nào? Thiết bị của khách hàng hiện đang ở đâu (ví dụ: đang kết nối với trạm nào)?</p>
<p><strong>Mobility manager</strong> (Trình quản lý di động) là một bộ điều khiển (hãy nghĩ nó giống như một CPU) quản lý chức năng mạng. Trình quản lý giúp chúng ta xác thực một người dùng (ví dụ: kiểm tra xem họ có thực sự là khách hàng của Verizon hay không). Trình quản lý cũng giúp chúng ta cập nhật các cấu hình khi người dùng di chuyển.</p>
<p>Để tóm tắt về hạ tầng: Các thiết bị người dùng gửi dữ liệu đến các trạm phát sóng di động trong <strong>RAN</strong>. Trạm phát sóng di động chuyển tiếp dữ liệu đến <strong>radio gateway</strong> (đi vào lõi). Dữ liệu cuối cùng đến <strong>packet gateway</strong> và được chuyển tiếp đến Internet (ra khỏi lõi). Cũng trong lõi là các thành phần điều khiển (<strong>mobility manager</strong>, <strong>database</strong>) để lưu trữ và quản lý thông tin về khách hàng.</p>
<h2 id="các-bước-hoạt-động-ở-mức-cao-của-mạng-di-động"><a class="header" href="#các-bước-hoạt-động-ở-mức-cao-của-mạng-di-động">Các Bước Hoạt động ở Mức Cao của Mạng Di động</a></h2>
<p><strong>Bước 0: Registration (Đăng ký).</strong> Người dùng đăng ký dịch vụ di động. Ví dụ, bạn bước vào một cửa hàng của Verizon, mua một <strong>data plan</strong> (gói dữ liệu) và ký hợp đồng. Nhà khai thác lúc này sẽ lưu trữ thông tin về bạn và gói dịch vụ của bạn trong <strong>database</strong>.</p>
<img width="900px" src="wireless/../assets/wireless/8-036-step0.png" />
 
**Bước 1: Discovery.** Người dùng bật điện thoại của họ ở một nơi bất kỳ. Điện thoại của họ phải khám phá xem có những trạm phát sóng nào ở gần, và cũng phải chọn một trạm để sử dụng.
<img width="900px" src="wireless/../assets/wireless/8-037-step1.png" />
<p><strong>Bước 2: Attachment (Gắn kết).</strong> Sau khi chọn một trạm phát sóng, thiết bị của người dùng thông báo cho trạm rằng nó muốn kết nối. Trạm phát sóng phải hỏi <strong>mobility manager</strong> xem kết nối có được phép không (ví dụ: kiểm tra xem người dùng đã vượt quá hạn ngạch của họ chưa).</p>
<img width="900px" src="wireless/../assets/wireless/8-038-step2.png" />
<p>Nếu việc xác thực thành công, <strong>mobility manager</strong> sẽ cấu hình trạm phát sóng và các <strong>router</strong> để thiết lập một đường dẫn từ người dùng đến Internet (thông qua trạm phát sóng và các <strong>router</strong>).</p>
<img width="900px" src="wireless/../assets/wireless/8-039-step2-part2.png" />
<p><strong>Bước 3: Data exchange (Trao đổi dữ liệu).</strong> Người dùng bây giờ có thể gửi và nhận dữ liệu dọc theo đường dẫn đã được cấu hình.</p>
<img width="900px" src="wireless/../assets/wireless/8-040-step3.png" />
<p><strong>Bước 4: Handover (Chuyển giao).</strong> Khi người dùng di chuyển, họ có thể đi xa khỏi trạm phát sóng ban đầu của mình và đến gần một trạm mới hơn (trong cùng <strong>RAN</strong> của nhà khai thác). Trạm cũ, trạm mới và thiết bị của người dùng đều phối hợp với nhau để quyết định xem người dùng có nên chuyển trạm hay không.</p>
<img width="900px" src="wireless/../assets/wireless/8-041-step4.png" />
<p>Nếu tất cả đều đồng ý rằng người dùng nên chuyển trạm, họ sẽ thông báo cho <strong>mobility manager</strong>, và <strong>mobility manager</strong> sẽ cấu hình lại trạm phát sóng và các <strong>router</strong> để thiết lập một đường dẫn mới từ người dùng đến Internet (lúc này sử dụng trạm mới, và có thể cả các <strong>router</strong> khác). Quá trình chuyển giao này phải liền mạch, nghĩa là người dùng có thể gửi và nhận dữ liệu trong suốt quá trình và không bị gián đoạn. Để đạt được một cuộc <strong>handover</strong> liền mạch như vậy đòi hỏi mạng phải liên tục giám sát thiết bị người dùng.</p>
<img width="900px" src="wireless/../assets/wireless/8-042-step4-part2.png" />
<p>Các bước 3 và 4 có thể lặp lại khi người dùng di chuyển và <strong>router</strong> tốt nhất để sử dụng liên tục thay đổi.</p>
<img width="900px" src="wireless/../assets/wireless/8-043-step4-part3.png" />
<p>Một tính năng cuối cùng chúng ta cần triển khai là <strong>roaming</strong> (chuyển vùng). Nếu người dùng đến một quốc gia khác như Đức, nhà khai thác của họ (ví dụ: Verizon, có trụ sở tại Mỹ) có thể không có vùng phủ sóng ở Đức. Nhưng, Verizon có thể ký hợp đồng với Deutsche Telecom (một nhà khai thác ở Đức), để cho phép khách hàng của Verizon sử dụng cơ sở hạ tầng của Deutsche Telecom. Điều này có nghĩa là Deutsche Telecom có thể cần hỗ trợ không chỉ người dùng của mình, mà cả người dùng từ các mạng khác như Verizon.</p>
<img width="900px" src="wireless/../assets/wireless/8-044-step-roaming.png" />
<p>Các bước kết nối trong một mạng khách (khi đang <strong>roaming</strong>) nói chung khá tương tự, ngoại trừ việc các <strong>mobility manager</strong> trong mạng khách và mạng chủ cũng phải phối hợp với nhau (ví dụ: Deutsche Telecom kiểm tra với Verizon để xem người dùng có trả tiền cho dịch vụ <strong>roaming</strong> hay không).</p>
<h2 id="bước-0-registration"><a class="header" href="#bước-0-registration">Bước 0: Registration</a></h2>
<p>Khi bạn đăng ký một <strong>data plan</strong>, bạn sẽ nhận được một <strong>IMSI (International Mobile Subscriber Identity)</strong> (Nhận dạng Thuê bao Di động Quốc tế), đây là một mã định danh duy nhất được liên kết với thuê bao của bạn. Số này được lưu trữ an toàn trong phần cứng của một <strong>SIM card</strong> (thẻ SIM).</p>
<p>Lưu ý: Đây là lý do tại sao các nhà khai thác như Verizon cung cấp cho bạn một <strong>SIM card</strong> để lắp vào điện thoại. Nếu bạn đổi điện thoại nhưng vẫn giữ nguyên gói cước, bạn chỉ cần chuyển <strong>SIM card</strong> sang điện thoại mới, và bây giờ điện thoại mới của bạn được liên kết với cùng một số <strong>IMSI</strong>. Hoặc, nếu bạn đổi gói cước nhưng sử dụng cùng một điện thoại, bạn lắp một <strong>SIM card</strong> mới vào điện thoại, và bây giờ điện thoại đó được liên kết với một số <strong>IMSI</strong> mới.</p>
<p>3 chữ số đầu tiên của <strong>IMSI</strong> là <strong>Mobile Country Code</strong> (Mã Quốc gia Di động), xác định một quốc gia. 2-3 chữ số tiếp theo là <strong>Mobile Network Code</strong> (Mã Mạng Di động), đại diện cho nhà cung cấp dịch vụ của bạn (ví dụ: Verizon, AT&amp;T). Các chữ số còn lại là <strong>Mobile Subscriber Identification Number</strong> (Số Nhận dạng Thuê bao Di động), xác định một người dùng cụ thể trong nhà cung cấp dịch vụ đó. Tổng thể <strong>IMSI</strong> không thể vượt quá 15 chữ số.</p>
<img width="600px" src="wireless/../assets/wireless/8-045-imsi.png" />
<p>Lưu ý rằng <strong>IMSI</strong> không giống như một <strong>IP address</strong> (địa chỉ IP). Nếu bạn trả tiền cho một <strong>data plan</strong> kéo dài một năm, bạn sẽ giữ nguyên <strong>IMSI</strong> trong cả năm. Nhưng, mỗi lần bạn <strong>attachment</strong> và kết nối với mạng, bạn có thể nhận được một <strong>IP address</strong> khác nhau.</p>
<p>Có hai mã định danh khác được sử dụng trong các mạng di động. Chúng khác biệt với <strong>IMSI</strong>, và chúng ta sẽ không đề cập chi tiết về chúng. <strong>IMEI (International Mobile Equipment Identity)</strong> (Nhận dạng Thiết bị Di động Quốc tế) định danh duy nhất một thiết bị vật lý. <strong>IMEI</strong> mã hóa nhà sản xuất và kiểu máy của thiết bị (&quot;đây là một chiếc iPhone 13&quot;), và không thay đổi ngay cả khi bạn thay đổi <strong>data plan</strong>. Hoặc, nếu bạn có hai điện thoại được bao phủ bởi cùng một <strong>data plan</strong>, bạn sẽ có hai số <strong>IMEI</strong>, nhưng chỉ có một <strong>IMSI</strong> duy nhất.</p>
<p>Mã định danh còn lại là số điện thoại của bạn. Một lần nữa, điều này khác biệt với <strong>IMSI</strong> hoặc <strong>IMEI</strong>, và các chữ số đại diện cho những thứ khác nhau (ví dụ: mã vùng của bạn). Mạng điện thoại sẽ cần liên kết số điện thoại của bạn với một <strong>IMSI</strong> cụ thể để xác định gói cước điện thoại của bạn.</p>
<p>Sau khi bạn đăng ký và nhận được <strong>IMSI</strong>, nhà khai thác (ví dụ: Verizon) sẽ lưu trữ <strong>IMSI</strong> của bạn và thông tin về gói cước của bạn trong <strong>database</strong>.</p>
<img width="600px" src="wireless/../assets/wireless/8-046-registration.png" />
<p>Trong quá trình <strong>registration</strong>, thiết bị của người dùng (<strong>SIM card</strong>) và nhà khai thác (<strong>database</strong>) cũng đồng ý về một khóa bí mật chia sẻ. Điều này sẽ hữu ích khi chúng ta thực hiện <strong>attachment</strong>.</p>
<h2 id="bước-1-discovery"><a class="header" href="#bước-1-discovery">Bước 1: Discovery</a></h2>
<p>Làm thế nào thiết bị người dùng khám phá ra những trạm phát sóng nào đang trong tầm phủ sóng và thuộc sở hữu của nhà khai thác của người dùng?</p>
<p>Mỗi trạm phát sóng sẽ truyền các <strong>beacons</strong> (tín hiệu báo hiệu) định kỳ, thông báo cho mọi người trong phạm vi rằng trạm đó tồn tại. Thông điệp <strong>beacon</strong> cũng bao gồm nhà khai thác mạng (ví dụ: xin chào, tôi là một trạm của Verizon), trong đó nhà khai thác được xác định bằng <strong>Mobile Network Code</strong> gồm 2-3 chữ số. Hãy nhớ rằng, <strong>IMSI</strong> của thiết bị (trên <strong>SIM card</strong>) cũng có một <strong>Mobile Network Code</strong>, vì vậy thiết bị có thể kiểm tra: <strong>SIM card</strong> của tôi nói rằng tôi ở trong mạng 220, và <strong>beacon</strong> của trạm này nói rằng nó ở trong mạng 220, vì vậy tôi có thể sử dụng trạm này.</p>
<p><strong>Beacon</strong> được truyền trên một tần số cụ thể gọi là <strong>control channel</strong> (kênh điều khiển), để <strong>beacon</strong> không gây nhiễu với việc truyền dữ liệu. Mỗi dải tần số có một <strong>control channel</strong> liên quan riêng. Nhớ lại rằng các trạm lân cận có các dải tần số không chồng chéo, điều này cũng có nghĩa là chúng có các <strong>control channel</strong> khác nhau (tránh nhiễu).</p>
<p>Thiết bị của người dùng có thể nghe thấy nhiều <strong>beacons</strong>. Người dùng đo cường độ tín hiệu đến các trạm khác nhau và chọn trạm (thuộc nhà khai thác của mình) có tín hiệu tốt nhất.</p>
<img width="300px" src="wireless/../assets/wireless/8-047-discovery.png" />
<p>Có một vấn đề chúng ta phải giải quyết. Làm thế nào thiết bị của người dùng biết nên nghe <strong>control channel</strong> nào? Thiết bị cần phải dò đúng <strong>control channel</strong> để nhận được các <strong>beacons</strong>. Chúng ta có một <strong>bootstrapping problem</strong> (vấn đề mồi).</p>
<p>Có một vài giải pháp cho vấn đề này. Thiết bị có thể chỉ cần quét và thử một loạt tần số (chậm, nhưng đôi khi là lựa chọn duy nhất). Nhà khai thác có thể cung cấp cho thiết bị một danh sách các <strong>control channel</strong> được cấu hình sẵn trong quá trình <strong>registration</strong>. Thiết bị cũng có thể lưu vào bộ đệm các kênh đã sử dụng trước đó.</p>
<p>Lưu ý rằng việc quét các trạm tiếp theo sau khi <strong>discovery</strong> là không cần thiết. Trong quá trình <strong>handover</strong>, trạm cũ sẽ cho người dùng biết chính xác tần số dữ liệu nào để sử dụng trên trạm mới. Đây là lý do tại sao <strong>handover</strong> (cỡ 0.01--0.1 giây) nhanh hơn nhiều so với việc quét trong quá trình <strong>discovery</strong> (cỡ 10--100 giây).</p>
<h2 id="bước-2-attachment"><a class="header" href="#bước-2-attachment">Bước 2: Attachment</a></h2>
<ol>
<li>Khi một người dùng đã khám phá ra một trạm, nó sẽ gửi một <strong>attach request</strong> (yêu cầu gắn kết) đến trạm đó. Người dùng bao gồm <strong>IMSI</strong> của mình (ID thuê bao) trong yêu cầu.</li>
<li>Trạm sau đó phải gửi yêu cầu đến <strong>mobility manager</strong>, nơi thực sự xử lý yêu cầu.</li>
<li>Trình quản lý tra cứu <strong>IMSI</strong> trong <strong>database</strong> để biết chi tiết về gói dịch vụ của người dùng. Trình quản lý cũng thực hiện xác thực (chi tiết mã hóa bị bỏ qua) bằng cách sử dụng khóa bí mật được biết bởi thiết bị và trình quản lý (trong <strong>database</strong> của nó).</li>
</ol>
<p>Nếu xác thực thành công, chúng ta biết người dùng chính là người mà họ tự nhận. Nếu việc tra cứu <strong>database</strong> cũng cho thấy người dùng đủ điều kiện sử dụng dịch vụ, thì trình quản lý sẽ chấp thuận <strong>attach request</strong>.</p>
<img width="700px" src="wireless/../assets/wireless/8-048-attachment1.png" />
<ol start="4">
<li>Sau khi <strong>attach request</strong> được chấp thuận, <strong>mobility manager</strong> bây giờ phải cấu hình <strong>data plane</strong> để cung cấp kết nối cho người dùng. Đầu tiên, trình quản lý gán một <strong>IP address</strong> cho thiết bị. Sau đó, trình quản lý cấu hình trạm, cho bộ điều khiển vô tuyến của trạm biết cần phân bổ bao nhiêu tài nguyên cho người dùng này. Trình quản lý cũng cấu hình trạm và các <strong>router</strong> để tạo ra một đường dẫn giữa thiết bị và Internet. Cuối cùng, trình quản lý khởi tạo các bộ đếm và bộ định hình để theo dõi việc sử dụng Internet của thiết bị.</li>
</ol>
<p>Sau khi thiết lập kết nối cho người dùng, trình quản lý kết thúc bằng cách ghi lại thông tin vị trí của người dùng trong <strong>database</strong>. Cụ thể, <strong>database</strong> ánh xạ <strong>IMSI</strong> của người dùng tới <strong>IP address</strong> của nó và đường dẫn mà nó đang sử dụng (trạm nào, cổng nào).</p>
<img width="700px" src="wireless/../assets/wireless/8-049-attachment2.png" />
<p>Lưu ý rằng toàn bộ quá trình <strong>attachment</strong> xảy ra trên các <strong>control channel</strong>. Chúng ta chưa gán bất kỳ tần số nào cho người dùng, vì vậy người dùng phải sử dụng các <strong>control channel</strong> chuyên dụng để giao tiếp.</p>
<img width="700px" src="wireless/../assets/wireless/8-050-attachment3.png" />
<h2 id="bước-3-data-exchange"><a class="header" href="#bước-3-data-exchange">Bước 3: Data Exchange</a></h2>
<p>Tại thời điểm này, mạng được cấu hình để thiết bị có thể sử dụng <strong>IP address</strong> của mình để gửi và nhận tin nhắn.</p>
<img width="900px" src="wireless/../assets/wireless/8-051-exchange1.png" />
<p>Làm thế nào mạng di động (<strong>tower</strong>, <strong>radio gateway</strong>, <strong>packet gateway</strong>) biết cách chuyển tiếp các gói tin? Người dùng liên tục di chuyển, vì vậy nếu chúng ta chạy một thuật toán định tuyến truyền thống như vector khoảng cách, các tuyến đường sẽ không bao giờ hội tụ.</p>
<p>Thay vào đó, trình quản lý sẽ tạo ra một đường dẫn giữa thiết bị và Internet bằng cách sử dụng <strong>tunnels</strong> (đường hầm). Hãy nhớ rằng, đường đi của gói tin là từ thiết bị, đến trạm, đến <strong>radio gateway</strong>, đến <strong>packet gateway</strong>.</p>
<p>Về mặt khái niệm, để triển khai <strong>tunnel</strong>, chúng ta sẽ nói với trạm: Nếu bạn nhận được một gói tin từ người dùng, hãy gửi nó theo đường này (vào <strong>tunnel</strong> màu xanh). Ở phía bên kia của liên kết có dây, các gói tin sẽ thoát khỏi <strong>tunnel</strong> màu xanh và đến <strong>radio gateway</strong>. Sau đó, chúng ta sẽ nói với <strong>radio gateway</strong>: Nếu bạn nhận được một gói tin thoát ra khỏi <strong>tunnel</strong>, hãy gửi nó theo đường này (vào <strong>tunnel</strong> màu xanh lá). Các gói tin sau đó đi qua <strong>tunnel</strong> màu xanh lá và đến <strong>packet gateway</strong>, nơi có thể chuyển tiếp gói tin vào Internet.</p>
<img width="900px" src="wireless/../assets/wireless/8-052-exchange2.png" />
<p>Các gói tin đến cũng đi qua các <strong>tunnels</strong>. Chúng ta nói với <strong>packet gateway</strong>: Nếu bạn nhận được một gói tin dành cho Người dùng A, hãy gửi nó vào <strong>tunnel</strong> màu xanh lá (hướng tới <strong>radio gateway</strong>). Chúng ta cũng nói với <strong>radio gateway</strong>: Nếu bạn nhận được một gói tin thoát ra khỏi <strong>tunnel</strong> màu xanh lá, hãy gửi nó vào <strong>tunnel</strong> màu xanh lam (hướng tới trạm).</p>
<p>Lưu ý rằng không có thành phần mạng nào đang chạy một giao thức định tuyến để tìm đường đi. Thay vào đó, trình quản lý đang chỉ cho các <strong>router</strong> cách chuyển tiếp các gói tin. Mỗi người dùng sẽ cần bộ <strong>tunnels</strong> của riêng mình, vì vậy mạng đang lưu trữ <strong>per-user state</strong> (trạng thái theo từng người dùng) (ví dụ: một mục trong bảng cho mỗi người dùng được kết nối).</p>
<p>Làm thế nào chúng ta thực sự triển khai các quy tắc này? Ví dụ, làm thế nào <strong>radio gateway</strong> biết khi nào một gói tin đến đang ra khỏi <strong>tunnel</strong> màu xanh? Chúng ta có thể sử dụng <strong>encapsulation</strong> (đóng gói). Khi đi vào một <strong>tunnel</strong>, chúng ta có thể thêm một tiêu đề mới, cho biết gói tin đang đi qua <strong>tunnel</strong> đó (ví dụ: &quot;gói tin này đang đi qua <strong>tunnel</strong> màu xanh&quot;). Ở đầu kia, khi gói tin thoát khỏi <strong>tunnel</strong>, cổng sẽ nhìn vào tiêu đề phụ và biết gói tin đến từ <strong>tunnel</strong> nào. Cổng sau đó có thể sử dụng thông tin này để quyết định nơi chuyển tiếp gói tin tiếp theo.</p>
<img width="900px" src="wireless/../assets/wireless/8-053-exchange3.png" />
<p>Lưu ý rằng với <strong>tunnels</strong> và <strong>encapsulation</strong>, các <strong>router</strong> không bao giờ chuyển tiếp dựa trên IP của người dùng. Người dùng luôn di chuyển, vì vậy chúng ta không thể sử dụng IP của họ để xác định vị trí của họ. Thay vào đó, chúng ta phải sử dụng các <strong>tunnels</strong> được cấu hình sẵn này để quyết định nơi chuyển tiếp gói tin.</p>
<h2 id="bước-4-handover"><a class="header" href="#bước-4-handover">Bước 4: Handover</a></h2>
<p>Điều gì xảy ra nếu người dùng di chuyển từ một trạm này sang một trạm khác? Hãy xem xét một giao thức (đơn giản hóa một chút). Chúng ta sẽ gọi các trạm là cũ và mới, và di chuyển từ trạm cũ sang trạm mới.</p>
<img width="900px" src="wireless/../assets/wireless/8-054-handover1.png" />
<ol>
<li>Thiết bị của bạn liên tục đo cường độ tín hiệu của nó tới trạm cũ và báo cáo cường độ đó cho trạm cũ. Tại một thời điểm nào đó, trạm cũ sẽ nói: Cường độ tín hiệu của bạn quá thấp. Đây là một số trạm lân cận (thuộc cùng một nhà khai thác) và các tần số <strong>control channel</strong> tương ứng của chúng. Bạn có thể đo cường độ tín hiệu của mình tới các trạm lân cận này không?</li>
<li>Thiết bị của bạn đo cường độ tín hiệu đến các trạm lân cận và báo cáo các giá trị đó cho trạm cũ. Trạm cũ sẽ chọn trạm mới tốt nhất, dựa trên bất kỳ chính sách nào mà nhà khai thác muốn.</li>
<li>Trạm cũ nói với trạm mới: Người dùng đang đến chỗ bạn. Điều này khiến trạm mới phân bổ một số tài nguyên tần số cho người dùng.</li>
<li>Trạm mới cho trạm cũ biết những tài nguyên tần số nào đã được phân bổ.</li>
<li>Trạm cũ nói với người dùng: Hãy kết nối với trạm mới, sử dụng các tần số này.</li>
<li>Trạm mới báo cáo cho <strong>mobility manager</strong>: Tôi là trạm mới cho người dùng. Trình quản lý cập nhật <strong>database</strong> của mình với vị trí mới của người dùng. Trình quản lý cũng cập nhật các <strong>tunnels</strong> để tạo ra một đường dẫn mới giữa người dùng và Internet (thông qua một trạm mới, và cũng có thể thông qua các <strong>radio gateway</strong> và <strong>packet gateway</strong> mới).</li>
<li>Cuối cùng, trạm mới thông báo cho trạm cũ rằng <strong>handover</strong> đã hoàn tất.</li>
</ol>
<p>Tại sao quá trình <strong>handover</strong> lại phức tạp đến vậy? Hãy nhớ rằng, chúng ta muốn cung cấp cho người dùng giao tiếp liền mạch, không bị gián đoạn khi họ di chuyển giữa các trạm. Điều này đòi hỏi sự hợp tác giữa người dùng, các trạm cũ và mới, <strong>mobility manager</strong>, và các cổng.</p>
<p>Giao tiếp liền mạch rất khó vì quá trình <strong>handover</strong> không phải là nguyên tử. Người dùng vẫn đang gửi và nhận dữ liệu trong khi <strong>handover</strong> đang diễn ra. Ví dụ, các máy chủ bên ngoài trả lời người dùng có thể đã gửi một loạt các gói tin đến trạm cũ. Trong quá trình chuyển giao, trạm cũ tiếp tục đệm bất kỳ dữ liệu nào nó nhận được cho người dùng đó. Sau khi chuyển giao, trạm cũ có thể gửi dữ liệu đã đệm đó đến trạm mới, nơi sẽ chuyển tiếp dữ liệu đó đến người dùng. Lưu ý rằng các mạng <strong>TCP/IP</strong> truyền thống không cần phải đệm dữ liệu như thế này. Loại đệm này là một tính năng mới được thêm vào cho các cuộc <strong>handover</strong> liền mạch khi người dùng di chuyển.</p>
<p>Lưu ý rằng các quyết định trong quá trình <strong>handover</strong> này luôn được thực hiện bởi nhà khai thác. Thiết bị không được chọn trạm tiếp theo để sử dụng. Lợi ích của thiết kế này là nó cho phép nhà khai thác kiểm soát nhiều hơn. Ví dụ, nếu một trạm bị quá tải, nhà khai thác có thể cân bằng tải và gửi người dùng đến một trạm khác. Hoặc, nếu một số người dùng được ưu tiên hơn những người khác, nhà khai thác có thể gửi những người dùng ít được ưu tiên hơn đến các trạm kém hơn. Nhược điểm của thiết kế này là nó hơi chậm hơn và đòi hỏi nhiều lượt đi-về và phức tạp hơn.</p>
<p>Lưu ý rằng <strong>IP address</strong> của người dùng không thay đổi trong quá trình chuyển giao. Chúng ta chỉ cập nhật các <strong>tunnels</strong> để các gói tin dành cho <strong>IP address</strong> của người dùng đi qua một đường dẫn khác.</p>
<p><strong>Handover</strong> rất phức tạp và đòi hỏi phải cập nhật <strong>per-user state</strong> trong mạng. Nếu số lượng người dùng tăng lên, hoặc người dùng di chuyển rất nhanh, giao thức này sẽ gặp phải những thách thức về khả năng mở rộng. Tuy nhiên, mạng di động hiện đại hoạt động khá tốt ở quy mô lớn, bởi vì rất nhiều công sức đã được đổ vào việc tối ưu hóa các giao thức này. Đó là lý do tại sao các tài liệu đặc tả tiêu chuẩn thường dài hàng ngàn trang!</p>
<h2 id="roaming"><a class="header" href="#roaming">Roaming</a></h2>
<p>Nhớ lại rằng một người dùng có thể <strong>roaming</strong> và kết nối với một mạng khác nếu họ đang đến thăm một quốc gia khác (hoặc bất kỳ nơi nào mà nhà khai thác của họ không có vùng phủ sóng).</p>
<p>Quá trình kết nối (<strong>discovery</strong>, <strong>attachment</strong>, <strong>handover</strong>) trong một mạng khách nói chung khá tương tự như kết nối trong mạng chủ. Sự khác biệt chính là, <strong>mobility manager</strong> trong mạng khách phải giao tiếp trở lại với <strong>mobility manager</strong> trong mạng chủ.</p>
<p>Ví dụ, mạng khách cần yêu cầu mạng chủ giúp xác thực người dùng (kiểm tra xem người dùng đã trả tiền cho dịch vụ <strong>roaming</strong> chưa). Ngoài ra, mạng khách cần gửi dữ liệu theo dõi trở lại mạng chủ, để mạng chủ biết vị trí của người dùng.</p>
<p>Làm thế nào mạng khách biết mạng chủ ở đâu? Hãy nhớ rằng, trong quá trình <strong>attachment</strong>, thiết bị trình diện <strong>IMSI</strong> của nó, và <strong>IMSI</strong> chứa một <strong>Mobile Network Code</strong> xác định nhà khai thác của người dùng.</p>
<p>Có hai cách tiếp cận khác nhau để thiết lập các <strong>tunnels</strong> giữa người dùng và Internet.</p>
<p>Trong phương pháp <strong>home routing</strong> (định tuyến tại nhà), lưu lượng được tạo <strong>tunnel</strong> thông qua <strong>packet gateway</strong> của mạng chủ. Điều này có nghĩa là tất cả các gói tin phải đi từ mạng khách trở về mạng chủ, trước khi được chuyển tiếp đến mạng Internet rộng lớn hơn. Điều này có lợi vì nó cho phép <strong>packet gateway</strong> của mạng chủ có thể theo dõi người dùng. Một nhược điểm là, nếu bạn là người dùng có trụ sở tại Hoa Kỳ, bạn <strong>roaming</strong> ở Đức, và bạn muốn truy cập một trang web ở Đức, gói tin của bạn phải đi từ Đức, trở về cổng ở Hoa Kỳ, và sau đó quay trở lại Đức.</p>
<img width="900px" src="wireless/../assets/wireless/8-055-roaming1.png" />
<p>Trong phương pháp <strong>local breakout</strong> (tách nhánh cục bộ), lưu lượng được tạo <strong>tunnel</strong> thông qua <strong>packet gateway</strong> của mạng khách. Điều này có thể rút ngắn tuyến đường giữa người dùng và Internet, vì các gói tin không phải đi hết quãng đường trở về mạng chủ trước. Tuy nhiên, điều này có thể làm cho việc tính toán mức sử dụng của người dùng trở nên phức tạp hơn, vì mạng <strong>roaming</strong> bây giờ phải thực hiện việc tính toán và gửi dữ liệu trở lại mạng chủ.</p>
<img width="900px" src="wireless/../assets/wireless/8-056-roaming2.png" />
<h2 id="các-hoạt-động-bổ-sung"><a class="header" href="#các-hoạt-động-bổ-sung">Các Hoạt động Bổ sung</a></h2>
<p>Chúng ta đã xem xét một số hoạt động chính trong các mạng di động, nhưng cũng có các hoạt động khác tồn tại.</p>
<p><strong>Lawful intercept</strong> (Can thiệp hợp pháp) là một yêu cầu pháp lý đối với tất cả các nhà khai thác di động. Điều này cho phép một chính phủ có lệnh khám xét có thể nghe lén kết nối của bạn và nghe các gói tin bạn đang gửi.</p>
<p><strong>Stolen phone registries</strong> (Sổ đăng ký điện thoại bị đánh cắp) cho phép người dùng báo cáo điện thoại của họ bị đánh cắp. Sau đó, nếu kẻ trộm cố gắng kết nối điện thoại bị đánh cắp của bạn vào mạng, nhà khai thác (<strong>mobility manager</strong> và <strong>database</strong>) sẽ nhận thấy rằng điện thoại đã bị đánh cắp và có thể cố gắng truy tìm điện thoại. Ở đây, nhà khai thác sử dụng <strong>IMEI</strong> (số ID được mã hóa cứng vào điện thoại của bạn) để xác định chiếc điện thoại cụ thể (bất kể <strong>IMSI</strong>, ID thuê bao). Các thiết bị cần phải báo cáo <strong>IMEI</strong> của chúng khi kết nối, cho phép nhà khai thác kiểm tra xem điện thoại có bị đánh cắp hay không.</p>
<p>Những hoạt động bổ sung này là khả thi vì nhà khai thác có quyền kiểm soát tập trung, theo dõi tất cả người dùng và vị trí của họ.</p>
<h2 id="suy-ngẫm-về-thiết-kế-mạng-di-động"><a class="header" href="#suy-ngẫm-về-thiết-kế-mạng-di-động">Suy ngẫm về Thiết kế Mạng Di động</a></h2>
<p>Như chúng ta đã lưu ý trước đó, các mạng di động có những mục tiêu và lựa chọn thiết kế cơ bản khác biệt so với Internet truyền thống. Ví dụ, chúng ta đã thấy rằng xác thực và tính toán cước là những mục tiêu trung tâm của mạng di động, mặc dù đây không phải là mục tiêu trong Internet truyền thống. Chúng ta cũng thấy rằng việc phân bổ dựa trên <strong>reservations</strong>, và mạng duy trì <strong>per-user state</strong> đang thay đổi một cách linh động.</p>
<p>Việc sử dụng các mạng dựa trên <strong>reservation</strong> có trạng thái đã làm tăng sự phức tạp của mạng lưới của chúng ta. Các thành phần khác nhau phải liên tục cấu hình lại các <strong>tunnels</strong> khi người dùng di chuyển.</p>
<p>Hãy nghĩ về một số thiết kế thay thế khả thi. Nhớ lại rằng <strong>handover</strong> phức tạp vì chúng ta muốn người dùng giữ nguyên <strong>IP address</strong> khi họ di chuyển. Điều gì sẽ xảy ra nếu thay vào đó chúng ta thay đổi <strong>IP address</strong> của người dùng trong mỗi lần <strong>handover</strong>? Bây giờ, các <strong>IP address</strong> thực sự phản ánh vị trí của người dùng, và chúng ta có thể sử dụng lại các giao thức định tuyến truyền thống. Tuy nhiên, các giao thức ở tầng cao hơn như <strong>TCP</strong> và <strong>HTTP</strong> sẽ bị hỏng. Hãy nhớ rằng, <strong>TCP</strong> dựa vào việc hai người dùng kết nối giữ nguyên cùng một <strong>IP address</strong>.</p>
<p>Việc sử dụng cùng một <strong>IP address</strong> làm tăng sự phức tạp, nhưng việc thay đổi <strong>IP address</strong> làm hỏng <strong>TCP</strong>. Một giải pháp khả thi là sử dụng một <strong>transport-level protocol</strong> (giao thức tầng vận chuyển) khác cho phép thay đổi <strong>IP address</strong>, như <strong>QUIC</strong> (được phát triển tại Google). Khi đó, mặc dù các <strong>IP address</strong> đang thay đổi, chúng ta có thể sử dụng trường <strong>flow label</strong> (nhãn luồng) trong tiêu đề <strong>IPv6</strong> để gắn nhãn cho tất cả các gói tin trong một luồng.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bảng-chú-giải-thuật-ngữ"><a class="header" href="#bảng-chú-giải-thuật-ngữ">Bảng chú giải thuật ngữ</a></h1>
<p>Bảng chú giải này được chuyển thể từ <a href="https://sp24.cs168.io/glossary">các khóa học CS 168 trước đây</a>.</p>
<table>
        <thead>
          <th>Thuật ngữ</th>
          <th>Định nghĩa</th>
        </thead>
        <tbody><tr>
            <td>ACK</td>
            <td align="left"><p>Một <code>packet</code> <code>TCP</code> với <code>ACK flag</code> (cờ báo nhận) được bật, cho biết dữ liệu đã được nhận.</p>
</td>
          </tr><tr>
            <td>ARP</td>
            <td align="left"><p><code>Address Resolution Protocol</code> (Giao thức Phân giải Địa chỉ). Giao thức cho phép các thiết bị ánh xạ <code>MAC address</code> (địa chỉ MAC) tới <code>IP address</code> (địa chỉ IP). Một thiết bị sẽ gửi ra (<code>broadcast</code> (quảng bá)) một thông điệp <strong>Request</strong> <code>ARP</code>, để tìm ra <code>MAC address</code> tương ứng với <code>IP Address</code>. Thiết bị được truy vấn sẽ trả lời (<code>unicast</code> (đơn bá)) bằng một thông điệp <strong>Response</strong> <code>ARP</code>. Các ánh xạ giữa <code>MAC address</code> và <code>IP address</code> được lưu trữ trong <code>ARP table</code> (bảng ARP), hoạt động như một <code>cache</code> (bộ đệm). Các mục trong <code>ARP table</code> sẽ hết hạn (<code>soft state</code> (trạng thái mềm)).</p>
</td>
          </tr><tr>
            <td>Autonomous System</td>
            <td align="left"><p>Một <code>network</code> (mạng) hoặc tập hợp các <code>network</code> được quản lý và giám sát bởi một thực thể hoặc tổ chức duy nhất. Một <code>ISP</code> thường là một <code>AS</code> (viết tắt của Autonomous System) duy nhất; tuy nhiên, một số <code>ISP</code> phân chia mạng của họ thành nhiều <code>AS</code>. Mỗi <code>AS</code> được gán một số hiệu, được sử dụng trong <code>BGP</code> (Border Gateway Protocol - Giao thức Cổng Biên giới) để xác định các đường đi.</p>
</td>
          </tr><tr>
            <td>AXE</td>
            <td align="left"><p>Một giải pháp thay thế được đề xuất cho <code>STP</code>, trong đó các vòng lặp được ngăn chặn mà không cần đến <code>spanning tree</code> (cây bao trùm) (thay vào đó sử dụng cơ chế loại bỏ trùng lặp). Nguồn gốc của một số bài thơ hay nhất mà thế giới từng thấy.</p>
</td>
          </tr><tr>
            <td>Bad things that can happen to packets</td>
            <td align="left"><p>Những điều tồi tệ có thể xảy ra với <code>packet</code>: Bị mất, bị hỏng, bị sắp xếp sai thứ tự, bị trễ, bị trùng lặp.</p>
</td>
          </tr><tr>
            <td>Bandwidth-Delay Product</td>
            <td align="left"><p>Đây là đại lượng (<code>bandwidth</code>) * (<code>propagation delay</code> (độ trễ lan truyền)) biểu thị số lượng bit cần thiết để "lấp đầy đường ống" (tức là số lượng bit đã được gửi đi nhưng chưa nhận được nếu bên gửi đang gửi với <code>bandwidth</code> của <code>link</code>).</p>
</td>
          </tr><tr>
            <td>Bellman Ford Equation</td>
            <td align="left"><p>Phương trình nói rằng khoảng cách ngắn nhất của bạn đến một đích là giá trị nhỏ nhất của chi phí đến một nút láng giềng cộng với khoảng cách từ láng giềng đó đến <code>link</code>, xét trên tất cả các láng giềng. Hay cụ thể hơn, chi phí của nút u đến một đích v cho trước là: d(u,v) = min(với mọi láng giềng w) [c(u,w) + d(w,v)]</p>
</td>
          </tr><tr>
            <td>Best Effort</td>
            <td align="left"><p><code>Best Effort</code> (Nỗ lực tối đa). Việc phân phối theo yêu cầu trong đó hệ thống không cung cấp đảm bảo về hiệu suất nào khác ngoài việc hệ thống sẽ cố gắng hết sức.</p>
</td>
          </tr><tr>
            <td>Border Router</td>
            <td align="left"><p>Các <code>router</code> được kết nối với các <code>router</code> trong một <code>network</code> khác.</p>
</td>
          </tr><tr>
            <td>Checksum</td>
            <td align="left"><p><code>Checksum</code> (Tổng kiểm) được sử dụng để phát hiện lỗi hỏng dữ liệu, và là một con số được tính toán trên một phần nào đó của <code>packet</code> (tùy thuộc vào giao thức cụ thể).</p>
</td>
          </tr><tr>
            <td>CIDR</td>
            <td align="left"><p>Viết tắt của <code>Classless Interdomain Routing</code> (Định tuyến liên miền không lớp). Kết hợp một <code>IP address</code> với một <code>network mask</code> (mặt nạ mạng) để xác định các bit nào là bit mạng. Linh hoạt hơn nhiều so với lược đồ địa chỉ IP ban đầu, hay <code>classful addressing</code> (địa chỉ hóa theo lớp).</p>
</td>
          </tr><tr>
            <td>Circuit Switching</td>
            <td align="left"><p><code>Circuit Switching</code> (Chuyển mạch kênh). Phương thức truyền dữ liệu trong đó một hệ thống đầu cuối đặt trước <code>bandwidth</code> dọc theo một đường đi - thiết lập một mạch (circuit) - để liên lạc. Không cần đến <code>packet</code>.</p>
</td>
          </tr><tr>
            <td>Classful Addressing</td>
            <td align="left"><p><code>Classful Addressing</code> (Địa chỉ hóa theo lớp). Một lược đồ để xác định các bit mạng và bit <code>host</code> của một <code>IP address</code>. Có ba lớp (mà chúng ta đề cập): Địa chỉ <strong>Lớp A</strong> bắt đầu bằng 0, và sử dụng 8 bit đầu tiên để xác định mạng. 24 bit cuối xác định <code>host</code>. Địa chỉ <strong>Lớp B</strong> bắt đầu bằng 10, và sử dụng 16 bit đầu tiên để xác định mạng. 16 bit cuối xác định <code>host</code>. Địa chỉ <strong>Lớp C</strong> bắt đầu bằng 110, và sử dụng 24 bit đầu tiên để xác định mạng. 8 bit cuối xác định <code>host</code>.”</p>
</td>
          </tr><tr>
            <td>Control Plane</td>
            <td align="left"><p><code>Control Plane</code> (Mặt phẳng điều khiển). Đề cập đến các cơ chế mạng được sử dụng để tính toán <code>routing table</code> (bảng định tuyến) và các thông tin chuyển tiếp khác.</p>
</td>
          </tr><tr>
            <td>Convergence</td>
            <td align="left"><p><code>Convergence</code> (Sự hội tụ). Chúng ta nói rằng một thuật toán đã hội tụ khi tất cả các bên đều có thông tin cập nhật và, trừ khi có sự thay đổi trong cấu trúc liên kết của mạng, tất cả các "cập nhật" tiếp theo được gửi và nhận không ảnh hưởng đến trạng thái định tuyến.</p>
</td>
          </tr><tr>
            <td>Core/Backbone Router</td>
            <td align="left"><p><code>Router</code> lõi/xương sống. Các <code>router</code> được kết nối với các <code>router</code> nội bộ khác.</p>
</td>
          </tr><tr>
            <td>Cost Table</td>
            <td align="left"><p><code>Cost Table</code> (Bảng chi phí). Cấu trúc dữ liệu trên các <code>router</code> chứa tập hợp chi phí đến tất cả các nút láng giềng.</p>
</td>
          </tr><tr>
            <td>Count-to-Infinity Problem</td>
            <td align="left"><p><code>Count-to-Infinity Problem</code> (Vấn đề đếm đến vô cực). Tên của một loại <code>routing loop</code> (vòng lặp định tuyến) có thể xảy ra do bản chất không đồng bộ của việc lan truyền thông tin bằng <code>Distance Vector</code> (Vector khoảng cách). Thường gây ra bởi một <code>link</code> bị hỏng, một <code>router</code>, ban đầu sử dụng một đường đi bị hỏng đến một đích nhất định, lại tin rằng láng giềng của nó có một đường đi hợp lệ đến đích đó và sử dụng đường đi này mà không biết rằng nó chứa một phần của đường đi bị hỏng ban đầu của chính nó. Cả hai láng giềng liên tục nhận cập nhật từ nhau, tiếp tục sử dụng đường đi bị hỏng này.</p>
</td>
          </tr><tr>
            <td>Cumulative ACK</td>
            <td align="left"><p><code>Cumulative ACK</code> (ACK tích lũy). <code>ACK</code> có nghĩa là "Tôi đã nhận được tất cả các <code>packet</code> (hoặc byte) cho đến <code>packet</code> này".</p>
</td>
          </tr><tr>
            <td>Data Plane</td>
            <td align="left"><p><code>Data Plane</code> (Mặt phẳng dữ liệu). Đề cập đến các cơ chế mạng được sử dụng để chuyển tiếp dữ liệu.</p>
</td>
          </tr><tr>
            <td>Datacenters</td>
            <td align="left"><p><code>Datacenter</code> (Trung tâm dữ liệu). Các tập hợp máy móc khổng lồ.</p>
</td>
          </tr><tr>
            <td>David Clark</td>
            <td align="left"><p>Người hùng thầm lặng của Internet. Ông là kiến trúc sư trưởng và là tác giả của <code>end-to-end principle</code> (nguyên tắc đầu cuối-đến-đầu cuối).</p>
</td>
          </tr><tr>
            <td>Dead End</td>
            <td align="left"><p><code>Dead End</code> (Ngõ cụt). Khi một <code>packet</code> đến một <code>router</code> hoặc <code>switch</code> (bộ chuyển mạch) nhưng quyết định chuyển tiếp không dẫn đến một cổng ra nào, buộc <code>packet</code> phải bị loại bỏ.</p>
</td>
          </tr><tr>
            <td>Destination-Based Routing</td>
            <td align="left"><p><code>Destination-Based Routing</code> (Định tuyến dựa trên đích). Định tuyến chỉ phụ thuộc vào đích đến. Các đường đi từ hai nguồn khác nhau đến cùng một đích phải trùng nhau một khi chúng giao nhau.</p>
</td>
          </tr><tr>
            <td>DHCP</td>
            <td align="left"><p><code>Dynamic Host Configuration Protocol</code> (Giao thức Cấu hình Host Động). Giao thức cung cấp cho một <code>host</code> địa chỉ IP của nó khi kết nối vào một <code>network</code>. Khi một <code>host</code> kết nối vào một <code>network</code> mới, nó sẽ gửi một thông điệp <strong>Discovery</strong> <code>DHCP</code> để thông báo cho (các) máy chủ <code>DHCP</code> rằng nó cần một <code>IP address</code>. Máy chủ gửi một thông điệp <strong>Offer</strong>, chứa một <code>IP address</code> được đề xuất, một <code>subnet mask</code> (mặt nạ mạng con), <code>IP address</code> của <code>router</code> chặng đầu tiên, và một thời gian thuê (lease time). <code>Host</code> sẽ gửi một thông điệp <strong>Request</strong>, tương ứng với đề nghị mà nó muốn chấp nhận. Máy chủ trả lời bằng một thông điệp <strong>Acknowledgement/Acceptance</strong>. Tất cả các thông điệp <code>DHCP</code> đều được <code>broadcast</code>.</p>
</td>
          </tr><tr>
            <td>Distance Vector Routing</td>
            <td align="left"><p><code>Distance Vector Routing</code> (Định tuyến theo Vector Khoảng cách). Là một thuật toán định tuyến phân tán và có khả năng mở rộng, trong đó mỗi <code>router</code> lưu giữ một "vector" các khoảng cách cũng như <code>router</code> chặng tiếp theo đến mỗi đích. Mỗi nút sẽ gửi tràn (flood) vector khoảng cách ngắn nhất của nó cho các láng giềng và khi nhận được một vector, mỗi <code>router</code> sử dụng thuật toán Bellman-Ford để cập nhật vector của chính mình.</p>
</td>
          </tr><tr>
            <td>DNS</td>
            <td align="left"><p><code>Domain Name Service</code> (Dịch vụ Tên miền), một hệ thống liên kết tên với địa chỉ và thường được sử dụng để tra cứu địa chỉ của một <code>host</code> khi biết tên.</p>
</td>
          </tr><tr>
            <td>Dotted-quad notation</td>
            <td align="left"><p><code>Dotted-quad notation</code> (Ký hiệu bộ bốn dấu chấm). Một ký hiệu viết các địa chỉ IPv4 dưới dạng 4 con số, mỗi số cho một byte. Ví dụ, 12.34.158.5</p>
</td>
          </tr><tr>
            <td>Duplicate ACKs</td>
            <td align="left"><p><code>Duplicate ACKs</code> (Các ACK trùng lặp). Một chuỗi các <code>cumulative ACK</code> xác nhận cùng một dữ liệu đã nhận nhiều lần: một dấu hiệu của việc mất một <code>packet</code> riêng lẻ, bởi vì các <code>ACK</code> bổ sung này cho thấy dữ liệu vẫn đang được nhận.</p>
</td>
          </tr><tr>
            <td>Edge Router</td>
            <td align="left"><p><code>Edge Router</code> (Router biên). Các <code>router</code> mà các <code>host</code> đầu cuối được gắn vào.</p>
</td>
          </tr><tr>
            <td>End to End Principle</td>
            <td align="left"><p><code>End to End Principle</code> (Nguyên tắc Đầu cuối-đến-Đầu cuối). Giúp xác định xem một chức năng nào đó nên được triển khai trong mạng, hay chỉ trong các <code>host</code> đầu cuối. Lớp học này đã trình bày ba cách diễn giải: <strong>Only-if-necessary</strong> (Chỉ khi cần thiết): Nếu một chức năng có thể được triển khai bởi các <code>host</code>, đừng triển khai nó trong mạng. <strong>Only-if-sufficient</strong> (Chỉ khi đủ): Chỉ triển khai một chức năng ở cấp độ này nếu nó có thể được triển khai hoàn toàn ở cấp độ này và bạn có thể giảm bớt gánh nặng cho các <code>host</code>. <strong>Only-if-useful</strong> (Chỉ khi hữu ích): Triển khai một chức năng trong mạng nếu nó có thể cải thiện hiệu suất của chức năng đó mà không gây gánh nặng cho các ứng dụng không yêu cầu nó.</p>
</td>
          </tr><tr>
            <td>Enterprises</td>
            <td align="left"><p>Doanh nghiệp và trường đại học.</p>
</td>
          </tr><tr>
            <td>Fate Sharing</td>
            <td align="left"><p><code>Fate Sharing</code> (Chia sẻ số phận). Lưu trữ trạng thái trong các thực thể dựa vào trạng thái đó, sao cho thực thể đó sẽ không bị ảnh hưởng bởi các lỗi khác.</p>
</td>
          </tr><tr>
            <td>First-hop router</td>
            <td align="left"><p><code>First-hop router</code> (Router chặng đầu tiên). <code>Router</code> mà một <code>host</code> gửi <code>packet</code> đến khi nó muốn gửi <code>packet</code> đó đến một đích bên ngoài mạng L2 của nó.</p>
</td>
          </tr><tr>
            <td>Flooding</td>
            <td align="left"><p><code>Flooding</code> (Gửi tràn). Trong lớp học này, chúng ta sử dụng thuật ngữ này để chỉ hành động gửi một <code>packet</code> ra tất cả các cổng (trừ cổng đến) trong một <code>switch</code> duy nhất.</p>
</td>
          </tr><tr>
            <td>Flow</td>
            <td align="left"><p><code>Flow</code> (Luồng). Một dòng các <code>packet</code> giữa hai tiến trình.</p>
</td>
          </tr><tr>
            <td>Forwarding</td>
            <td align="left"><p><code>Forwarding</code> (Chuyển tiếp). Gửi một <code>packet</code> về phía đích của nó. Điều này được thực hiện bằng cách đọc địa chỉ từ phần <code>header</code> (tiêu đề) của <code>packet</code>, tìm kiếm trong trạng thái định tuyến để tìm cổng ra chính xác, và gửi <code>packet</code> ra cổng đó. Đây là một quy trình cục bộ bên trong một <code>router</code>, được thực hiện trong <code>data plane</code>, và nó phải được thực hiện nhanh chóng.</p>
</td>
          </tr><tr>
            <td>Forwarding Entry</td>
            <td align="left"><p><code>Forwarding Entry</code> (Mục chuyển tiếp). Một mục trong <code>forwarding table</code> (bảng chuyển tiếp) ánh xạ một địa chỉ hoặc một tập hợp các địa chỉ đến một cổng ra.</p>
</td>
          </tr><tr>
            <td>Forwarding Table</td>
            <td align="left"><p><code>Forwarding Table</code> (Bảng chuyển tiếp). Một bảng mà <code>router</code> tự tính toán để hướng dẫn các quyết định chuyển tiếp của nó. <code>Forwarding table</code> được tính toán bằng cách sử dụng thông tin trong các bảng láng giềng và bảng chi phí.</p>
</td>
          </tr><tr>
            <td>Fragmentation</td>
            <td align="left"><p><code>Fragmentation</code> (Phân mảnh). Chia một <code>packet</code> thành các <code>packet</code> nhỏ hơn để phù hợp với <code>maximum transmission unit</code> (MTU) (đơn vị truyền dẫn tối đa) của một <code>link</code>.</p>
</td>
          </tr><tr>
            <td>Full-information ACK</td>
            <td align="left"><p><code>Full-information ACK</code> (ACK đầy đủ thông tin). Một <code>ACK</code> mô tả tất cả dữ liệu đã nhận được cho đến nay, và có thể có dạng "Tôi đã nhận được tất cả các <code>packet</code> cho đến <code>packet</code> này, cộng với những <code>packet</code> bổ sung này".</p>
</td>
          </tr><tr>
            <td>Hard State</td>
            <td align="left"><p><code>Hard State</code> (Trạng thái cứng). Các hệ thống ở "trạng thái cứng" không làm hết hạn thông tin của chúng – chúng giả định một khi đã được cung cấp một kiến thức nào đó, nó vẫn đúng và hợp lệ cho đến khi được thông báo rõ ràng là khác đi.</p>
</td>
          </tr><tr>
            <td>Host bits</td>
            <td align="left"><p><code>Host bits</code> (Các bit host). Phần của <code>IP address</code> xác định <code>host</code> bên trong mạng của nó.</p>
</td>
          </tr><tr>
            <td>Host/End System</td>
            <td align="left"><p><code>Host</code>/<code>End System</code> (Hệ thống đầu cuối). Các điểm cuối của một <code>network</code>. Các thực thể này chịu trách nhiệm tạo ra các <code>packet</code> dữ liệu sau đó được định tuyến qua mạng.</p>
</td>
          </tr><tr>
            <td>Individual ACK</td>
            <td align="left"><p><code>Individual ACK</code> (ACK riêng lẻ). Một <code>ACK</code> có nghĩa là "Tôi đã nhận được <code>packet</code> đơn lẻ, cụ thể này".</p>
</td>
          </tr><tr>
            <td>Internet</td>
            <td align="left"><p><code>Internet</code>. Cơ sở hạ tầng mạng cốt lõi kết nối tất cả các thiết bị máy tính được kết nối.</p>
</td>
          </tr><tr>
            <td>IP Address</td>
            <td align="left"><p><code>IP Address</code> (Địa chỉ IP). Lược đồ địa chỉ được sử dụng ở tầng 3.</p>
</td>
          </tr><tr>
            <td>IPv4</td>
            <td align="left"><p><code>IPv4</code>. Phiên bản 4 của giao thức IP.</p>
</td>
          </tr><tr>
            <td>ISP (Internet Service Provider)/ISP Network</td>
            <td align="left"><p><code>ISP</code> (Nhà cung cấp Dịch vụ Internet)/Mạng <code>ISP</code>. Một <code>network</code> gồm các <code>packet switch</code> (bộ chuyển mạch gói) và các <code>link</code> truyền thông cung cấp quyền truy cập mạng cho các hệ thống đầu cuối.</p>
</td>
          </tr><tr>
            <td>LAN</td>
            <td align="left"><p><code>LAN</code> (Local area network - Mạng cục bộ), một mạng L2 trải rộng trên một khu vực địa lý nhỏ, ví dụ như một ngôi nhà.</p>
</td>
          </tr><tr>
            <td>Layering</td>
            <td align="left"><p><code>Layering</code> (Phân tầng). Nói chung, phân tầng là việc chia một hệ thống phức tạp thành các cấp độ riêng biệt xây dựng/phụ thuộc lẫn nhau. Trong bối cảnh Internet, điều này đề cập đến một tập hợp các tầng cụ thể (physical = L1, datalink = L2, internetworking = L3, transport = L4) chỉ tương tác với các tầng ngay trên hoặc dưới nó.</p>
</td>
          </tr><tr>
            <td>Layers</td>
            <td align="left"><p><strong>Application</strong> (Hỗ trợ mạng cho các ứng dụng). 4: <strong>Transport</strong> (Phân phối đầu cuối-đến-đầu cuối đáng tin cậy/không đáng tin cậy). 3: <strong>Network</strong> (Phân phối toàn cục theo kiểu nỗ lực tối đa). 2: <strong>Datalink</strong> (Phân phối cục bộ theo kiểu nỗ lực tối đa). 1: <strong>Physical</strong> (Các bit được truyền qua một môi trường nào đó).</p>
</td>
          </tr><tr>
            <td>Learning Switches</td>
            <td align="left"><p><code>Learning Switches</code> (Switch học). Thường được sử dụng ở L2 kết hợp với <code>spanning tree protocol</code> (giao thức cây bao trùm). Các <code>learning switch</code> duy trì một <code>forwarding table</code> ánh xạ đích đến liên kết đầu ra. Chúng học từ trường "source" (nguồn) của một <code>packet</code>. Khi một <code>packet</code> đến, <code>switch</code> kiểm tra xem đích có trong bảng của nó không. Nếu có, nó sẽ chuyển tiếp <code>packet</code> xuống <code>link</code> đó. Nếu không, nó sẽ gửi tràn <code>packet</code>.</p>
</td>
          </tr><tr>
            <td>Linecard</td>
            <td align="left"><p><code>Linecard</code>. Một phần cứng (trong một <code>router</code>) nhận/gửi <code>packet</code>. Chúng cập nhật các trường khác nhau (<code>checksum</code>, <code>TTL</code>, v.v.) và chọn cổng ra.</p>
</td>
          </tr><tr>
            <td>Link</td>
            <td align="left"><p><code>Link</code> (Liên kết). Các phần cơ sở hạ tầng vật lý kết nối các <code>router</code>.</p>
</td>
          </tr><tr>
            <td>Link-State Routing</td>
            <td align="left"><p><code>Link-State Routing</code> (Định tuyến theo Trạng thái Liên kết). Trong <code>Link-State routing</code>, mỗi <code>router</code> gửi (sử dụng một cơ chế <code>broadcast</code> đặc thù của giao thức) trạng thái <code>link</code> của nó đến tất cả các <code>router</code> khác trong mạng. Bằng cách này, mọi <code>router</code> đều biết toàn bộ <code>network graph</code>. Sau đó, mọi <code>router</code> tính toán các đường đi có chi phí thấp nhất từ chính nó đến tất cả các nút khác bằng bất kỳ thuật toán hợp lệ nào (ví dụ, thuật toán Dijkstra).</p>
</td>
          </tr><tr>
            <td>Loop</td>
            <td align="left"><p><code>Loop</code> (Vòng lặp). Khi một <code>packet</code> quay vòng quanh cùng một tập hợp các nút mãi mãi.</p>
</td>
          </tr><tr>
            <td>LPM</td>
            <td align="left"><p><code>LPM</code> (Longest-prefix-match - Trùng khớp tiền tố dài nhất): Khi một <code>IP Address</code> trùng khớp với nhiều tiền tố, hãy chọn tiền tố trùng khớp dài nhất (Hãy tưởng tượng việc duyệt qua cây tiền tố cho đến khi địa chỉ 'rơi ra ngoài').</p>
</td>
          </tr><tr>
            <td>MAC Address</td>
            <td align="left"><p>Được sử dụng cho định tuyến L2, <code>MAC Address</code> (Địa chỉ MAC) là một số 48 bit được ghi cứng vào giao diện mạng của các <code>host</code> và <code>router</code>. <code>MAC address</code> được mã hóa trong phần cứng vật lý lưu trữ trong bộ nhớ chỉ đọc (Read-Only memory), làm cho nó trở thành một định danh vĩnh viễn.</p>
</td>
          </tr><tr>
            <td>Maximum Transmission Unit (MTU)</td>
            <td align="left"><p><code>Maximum Transmission Unit</code> (MTU) (Đơn vị Truyền dẫn Tối đa). Số lượng bit lớn nhất mà một <code>link</code> có thể truyền như một đơn vị duy nhất, kích thước <code>packet</code> lớn nhất có thể được gửi qua một <code>link</code>.</p>
</td>
          </tr><tr>
            <td>Modularity</td>
            <td align="left"><p><code>Modularity</code> (Tính mô-đun). Phân rã một vấn đề thành các tác vụ hoặc các khái niệm trừu tượng. Dẫn đến các nguyên tắc thiết kế của việc phân tầng.</p>
</td>
          </tr><tr>
            <td>Multihoming</td>
            <td align="left"><p><code>Multihoming</code>. Kết nối một <code>host</code> với nhiều mạng khác nhau, để nếu một mạng cha bị ngoại tuyến, <code>host</code> vẫn có thể truy cập được. Ngăn chặn việc tổng hợp (aggregation).</p>
</td>
          </tr><tr>
            <td>NACK</td>
            <td align="left"><p><code>NACK</code> (“Non-acknowledgement” - thông điệp không báo nhận) – “Tôi đã không nhận được dữ liệu này [mà tôi đang mong đợi]”.</p>
</td>
          </tr><tr>
            <td>Network</td>
            <td align="left"><p><code>Network</code> (Mạng). Khi được sử dụng không chính thức, thuật ngữ này đề cập đến một hệ thống bao gồm các hệ thống đầu cuối, <code>router</code>/<code>switch</code>, và các <code>link</code> có khả năng truyền dữ liệu giữa các <code>host</code> (ví dụ: mạng khuôn viên của Berkeley). Khi được sử dụng chính thức, nó đề cập đến một tập hợp các phần tử mạng chia sẻ cùng một địa chỉ mạng trong IPv4, và thường được sử dụng đồng nghĩa với <code>subnet</code> (mạng con).</p>
</td>
          </tr><tr>
            <td>Network Address</td>
            <td align="left"><p><code>Network Address</code> (Địa chỉ mạng). Thành phần của một <code>IP address</code> đề cập đến mạng (hoặc <code>subnet</code>), thay vì <code>host</code>.</p>
</td>
          </tr><tr>
            <td>Network bits</td>
            <td align="left"><p><code>Network bits</code> (Các bit mạng). Phần của <code>IP address</code> xác định mạng mà <code>host</code> đang ở trên đó.</p>
</td>
          </tr><tr>
            <td>Network mask</td>
            <td align="left"><p><code>Network mask</code> (Mặt nạ mạng). Một chuỗi bit giống như <code>IP-address</code> được sử dụng để xác định phần mạng của một <code>IP Address</code>. Bao gồm một số lượng nhất định các bit 1 (một bit cho mỗi bit địa chỉ mạng), theo sau là tất cả các bit 0.</p>
</td>
          </tr><tr>
            <td>Network Name</td>
            <td align="left"><p><code>Network Name</code> (Tên mạng). Tên của một <code>host</code> (Thứ gì đó thân thiện với con người).</p>
</td>
          </tr><tr>
            <td>Network Stack</td>
            <td align="left"><p><code>Network Stack</code> (Chồng giao thức mạng). Phần mềm mạng trên <code>host</code>, nó sao chép một số chức năng có ở các <code>router</code> và cũng bổ sung thêm chức năng (ví dụ: <code>Socket</code>, <code>header</code> <code>TCP</code>, v.v.).</p>
</td>
          </tr><tr>
            <td>Packet</td>
            <td align="left"><p><code>Packet</code> (Gói tin). Các túi bit. Bao gồm: <strong>Header</strong> (Tiêu đề) với thông tin có ý nghĩa để mạng và <code>network stack</code> đưa ra quyết định. <strong>Body</strong> (Thân) chứa một <code>payload</code> (dữ liệu tải). Ví dụ: Một tệp tin, hình ảnh, một <code>header</code> ứng dụng, v.v.</p>
</td>
          </tr><tr>
            <td>Packet Switching</td>
            <td align="left"><p><code>Packet Switching</code> (Chuyển mạch gói). Phương thức truyền dữ liệu trong đó dữ liệu được phân đoạn thành các <code>packet</code> và các <code>router</code>/<code>switch</code> phục vụ từng <code>packet</code> mà chúng nhận được một cách độc lập bằng cách kiểm tra <code>header</code> của nó.</p>
</td>
          </tr><tr>
            <td>Path Vector Routing</td>
            <td align="left"><p><code>Path Vector Routing</code> (Định tuyến theo Vector Đường đi). Tương tự như <code>distance vector routing</code>, nhưng khi quảng bá cho các láng giềng, thay vì gửi cho họ khoảng cách ngắn nhất của bạn, bạn gửi cho họ các đường đi của bạn đến các đích.</p>
</td>
          </tr><tr>
            <td>Payload</td>
            <td align="left"><p><code>Payload</code> (Dữ liệu tải). Dữ liệu được mang trong <code>packet</code>.</p>
</td>
          </tr><tr>
            <td>Peer Table</td>
            <td align="left"><p><code>Peer Table</code> (Bảng ngang hàng). Cấu trúc dữ liệu trên các <code>router</code> chứa các bản sao thông tin mà mỗi "peer" (ngang hàng) hoặc "neighbour" (láng giềng) của <code>router</code> đã gửi cho chúng.</p>
</td>
          </tr><tr>
            <td>Poison Reverse</td>
            <td align="left"><p><code>Poison Reverse</code>. Một phương pháp cố gắng giảm thiểu vấn đề đếm đến vô cực bằng cách không quảng bá khả năng đến một đích (tức là quảng bá một khoảng cách là vô cực) đến một láng giềng mà bạn sử dụng trên đường đi đến đích nói trên. Ví dụ, <code>router</code> A tạo một bản sao tạm thời của vector của nó để gửi đến <code>router</code> C, trong đó quảng bá một khoảng cách là vô cực cho tất cả các đích mà <code>router</code> A sử dụng <code>link</code> AC.</p>
</td>
          </tr><tr>
            <td>Port (Logical)</td>
            <td align="left"><p><code>Port</code> (Cổng logic). Một con số mà hệ điều hành gán cho một <code>socket</code> được sử dụng để xác định <code>socket</code> đó.</p>
</td>
          </tr><tr>
            <td>Port (Router)</td>
            <td align="left"><p><code>Port</code> (Cổng vật lý). Cổng vật lý kết nối một <code>router</code> với một <code>router</code> khác thông qua một <code>link</code>.</p>
</td>
          </tr><tr>
            <td>Prefix Aggregation</td>
            <td align="left"><p><code>Prefix Aggregation</code> (Tổng hợp Tiền tố). Kết hợp các mục trong bảng định tuyến thành một mục bằng cách sử dụng một tiền tố chung (tức là kết hợp 101 và 100 thành 10*).</p>
</td>
          </tr><tr>
            <td>Prefix Tree</td>
            <td align="left"><p><code>Prefix Tree</code> (Cây tiền tố). Cây nhị phân biểu diễn các bit trùng khớp trong việc tra cứu <code>IP address</code> (cách bảng tra cứu được duyệt).</p>
</td>
          </tr><tr>
            <td>Reliability (see Robustness)</td>
            <td align="left"><p><code>Reliability</code> (Độ tin cậy) (xem <code>Robustness</code>). Có hai cách diễn giải: 1) Mạng phục hồi sau sự cố một cách nhanh chóng, cho phép hai điểm cuối không bị phân tách có thể giao tiếp. 2) Lỗi mạng không can thiệp vào ngữ nghĩa của điểm cuối.</p>
</td>
          </tr><tr>
            <td>Reliable Delivery</td>
            <td align="left"><p><code>Reliable Delivery</code> (Phân phối đáng tin cậy). Xây dựng một dịch vụ vận chuyển đáng tin cậy trên nền tảng phân phối theo kiểu nỗ lực tối đa.</p>
</td>
          </tr><tr>
            <td>Reliable Transport</td>
            <td align="left"><p><code>Reliable Transport</code> (Vận chuyển đáng tin cậy). Một cơ chế vận chuyển là "đáng tin cậy" nếu và chỉ nếu (a) nó gửi lại tất cả các <code>packet</code> bị mất hoặc bị hỏng, và (b) nó cố gắng tạo ra sự tiến triển.</p>
</td>
          </tr><tr>
            <td>Resource Accountability</td>
            <td align="left"><p><code>Resource Accountability</code> (Trách nhiệm giải trình tài nguyên). Khả năng biết ai đang sử dụng tài nguyên nào (<code>bandwidth</code>) để bạn có thể yêu cầu họ chịu trách nhiệm về nó. Một thất bại trong kiến trúc Internet.</p>
</td>
          </tr><tr>
            <td>Robustness (see Reliability)</td>
            <td align="left"><p><code>Robustness</code> (Tính bền vững) (xem <code>Reliability</code>). Miễn là mạng không bị phân vùng, hai <code>host</code> phải có thể giao tiếp được với nhau cuối cùng, VÀ các lỗi không bao giờ được can thiệp vào ngữ nghĩa của ứng dụng.</p>
</td>
          </tr><tr>
            <td>Route Aggregation</td>
            <td align="left"><p><code>Route Aggregation</code> (Tổng hợp định tuyến). Thay vì có một mục chuyển tiếp cho mỗi <code>host</code>, hãy có một mục cho mỗi tập hợp các <code>host</code> có cùng tiền tố và tất cả đều đi ra cùng một cổng.</p>
</td>
          </tr><tr>
            <td>Route Poisoning</td>
            <td align="left"><p><code>Route Poisoning</code>. Thủ tục để giảm thiểu sự không nhất quán của mạng, quy định rằng khi một <code>link</code> giữa A và B bị hỏng, <code>router</code> B nên quảng bá cho tất cả các láng giềng của nó rằng nó không còn <code>link</code> đến <code>router</code> A (tức là B quảng bá một khoảng cách là vô cực), để báo hiệu rằng nó không còn có thể đến được A.</p>
</td>
          </tr><tr>
            <td>Routing</td>
            <td align="left"><p><code>Routing</code> (Định tuyến). Hướng dẫn các <code>packet</code> từ nguồn đến đích (có thể được thực hiện theo nhiều cách - xem <code>link-state</code>, <code>distance vector</code>, <code>spanning tree</code>, v.v.). Đây vốn là một quá trình toàn cục, vì vậy nó phải có khả năng mở rộng. Điều này được thực hiện trong <code>control plane</code>, và có thể được thực hiện một cách chậm rãi.</p>
</td>
          </tr><tr>
            <td>Routing Table</td>
            <td align="left"><p><code>Routing Table</code> (Bảng định tuyến). Tương tự như <code>Forwarding Table</code>, nhưng có thể đề cập đến tất cả thông tin mà một <code>router</code> có (bao gồm cả từ các peer khác) thay vì chỉ là các mục chuyển tiếp tốt nhất.</p>
</td>
          </tr><tr>
            <td>Slash notation</td>
            <td align="left"><p><code>Slash notation</code> (Ký hiệu gạch chéo). Ký hiệu để nói về một <code>subnet</code>. Trông giống như 1.2.0.0/10 trong đó 10 bit đầu tiên của 1.2.0.0 là tiền tố <code>subnet</code>.</p>
</td>
          </tr><tr>
            <td>Sliding window</td>
            <td align="left"><p><code>Sliding window</code> (Cửa sổ trượt). Một số lượng hữu hạn các <code>packet</code> chưa được xác nhận (un-acked) được phép tồn tại trên đường truyền (vì mục đích hiệu quả) trước khi chúng ta ngừng gửi thêm.</p>
</td>
          </tr><tr>
            <td>Socket</td>
            <td align="left"><p><code>Socket</code>. Một cơ chế của hệ điều hành được sử dụng để kết nối một tiến trình với <code>network stack</code>.</p>
</td>
          </tr><tr>
            <td>Soft State</td>
            <td align="left"><p><code>Soft State</code> (Trạng thái mềm). Khái niệm cho phép kiến thức được lưu trữ của bạn "hết hạn", với giả định rằng nó có thể đã thay đổi/không còn hợp lệ/v.v. Các hệ thống hoạt động theo <code>soft state</code> sẽ định kỳ "quên" những gì chúng biết và cần phải "học lại" nó – bằng cách yêu cầu lại thông tin, chờ đợi các thông điệp và thông tin mới, v.v. Các đề nghị <code>DHCP</code> có 'thời gian thuê', các mục <code>ARP</code> được lưu trong <code>cache</code> hết hạn, và các thông điệp định kỳ trong <code>Distance-Vector Routing</code> đều là những ví dụ về <code>soft-state</code>.</p>
</td>
          </tr><tr>
            <td>Spanning Tree Protocol</td>
            <td align="left"><p><code>Spanning Tree Protocol</code> (STP) (Giao thức Cây bao trùm). Một giao thức phân tán trong đó các <code>switch</code> gửi các thông điệp có định dạng (Y, d, X) từ nút X đề xuất Y làm gốc và quảng bá một khoảng cách là d đến Y. Giao thức này xác định nút có ID thấp nhất và xây dựng một <code>spanning tree</code> với nút đó làm gốc.</p>
</td>
          </tr><tr>
            <td>Split Horizon</td>
            <td align="left"><p><code>Split Horizon</code>. Cung cấp chức năng tương tự như <code>poison reverse</code>, nhưng thể hiện thông tin theo cách khác. <code>Split Horizon</code> được sử dụng trong bối cảnh cập nhật đầy đủ, và <code>router</code> không quảng bá bất kỳ tuyến đường nào đến đích X cho láng giềng mà nó sử dụng để đến đích X.</p>
</td>
          </tr><tr>
            <td>Statistical Multiplexing</td>
            <td align="left"><p><code>Statistical Multiplexing</code> (Ghép kênh thống kê). Tổng tốc độ tối đa của các luồng lớn hơn việc kết hợp các luồng và tìm tốc độ tối đa.</p>
</td>
          </tr><tr>
            <td>Subnet</td>
            <td align="left"><p><code>Subnet</code> (Mạng con). Trong lớp học này, chúng ta sử dụng thuật ngữ này để chỉ một phần của mạng được kết nối bằng L2 và chia sẻ cùng một địa chỉ mạng.</p>
</td>
          </tr><tr>
            <td>Time to Live (TTL)</td>
            <td align="left"><p><code>Time to Live</code> (TTL) (Thời gian sống). Trong IP, điều này đề cập đến số lượng chặng (hop) mà một <code>packet</code> có thể di chuyển trước khi bị loại bỏ, điều này hữu ích trong việc ngăn chặn các vòng lặp. Nói chung hơn, <code>TTL</code> đề cập đến thời gian cho đến khi một cái gì đó hết hạn (chẳng hạn như một mục được lưu trong <code>cache</code>).</p>
</td>
          </tr><tr>
            <td>Valid Routing State</td>
            <td align="left"><p><code>Valid Routing State</code> (Trạng thái định tuyến hợp lệ). Một trạng thái định tuyến là hợp lệ nếu và chỉ nếu không có vòng lặp và không có ngõ cụt (giả sử không có sự nhân bản <code>packet</code>). Nếu có sự nhân bản <code>packet</code>, thì điều này thay đổi thành việc ít nhất một bản sao không gặp ngõ cụt.</p>
</td>
          </tr><tr>
            <td>WAN</td>
            <td align="left"><p><code>WAN</code> (Wide Area Network - Mạng diện rộng). Thuật ngữ này có thể đề cập đến bất kỳ mạng L3 nào (tức là không chỉ là một mạng cục bộ), hoặc đến các mạng trải rộng trên các khoảng cách địa lý lớn (tức là không phải là một trung tâm dữ liệu).</p>
</td>
          </tr></tbody>
    </table>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
